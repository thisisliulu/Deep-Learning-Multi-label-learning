{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-TFmdX2msbog"
      },
      "outputs": [],
      "source": [
        "# Code to download file into Colaboratory:\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "id = '1ZImCbaRn01-HPhyA2rnQhabGXEOb_zJP'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('train.csv')  \n",
        "\n",
        "id = '1sS0ldxE0juPT0bCfLvInNV8wlYBVMa4P'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('test.csv')  \n",
        "\n",
        "id = '1s8sesFfPMJ9MSQ6ca5a8fDFZ7ML27s6o'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('data.zip')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJFnyV1bsen1",
        "outputId": "3878d3a4-aa8b-46f6-c2bb-b438368c7c40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "  inflating: data/15531.jpg          \n",
            "  inflating: __MACOSX/data/._15531.jpg  \n",
            "  inflating: data/12538.jpg          \n",
            "  inflating: __MACOSX/data/._12538.jpg  \n",
            "  inflating: data/25394.jpg          \n",
            "  inflating: __MACOSX/data/._25394.jpg  \n",
            "  inflating: data/35187.jpg          \n",
            "  inflating: __MACOSX/data/._35187.jpg  \n",
            "  inflating: data/7710.jpg           \n",
            "  inflating: __MACOSX/data/._7710.jpg  \n",
            "  inflating: data/8423.jpg           \n",
            "  inflating: __MACOSX/data/._8423.jpg  \n",
            "  inflating: data/15257.jpg          \n",
            "  inflating: __MACOSX/data/._15257.jpg  \n",
            "  inflating: data/34299.jpg          \n",
            "  inflating: __MACOSX/data/._34299.jpg  \n",
            "  inflating: data/14149.jpg          \n",
            "  inflating: __MACOSX/data/._14149.jpg  \n",
            "  inflating: data/32830.jpg          \n",
            "  inflating: __MACOSX/data/._32830.jpg  \n",
            "  inflating: data/13626.jpg          \n",
            "  inflating: __MACOSX/data/._13626.jpg  \n",
            "  inflating: data/1361.jpg           \n",
            "  inflating: __MACOSX/data/._1361.jpg  \n",
            "  inflating: data/39965.jpg          \n",
            "  inflating: __MACOSX/data/._39965.jpg  \n",
            "  inflating: data/16986.jpg          \n",
            "  inflating: __MACOSX/data/._16986.jpg  \n",
            "  inflating: data/2668.jpg           \n",
            "  inflating: __MACOSX/data/._2668.jpg  \n",
            "  inflating: data/27583.jpg          \n",
            "  inflating: __MACOSX/data/._27583.jpg  \n",
            "  inflating: data/17440.jpg          \n",
            "  inflating: __MACOSX/data/._17440.jpg  \n",
            "  inflating: data/18773.jpg          \n",
            "  inflating: __MACOSX/data/._18773.jpg  \n",
            "  inflating: data/37790.jpg          \n",
            "  inflating: __MACOSX/data/._37790.jpg  \n",
            "  inflating: data/5107.jpg           \n",
            "  inflating: __MACOSX/data/._5107.jpg  \n",
            "  inflating: data/26845.jpg          \n",
            "  inflating: __MACOSX/data/._26845.jpg  \n",
            "  inflating: data/28868.jpg          \n",
            "  inflating: __MACOSX/data/._28868.jpg  \n",
            "  inflating: data/4219.jpg           \n",
            "  inflating: __MACOSX/data/._4219.jpg  \n",
            "  inflating: data/3576.jpg           \n",
            "  inflating: __MACOSX/data/._3576.jpg  \n",
            "  inflating: data/37948.jpg          \n",
            "  inflating: __MACOSX/data/._37948.jpg  \n",
            "  inflating: data/11031.jpg          \n",
            "  inflating: __MACOSX/data/._11031.jpg  \n",
            "  inflating: data/2118.jpg           \n",
            "  inflating: __MACOSX/data/._2118.jpg  \n",
            "  inflating: data/17330.jpg          \n",
            "  inflating: __MACOSX/data/._17330.jpg  \n",
            "  inflating: data/18003.jpg          \n",
            "  inflating: __MACOSX/data/._18003.jpg  \n",
            "  inflating: data/5677.jpg           \n",
            "  inflating: __MACOSX/data/._5677.jpg  \n",
            "  inflating: data/11999.jpg          \n",
            "  inflating: __MACOSX/data/._11999.jpg  \n",
            "  inflating: data/21682.jpg          \n",
            "  inflating: __MACOSX/data/._21682.jpg  \n",
            "  inflating: data/30957.jpg          \n",
            "  inflating: __MACOSX/data/._30957.jpg  \n",
            "  inflating: data/4569.jpg           \n",
            "  inflating: __MACOSX/data/._4569.jpg  \n",
            "  inflating: data/3206.jpg           \n",
            "  inflating: __MACOSX/data/._3206.jpg  \n",
            "  inflating: data/31491.jpg          \n",
            "  inflating: __MACOSX/data/._31491.jpg  \n",
            "  inflating: data/11741.jpg          \n",
            "  inflating: __MACOSX/data/._11741.jpg  \n",
            "  inflating: data/12248.jpg          \n",
            "  inflating: __MACOSX/data/._12248.jpg  \n",
            "  inflating: data/32198.jpg          \n",
            "  inflating: __MACOSX/data/._32198.jpg  \n",
            "  inflating: data/24922.jpg          \n",
            "  inflating: __MACOSX/data/._24922.jpg  \n",
            "  inflating: data/7060.jpg           \n",
            "  inflating: __MACOSX/data/._7060.jpg  \n",
            "  inflating: data/8353.jpg           \n",
            "  inflating: __MACOSX/data/._8353.jpg  \n",
            "  inflating: data/15527.jpg          \n",
            "  inflating: __MACOSX/data/._15527.jpg  \n",
            "  inflating: data/14639.jpg          \n",
            "  inflating: __MACOSX/data/._14639.jpg  \n",
            "  inflating: data/23095.jpg          \n",
            "  inflating: __MACOSX/data/._23095.jpg  \n",
            "  inflating: data/13156.jpg          \n",
            "  inflating: __MACOSX/data/._13156.jpg  \n",
            "  inflating: data/185.jpg            \n",
            "  inflating: __MACOSX/data/._185.jpg  \n",
            "  inflating: data/1411.jpg           \n",
            "  inflating: __MACOSX/data/._1411.jpg  \n",
            "  inflating: data/33286.jpg          \n",
            "  inflating: __MACOSX/data/._33286.jpg  \n",
            "  inflating: data/13630.jpg          \n",
            "  inflating: __MACOSX/data/._13630.jpg  \n",
            "  inflating: data/1377.jpg           \n",
            "  inflating: __MACOSX/data/._1377.jpg  \n",
            "  inflating: data/6418.jpg           \n",
            "  inflating: __MACOSX/data/._6418.jpg  \n",
            "  inflating: data/32826.jpg          \n",
            "  inflating: __MACOSX/data/._32826.jpg  \n",
            "  inflating: data/35191.jpg          \n",
            "  inflating: __MACOSX/data/._35191.jpg  \n",
            "  inflating: data/7706.jpg           \n",
            "  inflating: __MACOSX/data/._7706.jpg  \n",
            "  inflating: data/8435.jpg           \n",
            "  inflating: __MACOSX/data/._8435.jpg  \n",
            "  inflating: data/15241.jpg          \n",
            "  inflating: __MACOSX/data/._15241.jpg  \n",
            "  inflating: data/25382.jpg          \n",
            "  inflating: __MACOSX/data/._25382.jpg  \n",
            "  inflating: data/3560.jpg           \n",
            "  inflating: __MACOSX/data/._3560.jpg  \n",
            "  inflating: data/11027.jpg          \n",
            "  inflating: __MACOSX/data/._11027.jpg  \n",
            "  inflating: data/16748.jpg          \n",
            "  inflating: __MACOSX/data/._16748.jpg  \n",
            "  inflating: data/36498.jpg          \n",
            "  inflating: __MACOSX/data/._36498.jpg  \n",
            "  inflating: data/17456.jpg          \n",
            "  inflating: __MACOSX/data/._17456.jpg  \n",
            "  inflating: data/18765.jpg          \n",
            "  inflating: __MACOSX/data/._18765.jpg  \n",
            "  inflating: data/37786.jpg          \n",
            "  inflating: __MACOSX/data/._37786.jpg  \n",
            "  inflating: data/5111.jpg           \n",
            "  inflating: __MACOSX/data/._5111.jpg  \n",
            "  inflating: data/26853.jpg          \n",
            "  inflating: __MACOSX/data/._26853.jpg  \n",
            "  inflating: data/39973.jpg          \n",
            "  inflating: __MACOSX/data/._39973.jpg  \n",
            "  inflating: data/16990.jpg          \n",
            "  inflating: __MACOSX/data/._16990.jpg  \n",
            "  inflating: data/10339.jpg          \n",
            "  inflating: __MACOSX/data/._10339.jpg  \n",
            "  inflating: data/27595.jpg          \n",
            "  inflating: __MACOSX/data/._27595.jpg  \n",
            "  inflating: data/3574.jpg           \n",
            "  inflating: __MACOSX/data/._3574.jpg  \n",
            "  inflating: data/11033.jpg          \n",
            "  inflating: __MACOSX/data/._11033.jpg  \n",
            "  inflating: data/17442.jpg          \n",
            "  inflating: __MACOSX/data/._17442.jpg  \n",
            "  inflating: data/26847.jpg          \n",
            "  inflating: __MACOSX/data/._26847.jpg  \n",
            "  inflating: data/5105.jpg           \n",
            "  inflating: __MACOSX/data/._5105.jpg  \n",
            "  inflating: data/37792.jpg          \n",
            "  inflating: __MACOSX/data/._37792.jpg  \n",
            "  inflating: data/18771.jpg          \n",
            "  inflating: __MACOSX/data/._18771.jpg  \n",
            "  inflating: data/16984.jpg          \n",
            "  inflating: __MACOSX/data/._16984.jpg  \n",
            "  inflating: data/39967.jpg          \n",
            "  inflating: __MACOSX/data/._39967.jpg  \n",
            "  inflating: data/27581.jpg          \n",
            "  inflating: __MACOSX/data/._27581.jpg  \n",
            "  inflating: data/13624.jpg          \n",
            "  inflating: __MACOSX/data/._13624.jpg  \n",
            "  inflating: data/24088.jpg          \n",
            "  inflating: __MACOSX/data/._24088.jpg  \n",
            "  inflating: data/1363.jpg           \n",
            "  inflating: __MACOSX/data/._1363.jpg  \n",
            "  inflating: data/32832.jpg          \n",
            "  inflating: __MACOSX/data/._32832.jpg  \n",
            "  inflating: data/7712.jpg           \n",
            "  inflating: __MACOSX/data/._7712.jpg  \n",
            "  inflating: data/35185.jpg          \n",
            "  inflating: __MACOSX/data/._35185.jpg  \n",
            "  inflating: data/15255.jpg          \n",
            "  inflating: __MACOSX/data/._15255.jpg  \n",
            "  inflating: data/8421.jpg           \n",
            "  inflating: __MACOSX/data/._8421.jpg  \n",
            "  inflating: data/25396.jpg          \n",
            "  inflating: __MACOSX/data/._25396.jpg  \n",
            "  inflating: data/7074.jpg           \n",
            "  inflating: __MACOSX/data/._7074.jpg  \n",
            "  inflating: data/24936.jpg          \n",
            "  inflating: __MACOSX/data/._24936.jpg  \n",
            "  inflating: data/15533.jpg          \n",
            "  inflating: __MACOSX/data/._15533.jpg  \n",
            "  inflating: data/8347.jpg           \n",
            "  inflating: __MACOSX/data/._8347.jpg  \n",
            "  inflating: data/23081.jpg          \n",
            "  inflating: __MACOSX/data/._23081.jpg  \n",
            "  inflating: data/9059.jpg           \n",
            "  inflating: __MACOSX/data/._9059.jpg  \n",
            "  inflating: data/13142.jpg          \n",
            "  inflating: __MACOSX/data/._13142.jpg  \n",
            "  inflating: data/33292.jpg          \n",
            "  inflating: __MACOSX/data/._33292.jpg  \n",
            "  inflating: data/1405.jpg           \n",
            "  inflating: __MACOSX/data/._1405.jpg  \n",
            "  inflating: data/191.jpg            \n",
            "  inflating: __MACOSX/data/._191.jpg  \n",
            "  inflating: data/17324.jpg          \n",
            "  inflating: __MACOSX/data/._17324.jpg  \n",
            "  inflating: data/20588.jpg          \n",
            "  inflating: __MACOSX/data/._20588.jpg  \n",
            "  inflating: data/5663.jpg           \n",
            "  inflating: __MACOSX/data/._5663.jpg  \n",
            "  inflating: data/18017.jpg          \n",
            "  inflating: __MACOSX/data/._18017.jpg  \n",
            "  inflating: data/30943.jpg          \n",
            "  inflating: __MACOSX/data/._30943.jpg  \n",
            "  inflating: data/21696.jpg          \n",
            "  inflating: __MACOSX/data/._21696.jpg  \n",
            "  inflating: data/19309.jpg          \n",
            "  inflating: __MACOSX/data/._19309.jpg  \n",
            "  inflating: data/31485.jpg          \n",
            "  inflating: __MACOSX/data/._31485.jpg  \n",
            "  inflating: data/3212.jpg           \n",
            "  inflating: __MACOSX/data/._3212.jpg  \n",
            "  inflating: data/11755.jpg          \n",
            "  inflating: __MACOSX/data/._11755.jpg  \n",
            "  inflating: data/12274.jpg          \n",
            "  inflating: __MACOSX/data/._12274.jpg  \n",
            "  inflating: data/14605.jpg          \n",
            "  inflating: __MACOSX/data/._14605.jpg  \n",
            "  inflating: data/9071.jpg           \n",
            "  inflating: __MACOSX/data/._9071.jpg  \n",
            "  inflating: data/6342.jpg           \n",
            "  inflating: __MACOSX/data/._6342.jpg  \n",
            "  inflating: data/35813.jpg          \n",
            "  inflating: __MACOSX/data/._35813.jpg  \n",
            "  inflating: data/10463.jpg          \n",
            "  inflating: __MACOSX/data/._10463.jpg  \n",
            "  inflating: data/2124.jpg           \n",
            "  inflating: __MACOSX/data/._2124.jpg  \n",
            "  inflating: data/21866.jpg          \n",
            "  inflating: __MACOSX/data/._21866.jpg  \n",
            "  inflating: data/4555.jpg           \n",
            "  inflating: __MACOSX/data/._4555.jpg  \n",
            "  inflating: data/19321.jpg          \n",
            "  inflating: __MACOSX/data/._19321.jpg  \n",
            "  inflating: data/16012.jpg          \n",
            "  inflating: __MACOSX/data/._16012.jpg  \n",
            "  inflating: data/5893.jpg           \n",
            "  inflating: __MACOSX/data/._5893.jpg  \n",
            "  inflating: data/37962.jpg          \n",
            "  inflating: __MACOSX/data/._37962.jpg  \n",
            "  inflating: data/18981.jpg          \n",
            "  inflating: __MACOSX/data/._18981.jpg  \n",
            "  inflating: data/29584.jpg          \n",
            "  inflating: __MACOSX/data/._29584.jpg  \n",
            "  inflating: data/4233.jpg           \n",
            "  inflating: __MACOSX/data/._4233.jpg  \n",
            "  inflating: data/19447.jpg          \n",
            "  inflating: __MACOSX/data/._19447.jpg  \n",
            "  inflating: data/28842.jpg          \n",
            "  inflating: __MACOSX/data/._28842.jpg  \n",
            "  inflating: data/16774.jpg          \n",
            "  inflating: __MACOSX/data/._16774.jpg  \n",
            "  inflating: data/39797.jpg          \n",
            "  inflating: __MACOSX/data/._39797.jpg  \n",
            "  inflating: data/18759.jpg          \n",
            "  inflating: __MACOSX/data/._18759.jpg  \n",
            "  inflating: data/38489.jpg          \n",
            "  inflating: __MACOSX/data/._38489.jpg  \n",
            "  inflating: data/10305.jpg          \n",
            "  inflating: __MACOSX/data/._10305.jpg  \n",
            "  inflating: data/2642.jpg           \n",
            "  inflating: __MACOSX/data/._2642.jpg  \n",
            "  inflating: data/14163.jpg          \n",
            "  inflating: __MACOSX/data/._14163.jpg  \n",
            "  inflating: data/9717.jpg           \n",
            "  inflating: __MACOSX/data/._9717.jpg  \n",
            "  inflating: data/47.jpg             \n",
            "  inflating: __MACOSX/data/._47.jpg  \n",
            "  inflating: data/6424.jpg           \n",
            "  inflating: __MACOSX/data/._6424.jpg  \n",
            "  inflating: data/807.jpg            \n",
            "  inflating: __MACOSX/data/._807.jpg  \n",
            "  inflating: data/8409.jpg           \n",
            "  inflating: __MACOSX/data/._8409.jpg  \n",
            "  inflating: data/23917.jpg          \n",
            "  inflating: __MACOSX/data/._23917.jpg  \n",
            "  inflating: data/12512.jpg          \n",
            "  inflating: __MACOSX/data/._12512.jpg  \n",
            "  inflating: data/13618.jpg          \n",
            "  inflating: __MACOSX/data/._13618.jpg  \n",
            "  inflating: data/9703.jpg           \n",
            "  inflating: __MACOSX/data/._9703.jpg  \n",
            "  inflating: data/14177.jpg          \n",
            "  inflating: __MACOSX/data/._14177.jpg  \n",
            "  inflating: data/6430.jpg           \n",
            "  inflating: __MACOSX/data/._6430.jpg  \n",
            "  inflating: data/53.jpg             \n",
            "  inflating: __MACOSX/data/._53.jpg  \n",
            "  inflating: data/15269.jpg          \n",
            "  inflating: __MACOSX/data/._15269.jpg  \n",
            "  inflating: data/813.jpg            \n",
            "  inflating: __MACOSX/data/._813.jpg  \n",
            "  inflating: data/23903.jpg          \n",
            "  inflating: __MACOSX/data/._23903.jpg  \n",
            "  inflating: data/12506.jpg          \n",
            "  inflating: __MACOSX/data/._12506.jpg  \n",
            "  inflating: data/18995.jpg          \n",
            "  inflating: __MACOSX/data/._18995.jpg  \n",
            "  inflating: data/37976.jpg          \n",
            "  inflating: __MACOSX/data/._37976.jpg  \n",
            "  inflating: data/29590.jpg          \n",
            "  inflating: __MACOSX/data/._29590.jpg  \n",
            "  inflating: data/3548.jpg           \n",
            "  inflating: __MACOSX/data/._3548.jpg  \n",
            "  inflating: data/19453.jpg          \n",
            "  inflating: __MACOSX/data/._19453.jpg  \n",
            "  inflating: data/4227.jpg           \n",
            "  inflating: __MACOSX/data/._4227.jpg  \n",
            "  inflating: data/39783.jpg          \n",
            "  inflating: __MACOSX/data/._39783.jpg  \n",
            "  inflating: data/16760.jpg          \n",
            "  inflating: __MACOSX/data/._16760.jpg  \n",
            "  inflating: data/28856.jpg          \n",
            "  inflating: __MACOSX/data/._28856.jpg  \n",
            "  inflating: data/5139.jpg           \n",
            "  inflating: __MACOSX/data/._5139.jpg  \n",
            "  inflating: data/10311.jpg          \n",
            "  inflating: __MACOSX/data/._10311.jpg  \n",
            "  inflating: data/2656.jpg           \n",
            "  inflating: __MACOSX/data/._2656.jpg  \n",
            "  inflating: data/10477.jpg          \n",
            "  inflating: __MACOSX/data/._10477.jpg  \n",
            "  inflating: data/21872.jpg          \n",
            "  inflating: __MACOSX/data/._21872.jpg  \n",
            "  inflating: data/2130.jpg           \n",
            "  inflating: __MACOSX/data/._2130.jpg  \n",
            "  inflating: data/17318.jpg          \n",
            "  inflating: __MACOSX/data/._17318.jpg  \n",
            "  inflating: data/19335.jpg          \n",
            "  inflating: __MACOSX/data/._19335.jpg  \n",
            "  inflating: data/4541.jpg           \n",
            "  inflating: __MACOSX/data/._4541.jpg  \n",
            "  inflating: data/16006.jpg          \n",
            "  inflating: __MACOSX/data/._16006.jpg  \n",
            "  inflating: data/11769.jpg          \n",
            "  inflating: __MACOSX/data/._11769.jpg  \n",
            "  inflating: data/1.jpg              \n",
            "  inflating: __MACOSX/data/._1.jpg   \n",
            "  inflating: data/5887.jpg           \n",
            "  inflating: __MACOSX/data/._5887.jpg  \n",
            "  inflating: data/12260.jpg          \n",
            "  inflating: __MACOSX/data/._12260.jpg  \n",
            "  inflating: data/7048.jpg           \n",
            "  inflating: __MACOSX/data/._7048.jpg  \n",
            "  inflating: data/9065.jpg           \n",
            "  inflating: __MACOSX/data/._9065.jpg  \n",
            "  inflating: data/14611.jpg          \n",
            "  inflating: __MACOSX/data/._14611.jpg  \n",
            "  inflating: data/6356.jpg           \n",
            "  inflating: __MACOSX/data/._6356.jpg  \n",
            "  inflating: data/1439.jpg           \n",
            "  inflating: __MACOSX/data/._1439.jpg  \n",
            "  inflating: data/35807.jpg          \n",
            "  inflating: __MACOSX/data/._35807.jpg  \n",
            "  inflating: data/23056.jpg          \n",
            "  inflating: __MACOSX/data/._23056.jpg  \n",
            "  inflating: data/13195.jpg          \n",
            "  inflating: __MACOSX/data/._13195.jpg  \n",
            "  inflating: data/24739.jpg          \n",
            "  inflating: __MACOSX/data/._24739.jpg  \n",
            "  inflating: data/146.jpg            \n",
            "  inflating: __MACOSX/data/._146.jpg  \n",
            "  inflating: data/33245.jpg          \n",
            "  inflating: __MACOSX/data/._33245.jpg  \n",
            "  inflating: data/25427.jpg          \n",
            "  inflating: __MACOSX/data/._25427.jpg  \n",
            "  inflating: data/14822.jpg          \n",
            "  inflating: __MACOSX/data/._14822.jpg  \n",
            "  inflating: data/35634.jpg          \n",
            "  inflating: __MACOSX/data/._35634.jpg  \n",
            "  inflating: data/8390.jpg           \n",
            "  inflating: __MACOSX/data/._8390.jpg  \n",
            "  inflating: data/22348.jpg          \n",
            "  inflating: __MACOSX/data/._22348.jpg  \n",
            "  inflating: data/21641.jpg          \n",
            "  inflating: __MACOSX/data/._21641.jpg  \n",
            "  inflating: data/30994.jpg          \n",
            "  inflating: __MACOSX/data/._30994.jpg  \n",
            "  inflating: data/31452.jpg          \n",
            "  inflating: __MACOSX/data/._31452.jpg  \n",
            "  inflating: data/11782.jpg          \n",
            "  inflating: __MACOSX/data/._11782.jpg  \n",
            "  inflating: data/21899.jpg          \n",
            "  inflating: __MACOSX/data/._21899.jpg  \n",
            "  inflating: data/28103.jpg          \n",
            "  inflating: __MACOSX/data/._28103.jpg  \n",
            "  inflating: data/27230.jpg          \n",
            "  inflating: __MACOSX/data/._27230.jpg  \n",
            "  inflating: data/38310.jpg          \n",
            "  inflating: __MACOSX/data/._38310.jpg  \n",
            "  inflating: data/37023.jpg          \n",
            "  inflating: __MACOSX/data/._37023.jpg  \n",
            "  inflating: data/17495.jpg          \n",
            "  inflating: __MACOSX/data/._17495.jpg  \n",
            "  inflating: data/38476.jpg          \n",
            "  inflating: __MACOSX/data/._38476.jpg  \n",
            "  inflating: data/20239.jpg          \n",
            "  inflating: __MACOSX/data/._20239.jpg  \n",
            "  inflating: data/37745.jpg          \n",
            "  inflating: __MACOSX/data/._37745.jpg  \n",
            "  inflating: data/26890.jpg          \n",
            "  inflating: __MACOSX/data/._26890.jpg  \n",
            "  inflating: data/16953.jpg          \n",
            "  inflating: __MACOSX/data/._16953.jpg  \n",
            "  inflating: data/28665.jpg          \n",
            "  inflating: __MACOSX/data/._28665.jpg  \n",
            "  inflating: data/27556.jpg          \n",
            "  inflating: __MACOSX/data/._27556.jpg  \n",
            "  inflating: data/31334.jpg          \n",
            "  inflating: __MACOSX/data/._31334.jpg  \n",
            "  inflating: data/26648.jpg          \n",
            "  inflating: __MACOSX/data/._26648.jpg  \n",
            "  inflating: data/2865.jpg           \n",
            "  inflating: __MACOSX/data/._2865.jpg  \n",
            "  inflating: data/21127.jpg          \n",
            "  inflating: __MACOSX/data/._21127.jpg  \n",
            "  inflating: data/39768.jpg          \n",
            "  inflating: __MACOSX/data/._39768.jpg  \n",
            "  inflating: data/35152.jpg          \n",
            "  inflating: __MACOSX/data/._35152.jpg  \n",
            "  inflating: data/15282.jpg          \n",
            "  inflating: __MACOSX/data/._15282.jpg  \n",
            "  inflating: data/25341.jpg          \n",
            "  inflating: __MACOSX/data/._25341.jpg  \n",
            "  inflating: data/9930.jpg           \n",
            "  inflating: __MACOSX/data/._9930.jpg  \n",
            "  inflating: data/33523.jpg          \n",
            "  inflating: __MACOSX/data/._33523.jpg  \n",
            "  inflating: data/620.jpg            \n",
            "  inflating: __MACOSX/data/._620.jpg  \n",
            "  inflating: data/23730.jpg          \n",
            "  inflating: __MACOSX/data/._23730.jpg  \n",
            "  inflating: data/35146.jpg          \n",
            "  inflating: __MACOSX/data/._35146.jpg  \n",
            "  inflating: data/15296.jpg          \n",
            "  inflating: __MACOSX/data/._15296.jpg  \n",
            "  inflating: data/25355.jpg          \n",
            "  inflating: __MACOSX/data/._25355.jpg  \n",
            "  inflating: data/9924.jpg           \n",
            "  inflating: __MACOSX/data/._9924.jpg  \n",
            "  inflating: data/32629.jpg          \n",
            "  inflating: __MACOSX/data/._32629.jpg  \n",
            "  inflating: data/7909.jpg           \n",
            "  inflating: __MACOSX/data/._7909.jpg  \n",
            "  inflating: data/634.jpg            \n",
            "  inflating: __MACOSX/data/._634.jpg  \n",
            "  inflating: data/33537.jpg          \n",
            "  inflating: __MACOSX/data/._33537.jpg  \n",
            "  inflating: data/34258.jpg          \n",
            "  inflating: __MACOSX/data/._34258.jpg  \n",
            "  inflating: data/14188.jpg          \n",
            "  inflating: __MACOSX/data/._14188.jpg  \n",
            "  inflating: data/23724.jpg          \n",
            "  inflating: __MACOSX/data/._23724.jpg  \n",
            "  inflating: data/38462.jpg          \n",
            "  inflating: __MACOSX/data/._38462.jpg  \n",
            "  inflating: data/17481.jpg          \n",
            "  inflating: __MACOSX/data/._17481.jpg  \n",
            "  inflating: data/26884.jpg          \n",
            "  inflating: __MACOSX/data/._26884.jpg  \n",
            "  inflating: data/37751.jpg          \n",
            "  inflating: __MACOSX/data/._37751.jpg  \n",
            "  inflating: data/28671.jpg          \n",
            "  inflating: __MACOSX/data/._28671.jpg  \n",
            "  inflating: data/16947.jpg          \n",
            "  inflating: __MACOSX/data/._16947.jpg  \n",
            "  inflating: data/27542.jpg          \n",
            "  inflating: __MACOSX/data/._27542.jpg  \n",
            "  inflating: data/31320.jpg          \n",
            "  inflating: __MACOSX/data/._31320.jpg  \n",
            "  inflating: data/37989.jpg          \n",
            "  inflating: __MACOSX/data/._37989.jpg  \n",
            "  inflating: data/21133.jpg          \n",
            "  inflating: __MACOSX/data/._21133.jpg  \n",
            "  inflating: data/2871.jpg           \n",
            "  inflating: __MACOSX/data/._2871.jpg  \n",
            "  inflating: data/30980.jpg          \n",
            "  inflating: __MACOSX/data/._30980.jpg  \n",
            "  inflating: data/21655.jpg          \n",
            "  inflating: __MACOSX/data/._21655.jpg  \n",
            "  inflating: data/36329.jpg          \n",
            "  inflating: __MACOSX/data/._36329.jpg  \n",
            "  inflating: data/31446.jpg          \n",
            "  inflating: __MACOSX/data/._31446.jpg  \n",
            "  inflating: data/29209.jpg          \n",
            "  inflating: __MACOSX/data/._29209.jpg  \n",
            "  inflating: data/5878.jpg           \n",
            "  inflating: __MACOSX/data/._5878.jpg  \n",
            "  inflating: data/11796.jpg          \n",
            "  inflating: __MACOSX/data/._11796.jpg  \n",
            "  inflating: data/28117.jpg          \n",
            "  inflating: __MACOSX/data/._28117.jpg  \n",
            "  inflating: data/30758.jpg          \n",
            "  inflating: __MACOSX/data/._30758.jpg  \n",
            "  inflating: data/10488.jpg          \n",
            "  inflating: __MACOSX/data/._10488.jpg  \n",
            "  inflating: data/27224.jpg          \n",
            "  inflating: __MACOSX/data/._27224.jpg  \n",
            "  inflating: data/38304.jpg          \n",
            "  inflating: __MACOSX/data/._38304.jpg  \n",
            "  inflating: data/37037.jpg          \n",
            "  inflating: __MACOSX/data/._37037.jpg  \n",
            "  inflating: data/23042.jpg          \n",
            "  inflating: __MACOSX/data/._23042.jpg  \n",
            "  inflating: data/13181.jpg          \n",
            "  inflating: __MACOSX/data/._13181.jpg  \n",
            "  inflating: data/33251.jpg          \n",
            "  inflating: __MACOSX/data/._33251.jpg  \n",
            "  inflating: data/152.jpg            \n",
            "  inflating: __MACOSX/data/._152.jpg  \n",
            "  inflating: data/25433.jpg          \n",
            "  inflating: __MACOSX/data/._25433.jpg  \n",
            "  inflating: data/14836.jpg          \n",
            "  inflating: __MACOSX/data/._14836.jpg  \n",
            "  inflating: data/35620.jpg          \n",
            "  inflating: __MACOSX/data/._35620.jpg  \n",
            "  inflating: data/8384.jpg           \n",
            "  inflating: __MACOSX/data/._8384.jpg  \n",
            "  inflating: data/4596.jpg           \n",
            "  inflating: __MACOSX/data/._4596.jpg  \n",
            "  inflating: data/36301.jpg          \n",
            "  inflating: __MACOSX/data/._36301.jpg  \n",
            "  inflating: data/39032.jpg          \n",
            "  inflating: __MACOSX/data/._39032.jpg  \n",
            "  inflating: data/5850.jpg           \n",
            "  inflating: __MACOSX/data/._5850.jpg  \n",
            "  inflating: data/26112.jpg          \n",
            "  inflating: __MACOSX/data/._26112.jpg  \n",
            "  inflating: data/29221.jpg          \n",
            "  inflating: __MACOSX/data/._29221.jpg  \n",
            "  inflating: data/30770.jpg          \n",
            "  inflating: __MACOSX/data/._30770.jpg  \n",
            "  inflating: data/11966.jpg          \n",
            "  inflating: __MACOSX/data/._11966.jpg  \n",
            "  inflating: data/5688.jpg           \n",
            "  inflating: __MACOSX/data/._5688.jpg  \n",
            "  inflating: data/20563.jpg          \n",
            "  inflating: __MACOSX/data/._20563.jpg  \n",
            "  inflating: data/6381.jpg           \n",
            "  inflating: __MACOSX/data/._6381.jpg  \n",
            "  inflating: data/34516.jpg          \n",
            "  inflating: __MACOSX/data/._34516.jpg  \n",
            "  inflating: data/33279.jpg          \n",
            "  inflating: __MACOSX/data/._33279.jpg  \n",
            "  inflating: data/24705.jpg          \n",
            "  inflating: __MACOSX/data/._24705.jpg  \n",
            "  inflating: data/32167.jpg          \n",
            "  inflating: __MACOSX/data/._32167.jpg  \n",
            "  inflating: data/22374.jpg          \n",
            "  inflating: __MACOSX/data/._22374.jpg  \n",
            "  inflating: data/35608.jpg          \n",
            "  inflating: __MACOSX/data/._35608.jpg  \n",
            "  inflating: data/22412.jpg          \n",
            "  inflating: __MACOSX/data/._22412.jpg  \n",
            "  inflating: data/13817.jpg          \n",
            "  inflating: __MACOSX/data/._13817.jpg  \n",
            "  inflating: data/32601.jpg          \n",
            "  inflating: __MACOSX/data/._32601.jpg  \n",
            "  inflating: data/1388.jpg           \n",
            "  inflating: __MACOSX/data/._1388.jpg  \n",
            "  inflating: data/24063.jpg          \n",
            "  inflating: __MACOSX/data/._24063.jpg  \n",
            "  inflating: data/7921.jpg           \n",
            "  inflating: __MACOSX/data/._7921.jpg  \n",
            "  inflating: data/34270.jpg          \n",
            "  inflating: __MACOSX/data/._34270.jpg  \n",
            "  inflating: data/84.jpg             \n",
            "  inflating: __MACOSX/data/._84.jpg  \n",
            "  inflating: data/37779.jpg          \n",
            "  inflating: __MACOSX/data/._37779.jpg  \n",
            "  inflating: data/20205.jpg          \n",
            "  inflating: __MACOSX/data/._20205.jpg  \n",
            "  inflating: data/30016.jpg          \n",
            "  inflating: __MACOSX/data/._30016.jpg  \n",
            "  inflating: data/2681.jpg           \n",
            "  inflating: __MACOSX/data/._2681.jpg  \n",
            "  inflating: data/28659.jpg          \n",
            "  inflating: __MACOSX/data/._28659.jpg  \n",
            "  inflating: data/26674.jpg          \n",
            "  inflating: __MACOSX/data/._26674.jpg  \n",
            "  inflating: data/18942.jpg          \n",
            "  inflating: __MACOSX/data/._18942.jpg  \n",
            "  inflating: data/29547.jpg          \n",
            "  inflating: __MACOSX/data/._29547.jpg  \n",
            "  inflating: data/31308.jpg          \n",
            "  inflating: __MACOSX/data/._31308.jpg  \n",
            "  inflating: data/19484.jpg          \n",
            "  inflating: __MACOSX/data/._19484.jpg  \n",
            "  inflating: data/36467.jpg          \n",
            "  inflating: __MACOSX/data/._36467.jpg  \n",
            "  inflating: data/2859.jpg           \n",
            "  inflating: __MACOSX/data/._2859.jpg  \n",
            "  inflating: data/28881.jpg          \n",
            "  inflating: __MACOSX/data/._28881.jpg  \n",
            "  inflating: data/39754.jpg          \n",
            "  inflating: __MACOSX/data/._39754.jpg  \n",
            "  inflating: data/20211.jpg          \n",
            "  inflating: __MACOSX/data/._20211.jpg  \n",
            "  inflating: data/39998.jpg          \n",
            "  inflating: __MACOSX/data/._39998.jpg  \n",
            "  inflating: data/2695.jpg           \n",
            "  inflating: __MACOSX/data/._2695.jpg  \n",
            "  inflating: data/30002.jpg          \n",
            "  inflating: __MACOSX/data/._30002.jpg  \n",
            "  inflating: data/18956.jpg          \n",
            "  inflating: __MACOSX/data/._18956.jpg  \n",
            "  inflating: data/26660.jpg          \n",
            "  inflating: __MACOSX/data/._26660.jpg  \n",
            "  inflating: data/29553.jpg          \n",
            "  inflating: __MACOSX/data/._29553.jpg  \n",
            "  inflating: data/36473.jpg          \n",
            "  inflating: __MACOSX/data/._36473.jpg  \n",
            "  inflating: data/19490.jpg          \n",
            "  inflating: __MACOSX/data/._19490.jpg  \n",
            "  inflating: data/39740.jpg          \n",
            "  inflating: __MACOSX/data/._39740.jpg  \n",
            "  inflating: data/28895.jpg          \n",
            "  inflating: __MACOSX/data/._28895.jpg  \n",
            "  inflating: data/22406.jpg          \n",
            "  inflating: __MACOSX/data/._22406.jpg  \n",
            "  inflating: data/13803.jpg          \n",
            "  inflating: __MACOSX/data/._13803.jpg  \n",
            "  inflating: data/9918.jpg           \n",
            "  inflating: __MACOSX/data/._9918.jpg  \n",
            "  inflating: data/32615.jpg          \n",
            "  inflating: __MACOSX/data/._32615.jpg  \n",
            "  inflating: data/25369.jpg          \n",
            "  inflating: __MACOSX/data/._25369.jpg  \n",
            "  inflating: data/608.jpg            \n",
            "  inflating: __MACOSX/data/._608.jpg  \n",
            "  inflating: data/7935.jpg           \n",
            "  inflating: __MACOSX/data/._7935.jpg  \n",
            "  inflating: data/24077.jpg          \n",
            "  inflating: __MACOSX/data/._24077.jpg  \n",
            "  inflating: data/23718.jpg          \n",
            "  inflating: __MACOSX/data/._23718.jpg  \n",
            "  inflating: data/90.jpg             \n",
            "  inflating: __MACOSX/data/._90.jpg  \n",
            "  inflating: data/34264.jpg          \n",
            "  inflating: __MACOSX/data/._34264.jpg  \n",
            "  inflating: data/34502.jpg          \n",
            "  inflating: __MACOSX/data/._34502.jpg  \n",
            "  inflating: data/6395.jpg           \n",
            "  inflating: __MACOSX/data/._6395.jpg  \n",
            "  inflating: data/24711.jpg          \n",
            "  inflating: __MACOSX/data/._24711.jpg  \n",
            "  inflating: data/32173.jpg          \n",
            "  inflating: __MACOSX/data/._32173.jpg  \n",
            "  inflating: data/22360.jpg          \n",
            "  inflating: __MACOSX/data/._22360.jpg  \n",
            "  inflating: data/36315.jpg          \n",
            "  inflating: __MACOSX/data/._36315.jpg  \n",
            "  inflating: data/4582.jpg           \n",
            "  inflating: __MACOSX/data/._4582.jpg  \n",
            "  inflating: data/39026.jpg          \n",
            "  inflating: __MACOSX/data/._39026.jpg  \n",
            "  inflating: data/21669.jpg          \n",
            "  inflating: __MACOSX/data/._21669.jpg  \n",
            "  inflating: data/26106.jpg          \n",
            "  inflating: __MACOSX/data/._26106.jpg  \n",
            "  inflating: data/5844.jpg           \n",
            "  inflating: __MACOSX/data/._5844.jpg  \n",
            "  inflating: data/29235.jpg          \n",
            "  inflating: __MACOSX/data/._29235.jpg  \n",
            "  inflating: data/27218.jpg          \n",
            "  inflating: __MACOSX/data/._27218.jpg  \n",
            "  inflating: data/30764.jpg          \n",
            "  inflating: __MACOSX/data/._30764.jpg  \n",
            "  inflating: data/11972.jpg          \n",
            "  inflating: __MACOSX/data/._11972.jpg  \n",
            "  inflating: data/20577.jpg          \n",
            "  inflating: __MACOSX/data/._20577.jpg  \n",
            "  inflating: data/38338.jpg          \n",
            "  inflating: __MACOSX/data/._38338.jpg  \n",
            "  inflating: data/27797.jpg          \n",
            "  inflating: __MACOSX/data/._27797.jpg  \n",
            "  inflating: data/36842.jpg          \n",
            "  inflating: __MACOSX/data/._36842.jpg  \n",
            "  inflating: data/18567.jpg          \n",
            "  inflating: __MACOSX/data/._18567.jpg  \n",
            "  inflating: data/37584.jpg          \n",
            "  inflating: __MACOSX/data/._37584.jpg  \n",
            "  inflating: data/5313.jpg           \n",
            "  inflating: __MACOSX/data/._5313.jpg  \n",
            "  inflating: data/29962.jpg          \n",
            "  inflating: __MACOSX/data/._29962.jpg  \n",
            "  inflating: data/17654.jpg          \n",
            "  inflating: __MACOSX/data/._17654.jpg  \n",
            "  inflating: data/19679.jpg          \n",
            "  inflating: __MACOSX/data/._19679.jpg  \n",
            "  inflating: data/11225.jpg          \n",
            "  inflating: __MACOSX/data/._11225.jpg  \n",
            "  inflating: data/26489.jpg          \n",
            "  inflating: __MACOSX/data/._26489.jpg  \n",
            "  inflating: data/3762.jpg           \n",
            "  inflating: __MACOSX/data/._3762.jpg  \n",
            "  inflating: data/25180.jpg          \n",
            "  inflating: __MACOSX/data/._25180.jpg  \n",
            "  inflating: data/8637.jpg           \n",
            "  inflating: __MACOSX/data/._8637.jpg  \n",
            "  inflating: data/15043.jpg          \n",
            "  inflating: __MACOSX/data/._15043.jpg  \n",
            "  inflating: data/35393.jpg          \n",
            "  inflating: __MACOSX/data/._35393.jpg  \n",
            "  inflating: data/7504.jpg           \n",
            "  inflating: __MACOSX/data/._7504.jpg  \n",
            "  inflating: data/9529.jpg           \n",
            "  inflating: __MACOSX/data/._9529.jpg  \n",
            "  inflating: data/22837.jpg          \n",
            "  inflating: __MACOSX/data/._22837.jpg  \n",
            "  inflating: data/1175.jpg           \n",
            "  inflating: __MACOSX/data/._1175.jpg  \n",
            "  inflating: data/13432.jpg          \n",
            "  inflating: __MACOSX/data/._13432.jpg  \n",
            "  inflating: data/1613.jpg           \n",
            "  inflating: __MACOSX/data/._1613.jpg  \n",
            "  inflating: data/33084.jpg          \n",
            "  inflating: __MACOSX/data/._33084.jpg  \n",
            "  inflating: data/387.jpg            \n",
            "  inflating: __MACOSX/data/._387.jpg  \n",
            "  inflating: data/13354.jpg          \n",
            "  inflating: __MACOSX/data/._13354.jpg  \n",
            "  inflating: data/23297.jpg          \n",
            "  inflating: __MACOSX/data/._23297.jpg  \n",
            "  inflating: data/8151.jpg           \n",
            "  inflating: __MACOSX/data/._8151.jpg  \n",
            "  inflating: data/15725.jpg          \n",
            "  inflating: __MACOSX/data/._15725.jpg  \n",
            "  inflating: data/22189.jpg          \n",
            "  inflating: __MACOSX/data/._22189.jpg  \n",
            "  inflating: data/7262.jpg           \n",
            "  inflating: __MACOSX/data/._7262.jpg  \n",
            "  inflating: data/34933.jpg          \n",
            "  inflating: __MACOSX/data/._34933.jpg  \n",
            "  inflating: data/11543.jpg          \n",
            "  inflating: __MACOSX/data/._11543.jpg  \n",
            "  inflating: data/3004.jpg           \n",
            "  inflating: __MACOSX/data/._3004.jpg  \n",
            "  inflating: data/31693.jpg          \n",
            "  inflating: __MACOSX/data/._31693.jpg  \n",
            "  inflating: data/20946.jpg          \n",
            "  inflating: __MACOSX/data/._20946.jpg  \n",
            "  inflating: data/10885.jpg          \n",
            "  inflating: __MACOSX/data/._10885.jpg  \n",
            "  inflating: data/21480.jpg          \n",
            "  inflating: __MACOSX/data/._21480.jpg  \n",
            "  inflating: data/18201.jpg          \n",
            "  inflating: __MACOSX/data/._18201.jpg  \n",
            "  inflating: data/5475.jpg           \n",
            "  inflating: __MACOSX/data/._5475.jpg  \n",
            "  inflating: data/17132.jpg          \n",
            "  inflating: __MACOSX/data/._17132.jpg  \n",
            "  inflating: data/11557.jpg          \n",
            "  inflating: __MACOSX/data/._11557.jpg  \n",
            "  inflating: data/20952.jpg          \n",
            "  inflating: __MACOSX/data/._20952.jpg  \n",
            "  inflating: data/31687.jpg          \n",
            "  inflating: __MACOSX/data/._31687.jpg  \n",
            "  inflating: data/3010.jpg           \n",
            "  inflating: __MACOSX/data/._3010.jpg  \n",
            "  inflating: data/10891.jpg          \n",
            "  inflating: __MACOSX/data/._10891.jpg  \n",
            "  inflating: data/16238.jpg          \n",
            "  inflating: __MACOSX/data/._16238.jpg  \n",
            "  inflating: data/21494.jpg          \n",
            "  inflating: __MACOSX/data/._21494.jpg  \n",
            "  inflating: data/5461.jpg           \n",
            "  inflating: __MACOSX/data/._5461.jpg  \n",
            "  inflating: data/18215.jpg          \n",
            "  inflating: __MACOSX/data/._18215.jpg  \n",
            "  inflating: data/17126.jpg          \n",
            "  inflating: __MACOSX/data/._17126.jpg  \n",
            "  inflating: data/10649.jpg          \n",
            "  inflating: __MACOSX/data/._10649.jpg  \n",
            "  inflating: data/30599.jpg          \n",
            "  inflating: __MACOSX/data/._30599.jpg  \n",
            "  inflating: data/393.jpg            \n",
            "  inflating: __MACOSX/data/._393.jpg  \n",
            "  inflating: data/33090.jpg          \n",
            "  inflating: __MACOSX/data/._33090.jpg  \n",
            "  inflating: data/1607.jpg           \n",
            "  inflating: __MACOSX/data/._1607.jpg  \n",
            "  inflating: data/13340.jpg          \n",
            "  inflating: __MACOSX/data/._13340.jpg  \n",
            "  inflating: data/23283.jpg          \n",
            "  inflating: __MACOSX/data/._23283.jpg  \n",
            "  inflating: data/6168.jpg           \n",
            "  inflating: __MACOSX/data/._6168.jpg  \n",
            "  inflating: data/15731.jpg          \n",
            "  inflating: __MACOSX/data/._15731.jpg  \n",
            "  inflating: data/8145.jpg           \n",
            "  inflating: __MACOSX/data/._8145.jpg  \n",
            "  inflating: data/7276.jpg           \n",
            "  inflating: __MACOSX/data/._7276.jpg  \n",
            "  inflating: data/34927.jpg          \n",
            "  inflating: __MACOSX/data/._34927.jpg  \n",
            "  inflating: data/12738.jpg          \n",
            "  inflating: __MACOSX/data/._12738.jpg  \n",
            "  inflating: data/25194.jpg          \n",
            "  inflating: __MACOSX/data/._25194.jpg  \n",
            "  inflating: data/15057.jpg          \n",
            "  inflating: __MACOSX/data/._15057.jpg  \n",
            "  inflating: data/8623.jpg           \n",
            "  inflating: __MACOSX/data/._8623.jpg  \n",
            "  inflating: data/7510.jpg           \n",
            "  inflating: __MACOSX/data/._7510.jpg  \n",
            "  inflating: data/35387.jpg          \n",
            "  inflating: __MACOSX/data/._35387.jpg  \n",
            "  inflating: data/14349.jpg          \n",
            "  inflating: __MACOSX/data/._14349.jpg  \n",
            "  inflating: data/34099.jpg          \n",
            "  inflating: __MACOSX/data/._34099.jpg  \n",
            "  inflating: data/1161.jpg           \n",
            "  inflating: __MACOSX/data/._1161.jpg  \n",
            "  inflating: data/22823.jpg          \n",
            "  inflating: __MACOSX/data/._22823.jpg  \n",
            "  inflating: data/13426.jpg          \n",
            "  inflating: __MACOSX/data/._13426.jpg  \n",
            "  inflating: data/36856.jpg          \n",
            "  inflating: __MACOSX/data/._36856.jpg  \n",
            "  inflating: data/27783.jpg          \n",
            "  inflating: __MACOSX/data/._27783.jpg  \n",
            "  inflating: data/2468.jpg           \n",
            "  inflating: __MACOSX/data/._2468.jpg  \n",
            "  inflating: data/5307.jpg           \n",
            "  inflating: __MACOSX/data/._5307.jpg  \n",
            "  inflating: data/37590.jpg          \n",
            "  inflating: __MACOSX/data/._37590.jpg  \n",
            "  inflating: data/18573.jpg          \n",
            "  inflating: __MACOSX/data/._18573.jpg  \n",
            "  inflating: data/17640.jpg          \n",
            "  inflating: __MACOSX/data/._17640.jpg  \n",
            "  inflating: data/29976.jpg          \n",
            "  inflating: __MACOSX/data/._29976.jpg  \n",
            "  inflating: data/4019.jpg           \n",
            "  inflating: __MACOSX/data/._4019.jpg  \n",
            "  inflating: data/11231.jpg          \n",
            "  inflating: __MACOSX/data/._11231.jpg  \n",
            "  inflating: data/3776.jpg           \n",
            "  inflating: __MACOSX/data/._3776.jpg  \n",
            "  inflating: data/17898.jpg          \n",
            "  inflating: __MACOSX/data/._17898.jpg  \n",
            "  inflating: data/12710.jpg          \n",
            "  inflating: __MACOSX/data/._12710.jpg  \n",
            "  inflating: data/7538.jpg           \n",
            "  inflating: __MACOSX/data/._7538.jpg  \n",
            "  inflating: data/33906.jpg          \n",
            "  inflating: __MACOSX/data/._33906.jpg  \n",
            "  inflating: data/6626.jpg           \n",
            "  inflating: __MACOSX/data/._6626.jpg  \n",
            "  inflating: data/14361.jpg          \n",
            "  inflating: __MACOSX/data/._14361.jpg  \n",
            "  inflating: data/9515.jpg           \n",
            "  inflating: __MACOSX/data/._9515.jpg  \n",
            "  inflating: data/1149.jpg           \n",
            "  inflating: __MACOSX/data/._1149.jpg  \n",
            "  inflating: data/2440.jpg           \n",
            "  inflating: __MACOSX/data/._2440.jpg  \n",
            "  inflating: data/28498.jpg          \n",
            "  inflating: __MACOSX/data/._28498.jpg  \n",
            "  inflating: data/10107.jpg          \n",
            "  inflating: __MACOSX/data/._10107.jpg  \n",
            "  inflating: data/17668.jpg          \n",
            "  inflating: __MACOSX/data/._17668.jpg  \n",
            "  inflating: data/3986.jpg           \n",
            "  inflating: __MACOSX/data/._3986.jpg  \n",
            "  inflating: data/16576.jpg          \n",
            "  inflating: __MACOSX/data/._16576.jpg  \n",
            "  inflating: data/39595.jpg          \n",
            "  inflating: __MACOSX/data/._39595.jpg  \n",
            "  inflating: data/4031.jpg           \n",
            "  inflating: __MACOSX/data/._4031.jpg  \n",
            "  inflating: data/19645.jpg          \n",
            "  inflating: __MACOSX/data/._19645.jpg  \n",
            "  inflating: data/27973.jpg          \n",
            "  inflating: __MACOSX/data/._27973.jpg  \n",
            "  inflating: data/38853.jpg          \n",
            "  inflating: __MACOSX/data/._38853.jpg  \n",
            "  inflating: data/29786.jpg          \n",
            "  inflating: __MACOSX/data/._29786.jpg  \n",
            "  inflating: data/11219.jpg          \n",
            "  inflating: __MACOSX/data/._11219.jpg  \n",
            "  inflating: data/3038.jpg           \n",
            "  inflating: __MACOSX/data/._3038.jpg  \n",
            "  inflating: data/16210.jpg          \n",
            "  inflating: __MACOSX/data/._16210.jpg  \n",
            "  inflating: data/4757.jpg           \n",
            "  inflating: __MACOSX/data/._4757.jpg  \n",
            "  inflating: data/19123.jpg          \n",
            "  inflating: __MACOSX/data/._19123.jpg  \n",
            "  inflating: data/31877.jpg          \n",
            "  inflating: __MACOSX/data/._31877.jpg  \n",
            "  inflating: data/5449.jpg           \n",
            "  inflating: __MACOSX/data/._5449.jpg  \n",
            "  inflating: data/2326.jpg           \n",
            "  inflating: __MACOSX/data/._2326.jpg  \n",
            "  inflating: data/10661.jpg          \n",
            "  inflating: __MACOSX/data/._10661.jpg  \n",
            "  inflating: data/13368.jpg          \n",
            "  inflating: __MACOSX/data/._13368.jpg  \n",
            "  inflating: data/25802.jpg          \n",
            "  inflating: __MACOSX/data/._25802.jpg  \n",
            "  inflating: data/6140.jpg           \n",
            "  inflating: __MACOSX/data/._6140.jpg  \n",
            "  inflating: data/14407.jpg          \n",
            "  inflating: __MACOSX/data/._14407.jpg  \n",
            "  inflating: data/9273.jpg           \n",
            "  inflating: __MACOSX/data/._9273.jpg  \n",
            "  inflating: data/15719.jpg          \n",
            "  inflating: __MACOSX/data/._15719.jpg  \n",
            "  inflating: data/12076.jpg          \n",
            "  inflating: __MACOSX/data/._12076.jpg  \n",
            "  inflating: data/6154.jpg           \n",
            "  inflating: __MACOSX/data/._6154.jpg  \n",
            "  inflating: data/25816.jpg          \n",
            "  inflating: __MACOSX/data/._25816.jpg  \n",
            "  inflating: data/9267.jpg           \n",
            "  inflating: __MACOSX/data/._9267.jpg  \n",
            "  inflating: data/14413.jpg          \n",
            "  inflating: __MACOSX/data/._14413.jpg  \n",
            "  inflating: data/8179.jpg           \n",
            "  inflating: __MACOSX/data/._8179.jpg  \n",
            "  inflating: data/12062.jpg          \n",
            "  inflating: __MACOSX/data/._12062.jpg  \n",
            "  inflating: data/16204.jpg          \n",
            "  inflating: __MACOSX/data/._16204.jpg  \n",
            "  inflating: data/19137.jpg          \n",
            "  inflating: __MACOSX/data/._19137.jpg  \n",
            "  inflating: data/4743.jpg           \n",
            "  inflating: __MACOSX/data/._4743.jpg  \n",
            "  inflating: data/31863.jpg          \n",
            "  inflating: __MACOSX/data/._31863.jpg  \n",
            "  inflating: data/18229.jpg          \n",
            "  inflating: __MACOSX/data/._18229.jpg  \n",
            "  inflating: data/2332.jpg           \n",
            "  inflating: __MACOSX/data/._2332.jpg  \n",
            "  inflating: data/10675.jpg          \n",
            "  inflating: __MACOSX/data/._10675.jpg  \n",
            "  inflating: data/2454.jpg           \n",
            "  inflating: __MACOSX/data/._2454.jpg  \n",
            "  inflating: data/10113.jpg          \n",
            "  inflating: __MACOSX/data/._10113.jpg  \n",
            "  inflating: data/19889.jpg          \n",
            "  inflating: __MACOSX/data/._19889.jpg  \n",
            "  inflating: data/3992.jpg           \n",
            "  inflating: __MACOSX/data/._3992.jpg  \n",
            "  inflating: data/39581.jpg          \n",
            "  inflating: __MACOSX/data/._39581.jpg  \n",
            "  inflating: data/16562.jpg          \n",
            "  inflating: __MACOSX/data/._16562.jpg  \n",
            "  inflating: data/27967.jpg          \n",
            "  inflating: __MACOSX/data/._27967.jpg  \n",
            "  inflating: data/19651.jpg          \n",
            "  inflating: __MACOSX/data/._19651.jpg  \n",
            "  inflating: data/4025.jpg           \n",
            "  inflating: __MACOSX/data/._4025.jpg  \n",
            "  inflating: data/29792.jpg          \n",
            "  inflating: __MACOSX/data/._29792.jpg  \n",
            "  inflating: data/38847.jpg          \n",
            "  inflating: __MACOSX/data/._38847.jpg  \n",
            "  inflating: data/12704.jpg          \n",
            "  inflating: __MACOSX/data/._12704.jpg  \n",
            "  inflating: data/33912.jpg          \n",
            "  inflating: __MACOSX/data/._33912.jpg  \n",
            "  inflating: data/6632.jpg           \n",
            "  inflating: __MACOSX/data/._6632.jpg  \n",
            "  inflating: data/9501.jpg           \n",
            "  inflating: __MACOSX/data/._9501.jpg  \n",
            "  inflating: data/14375.jpg          \n",
            "  inflating: __MACOSX/data/._14375.jpg  \n",
            "  inflating: data/23532.jpg          \n",
            "  inflating: __MACOSX/data/._23532.jpg  \n",
            "  inflating: data/12937.jpg          \n",
            "  inflating: __MACOSX/data/._12937.jpg  \n",
            "  inflating: data/422.jpg            \n",
            "  inflating: __MACOSX/data/._422.jpg  \n",
            "  inflating: data/33721.jpg          \n",
            "  inflating: __MACOSX/data/._33721.jpg  \n",
            "  inflating: data/25143.jpg          \n",
            "  inflating: __MACOSX/data/._25143.jpg  \n",
            "  inflating: data/6801.jpg           \n",
            "  inflating: __MACOSX/data/._6801.jpg  \n",
            "  inflating: data/15080.jpg          \n",
            "  inflating: __MACOSX/data/._15080.jpg  \n",
            "  inflating: data/35350.jpg          \n",
            "  inflating: __MACOSX/data/._35350.jpg  \n",
            "  inflating: data/36659.jpg          \n",
            "  inflating: __MACOSX/data/._36659.jpg  \n",
            "  inflating: data/16589.jpg          \n",
            "  inflating: __MACOSX/data/._16589.jpg  \n",
            "  inflating: data/21325.jpg          \n",
            "  inflating: __MACOSX/data/._21325.jpg  \n",
            "  inflating: data/31136.jpg          \n",
            "  inflating: __MACOSX/data/._31136.jpg  \n",
            "  inflating: data/29779.jpg          \n",
            "  inflating: __MACOSX/data/._29779.jpg  \n",
            "  inflating: data/27754.jpg          \n",
            "  inflating: __MACOSX/data/._27754.jpg  \n",
            "  inflating: data/36881.jpg          \n",
            "  inflating: __MACOSX/data/._36881.jpg  \n",
            "  inflating: data/19862.jpg          \n",
            "  inflating: __MACOSX/data/._19862.jpg  \n",
            "  inflating: data/28467.jpg          \n",
            "  inflating: __MACOSX/data/._28467.jpg  \n",
            "  inflating: data/30228.jpg          \n",
            "  inflating: __MACOSX/data/._30228.jpg  \n",
            "  inflating: data/37547.jpg          \n",
            "  inflating: __MACOSX/data/._37547.jpg  \n",
            "  inflating: data/3979.jpg           \n",
            "  inflating: __MACOSX/data/._3979.jpg  \n",
            "  inflating: data/17697.jpg          \n",
            "  inflating: __MACOSX/data/._17697.jpg  \n",
            "  inflating: data/38674.jpg          \n",
            "  inflating: __MACOSX/data/._38674.jpg  \n",
            "  inflating: data/37221.jpg          \n",
            "  inflating: __MACOSX/data/._37221.jpg  \n",
            "  inflating: data/31888.jpg          \n",
            "  inflating: __MACOSX/data/._31888.jpg  \n",
            "  inflating: data/38112.jpg          \n",
            "  inflating: __MACOSX/data/._38112.jpg  \n",
            "  inflating: data/4970.jpg           \n",
            "  inflating: __MACOSX/data/._4970.jpg  \n",
            "  inflating: data/27032.jpg          \n",
            "  inflating: __MACOSX/data/._27032.jpg  \n",
            "  inflating: data/28301.jpg          \n",
            "  inflating: __MACOSX/data/._28301.jpg  \n",
            "  inflating: data/11580.jpg          \n",
            "  inflating: __MACOSX/data/._11580.jpg  \n",
            "  inflating: data/31650.jpg          \n",
            "  inflating: __MACOSX/data/._31650.jpg  \n",
            "  inflating: data/20985.jpg          \n",
            "  inflating: __MACOSX/data/._20985.jpg  \n",
            "  inflating: data/10846.jpg          \n",
            "  inflating: __MACOSX/data/._10846.jpg  \n",
            "  inflating: data/21443.jpg          \n",
            "  inflating: __MACOSX/data/._21443.jpg  \n",
            "  inflating: data/1808.jpg           \n",
            "  inflating: __MACOSX/data/._1808.jpg  \n",
            "  inflating: data/8192.jpg           \n",
            "  inflating: __MACOSX/data/._8192.jpg  \n",
            "  inflating: data/35436.jpg          \n",
            "  inflating: __MACOSX/data/._35436.jpg  \n",
            "  inflating: data/32359.jpg          \n",
            "  inflating: __MACOSX/data/._32359.jpg  \n",
            "  inflating: data/12089.jpg          \n",
            "  inflating: __MACOSX/data/._12089.jpg  \n",
            "  inflating: data/25625.jpg          \n",
            "  inflating: __MACOSX/data/._25625.jpg  \n",
            "  inflating: data/33047.jpg          \n",
            "  inflating: __MACOSX/data/._33047.jpg  \n",
            "  inflating: data/344.jpg            \n",
            "  inflating: __MACOSX/data/._344.jpg  \n",
            "  inflating: data/13397.jpg          \n",
            "  inflating: __MACOSX/data/._13397.jpg  \n",
            "  inflating: data/23254.jpg          \n",
            "  inflating: __MACOSX/data/._23254.jpg  \n",
            "  inflating: data/34728.jpg          \n",
            "  inflating: __MACOSX/data/._34728.jpg  \n",
            "  inflating: data/8186.jpg           \n",
            "  inflating: __MACOSX/data/._8186.jpg  \n",
            "  inflating: data/35422.jpg          \n",
            "  inflating: __MACOSX/data/._35422.jpg  \n",
            "  inflating: data/25631.jpg          \n",
            "  inflating: __MACOSX/data/._25631.jpg  \n",
            "  inflating: data/350.jpg            \n",
            "  inflating: __MACOSX/data/._350.jpg  \n",
            "  inflating: data/33053.jpg          \n",
            "  inflating: __MACOSX/data/._33053.jpg  \n",
            "  inflating: data/13383.jpg          \n",
            "  inflating: __MACOSX/data/._13383.jpg  \n",
            "  inflating: data/23240.jpg          \n",
            "  inflating: __MACOSX/data/._23240.jpg  \n",
            "  inflating: data/9298.jpg           \n",
            "  inflating: __MACOSX/data/._9298.jpg  \n",
            "  inflating: data/37235.jpg          \n",
            "  inflating: __MACOSX/data/._37235.jpg  \n",
            "  inflating: data/38106.jpg          \n",
            "  inflating: __MACOSX/data/._38106.jpg  \n",
            "  inflating: data/20749.jpg          \n",
            "  inflating: __MACOSX/data/._20749.jpg  \n",
            "  inflating: data/27026.jpg          \n",
            "  inflating: __MACOSX/data/._27026.jpg  \n",
            "  inflating: data/4964.jpg           \n",
            "  inflating: __MACOSX/data/._4964.jpg  \n",
            "  inflating: data/28315.jpg          \n",
            "  inflating: __MACOSX/data/._28315.jpg  \n",
            "  inflating: data/11594.jpg          \n",
            "  inflating: __MACOSX/data/._11594.jpg  \n",
            "  inflating: data/26338.jpg          \n",
            "  inflating: __MACOSX/data/._26338.jpg  \n",
            "  inflating: data/20991.jpg          \n",
            "  inflating: __MACOSX/data/._20991.jpg  \n",
            "  inflating: data/31644.jpg          \n",
            "  inflating: __MACOSX/data/._31644.jpg  \n",
            "  inflating: data/10852.jpg          \n",
            "  inflating: __MACOSX/data/._10852.jpg  \n",
            "  inflating: data/21457.jpg          \n",
            "  inflating: __MACOSX/data/._21457.jpg  \n",
            "  inflating: data/39218.jpg          \n",
            "  inflating: __MACOSX/data/._39218.jpg  \n",
            "  inflating: data/27998.jpg          \n",
            "  inflating: __MACOSX/data/._27998.jpg  \n",
            "  inflating: data/21331.jpg          \n",
            "  inflating: __MACOSX/data/._21331.jpg  \n",
            "  inflating: data/31122.jpg          \n",
            "  inflating: __MACOSX/data/._31122.jpg  \n",
            "  inflating: data/19876.jpg          \n",
            "  inflating: __MACOSX/data/._19876.jpg  \n",
            "  inflating: data/36895.jpg          \n",
            "  inflating: __MACOSX/data/._36895.jpg  \n",
            "  inflating: data/27740.jpg          \n",
            "  inflating: __MACOSX/data/._27740.jpg  \n",
            "  inflating: data/28473.jpg          \n",
            "  inflating: __MACOSX/data/._28473.jpg  \n",
            "  inflating: data/37553.jpg          \n",
            "  inflating: __MACOSX/data/._37553.jpg  \n",
            "  inflating: data/38660.jpg          \n",
            "  inflating: __MACOSX/data/._38660.jpg  \n",
            "  inflating: data/17683.jpg          \n",
            "  inflating: __MACOSX/data/._17683.jpg  \n",
            "  inflating: data/23526.jpg          \n",
            "  inflating: __MACOSX/data/._23526.jpg  \n",
            "  inflating: data/12923.jpg          \n",
            "  inflating: __MACOSX/data/._12923.jpg  \n",
            "  inflating: data/8838.jpg           \n",
            "  inflating: __MACOSX/data/._8838.jpg  \n",
            "  inflating: data/33735.jpg          \n",
            "  inflating: __MACOSX/data/._33735.jpg  \n",
            "  inflating: data/436.jpg            \n",
            "  inflating: __MACOSX/data/._436.jpg  \n",
            "  inflating: data/24249.jpg          \n",
            "  inflating: __MACOSX/data/._24249.jpg  \n",
            "  inflating: data/6815.jpg           \n",
            "  inflating: __MACOSX/data/._6815.jpg  \n",
            "  inflating: data/25157.jpg          \n",
            "  inflating: __MACOSX/data/._25157.jpg  \n",
            "  inflating: data/15094.jpg          \n",
            "  inflating: __MACOSX/data/._15094.jpg  \n",
            "  inflating: data/22638.jpg          \n",
            "  inflating: __MACOSX/data/._22638.jpg  \n",
            "  inflating: data/35344.jpg          \n",
            "  inflating: __MACOSX/data/._35344.jpg  \n",
            "  inflating: data/39556.jpg          \n",
            "  inflating: __MACOSX/data/._39556.jpg  \n",
            "  inflating: data/21319.jpg          \n",
            "  inflating: __MACOSX/data/._21319.jpg  \n",
            "  inflating: data/19686.jpg          \n",
            "  inflating: __MACOSX/data/._19686.jpg  \n",
            "  inflating: data/36665.jpg          \n",
            "  inflating: __MACOSX/data/._36665.jpg  \n",
            "  inflating: data/38890.jpg          \n",
            "  inflating: __MACOSX/data/._38890.jpg  \n",
            "  inflating: data/17873.jpg          \n",
            "  inflating: __MACOSX/data/._17873.jpg  \n",
            "  inflating: data/29745.jpg          \n",
            "  inflating: __MACOSX/data/._29745.jpg  \n",
            "  inflating: data/26476.jpg          \n",
            "  inflating: __MACOSX/data/._26476.jpg  \n",
            "  inflating: data/30214.jpg          \n",
            "  inflating: __MACOSX/data/._30214.jpg  \n",
            "  inflating: data/2483.jpg           \n",
            "  inflating: __MACOSX/data/._2483.jpg  \n",
            "  inflating: data/27768.jpg          \n",
            "  inflating: __MACOSX/data/._27768.jpg  \n",
            "  inflating: data/3945.jpg           \n",
            "  inflating: __MACOSX/data/._3945.jpg  \n",
            "  inflating: data/20007.jpg          \n",
            "  inflating: __MACOSX/data/._20007.jpg  \n",
            "  inflating: data/38648.jpg          \n",
            "  inflating: __MACOSX/data/._38648.jpg  \n",
            "  inflating: data/18598.jpg          \n",
            "  inflating: __MACOSX/data/._18598.jpg  \n",
            "  inflating: data/34072.jpg          \n",
            "  inflating: __MACOSX/data/._34072.jpg  \n",
            "  inflating: data/24261.jpg          \n",
            "  inflating: __MACOSX/data/._24261.jpg  \n",
            "  inflating: data/8810.jpg           \n",
            "  inflating: __MACOSX/data/._8810.jpg  \n",
            "  inflating: data/32403.jpg          \n",
            "  inflating: __MACOSX/data/._32403.jpg  \n",
            "  inflating: data/22610.jpg          \n",
            "  inflating: __MACOSX/data/._22610.jpg  \n",
            "  inflating: data/22176.jpg          \n",
            "  inflating: __MACOSX/data/._22176.jpg  \n",
            "  inflating: data/1834.jpg           \n",
            "  inflating: __MACOSX/data/._1834.jpg  \n",
            "  inflating: data/25619.jpg          \n",
            "  inflating: __MACOSX/data/._25619.jpg  \n",
            "  inflating: data/32365.jpg          \n",
            "  inflating: __MACOSX/data/._32365.jpg  \n",
            "  inflating: data/24507.jpg          \n",
            "  inflating: __MACOSX/data/._24507.jpg  \n",
            "  inflating: data/378.jpg            \n",
            "  inflating: __MACOSX/data/._378.jpg  \n",
            "  inflating: data/15902.jpg          \n",
            "  inflating: __MACOSX/data/._15902.jpg  \n",
            "  inflating: data/6183.jpg           \n",
            "  inflating: __MACOSX/data/._6183.jpg  \n",
            "  inflating: data/34714.jpg          \n",
            "  inflating: __MACOSX/data/._34714.jpg  \n",
            "  inflating: data/23268.jpg          \n",
            "  inflating: __MACOSX/data/._23268.jpg  \n",
            "  inflating: data/20761.jpg          \n",
            "  inflating: __MACOSX/data/._20761.jpg  \n",
            "  inflating: data/30572.jpg          \n",
            "  inflating: __MACOSX/data/._30572.jpg  \n",
            "  inflating: data/29023.jpg          \n",
            "  inflating: __MACOSX/data/._29023.jpg  \n",
            "  inflating: data/26310.jpg          \n",
            "  inflating: __MACOSX/data/._26310.jpg  \n",
            "  inflating: data/39230.jpg          \n",
            "  inflating: __MACOSX/data/._39230.jpg  \n",
            "  inflating: data/4794.jpg           \n",
            "  inflating: __MACOSX/data/._4794.jpg  \n",
            "  inflating: data/36103.jpg          \n",
            "  inflating: __MACOSX/data/._36103.jpg  \n",
            "  inflating: data/20775.jpg          \n",
            "  inflating: __MACOSX/data/._20775.jpg  \n",
            "  inflating: data/37209.jpg          \n",
            "  inflating: __MACOSX/data/._37209.jpg  \n",
            "  inflating: data/30566.jpg          \n",
            "  inflating: __MACOSX/data/._30566.jpg  \n",
            "  inflating: data/28329.jpg          \n",
            "  inflating: __MACOSX/data/._28329.jpg  \n",
            "  inflating: data/4958.jpg           \n",
            "  inflating: __MACOSX/data/._4958.jpg  \n",
            "  inflating: data/29037.jpg          \n",
            "  inflating: __MACOSX/data/._29037.jpg  \n",
            "  inflating: data/31678.jpg          \n",
            "  inflating: __MACOSX/data/._31678.jpg  \n",
            "  inflating: data/26304.jpg          \n",
            "  inflating: __MACOSX/data/._26304.jpg  \n",
            "  inflating: data/39224.jpg          \n",
            "  inflating: __MACOSX/data/._39224.jpg  \n",
            "  inflating: data/36117.jpg          \n",
            "  inflating: __MACOSX/data/._36117.jpg  \n",
            "  inflating: data/4780.jpg           \n",
            "  inflating: __MACOSX/data/._4780.jpg  \n",
            "  inflating: data/7289.jpg           \n",
            "  inflating: __MACOSX/data/._7289.jpg  \n",
            "  inflating: data/1820.jpg           \n",
            "  inflating: __MACOSX/data/._1820.jpg  \n",
            "  inflating: data/22162.jpg          \n",
            "  inflating: __MACOSX/data/._22162.jpg  \n",
            "  inflating: data/32371.jpg          \n",
            "  inflating: __MACOSX/data/._32371.jpg  \n",
            "  inflating: data/24513.jpg          \n",
            "  inflating: __MACOSX/data/._24513.jpg  \n",
            "  inflating: data/15916.jpg          \n",
            "  inflating: __MACOSX/data/._15916.jpg  \n",
            "  inflating: data/34700.jpg          \n",
            "  inflating: __MACOSX/data/._34700.jpg  \n",
            "  inflating: data/6197.jpg           \n",
            "  inflating: __MACOSX/data/._6197.jpg  \n",
            "  inflating: data/34066.jpg          \n",
            "  inflating: __MACOSX/data/._34066.jpg  \n",
            "  inflating: data/24275.jpg          \n",
            "  inflating: __MACOSX/data/._24275.jpg  \n",
            "  inflating: data/8804.jpg           \n",
            "  inflating: __MACOSX/data/._8804.jpg  \n",
            "  inflating: data/33709.jpg          \n",
            "  inflating: __MACOSX/data/._33709.jpg  \n",
            "  inflating: data/6829.jpg           \n",
            "  inflating: __MACOSX/data/._6829.jpg  \n",
            "  inflating: data/32417.jpg          \n",
            "  inflating: __MACOSX/data/._32417.jpg  \n",
            "  inflating: data/35378.jpg          \n",
            "  inflating: __MACOSX/data/._35378.jpg  \n",
            "  inflating: data/22604.jpg          \n",
            "  inflating: __MACOSX/data/._22604.jpg  \n",
            "  inflating: data/39542.jpg          \n",
            "  inflating: __MACOSX/data/._39542.jpg  \n",
            "  inflating: data/36671.jpg          \n",
            "  inflating: __MACOSX/data/._36671.jpg  \n",
            "  inflating: data/19692.jpg          \n",
            "  inflating: __MACOSX/data/._19692.jpg  \n",
            "  inflating: data/29751.jpg          \n",
            "  inflating: __MACOSX/data/._29751.jpg  \n",
            "  inflating: data/17867.jpg          \n",
            "  inflating: __MACOSX/data/._17867.jpg  \n",
            "  inflating: data/38884.jpg          \n",
            "  inflating: __MACOSX/data/._38884.jpg  \n",
            "  inflating: data/3789.jpg           \n",
            "  inflating: __MACOSX/data/._3789.jpg  \n",
            "  inflating: data/26462.jpg          \n",
            "  inflating: __MACOSX/data/._26462.jpg  \n",
            "  inflating: data/2497.jpg           \n",
            "  inflating: __MACOSX/data/._2497.jpg  \n",
            "  inflating: data/30200.jpg          \n",
            "  inflating: __MACOSX/data/._30200.jpg  \n",
            "  inflating: data/29989.jpg          \n",
            "  inflating: __MACOSX/data/._29989.jpg  \n",
            "  inflating: data/20013.jpg          \n",
            "  inflating: __MACOSX/data/._20013.jpg  \n",
            "  inflating: data/3951.jpg           \n",
            "  inflating: __MACOSX/data/._3951.jpg  \n",
            "  inflating: data/11351.jpg          \n",
            "  inflating: __MACOSX/data/._11351.jpg  \n",
            "  inflating: data/31081.jpg          \n",
            "  inflating: __MACOSX/data/._31081.jpg  \n",
            "  inflating: data/3616.jpg           \n",
            "  inflating: __MACOSX/data/._3616.jpg  \n",
            "  inflating: data/4179.jpg           \n",
            "  inflating: __MACOSX/data/._4179.jpg  \n",
            "  inflating: data/21292.jpg          \n",
            "  inflating: __MACOSX/data/._21292.jpg  \n",
            "  inflating: data/5267.jpg           \n",
            "  inflating: __MACOSX/data/._5267.jpg  \n",
            "  inflating: data/18413.jpg          \n",
            "  inflating: __MACOSX/data/._18413.jpg  \n",
            "  inflating: data/17720.jpg          \n",
            "  inflating: __MACOSX/data/._17720.jpg  \n",
            "  inflating: data/29816.jpg          \n",
            "  inflating: __MACOSX/data/._29816.jpg  \n",
            "  inflating: data/36936.jpg          \n",
            "  inflating: __MACOSX/data/._36936.jpg  \n",
            "  inflating: data/2508.jpg           \n",
            "  inflating: __MACOSX/data/._2508.jpg  \n",
            "  inflating: data/33696.jpg          \n",
            "  inflating: __MACOSX/data/._33696.jpg  \n",
            "  inflating: data/1001.jpg           \n",
            "  inflating: __MACOSX/data/._1001.jpg  \n",
            "  inflating: data/22943.jpg          \n",
            "  inflating: __MACOSX/data/._22943.jpg  \n",
            "  inflating: data/595.jpg            \n",
            "  inflating: __MACOSX/data/._595.jpg  \n",
            "  inflating: data/13546.jpg          \n",
            "  inflating: __MACOSX/data/._13546.jpg  \n",
            "  inflating: data/14229.jpg          \n",
            "  inflating: __MACOSX/data/._14229.jpg  \n",
            "  inflating: data/23485.jpg          \n",
            "  inflating: __MACOSX/data/._23485.jpg  \n",
            "  inflating: data/12880.jpg          \n",
            "  inflating: __MACOSX/data/._12880.jpg  \n",
            "  inflating: data/15137.jpg          \n",
            "  inflating: __MACOSX/data/._15137.jpg  \n",
            "  inflating: data/8743.jpg           \n",
            "  inflating: __MACOSX/data/._8743.jpg  \n",
            "  inflating: data/7470.jpg           \n",
            "  inflating: __MACOSX/data/._7470.jpg  \n",
            "  inflating: data/32588.jpg          \n",
            "  inflating: __MACOSX/data/._32588.jpg  \n",
            "  inflating: data/12658.jpg          \n",
            "  inflating: __MACOSX/data/._12658.jpg  \n",
            "  inflating: data/25792.jpg          \n",
            "  inflating: __MACOSX/data/._25792.jpg  \n",
            "  inflating: data/34847.jpg          \n",
            "  inflating: __MACOSX/data/._34847.jpg  \n",
            "  inflating: data/15651.jpg          \n",
            "  inflating: __MACOSX/data/._15651.jpg  \n",
            "  inflating: data/8025.jpg           \n",
            "  inflating: __MACOSX/data/._8025.jpg  \n",
            "  inflating: data/7316.jpg           \n",
            "  inflating: __MACOSX/data/._7316.jpg  \n",
            "  inflating: data/35581.jpg          \n",
            "  inflating: __MACOSX/data/._35581.jpg  \n",
            "  inflating: data/6008.jpg           \n",
            "  inflating: __MACOSX/data/._6008.jpg  \n",
            "  inflating: data/1767.jpg           \n",
            "  inflating: __MACOSX/data/._1767.jpg  \n",
            "  inflating: data/15889.jpg          \n",
            "  inflating: __MACOSX/data/._15889.jpg  \n",
            "  inflating: data/13220.jpg          \n",
            "  inflating: __MACOSX/data/._13220.jpg  \n",
            "  inflating: data/10729.jpg          \n",
            "  inflating: __MACOSX/data/._10729.jpg  \n",
            "  inflating: data/27185.jpg          \n",
            "  inflating: __MACOSX/data/._27185.jpg  \n",
            "  inflating: data/5501.jpg           \n",
            "  inflating: __MACOSX/data/._5501.jpg  \n",
            "  inflating: data/37396.jpg          \n",
            "  inflating: __MACOSX/data/._37396.jpg  \n",
            "  inflating: data/18375.jpg          \n",
            "  inflating: __MACOSX/data/._18375.jpg  \n",
            "  inflating: data/17046.jpg          \n",
            "  inflating: __MACOSX/data/._17046.jpg  \n",
            "  inflating: data/36088.jpg          \n",
            "  inflating: __MACOSX/data/._36088.jpg  \n",
            "  inflating: data/16358.jpg          \n",
            "  inflating: __MACOSX/data/._16358.jpg  \n",
            "  inflating: data/11437.jpg          \n",
            "  inflating: __MACOSX/data/._11437.jpg  \n",
            "  inflating: data/20832.jpg          \n",
            "  inflating: __MACOSX/data/._20832.jpg  \n",
            "  inflating: data/3170.jpg           \n",
            "  inflating: __MACOSX/data/._3170.jpg  \n",
            "  inflating: data/27191.jpg          \n",
            "  inflating: __MACOSX/data/._27191.jpg  \n",
            "  inflating: data/18361.jpg          \n",
            "  inflating: __MACOSX/data/._18361.jpg  \n",
            "  inflating: data/37382.jpg          \n",
            "  inflating: __MACOSX/data/._37382.jpg  \n",
            "  inflating: data/5515.jpg           \n",
            "  inflating: __MACOSX/data/._5515.jpg  \n",
            "  inflating: data/17052.jpg          \n",
            "  inflating: __MACOSX/data/._17052.jpg  \n",
            "  inflating: data/11423.jpg          \n",
            "  inflating: __MACOSX/data/._11423.jpg  \n",
            "  inflating: data/3164.jpg           \n",
            "  inflating: __MACOSX/data/._3164.jpg  \n",
            "  inflating: data/20826.jpg          \n",
            "  inflating: __MACOSX/data/._20826.jpg  \n",
            "  inflating: data/34853.jpg          \n",
            "  inflating: __MACOSX/data/._34853.jpg  \n",
            "  inflating: data/25786.jpg          \n",
            "  inflating: __MACOSX/data/._25786.jpg  \n",
            "  inflating: data/8031.jpg           \n",
            "  inflating: __MACOSX/data/._8031.jpg  \n",
            "  inflating: data/15645.jpg          \n",
            "  inflating: __MACOSX/data/._15645.jpg  \n",
            "  inflating: data/35595.jpg          \n",
            "  inflating: __MACOSX/data/._35595.jpg  \n",
            "  inflating: data/7302.jpg           \n",
            "  inflating: __MACOSX/data/._7302.jpg  \n",
            "  inflating: data/1773.jpg           \n",
            "  inflating: __MACOSX/data/._1773.jpg  \n",
            "  inflating: data/13234.jpg          \n",
            "  inflating: __MACOSX/data/._13234.jpg  \n",
            "  inflating: data/24498.jpg          \n",
            "  inflating: __MACOSX/data/._24498.jpg  \n",
            "  inflating: data/581.jpg            \n",
            "  inflating: __MACOSX/data/._581.jpg  \n",
            "  inflating: data/22957.jpg          \n",
            "  inflating: __MACOSX/data/._22957.jpg  \n",
            "  inflating: data/1015.jpg           \n",
            "  inflating: __MACOSX/data/._1015.jpg  \n",
            "  inflating: data/33682.jpg          \n",
            "  inflating: __MACOSX/data/._33682.jpg  \n",
            "  inflating: data/13552.jpg          \n",
            "  inflating: __MACOSX/data/._13552.jpg  \n",
            "  inflating: data/23491.jpg          \n",
            "  inflating: __MACOSX/data/._23491.jpg  \n",
            "  inflating: data/9449.jpg           \n",
            "  inflating: __MACOSX/data/._9449.jpg  \n",
            "  inflating: data/12894.jpg          \n",
            "  inflating: __MACOSX/data/._12894.jpg  \n",
            "  inflating: data/8757.jpg           \n",
            "  inflating: __MACOSX/data/._8757.jpg  \n",
            "  inflating: data/15123.jpg          \n",
            "  inflating: __MACOSX/data/._15123.jpg  \n",
            "  inflating: data/7464.jpg           \n",
            "  inflating: __MACOSX/data/._7464.jpg  \n",
            "  inflating: data/11345.jpg          \n",
            "  inflating: __MACOSX/data/._11345.jpg  \n",
            "  inflating: data/3602.jpg           \n",
            "  inflating: __MACOSX/data/._3602.jpg  \n",
            "  inflating: data/31095.jpg          \n",
            "  inflating: __MACOSX/data/._31095.jpg  \n",
            "  inflating: data/19719.jpg          \n",
            "  inflating: __MACOSX/data/._19719.jpg  \n",
            "  inflating: data/21286.jpg          \n",
            "  inflating: __MACOSX/data/._21286.jpg  \n",
            "  inflating: data/18407.jpg          \n",
            "  inflating: __MACOSX/data/._18407.jpg  \n",
            "  inflating: data/5273.jpg           \n",
            "  inflating: __MACOSX/data/._5273.jpg  \n",
            "  inflating: data/29802.jpg          \n",
            "  inflating: __MACOSX/data/._29802.jpg  \n",
            "  inflating: data/17734.jpg          \n",
            "  inflating: __MACOSX/data/._17734.jpg  \n",
            "  inflating: data/20198.jpg          \n",
            "  inflating: __MACOSX/data/._20198.jpg  \n",
            "  inflating: data/36922.jpg          \n",
            "  inflating: __MACOSX/data/._36922.jpg  \n",
            "  inflating: data/6752.jpg           \n",
            "  inflating: __MACOSX/data/._6752.jpg  \n",
            "  inflating: data/9461.jpg           \n",
            "  inflating: __MACOSX/data/._9461.jpg  \n",
            "  inflating: data/14215.jpg          \n",
            "  inflating: __MACOSX/data/._14215.jpg  \n",
            "  inflating: data/33872.jpg          \n",
            "  inflating: __MACOSX/data/._33872.jpg  \n",
            "  inflating: data/12664.jpg          \n",
            "  inflating: __MACOSX/data/._12664.jpg  \n",
            "  inflating: data/38927.jpg          \n",
            "  inflating: __MACOSX/data/._38927.jpg  \n",
            "  inflating: data/16402.jpg          \n",
            "  inflating: __MACOSX/data/._16402.jpg  \n",
            "  inflating: data/27807.jpg          \n",
            "  inflating: __MACOSX/data/._27807.jpg  \n",
            "  inflating: data/19731.jpg          \n",
            "  inflating: __MACOSX/data/._19731.jpg  \n",
            "  inflating: data/4145.jpg           \n",
            "  inflating: __MACOSX/data/._4145.jpg  \n",
            "  inflating: data/2534.jpg           \n",
            "  inflating: __MACOSX/data/._2534.jpg  \n",
            "  inflating: data/10073.jpg          \n",
            "  inflating: __MACOSX/data/._10073.jpg  \n",
            "  inflating: data/2252.jpg           \n",
            "  inflating: __MACOSX/data/._2252.jpg  \n",
            "  inflating: data/10715.jpg          \n",
            "  inflating: __MACOSX/data/._10715.jpg  \n",
            "  inflating: data/31903.jpg          \n",
            "  inflating: __MACOSX/data/._31903.jpg  \n",
            "  inflating: data/38099.jpg          \n",
            "  inflating: __MACOSX/data/._38099.jpg  \n",
            "  inflating: data/18349.jpg          \n",
            "  inflating: __MACOSX/data/._18349.jpg  \n",
            "  inflating: data/39387.jpg          \n",
            "  inflating: __MACOSX/data/._39387.jpg  \n",
            "  inflating: data/16364.jpg          \n",
            "  inflating: __MACOSX/data/._16364.jpg  \n",
            "  inflating: data/19057.jpg          \n",
            "  inflating: __MACOSX/data/._19057.jpg  \n",
            "  inflating: data/4623.jpg           \n",
            "  inflating: __MACOSX/data/._4623.jpg  \n",
            "  inflating: data/29194.jpg          \n",
            "  inflating: __MACOSX/data/._29194.jpg  \n",
            "  inflating: data/12102.jpg          \n",
            "  inflating: __MACOSX/data/._12102.jpg  \n",
            "  inflating: data/1983.jpg           \n",
            "  inflating: __MACOSX/data/._1983.jpg  \n",
            "  inflating: data/8019.jpg           \n",
            "  inflating: __MACOSX/data/._8019.jpg  \n",
            "  inflating: data/6034.jpg           \n",
            "  inflating: __MACOSX/data/._6034.jpg  \n",
            "  inflating: data/25976.jpg          \n",
            "  inflating: __MACOSX/data/._25976.jpg  \n",
            "  inflating: data/9307.jpg           \n",
            "  inflating: __MACOSX/data/._9307.jpg  \n",
            "  inflating: data/14573.jpg          \n",
            "  inflating: __MACOSX/data/._14573.jpg  \n",
            "  inflating: data/12116.jpg          \n",
            "  inflating: __MACOSX/data/._12116.jpg  \n",
            "  inflating: data/15679.jpg          \n",
            "  inflating: __MACOSX/data/._15679.jpg  \n",
            "  inflating: data/1997.jpg           \n",
            "  inflating: __MACOSX/data/._1997.jpg  \n",
            "  inflating: data/25962.jpg          \n",
            "  inflating: __MACOSX/data/._25962.jpg  \n",
            "  inflating: data/6020.jpg           \n",
            "  inflating: __MACOSX/data/._6020.jpg  \n",
            "  inflating: data/14567.jpg          \n",
            "  inflating: __MACOSX/data/._14567.jpg  \n",
            "  inflating: data/9313.jpg           \n",
            "  inflating: __MACOSX/data/._9313.jpg  \n",
            "  inflating: data/13208.jpg          \n",
            "  inflating: __MACOSX/data/._13208.jpg  \n",
            "  inflating: data/2246.jpg           \n",
            "  inflating: __MACOSX/data/._2246.jpg  \n",
            "  inflating: data/10701.jpg          \n",
            "  inflating: __MACOSX/data/._10701.jpg  \n",
            "  inflating: data/31917.jpg          \n",
            "  inflating: __MACOSX/data/._31917.jpg  \n",
            "  inflating: data/5529.jpg           \n",
            "  inflating: __MACOSX/data/._5529.jpg  \n",
            "  inflating: data/16370.jpg          \n",
            "  inflating: __MACOSX/data/._16370.jpg  \n",
            "  inflating: data/39393.jpg          \n",
            "  inflating: __MACOSX/data/._39393.jpg  \n",
            "  inflating: data/4637.jpg           \n",
            "  inflating: __MACOSX/data/._4637.jpg  \n",
            "  inflating: data/19043.jpg          \n",
            "  inflating: __MACOSX/data/._19043.jpg  \n",
            "  inflating: data/29180.jpg          \n",
            "  inflating: __MACOSX/data/._29180.jpg  \n",
            "  inflating: data/3158.jpg           \n",
            "  inflating: __MACOSX/data/._3158.jpg  \n",
            "  inflating: data/38933.jpg          \n",
            "  inflating: __MACOSX/data/._38933.jpg  \n",
            "  inflating: data/11379.jpg          \n",
            "  inflating: __MACOSX/data/._11379.jpg  \n",
            "  inflating: data/16416.jpg          \n",
            "  inflating: __MACOSX/data/._16416.jpg  \n",
            "  inflating: data/4151.jpg           \n",
            "  inflating: __MACOSX/data/._4151.jpg  \n",
            "  inflating: data/19725.jpg          \n",
            "  inflating: __MACOSX/data/._19725.jpg  \n",
            "  inflating: data/27813.jpg          \n",
            "  inflating: __MACOSX/data/._27813.jpg  \n",
            "  inflating: data/17708.jpg          \n",
            "  inflating: __MACOSX/data/._17708.jpg  \n",
            "  inflating: data/2520.jpg           \n",
            "  inflating: __MACOSX/data/._2520.jpg  \n",
            "  inflating: data/10067.jpg          \n",
            "  inflating: __MACOSX/data/._10067.jpg  \n",
            "  inflating: data/1029.jpg           \n",
            "  inflating: __MACOSX/data/._1029.jpg  \n",
            "  inflating: data/6746.jpg           \n",
            "  inflating: __MACOSX/data/._6746.jpg  \n",
            "  inflating: data/14201.jpg          \n",
            "  inflating: __MACOSX/data/._14201.jpg  \n",
            "  inflating: data/9475.jpg           \n",
            "  inflating: __MACOSX/data/._9475.jpg  \n",
            "  inflating: data/7458.jpg           \n",
            "  inflating: __MACOSX/data/._7458.jpg  \n",
            "  inflating: data/33866.jpg          \n",
            "  inflating: __MACOSX/data/._33866.jpg  \n",
            "  inflating: data/12670.jpg          \n",
            "  inflating: __MACOSX/data/._12670.jpg  \n",
            "  inflating: data/8780.jpg           \n",
            "  inflating: __MACOSX/data/._8780.jpg  \n",
            "  inflating: data/22758.jpg          \n",
            "  inflating: __MACOSX/data/._22758.jpg  \n",
            "  inflating: data/35224.jpg          \n",
            "  inflating: __MACOSX/data/._35224.jpg  \n",
            "  inflating: data/6975.jpg           \n",
            "  inflating: __MACOSX/data/._6975.jpg  \n",
            "  inflating: data/25037.jpg          \n",
            "  inflating: __MACOSX/data/._25037.jpg  \n",
            "  inflating: data/8958.jpg           \n",
            "  inflating: __MACOSX/data/._8958.jpg  \n",
            "  inflating: data/33655.jpg          \n",
            "  inflating: __MACOSX/data/._33655.jpg  \n",
            "  inflating: data/556.jpg            \n",
            "  inflating: __MACOSX/data/._556.jpg  \n",
            "  inflating: data/22980.jpg          \n",
            "  inflating: __MACOSX/data/._22980.jpg  \n",
            "  inflating: data/13585.jpg          \n",
            "  inflating: __MACOSX/data/._13585.jpg  \n",
            "  inflating: data/24329.jpg          \n",
            "  inflating: __MACOSX/data/._24329.jpg  \n",
            "  inflating: data/23446.jpg          \n",
            "  inflating: __MACOSX/data/._23446.jpg  \n",
            "  inflating: data/12843.jpg          \n",
            "  inflating: __MACOSX/data/._12843.jpg  \n",
            "  inflating: data/37433.jpg          \n",
            "  inflating: __MACOSX/data/._37433.jpg  \n",
            "  inflating: data/38700.jpg          \n",
            "  inflating: __MACOSX/data/._38700.jpg  \n",
            "  inflating: data/19916.jpg          \n",
            "  inflating: __MACOSX/data/._19916.jpg  \n",
            "  inflating: data/27620.jpg          \n",
            "  inflating: __MACOSX/data/._27620.jpg  \n",
            "  inflating: data/28513.jpg          \n",
            "  inflating: __MACOSX/data/._28513.jpg  \n",
            "  inflating: data/11392.jpg          \n",
            "  inflating: __MACOSX/data/._11392.jpg  \n",
            "  inflating: data/31042.jpg          \n",
            "  inflating: __MACOSX/data/._31042.jpg  \n",
            "  inflating: data/21251.jpg          \n",
            "  inflating: __MACOSX/data/._21251.jpg  \n",
            "  inflating: data/10932.jpg          \n",
            "  inflating: __MACOSX/data/._10932.jpg  \n",
            "  inflating: data/21537.jpg          \n",
            "  inflating: __MACOSX/data/._21537.jpg  \n",
            "  inflating: data/39378.jpg          \n",
            "  inflating: __MACOSX/data/._39378.jpg  \n",
            "  inflating: data/26258.jpg          \n",
            "  inflating: __MACOSX/data/._26258.jpg  \n",
            "  inflating: data/31724.jpg          \n",
            "  inflating: __MACOSX/data/._31724.jpg  \n",
            "  inflating: data/27146.jpg          \n",
            "  inflating: __MACOSX/data/._27146.jpg  \n",
            "  inflating: data/4804.jpg           \n",
            "  inflating: __MACOSX/data/._4804.jpg  \n",
            "  inflating: data/28275.jpg          \n",
            "  inflating: __MACOSX/data/._28275.jpg  \n",
            "  inflating: data/37355.jpg          \n",
            "  inflating: __MACOSX/data/._37355.jpg  \n",
            "  inflating: data/38066.jpg          \n",
            "  inflating: __MACOSX/data/._38066.jpg  \n",
            "  inflating: data/17085.jpg          \n",
            "  inflating: __MACOSX/data/._17085.jpg  \n",
            "  inflating: data/20629.jpg          \n",
            "  inflating: __MACOSX/data/._20629.jpg  \n",
            "  inflating: data/23320.jpg          \n",
            "  inflating: __MACOSX/data/._23320.jpg  \n",
            "  inflating: data/25989.jpg          \n",
            "  inflating: __MACOSX/data/._25989.jpg  \n",
            "  inflating: data/230.jpg            \n",
            "  inflating: __MACOSX/data/._230.jpg  \n",
            "  inflating: data/33133.jpg          \n",
            "  inflating: __MACOSX/data/._33133.jpg  \n",
            "  inflating: data/25751.jpg          \n",
            "  inflating: __MACOSX/data/._25751.jpg  \n",
            "  inflating: data/34884.jpg          \n",
            "  inflating: __MACOSX/data/._34884.jpg  \n",
            "  inflating: data/15692.jpg          \n",
            "  inflating: __MACOSX/data/._15692.jpg  \n",
            "  inflating: data/35542.jpg          \n",
            "  inflating: __MACOSX/data/._35542.jpg  \n",
            "  inflating: data/14598.jpg          \n",
            "  inflating: __MACOSX/data/._14598.jpg  \n",
            "  inflating: data/23334.jpg          \n",
            "  inflating: __MACOSX/data/._23334.jpg  \n",
            "  inflating: data/34648.jpg          \n",
            "  inflating: __MACOSX/data/._34648.jpg  \n",
            "  inflating: data/33127.jpg          \n",
            "  inflating: __MACOSX/data/._33127.jpg  \n",
            "  inflating: data/224.jpg            \n",
            "  inflating: __MACOSX/data/._224.jpg  \n",
            "  inflating: data/32239.jpg          \n",
            "  inflating: __MACOSX/data/._32239.jpg  \n",
            "  inflating: data/34890.jpg          \n",
            "  inflating: __MACOSX/data/._34890.jpg  \n",
            "  inflating: data/25745.jpg          \n",
            "  inflating: __MACOSX/data/._25745.jpg  \n",
            "  inflating: data/1968.jpg           \n",
            "  inflating: __MACOSX/data/._1968.jpg  \n",
            "  inflating: data/15686.jpg          \n",
            "  inflating: __MACOSX/data/._15686.jpg  \n",
            "  inflating: data/35556.jpg          \n",
            "  inflating: __MACOSX/data/._35556.jpg  \n",
            "  inflating: data/10926.jpg          \n",
            "  inflating: __MACOSX/data/._10926.jpg  \n",
            "  inflating: data/21523.jpg          \n",
            "  inflating: __MACOSX/data/._21523.jpg  \n",
            "  inflating: data/31730.jpg          \n",
            "  inflating: __MACOSX/data/._31730.jpg  \n",
            "  inflating: data/4810.jpg           \n",
            "  inflating: __MACOSX/data/._4810.jpg  \n",
            "  inflating: data/27152.jpg          \n",
            "  inflating: __MACOSX/data/._27152.jpg  \n",
            "  inflating: data/28261.jpg          \n",
            "  inflating: __MACOSX/data/._28261.jpg  \n",
            "  inflating: data/37341.jpg          \n",
            "  inflating: __MACOSX/data/._37341.jpg  \n",
            "  inflating: data/17091.jpg          \n",
            "  inflating: __MACOSX/data/._17091.jpg  \n",
            "  inflating: data/38072.jpg          \n",
            "  inflating: __MACOSX/data/._38072.jpg  \n",
            "  inflating: data/37427.jpg          \n",
            "  inflating: __MACOSX/data/._37427.jpg  \n",
            "  inflating: data/3819.jpg           \n",
            "  inflating: __MACOSX/data/._3819.jpg  \n",
            "  inflating: data/38714.jpg          \n",
            "  inflating: __MACOSX/data/._38714.jpg  \n",
            "  inflating: data/10098.jpg          \n",
            "  inflating: __MACOSX/data/._10098.jpg  \n",
            "  inflating: data/27634.jpg          \n",
            "  inflating: __MACOSX/data/._27634.jpg  \n",
            "  inflating: data/19902.jpg          \n",
            "  inflating: __MACOSX/data/._19902.jpg  \n",
            "  inflating: data/28507.jpg          \n",
            "  inflating: __MACOSX/data/._28507.jpg  \n",
            "  inflating: data/30348.jpg          \n",
            "  inflating: __MACOSX/data/._30348.jpg  \n",
            "  inflating: data/11386.jpg          \n",
            "  inflating: __MACOSX/data/._11386.jpg  \n",
            "  inflating: data/31056.jpg          \n",
            "  inflating: __MACOSX/data/._31056.jpg  \n",
            "  inflating: data/29619.jpg          \n",
            "  inflating: __MACOSX/data/._29619.jpg  \n",
            "  inflating: data/36739.jpg          \n",
            "  inflating: __MACOSX/data/._36739.jpg  \n",
            "  inflating: data/21245.jpg          \n",
            "  inflating: __MACOSX/data/._21245.jpg  \n",
            "  inflating: data/33899.jpg          \n",
            "  inflating: __MACOSX/data/._33899.jpg  \n",
            "  inflating: data/8794.jpg           \n",
            "  inflating: __MACOSX/data/._8794.jpg  \n",
            "  inflating: data/35230.jpg          \n",
            "  inflating: __MACOSX/data/._35230.jpg  \n",
            "  inflating: data/25023.jpg          \n",
            "  inflating: __MACOSX/data/._25023.jpg  \n",
            "  inflating: data/6961.jpg           \n",
            "  inflating: __MACOSX/data/._6961.jpg  \n",
            "  inflating: data/22994.jpg          \n",
            "  inflating: __MACOSX/data/._22994.jpg  \n",
            "  inflating: data/542.jpg            \n",
            "  inflating: __MACOSX/data/._542.jpg  \n",
            "  inflating: data/33641.jpg          \n",
            "  inflating: __MACOSX/data/._33641.jpg  \n",
            "  inflating: data/13591.jpg          \n",
            "  inflating: __MACOSX/data/._13591.jpg  \n",
            "  inflating: data/23452.jpg          \n",
            "  inflating: __MACOSX/data/._23452.jpg  \n",
            "  inflating: data/12857.jpg          \n",
            "  inflating: __MACOSX/data/._12857.jpg  \n",
            "  inflating: data/20173.jpg          \n",
            "  inflating: __MACOSX/data/._20173.jpg  \n",
            "  inflating: data/3831.jpg           \n",
            "  inflating: __MACOSX/data/._3831.jpg  \n",
            "  inflating: data/5298.jpg           \n",
            "  inflating: __MACOSX/data/._5298.jpg  \n",
            "  inflating: data/30360.jpg          \n",
            "  inflating: __MACOSX/data/._30360.jpg  \n",
            "  inflating: data/29631.jpg          \n",
            "  inflating: __MACOSX/data/._29631.jpg  \n",
            "  inflating: data/17907.jpg          \n",
            "  inflating: __MACOSX/data/._17907.jpg  \n",
            "  inflating: data/26502.jpg          \n",
            "  inflating: __MACOSX/data/._26502.jpg  \n",
            "  inflating: data/39422.jpg          \n",
            "  inflating: __MACOSX/data/._39422.jpg  \n",
            "  inflating: data/36711.jpg          \n",
            "  inflating: __MACOSX/data/._36711.jpg  \n",
            "  inflating: data/4186.jpg           \n",
            "  inflating: __MACOSX/data/._4186.jpg  \n",
            "  inflating: data/35218.jpg          \n",
            "  inflating: __MACOSX/data/._35218.jpg  \n",
            "  inflating: data/22764.jpg          \n",
            "  inflating: __MACOSX/data/._22764.jpg  \n",
            "  inflating: data/6949.jpg           \n",
            "  inflating: __MACOSX/data/._6949.jpg  \n",
            "  inflating: data/32577.jpg          \n",
            "  inflating: __MACOSX/data/._32577.jpg  \n",
            "  inflating: data/24315.jpg          \n",
            "  inflating: __MACOSX/data/._24315.jpg  \n",
            "  inflating: data/8964.jpg           \n",
            "  inflating: __MACOSX/data/._8964.jpg  \n",
            "  inflating: data/33669.jpg          \n",
            "  inflating: __MACOSX/data/._33669.jpg  \n",
            "  inflating: data/34106.jpg          \n",
            "  inflating: __MACOSX/data/._34106.jpg  \n",
            "  inflating: data/6791.jpg           \n",
            "  inflating: __MACOSX/data/._6791.jpg  \n",
            "  inflating: data/34660.jpg          \n",
            "  inflating: __MACOSX/data/._34660.jpg  \n",
            "  inflating: data/24473.jpg          \n",
            "  inflating: __MACOSX/data/._24473.jpg  \n",
            "  inflating: data/15876.jpg          \n",
            "  inflating: __MACOSX/data/._15876.jpg  \n",
            "  inflating: data/1798.jpg           \n",
            "  inflating: __MACOSX/data/._1798.jpg  \n",
            "  inflating: data/32211.jpg          \n",
            "  inflating: __MACOSX/data/._32211.jpg  \n",
            "  inflating: data/1940.jpg           \n",
            "  inflating: __MACOSX/data/._1940.jpg  \n",
            "  inflating: data/22002.jpg          \n",
            "  inflating: __MACOSX/data/._22002.jpg  \n",
            "  inflating: data/39344.jpg          \n",
            "  inflating: __MACOSX/data/._39344.jpg  \n",
            "  inflating: data/36077.jpg          \n",
            "  inflating: __MACOSX/data/._36077.jpg  \n",
            "  inflating: data/19094.jpg          \n",
            "  inflating: __MACOSX/data/._19094.jpg  \n",
            "  inflating: data/29157.jpg          \n",
            "  inflating: __MACOSX/data/._29157.jpg  \n",
            "  inflating: data/31718.jpg          \n",
            "  inflating: __MACOSX/data/._31718.jpg  \n",
            "  inflating: data/26264.jpg          \n",
            "  inflating: __MACOSX/data/._26264.jpg  \n",
            "  inflating: data/2291.jpg           \n",
            "  inflating: __MACOSX/data/._2291.jpg  \n",
            "  inflating: data/30406.jpg          \n",
            "  inflating: __MACOSX/data/._30406.jpg  \n",
            "  inflating: data/28249.jpg          \n",
            "  inflating: __MACOSX/data/._28249.jpg  \n",
            "  inflating: data/4838.jpg           \n",
            "  inflating: __MACOSX/data/._4838.jpg  \n",
            "  inflating: data/20615.jpg          \n",
            "  inflating: __MACOSX/data/._20615.jpg  \n",
            "  inflating: data/37369.jpg          \n",
            "  inflating: __MACOSX/data/._37369.jpg  \n",
            "  inflating: data/39350.jpg          \n",
            "  inflating: __MACOSX/data/._39350.jpg  \n",
            "  inflating: data/19080.jpg          \n",
            "  inflating: __MACOSX/data/._19080.jpg  \n",
            "  inflating: data/36063.jpg          \n",
            "  inflating: __MACOSX/data/._36063.jpg  \n",
            "  inflating: data/29143.jpg          \n",
            "  inflating: __MACOSX/data/._29143.jpg  \n",
            "  inflating: data/26270.jpg          \n",
            "  inflating: __MACOSX/data/._26270.jpg  \n",
            "  inflating: data/30412.jpg          \n",
            "  inflating: __MACOSX/data/._30412.jpg  \n",
            "  inflating: data/2285.jpg           \n",
            "  inflating: __MACOSX/data/._2285.jpg  \n",
            "  inflating: data/20601.jpg          \n",
            "  inflating: __MACOSX/data/._20601.jpg  \n",
            "  inflating: data/34674.jpg          \n",
            "  inflating: __MACOSX/data/._34674.jpg  \n",
            "  inflating: data/23308.jpg          \n",
            "  inflating: __MACOSX/data/._23308.jpg  \n",
            "  inflating: data/24467.jpg          \n",
            "  inflating: __MACOSX/data/._24467.jpg  \n",
            "  inflating: data/218.jpg            \n",
            "  inflating: __MACOSX/data/._218.jpg  \n",
            "  inflating: data/15862.jpg          \n",
            "  inflating: __MACOSX/data/._15862.jpg  \n",
            "  inflating: data/25779.jpg          \n",
            "  inflating: __MACOSX/data/._25779.jpg  \n",
            "  inflating: data/32205.jpg          \n",
            "  inflating: __MACOSX/data/._32205.jpg  \n",
            "  inflating: data/22016.jpg          \n",
            "  inflating: __MACOSX/data/._22016.jpg  \n",
            "  inflating: data/1954.jpg           \n",
            "  inflating: __MACOSX/data/._1954.jpg  \n",
            "  inflating: data/22770.jpg          \n",
            "  inflating: __MACOSX/data/._22770.jpg  \n",
            "  inflating: data/32563.jpg          \n",
            "  inflating: __MACOSX/data/._32563.jpg  \n",
            "  inflating: data/24301.jpg          \n",
            "  inflating: __MACOSX/data/._24301.jpg  \n",
            "  inflating: data/8970.jpg           \n",
            "  inflating: __MACOSX/data/._8970.jpg  \n",
            "  inflating: data/6785.jpg           \n",
            "  inflating: __MACOSX/data/._6785.jpg  \n",
            "  inflating: data/34112.jpg          \n",
            "  inflating: __MACOSX/data/._34112.jpg  \n",
            "  inflating: data/3825.jpg           \n",
            "  inflating: __MACOSX/data/._3825.jpg  \n",
            "  inflating: data/20167.jpg          \n",
            "  inflating: __MACOSX/data/._20167.jpg  \n",
            "  inflating: data/38728.jpg          \n",
            "  inflating: __MACOSX/data/._38728.jpg  \n",
            "  inflating: data/30374.jpg          \n",
            "  inflating: __MACOSX/data/._30374.jpg  \n",
            "  inflating: data/27608.jpg          \n",
            "  inflating: __MACOSX/data/._27608.jpg  \n",
            "  inflating: data/17913.jpg          \n",
            "  inflating: __MACOSX/data/._17913.jpg  \n",
            "  inflating: data/29625.jpg          \n",
            "  inflating: __MACOSX/data/._29625.jpg  \n",
            "  inflating: data/26516.jpg          \n",
            "  inflating: __MACOSX/data/._26516.jpg  \n",
            "  inflating: data/39436.jpg          \n",
            "  inflating: __MACOSX/data/._39436.jpg  \n",
            "  inflating: data/21279.jpg          \n",
            "  inflating: __MACOSX/data/._21279.jpg  \n",
            "  inflating: data/4192.jpg           \n",
            "  inflating: __MACOSX/data/._4192.jpg  \n",
            "  inflating: data/36705.jpg          \n",
            "  inflating: __MACOSX/data/._36705.jpg  \n",
            "  inflating: data/3372.jpg           \n",
            "  inflating: __MACOSX/data/._3372.jpg  \n",
            "  inflating: data/11635.jpg          \n",
            "  inflating: __MACOSX/data/._11635.jpg  \n",
            "  inflating: data/26099.jpg          \n",
            "  inflating: __MACOSX/data/._26099.jpg  \n",
            "  inflating: data/30823.jpg          \n",
            "  inflating: __MACOSX/data/._30823.jpg  \n",
            "  inflating: data/19269.jpg          \n",
            "  inflating: __MACOSX/data/._19269.jpg  \n",
            "  inflating: data/17244.jpg          \n",
            "  inflating: __MACOSX/data/._17244.jpg  \n",
            "  inflating: data/5703.jpg           \n",
            "  inflating: __MACOSX/data/._5703.jpg  \n",
            "  inflating: data/37194.jpg          \n",
            "  inflating: __MACOSX/data/._37194.jpg  \n",
            "  inflating: data/18177.jpg          \n",
            "  inflating: __MACOSX/data/._18177.jpg  \n",
            "  inflating: data/27387.jpg          \n",
            "  inflating: __MACOSX/data/._27387.jpg  \n",
            "  inflating: data/13022.jpg          \n",
            "  inflating: __MACOSX/data/._13022.jpg  \n",
            "  inflating: data/1565.jpg           \n",
            "  inflating: __MACOSX/data/._1565.jpg  \n",
            "  inflating: data/9139.jpg           \n",
            "  inflating: __MACOSX/data/._9139.jpg  \n",
            "  inflating: data/7114.jpg           \n",
            "  inflating: __MACOSX/data/._7114.jpg  \n",
            "  inflating: data/35783.jpg          \n",
            "  inflating: __MACOSX/data/._35783.jpg  \n",
            "  inflating: data/24856.jpg          \n",
            "  inflating: __MACOSX/data/._24856.jpg  \n",
            "  inflating: data/15453.jpg          \n",
            "  inflating: __MACOSX/data/._15453.jpg  \n",
            "  inflating: data/8227.jpg           \n",
            "  inflating: __MACOSX/data/._8227.jpg  \n",
            "  inflating: data/25590.jpg          \n",
            "  inflating: __MACOSX/data/._25590.jpg  \n",
            "  inflating: data/14995.jpg          \n",
            "  inflating: __MACOSX/data/._14995.jpg  \n",
            "  inflating: data/9887.jpg           \n",
            "  inflating: __MACOSX/data/._9887.jpg  \n",
            "  inflating: data/7672.jpg           \n",
            "  inflating: __MACOSX/data/._7672.jpg  \n",
            "  inflating: data/15335.jpg          \n",
            "  inflating: __MACOSX/data/._15335.jpg  \n",
            "  inflating: data/8541.jpg           \n",
            "  inflating: __MACOSX/data/._8541.jpg  \n",
            "  inflating: data/22599.jpg          \n",
            "  inflating: __MACOSX/data/._22599.jpg  \n",
            "  inflating: data/23687.jpg          \n",
            "  inflating: __MACOSX/data/._23687.jpg  \n",
            "  inflating: data/32952.jpg          \n",
            "  inflating: __MACOSX/data/._32952.jpg  \n",
            "  inflating: data/13744.jpg          \n",
            "  inflating: __MACOSX/data/._13744.jpg  \n",
            "  inflating: data/797.jpg            \n",
            "  inflating: __MACOSX/data/._797.jpg  \n",
            "  inflating: data/33494.jpg          \n",
            "  inflating: __MACOSX/data/._33494.jpg  \n",
            "  inflating: data/1203.jpg           \n",
            "  inflating: __MACOSX/data/._1203.jpg  \n",
            "  inflating: data/39807.jpg          \n",
            "  inflating: __MACOSX/data/._39807.jpg  \n",
            "  inflating: data/17522.jpg          \n",
            "  inflating: __MACOSX/data/._17522.jpg  \n",
            "  inflating: data/26927.jpg          \n",
            "  inflating: __MACOSX/data/._26927.jpg  \n",
            "  inflating: data/5065.jpg           \n",
            "  inflating: __MACOSX/data/._5065.jpg  \n",
            "  inflating: data/18611.jpg          \n",
            "  inflating: __MACOSX/data/._18611.jpg  \n",
            "  inflating: data/21090.jpg          \n",
            "  inflating: __MACOSX/data/._21090.jpg  \n",
            "  inflating: data/31283.jpg          \n",
            "  inflating: __MACOSX/data/._31283.jpg  \n",
            "  inflating: data/3414.jpg           \n",
            "  inflating: __MACOSX/data/._3414.jpg  \n",
            "  inflating: data/11153.jpg          \n",
            "  inflating: __MACOSX/data/._11153.jpg  \n",
            "  inflating: data/39813.jpg          \n",
            "  inflating: __MACOSX/data/._39813.jpg  \n",
            "  inflating: data/30189.jpg          \n",
            "  inflating: __MACOSX/data/._30189.jpg  \n",
            "  inflating: data/10259.jpg          \n",
            "  inflating: __MACOSX/data/._10259.jpg  \n",
            "  inflating: data/17536.jpg          \n",
            "  inflating: __MACOSX/data/._17536.jpg  \n",
            "  inflating: data/18605.jpg          \n",
            "  inflating: __MACOSX/data/._18605.jpg  \n",
            "  inflating: data/5071.jpg           \n",
            "  inflating: __MACOSX/data/._5071.jpg  \n",
            "  inflating: data/26933.jpg          \n",
            "  inflating: __MACOSX/data/._26933.jpg  \n",
            "  inflating: data/16628.jpg          \n",
            "  inflating: __MACOSX/data/._16628.jpg  \n",
            "  inflating: data/21084.jpg          \n",
            "  inflating: __MACOSX/data/._21084.jpg  \n",
            "  inflating: data/3400.jpg           \n",
            "  inflating: __MACOSX/data/._3400.jpg  \n",
            "  inflating: data/31297.jpg          \n",
            "  inflating: __MACOSX/data/._31297.jpg  \n",
            "  inflating: data/11147.jpg          \n",
            "  inflating: __MACOSX/data/._11147.jpg  \n",
            "  inflating: data/9893.jpg           \n",
            "  inflating: __MACOSX/data/._9893.jpg  \n",
            "  inflating: data/7666.jpg           \n",
            "  inflating: __MACOSX/data/._7666.jpg  \n",
            "  inflating: data/13988.jpg          \n",
            "  inflating: __MACOSX/data/._13988.jpg  \n",
            "  inflating: data/8555.jpg           \n",
            "  inflating: __MACOSX/data/._8555.jpg  \n",
            "  inflating: data/15321.jpg          \n",
            "  inflating: __MACOSX/data/._15321.jpg  \n",
            "  inflating: data/6578.jpg           \n",
            "  inflating: __MACOSX/data/._6578.jpg  \n",
            "  inflating: data/32946.jpg          \n",
            "  inflating: __MACOSX/data/._32946.jpg  \n",
            "  inflating: data/23693.jpg          \n",
            "  inflating: __MACOSX/data/._23693.jpg  \n",
            "  inflating: data/13750.jpg          \n",
            "  inflating: __MACOSX/data/._13750.jpg  \n",
            "  inflating: data/1217.jpg           \n",
            "  inflating: __MACOSX/data/._1217.jpg  \n",
            "  inflating: data/33480.jpg          \n",
            "  inflating: __MACOSX/data/._33480.jpg  \n",
            "  inflating: data/783.jpg            \n",
            "  inflating: __MACOSX/data/._783.jpg  \n",
            "  inflating: data/13036.jpg          \n",
            "  inflating: __MACOSX/data/._13036.jpg  \n",
            "  inflating: data/1571.jpg           \n",
            "  inflating: __MACOSX/data/._1571.jpg  \n",
            "  inflating: data/34489.jpg          \n",
            "  inflating: __MACOSX/data/._34489.jpg  \n",
            "  inflating: data/14759.jpg          \n",
            "  inflating: __MACOSX/data/._14759.jpg  \n",
            "  inflating: data/24842.jpg          \n",
            "  inflating: __MACOSX/data/._24842.jpg  \n",
            "  inflating: data/35797.jpg          \n",
            "  inflating: __MACOSX/data/._35797.jpg  \n",
            "  inflating: data/7100.jpg           \n",
            "  inflating: __MACOSX/data/._7100.jpg  \n",
            "  inflating: data/8233.jpg           \n",
            "  inflating: __MACOSX/data/._8233.jpg  \n",
            "  inflating: data/15447.jpg          \n",
            "  inflating: __MACOSX/data/._15447.jpg  \n",
            "  inflating: data/12328.jpg          \n",
            "  inflating: __MACOSX/data/._12328.jpg  \n",
            "  inflating: data/25584.jpg          \n",
            "  inflating: __MACOSX/data/._25584.jpg  \n",
            "  inflating: data/14981.jpg          \n",
            "  inflating: __MACOSX/data/._14981.jpg  \n",
            "  inflating: data/3366.jpg           \n",
            "  inflating: __MACOSX/data/._3366.jpg  \n",
            "  inflating: data/11621.jpg          \n",
            "  inflating: __MACOSX/data/._11621.jpg  \n",
            "  inflating: data/30837.jpg          \n",
            "  inflating: __MACOSX/data/._30837.jpg  \n",
            "  inflating: data/4409.jpg           \n",
            "  inflating: __MACOSX/data/._4409.jpg  \n",
            "  inflating: data/17250.jpg          \n",
            "  inflating: __MACOSX/data/._17250.jpg  \n",
            "  inflating: data/18163.jpg          \n",
            "  inflating: __MACOSX/data/._18163.jpg  \n",
            "  inflating: data/37180.jpg          \n",
            "  inflating: __MACOSX/data/._37180.jpg  \n",
            "  inflating: data/5717.jpg           \n",
            "  inflating: __MACOSX/data/._5717.jpg  \n",
            "  inflating: data/2078.jpg           \n",
            "  inflating: __MACOSX/data/._2078.jpg  \n",
            "  inflating: data/27393.jpg          \n",
            "  inflating: __MACOSX/data/._27393.jpg  \n",
            "  inflating: data/1559.jpg           \n",
            "  inflating: __MACOSX/data/._1559.jpg  \n",
            "  inflating: data/35967.jpg          \n",
            "  inflating: __MACOSX/data/._35967.jpg  \n",
            "  inflating: data/9105.jpg           \n",
            "  inflating: __MACOSX/data/._9105.jpg  \n",
            "  inflating: data/14771.jpg          \n",
            "  inflating: __MACOSX/data/._14771.jpg  \n",
            "  inflating: data/6236.jpg           \n",
            "  inflating: __MACOSX/data/._6236.jpg  \n",
            "  inflating: data/7128.jpg           \n",
            "  inflating: __MACOSX/data/._7128.jpg  \n",
            "  inflating: data/12300.jpg          \n",
            "  inflating: __MACOSX/data/._12300.jpg  \n",
            "  inflating: data/11609.jpg          \n",
            "  inflating: __MACOSX/data/._11609.jpg  \n",
            "  inflating: data/29396.jpg          \n",
            "  inflating: __MACOSX/data/._29396.jpg  \n",
            "  inflating: data/19255.jpg          \n",
            "  inflating: __MACOSX/data/._19255.jpg  \n",
            "  inflating: data/4421.jpg           \n",
            "  inflating: __MACOSX/data/._4421.jpg  \n",
            "  inflating: data/39185.jpg          \n",
            "  inflating: __MACOSX/data/._39185.jpg  \n",
            "  inflating: data/16166.jpg          \n",
            "  inflating: __MACOSX/data/._16166.jpg  \n",
            "  inflating: data/17278.jpg          \n",
            "  inflating: __MACOSX/data/._17278.jpg  \n",
            "  inflating: data/10517.jpg          \n",
            "  inflating: __MACOSX/data/._10517.jpg  \n",
            "  inflating: data/21912.jpg          \n",
            "  inflating: __MACOSX/data/._21912.jpg  \n",
            "  inflating: data/2050.jpg           \n",
            "  inflating: __MACOSX/data/._2050.jpg  \n",
            "  inflating: data/28088.jpg          \n",
            "  inflating: __MACOSX/data/._28088.jpg  \n",
            "  inflating: data/10271.jpg          \n",
            "  inflating: __MACOSX/data/._10271.jpg  \n",
            "  inflating: data/2736.jpg           \n",
            "  inflating: __MACOSX/data/._2736.jpg  \n",
            "  inflating: data/5059.jpg           \n",
            "  inflating: __MACOSX/data/._5059.jpg  \n",
            "  inflating: data/19533.jpg          \n",
            "  inflating: __MACOSX/data/._19533.jpg  \n",
            "  inflating: data/4347.jpg           \n",
            "  inflating: __MACOSX/data/._4347.jpg  \n",
            "  inflating: data/16600.jpg          \n",
            "  inflating: __MACOSX/data/._16600.jpg  \n",
            "  inflating: data/28936.jpg          \n",
            "  inflating: __MACOSX/data/._28936.jpg  \n",
            "  inflating: data/37816.jpg          \n",
            "  inflating: __MACOSX/data/._37816.jpg  \n",
            "  inflating: data/3428.jpg           \n",
            "  inflating: __MACOSX/data/._3428.jpg  \n",
            "  inflating: data/23863.jpg          \n",
            "  inflating: __MACOSX/data/._23863.jpg  \n",
            "  inflating: data/12466.jpg          \n",
            "  inflating: __MACOSX/data/._12466.jpg  \n",
            "  inflating: data/15309.jpg          \n",
            "  inflating: __MACOSX/data/._15309.jpg  \n",
            "  inflating: data/973.jpg            \n",
            "  inflating: __MACOSX/data/._973.jpg  \n",
            "  inflating: data/9663.jpg           \n",
            "  inflating: __MACOSX/data/._9663.jpg  \n",
            "  inflating: data/14017.jpg          \n",
            "  inflating: __MACOSX/data/._14017.jpg  \n",
            "  inflating: data/6550.jpg           \n",
            "  inflating: __MACOSX/data/._6550.jpg  \n",
            "  inflating: data/13778.jpg          \n",
            "  inflating: __MACOSX/data/._13778.jpg  \n",
            "  inflating: data/7896.jpg           \n",
            "  inflating: __MACOSX/data/._7896.jpg  \n",
            "  inflating: data/23877.jpg          \n",
            "  inflating: __MACOSX/data/._23877.jpg  \n",
            "  inflating: data/12472.jpg          \n",
            "  inflating: __MACOSX/data/._12472.jpg  \n",
            "  inflating: data/967.jpg            \n",
            "  inflating: __MACOSX/data/._967.jpg  \n",
            "  inflating: data/8569.jpg           \n",
            "  inflating: __MACOSX/data/._8569.jpg  \n",
            "  inflating: data/14003.jpg          \n",
            "  inflating: __MACOSX/data/._14003.jpg  \n",
            "  inflating: data/9677.jpg           \n",
            "  inflating: __MACOSX/data/._9677.jpg  \n",
            "  inflating: data/6544.jpg           \n",
            "  inflating: __MACOSX/data/._6544.jpg  \n",
            "  inflating: data/7882.jpg           \n",
            "  inflating: __MACOSX/data/._7882.jpg  \n",
            "  inflating: data/10265.jpg          \n",
            "  inflating: __MACOSX/data/._10265.jpg  \n",
            "  inflating: data/2722.jpg           \n",
            "  inflating: __MACOSX/data/._2722.jpg  \n",
            "  inflating: data/18639.jpg          \n",
            "  inflating: __MACOSX/data/._18639.jpg  \n",
            "  inflating: data/4353.jpg           \n",
            "  inflating: __MACOSX/data/._4353.jpg  \n",
            "  inflating: data/19527.jpg          \n",
            "  inflating: __MACOSX/data/._19527.jpg  \n",
            "  inflating: data/28922.jpg          \n",
            "  inflating: __MACOSX/data/._28922.jpg  \n",
            "  inflating: data/16614.jpg          \n",
            "  inflating: __MACOSX/data/._16614.jpg  \n",
            "  inflating: data/37802.jpg          \n",
            "  inflating: __MACOSX/data/._37802.jpg  \n",
            "  inflating: data/29382.jpg          \n",
            "  inflating: __MACOSX/data/._29382.jpg  \n",
            "  inflating: data/4435.jpg           \n",
            "  inflating: __MACOSX/data/._4435.jpg  \n",
            "  inflating: data/19241.jpg          \n",
            "  inflating: __MACOSX/data/._19241.jpg  \n",
            "  inflating: data/16172.jpg          \n",
            "  inflating: __MACOSX/data/._16172.jpg  \n",
            "  inflating: data/39191.jpg          \n",
            "  inflating: __MACOSX/data/._39191.jpg  \n",
            "  inflating: data/10503.jpg          \n",
            "  inflating: __MACOSX/data/._10503.jpg  \n",
            "  inflating: data/2044.jpg           \n",
            "  inflating: __MACOSX/data/._2044.jpg  \n",
            "  inflating: data/21906.jpg          \n",
            "  inflating: __MACOSX/data/._21906.jpg  \n",
            "  inflating: data/35973.jpg          \n",
            "  inflating: __MACOSX/data/._35973.jpg  \n",
            "  inflating: data/14765.jpg          \n",
            "  inflating: __MACOSX/data/._14765.jpg  \n",
            "  inflating: data/9111.jpg           \n",
            "  inflating: __MACOSX/data/._9111.jpg  \n",
            "  inflating: data/6222.jpg           \n",
            "  inflating: __MACOSX/data/._6222.jpg  \n",
            "  inflating: data/12314.jpg          \n",
            "  inflating: __MACOSX/data/._12314.jpg  \n",
            "  inflating: data/35740.jpg          \n",
            "  inflating: __MACOSX/data/._35740.jpg  \n",
            "  inflating: data/24895.jpg          \n",
            "  inflating: __MACOSX/data/._24895.jpg  \n",
            "  inflating: data/15490.jpg          \n",
            "  inflating: __MACOSX/data/._15490.jpg  \n",
            "  inflating: data/25553.jpg          \n",
            "  inflating: __MACOSX/data/._25553.jpg  \n",
            "  inflating: data/14956.jpg          \n",
            "  inflating: __MACOSX/data/._14956.jpg  \n",
            "  inflating: data/35998.jpg          \n",
            "  inflating: __MACOSX/data/._35998.jpg  \n",
            "  inflating: data/33331.jpg          \n",
            "  inflating: __MACOSX/data/._33331.jpg  \n",
            "  inflating: data/23122.jpg          \n",
            "  inflating: __MACOSX/data/._23122.jpg  \n",
            "  inflating: data/38264.jpg          \n",
            "  inflating: __MACOSX/data/._38264.jpg  \n",
            "  inflating: data/17287.jpg          \n",
            "  inflating: __MACOSX/data/._17287.jpg  \n",
            "  inflating: data/37157.jpg          \n",
            "  inflating: __MACOSX/data/._37157.jpg  \n",
            "  inflating: data/28077.jpg          \n",
            "  inflating: __MACOSX/data/._28077.jpg  \n",
            "  inflating: data/30638.jpg          \n",
            "  inflating: __MACOSX/data/._30638.jpg  \n",
            "  inflating: data/27344.jpg          \n",
            "  inflating: __MACOSX/data/._27344.jpg  \n",
            "  inflating: data/31526.jpg          \n",
            "  inflating: __MACOSX/data/._31526.jpg  \n",
            "  inflating: data/29369.jpg          \n",
            "  inflating: __MACOSX/data/._29369.jpg  \n",
            "  inflating: data/5918.jpg           \n",
            "  inflating: __MACOSX/data/._5918.jpg  \n",
            "  inflating: data/16199.jpg          \n",
            "  inflating: __MACOSX/data/._16199.jpg  \n",
            "  inflating: data/21735.jpg          \n",
            "  inflating: __MACOSX/data/._21735.jpg  \n",
            "  inflating: data/36249.jpg          \n",
            "  inflating: __MACOSX/data/._36249.jpg  \n",
            "  inflating: data/21053.jpg          \n",
            "  inflating: __MACOSX/data/._21053.jpg  \n",
            "  inflating: data/2911.jpg           \n",
            "  inflating: __MACOSX/data/._2911.jpg  \n",
            "  inflating: data/31240.jpg          \n",
            "  inflating: __MACOSX/data/._31240.jpg  \n",
            "  inflating: data/11190.jpg          \n",
            "  inflating: __MACOSX/data/._11190.jpg  \n",
            "  inflating: data/28711.jpg          \n",
            "  inflating: __MACOSX/data/._28711.jpg  \n",
            "  inflating: data/16827.jpg          \n",
            "  inflating: __MACOSX/data/._16827.jpg  \n",
            "  inflating: data/27422.jpg          \n",
            "  inflating: __MACOSX/data/._27422.jpg  \n",
            "  inflating: data/38502.jpg          \n",
            "  inflating: __MACOSX/data/._38502.jpg  \n",
            "  inflating: data/37631.jpg          \n",
            "  inflating: __MACOSX/data/._37631.jpg  \n",
            "  inflating: data/34338.jpg          \n",
            "  inflating: __MACOSX/data/._34338.jpg  \n",
            "  inflating: data/23644.jpg          \n",
            "  inflating: __MACOSX/data/._23644.jpg  \n",
            "  inflating: data/32991.jpg          \n",
            "  inflating: __MACOSX/data/._32991.jpg  \n",
            "  inflating: data/7869.jpg           \n",
            "  inflating: __MACOSX/data/._7869.jpg  \n",
            "  inflating: data/13787.jpg          \n",
            "  inflating: __MACOSX/data/._13787.jpg  \n",
            "  inflating: data/754.jpg            \n",
            "  inflating: __MACOSX/data/._754.jpg  \n",
            "  inflating: data/33457.jpg          \n",
            "  inflating: __MACOSX/data/._33457.jpg  \n",
            "  inflating: data/12499.jpg          \n",
            "  inflating: __MACOSX/data/._12499.jpg  \n",
            "  inflating: data/25235.jpg          \n",
            "  inflating: __MACOSX/data/._25235.jpg  \n",
            "  inflating: data/9844.jpg           \n",
            "  inflating: __MACOSX/data/._9844.jpg  \n",
            "  inflating: data/32749.jpg          \n",
            "  inflating: __MACOSX/data/._32749.jpg  \n",
            "  inflating: data/35026.jpg          \n",
            "  inflating: __MACOSX/data/._35026.jpg  \n",
            "  inflating: data/8582.jpg           \n",
            "  inflating: __MACOSX/data/._8582.jpg  \n",
            "  inflating: data/32985.jpg          \n",
            "  inflating: __MACOSX/data/._32985.jpg  \n",
            "  inflating: data/23650.jpg          \n",
            "  inflating: __MACOSX/data/._23650.jpg  \n",
            "  inflating: data/9688.jpg           \n",
            "  inflating: __MACOSX/data/._9688.jpg  \n",
            "  inflating: data/13793.jpg          \n",
            "  inflating: __MACOSX/data/._13793.jpg  \n",
            "  inflating: data/33443.jpg          \n",
            "  inflating: __MACOSX/data/._33443.jpg  \n",
            "  inflating: data/740.jpg            \n",
            "  inflating: __MACOSX/data/._740.jpg  \n",
            "  inflating: data/25221.jpg          \n",
            "  inflating: __MACOSX/data/._25221.jpg  \n",
            "  inflating: data/23888.jpg          \n",
            "  inflating: __MACOSX/data/._23888.jpg  \n",
            "  inflating: data/9850.jpg           \n",
            "  inflating: __MACOSX/data/._9850.jpg  \n",
            "  inflating: data/35032.jpg          \n",
            "  inflating: __MACOSX/data/._35032.jpg  \n",
            "  inflating: data/8596.jpg           \n",
            "  inflating: __MACOSX/data/._8596.jpg  \n",
            "  inflating: data/998.jpg            \n",
            "  inflating: __MACOSX/data/._998.jpg  \n",
            "  inflating: data/2905.jpg           \n",
            "  inflating: __MACOSX/data/._2905.jpg  \n",
            "  inflating: data/21047.jpg          \n",
            "  inflating: __MACOSX/data/._21047.jpg  \n",
            "  inflating: data/39608.jpg          \n",
            "  inflating: __MACOSX/data/._39608.jpg  \n",
            "  inflating: data/31254.jpg          \n",
            "  inflating: __MACOSX/data/._31254.jpg  \n",
            "  inflating: data/11184.jpg          \n",
            "  inflating: __MACOSX/data/._11184.jpg  \n",
            "  inflating: data/26728.jpg          \n",
            "  inflating: __MACOSX/data/._26728.jpg  \n",
            "  inflating: data/16833.jpg          \n",
            "  inflating: __MACOSX/data/._16833.jpg  \n",
            "  inflating: data/28705.jpg          \n",
            "  inflating: __MACOSX/data/._28705.jpg  \n",
            "  inflating: data/27436.jpg          \n",
            "  inflating: __MACOSX/data/._27436.jpg  \n",
            "  inflating: data/38516.jpg          \n",
            "  inflating: __MACOSX/data/._38516.jpg  \n",
            "  inflating: data/20359.jpg          \n",
            "  inflating: __MACOSX/data/._20359.jpg  \n",
            "  inflating: data/37625.jpg          \n",
            "  inflating: __MACOSX/data/._37625.jpg  \n",
            "  inflating: data/17293.jpg          \n",
            "  inflating: __MACOSX/data/._17293.jpg  \n",
            "  inflating: data/38270.jpg          \n",
            "  inflating: __MACOSX/data/._38270.jpg  \n",
            "  inflating: data/37143.jpg          \n",
            "  inflating: __MACOSX/data/._37143.jpg  \n",
            "  inflating: data/28063.jpg          \n",
            "  inflating: __MACOSX/data/._28063.jpg  \n",
            "  inflating: data/27350.jpg          \n",
            "  inflating: __MACOSX/data/._27350.jpg  \n",
            "  inflating: data/31532.jpg          \n",
            "  inflating: __MACOSX/data/._31532.jpg  \n",
            "  inflating: data/21721.jpg          \n",
            "  inflating: __MACOSX/data/._21721.jpg  \n",
            "  inflating: data/24881.jpg          \n",
            "  inflating: __MACOSX/data/._24881.jpg  \n",
            "  inflating: data/35754.jpg          \n",
            "  inflating: __MACOSX/data/._35754.jpg  \n",
            "  inflating: data/15484.jpg          \n",
            "  inflating: __MACOSX/data/._15484.jpg  \n",
            "  inflating: data/22228.jpg          \n",
            "  inflating: __MACOSX/data/._22228.jpg  \n",
            "  inflating: data/25547.jpg          \n",
            "  inflating: __MACOSX/data/._25547.jpg  \n",
            "  inflating: data/14942.jpg          \n",
            "  inflating: __MACOSX/data/._14942.jpg  \n",
            "  inflating: data/24659.jpg          \n",
            "  inflating: __MACOSX/data/._24659.jpg  \n",
            "  inflating: data/33325.jpg          \n",
            "  inflating: __MACOSX/data/._33325.jpg  \n",
            "  inflating: data/23136.jpg          \n",
            "  inflating: __MACOSX/data/._23136.jpg  \n",
            "  inflating: data/18188.jpg          \n",
            "  inflating: __MACOSX/data/._18188.jpg  \n",
            "  inflating: data/11812.jpg          \n",
            "  inflating: __MACOSX/data/._11812.jpg  \n",
            "  inflating: data/20417.jpg          \n",
            "  inflating: __MACOSX/data/._20417.jpg  \n",
            "  inflating: data/38258.jpg          \n",
            "  inflating: __MACOSX/data/._38258.jpg  \n",
            "  inflating: data/27378.jpg          \n",
            "  inflating: __MACOSX/data/._27378.jpg  \n",
            "  inflating: data/2093.jpg           \n",
            "  inflating: __MACOSX/data/._2093.jpg  \n",
            "  inflating: data/30604.jpg          \n",
            "  inflating: __MACOSX/data/._30604.jpg  \n",
            "  inflating: data/26066.jpg          \n",
            "  inflating: __MACOSX/data/._26066.jpg  \n",
            "  inflating: data/5924.jpg           \n",
            "  inflating: __MACOSX/data/._5924.jpg  \n",
            "  inflating: data/29355.jpg          \n",
            "  inflating: __MACOSX/data/._29355.jpg  \n",
            "  inflating: data/36275.jpg          \n",
            "  inflating: __MACOSX/data/._36275.jpg  \n",
            "  inflating: data/19296.jpg          \n",
            "  inflating: __MACOSX/data/._19296.jpg  \n",
            "  inflating: data/39146.jpg          \n",
            "  inflating: __MACOSX/data/._39146.jpg  \n",
            "  inflating: data/21709.jpg          \n",
            "  inflating: __MACOSX/data/._21709.jpg  \n",
            "  inflating: data/22200.jpg          \n",
            "  inflating: __MACOSX/data/._22200.jpg  \n",
            "  inflating: data/32013.jpg          \n",
            "  inflating: __MACOSX/data/._32013.jpg  \n",
            "  inflating: data/24671.jpg          \n",
            "  inflating: __MACOSX/data/._24671.jpg  \n",
            "  inflating: data/34462.jpg          \n",
            "  inflating: __MACOSX/data/._34462.jpg  \n",
            "  inflating: data/23678.jpg          \n",
            "  inflating: __MACOSX/data/._23678.jpg  \n",
            "  inflating: data/34304.jpg          \n",
            "  inflating: __MACOSX/data/._34304.jpg  \n",
            "  inflating: data/6593.jpg           \n",
            "  inflating: __MACOSX/data/._6593.jpg  \n",
            "  inflating: data/768.jpg            \n",
            "  inflating: __MACOSX/data/._768.jpg  \n",
            "  inflating: data/7855.jpg           \n",
            "  inflating: __MACOSX/data/._7855.jpg  \n",
            "  inflating: data/24117.jpg          \n",
            "  inflating: __MACOSX/data/._24117.jpg  \n",
            "  inflating: data/9878.jpg           \n",
            "  inflating: __MACOSX/data/._9878.jpg  \n",
            "  inflating: data/32775.jpg          \n",
            "  inflating: __MACOSX/data/._32775.jpg  \n",
            "  inflating: data/25209.jpg          \n",
            "  inflating: __MACOSX/data/._25209.jpg  \n",
            "  inflating: data/22566.jpg          \n",
            "  inflating: __MACOSX/data/._22566.jpg  \n",
            "  inflating: data/13963.jpg          \n",
            "  inflating: __MACOSX/data/._13963.jpg  \n",
            "  inflating: data/36513.jpg          \n",
            "  inflating: __MACOSX/data/._36513.jpg  \n",
            "  inflating: data/4384.jpg           \n",
            "  inflating: __MACOSX/data/._4384.jpg  \n",
            "  inflating: data/39620.jpg          \n",
            "  inflating: __MACOSX/data/._39620.jpg  \n",
            "  inflating: data/18836.jpg          \n",
            "  inflating: __MACOSX/data/._18836.jpg  \n",
            "  inflating: data/26700.jpg          \n",
            "  inflating: __MACOSX/data/._26700.jpg  \n",
            "  inflating: data/29433.jpg          \n",
            "  inflating: __MACOSX/data/._29433.jpg  \n",
            "  inflating: data/30162.jpg          \n",
            "  inflating: __MACOSX/data/._30162.jpg  \n",
            "  inflating: data/20371.jpg          \n",
            "  inflating: __MACOSX/data/._20371.jpg  \n",
            "  inflating: data/4390.jpg           \n",
            "  inflating: __MACOSX/data/._4390.jpg  \n",
            "  inflating: data/36507.jpg          \n",
            "  inflating: __MACOSX/data/._36507.jpg  \n",
            "  inflating: data/2939.jpg           \n",
            "  inflating: __MACOSX/data/._2939.jpg  \n",
            "  inflating: data/39634.jpg          \n",
            "  inflating: __MACOSX/data/._39634.jpg  \n",
            "  inflating: data/26714.jpg          \n",
            "  inflating: __MACOSX/data/._26714.jpg  \n",
            "  inflating: data/18822.jpg          \n",
            "  inflating: __MACOSX/data/._18822.jpg  \n",
            "  inflating: data/29427.jpg          \n",
            "  inflating: __MACOSX/data/._29427.jpg  \n",
            "  inflating: data/31268.jpg          \n",
            "  inflating: __MACOSX/data/._31268.jpg  \n",
            "  inflating: data/30176.jpg          \n",
            "  inflating: __MACOSX/data/._30176.jpg  \n",
            "  inflating: data/28739.jpg          \n",
            "  inflating: __MACOSX/data/._28739.jpg  \n",
            "  inflating: data/37619.jpg          \n",
            "  inflating: __MACOSX/data/._37619.jpg  \n",
            "  inflating: data/20365.jpg          \n",
            "  inflating: __MACOSX/data/._20365.jpg  \n",
            "  inflating: data/6587.jpg           \n",
            "  inflating: __MACOSX/data/._6587.jpg  \n",
            "  inflating: data/34310.jpg          \n",
            "  inflating: __MACOSX/data/._34310.jpg  \n",
            "  inflating: data/24103.jpg          \n",
            "  inflating: __MACOSX/data/._24103.jpg  \n",
            "  inflating: data/7841.jpg           \n",
            "  inflating: __MACOSX/data/._7841.jpg  \n",
            "  inflating: data/32761.jpg          \n",
            "  inflating: __MACOSX/data/._32761.jpg  \n",
            "  inflating: data/22572.jpg          \n",
            "  inflating: __MACOSX/data/._22572.jpg  \n",
            "  inflating: data/13977.jpg          \n",
            "  inflating: __MACOSX/data/._13977.jpg  \n",
            "  inflating: data/7699.jpg           \n",
            "  inflating: __MACOSX/data/._7699.jpg  \n",
            "  inflating: data/22214.jpg          \n",
            "  inflating: __MACOSX/data/._22214.jpg  \n",
            "  inflating: data/35768.jpg          \n",
            "  inflating: __MACOSX/data/._35768.jpg  \n",
            "  inflating: data/32007.jpg          \n",
            "  inflating: __MACOSX/data/._32007.jpg  \n",
            "  inflating: data/33319.jpg          \n",
            "  inflating: __MACOSX/data/._33319.jpg  \n",
            "  inflating: data/24665.jpg          \n",
            "  inflating: __MACOSX/data/._24665.jpg  \n",
            "  inflating: data/34476.jpg          \n",
            "  inflating: __MACOSX/data/._34476.jpg  \n",
            "  inflating: data/11806.jpg          \n",
            "  inflating: __MACOSX/data/._11806.jpg  \n",
            "  inflating: data/20403.jpg          \n",
            "  inflating: __MACOSX/data/._20403.jpg  \n",
            "  inflating: data/30610.jpg          \n",
            "  inflating: __MACOSX/data/._30610.jpg  \n",
            "  inflating: data/2087.jpg           \n",
            "  inflating: __MACOSX/data/._2087.jpg  \n",
            "  inflating: data/5930.jpg           \n",
            "  inflating: __MACOSX/data/._5930.jpg  \n",
            "  inflating: data/26072.jpg          \n",
            "  inflating: __MACOSX/data/._26072.jpg  \n",
            "  inflating: data/29341.jpg          \n",
            "  inflating: __MACOSX/data/._29341.jpg  \n",
            "  inflating: data/3399.jpg           \n",
            "  inflating: __MACOSX/data/._3399.jpg  \n",
            "  inflating: data/19282.jpg          \n",
            "  inflating: __MACOSX/data/._19282.jpg  \n",
            "  inflating: data/36261.jpg          \n",
            "  inflating: __MACOSX/data/._36261.jpg  \n",
            "  inflating: data/39152.jpg          \n",
            "  inflating: __MACOSX/data/._39152.jpg  \n",
            "  inflating: data/13976.jpg          \n",
            "  inflating: __MACOSX/data/._13976.jpg  \n",
            "  inflating: data/7698.jpg           \n",
            "  inflating: __MACOSX/data/._7698.jpg  \n",
            "  inflating: data/22573.jpg          \n",
            "  inflating: __MACOSX/data/._22573.jpg  \n",
            "  inflating: data/32760.jpg          \n",
            "  inflating: __MACOSX/data/._32760.jpg  \n",
            "  inflating: data/7840.jpg           \n",
            "  inflating: __MACOSX/data/._7840.jpg  \n",
            "  inflating: data/24102.jpg          \n",
            "  inflating: __MACOSX/data/._24102.jpg  \n",
            "  inflating: data/34311.jpg          \n",
            "  inflating: __MACOSX/data/._34311.jpg  \n",
            "  inflating: data/6586.jpg           \n",
            "  inflating: __MACOSX/data/._6586.jpg  \n",
            "  inflating: data/20364.jpg          \n",
            "  inflating: __MACOSX/data/._20364.jpg  \n",
            "  inflating: data/37618.jpg          \n",
            "  inflating: __MACOSX/data/._37618.jpg  \n",
            "  inflating: data/30177.jpg          \n",
            "  inflating: __MACOSX/data/._30177.jpg  \n",
            "  inflating: data/28738.jpg          \n",
            "  inflating: __MACOSX/data/._28738.jpg  \n",
            "  inflating: data/29426.jpg          \n",
            "  inflating: __MACOSX/data/._29426.jpg  \n",
            "  inflating: data/31269.jpg          \n",
            "  inflating: __MACOSX/data/._31269.jpg  \n",
            "  inflating: data/18823.jpg          \n",
            "  inflating: __MACOSX/data/._18823.jpg  \n",
            "  inflating: data/26715.jpg          \n",
            "  inflating: __MACOSX/data/._26715.jpg  \n",
            "  inflating: data/2938.jpg           \n",
            "  inflating: __MACOSX/data/._2938.jpg  \n",
            "  inflating: data/39635.jpg          \n",
            "  inflating: __MACOSX/data/._39635.jpg  \n",
            "  inflating: data/36506.jpg          \n",
            "  inflating: __MACOSX/data/._36506.jpg  \n",
            "  inflating: data/4391.jpg           \n",
            "  inflating: __MACOSX/data/._4391.jpg  \n",
            "  inflating: data/39153.jpg          \n",
            "  inflating: __MACOSX/data/._39153.jpg  \n",
            "  inflating: data/36260.jpg          \n",
            "  inflating: __MACOSX/data/._36260.jpg  \n",
            "  inflating: data/19283.jpg          \n",
            "  inflating: __MACOSX/data/._19283.jpg  \n",
            "  inflating: data/29340.jpg          \n",
            "  inflating: __MACOSX/data/._29340.jpg  \n",
            "  inflating: data/3398.jpg           \n",
            "  inflating: __MACOSX/data/._3398.jpg  \n",
            "  inflating: data/26073.jpg          \n",
            "  inflating: __MACOSX/data/._26073.jpg  \n",
            "  inflating: data/5931.jpg           \n",
            "  inflating: __MACOSX/data/._5931.jpg  \n",
            "  inflating: data/2086.jpg           \n",
            "  inflating: __MACOSX/data/._2086.jpg  \n",
            "  inflating: data/30611.jpg          \n",
            "  inflating: __MACOSX/data/._30611.jpg  \n",
            "  inflating: data/20402.jpg          \n",
            "  inflating: __MACOSX/data/._20402.jpg  \n",
            "  inflating: data/11807.jpg          \n",
            "  inflating: __MACOSX/data/._11807.jpg  \n",
            "  inflating: data/34477.jpg          \n",
            "  inflating: __MACOSX/data/._34477.jpg  \n",
            "  inflating: data/24664.jpg          \n",
            "  inflating: __MACOSX/data/._24664.jpg  \n",
            "  inflating: data/33318.jpg          \n",
            "  inflating: __MACOSX/data/._33318.jpg  \n",
            "  inflating: data/32006.jpg          \n",
            "  inflating: __MACOSX/data/._32006.jpg  \n",
            "  inflating: data/35769.jpg          \n",
            "  inflating: __MACOSX/data/._35769.jpg  \n",
            "  inflating: data/22215.jpg          \n",
            "  inflating: __MACOSX/data/._22215.jpg  \n",
            "  inflating: data/34463.jpg          \n",
            "  inflating: __MACOSX/data/._34463.jpg  \n",
            "  inflating: data/24670.jpg          \n",
            "  inflating: __MACOSX/data/._24670.jpg  \n",
            "  inflating: data/32012.jpg          \n",
            "  inflating: __MACOSX/data/._32012.jpg  \n",
            "  inflating: data/22201.jpg          \n",
            "  inflating: __MACOSX/data/._22201.jpg  \n",
            "  inflating: data/39147.jpg          \n",
            "  inflating: __MACOSX/data/._39147.jpg  \n",
            "  inflating: data/21708.jpg          \n",
            "  inflating: __MACOSX/data/._21708.jpg  \n",
            "  inflating: data/19297.jpg          \n",
            "  inflating: __MACOSX/data/._19297.jpg  \n",
            "  inflating: data/36274.jpg          \n",
            "  inflating: __MACOSX/data/._36274.jpg  \n",
            "  inflating: data/29354.jpg          \n",
            "  inflating: __MACOSX/data/._29354.jpg  \n",
            "  inflating: data/5925.jpg           \n",
            "  inflating: __MACOSX/data/._5925.jpg  \n",
            "  inflating: data/26067.jpg          \n",
            "  inflating: __MACOSX/data/._26067.jpg  \n",
            "  inflating: data/30605.jpg          \n",
            "  inflating: __MACOSX/data/._30605.jpg  \n",
            "  inflating: data/2092.jpg           \n",
            "  inflating: __MACOSX/data/._2092.jpg  \n",
            "  inflating: data/27379.jpg          \n",
            "  inflating: __MACOSX/data/._27379.jpg  \n",
            "  inflating: data/20416.jpg          \n",
            "  inflating: __MACOSX/data/._20416.jpg  \n",
            "  inflating: data/38259.jpg          \n",
            "  inflating: __MACOSX/data/._38259.jpg  \n",
            "  inflating: data/18189.jpg          \n",
            "  inflating: __MACOSX/data/._18189.jpg  \n",
            "  inflating: data/11813.jpg          \n",
            "  inflating: __MACOSX/data/._11813.jpg  \n",
            "  inflating: data/20370.jpg          \n",
            "  inflating: __MACOSX/data/._20370.jpg  \n",
            "  inflating: data/30163.jpg          \n",
            "  inflating: __MACOSX/data/._30163.jpg  \n",
            "  inflating: data/29432.jpg          \n",
            "  inflating: __MACOSX/data/._29432.jpg  \n",
            "  inflating: data/26701.jpg          \n",
            "  inflating: __MACOSX/data/._26701.jpg  \n",
            "  inflating: data/18837.jpg          \n",
            "  inflating: __MACOSX/data/._18837.jpg  \n",
            "  inflating: data/39621.jpg          \n",
            "  inflating: __MACOSX/data/._39621.jpg  \n",
            "  inflating: data/4385.jpg           \n",
            "  inflating: __MACOSX/data/._4385.jpg  \n",
            "  inflating: data/36512.jpg          \n",
            "  inflating: __MACOSX/data/._36512.jpg  \n",
            "  inflating: data/13962.jpg          \n",
            "  inflating: __MACOSX/data/._13962.jpg  \n",
            "  inflating: data/22567.jpg          \n",
            "  inflating: __MACOSX/data/._22567.jpg  \n",
            "  inflating: data/25208.jpg          \n",
            "  inflating: __MACOSX/data/._25208.jpg  \n",
            "  inflating: data/9879.jpg           \n",
            "  inflating: __MACOSX/data/._9879.jpg  \n",
            "  inflating: data/32774.jpg          \n",
            "  inflating: __MACOSX/data/._32774.jpg  \n",
            "  inflating: data/24116.jpg          \n",
            "  inflating: __MACOSX/data/._24116.jpg  \n",
            "  inflating: data/7854.jpg           \n",
            "  inflating: __MACOSX/data/._7854.jpg  \n",
            "  inflating: data/769.jpg            \n",
            "  inflating: __MACOSX/data/._769.jpg  \n",
            "  inflating: data/6592.jpg           \n",
            "  inflating: __MACOSX/data/._6592.jpg  \n",
            "  inflating: data/34305.jpg          \n",
            "  inflating: __MACOSX/data/._34305.jpg  \n",
            "  inflating: data/23679.jpg          \n",
            "  inflating: __MACOSX/data/._23679.jpg  \n",
            "  inflating: data/37624.jpg          \n",
            "  inflating: __MACOSX/data/._37624.jpg  \n",
            "  inflating: data/38517.jpg          \n",
            "  inflating: __MACOSX/data/._38517.jpg  \n",
            "  inflating: data/20358.jpg          \n",
            "  inflating: __MACOSX/data/._20358.jpg  \n",
            "  inflating: data/27437.jpg          \n",
            "  inflating: __MACOSX/data/._27437.jpg  \n",
            "  inflating: data/28704.jpg          \n",
            "  inflating: __MACOSX/data/._28704.jpg  \n",
            "  inflating: data/16832.jpg          \n",
            "  inflating: __MACOSX/data/._16832.jpg  \n",
            "  inflating: data/11185.jpg          \n",
            "  inflating: __MACOSX/data/._11185.jpg  \n",
            "  inflating: data/26729.jpg          \n",
            "  inflating: __MACOSX/data/._26729.jpg  \n",
            "  inflating: data/31255.jpg          \n",
            "  inflating: __MACOSX/data/._31255.jpg  \n",
            "  inflating: data/21046.jpg          \n",
            "  inflating: __MACOSX/data/._21046.jpg  \n",
            "  inflating: data/2904.jpg           \n",
            "  inflating: __MACOSX/data/._2904.jpg  \n",
            "  inflating: data/39609.jpg          \n",
            "  inflating: __MACOSX/data/._39609.jpg  \n",
            "  inflating: data/8597.jpg           \n",
            "  inflating: __MACOSX/data/._8597.jpg  \n",
            "  inflating: data/999.jpg            \n",
            "  inflating: __MACOSX/data/._999.jpg  \n",
            "  inflating: data/35033.jpg          \n",
            "  inflating: __MACOSX/data/._35033.jpg  \n",
            "  inflating: data/23889.jpg          \n",
            "  inflating: __MACOSX/data/._23889.jpg  \n",
            "  inflating: data/9851.jpg           \n",
            "  inflating: __MACOSX/data/._9851.jpg  \n",
            "  inflating: data/25220.jpg          \n",
            "  inflating: __MACOSX/data/._25220.jpg  \n",
            "  inflating: data/741.jpg            \n",
            "  inflating: __MACOSX/data/._741.jpg  \n",
            "  inflating: data/33442.jpg          \n",
            "  inflating: __MACOSX/data/._33442.jpg  \n",
            "  inflating: data/13792.jpg          \n",
            "  inflating: __MACOSX/data/._13792.jpg  \n",
            "  inflating: data/23651.jpg          \n",
            "  inflating: __MACOSX/data/._23651.jpg  \n",
            "  inflating: data/32984.jpg          \n",
            "  inflating: __MACOSX/data/._32984.jpg  \n",
            "  inflating: data/9689.jpg           \n",
            "  inflating: __MACOSX/data/._9689.jpg  \n",
            "  inflating: data/23137.jpg          \n",
            "  inflating: __MACOSX/data/._23137.jpg  \n",
            "  inflating: data/33324.jpg          \n",
            "  inflating: __MACOSX/data/._33324.jpg  \n",
            "  inflating: data/24658.jpg          \n",
            "  inflating: __MACOSX/data/._24658.jpg  \n",
            "  inflating: data/14943.jpg          \n",
            "  inflating: __MACOSX/data/._14943.jpg  \n",
            "  inflating: data/25546.jpg          \n",
            "  inflating: __MACOSX/data/._25546.jpg  \n",
            "  inflating: data/15485.jpg          \n",
            "  inflating: __MACOSX/data/._15485.jpg  \n",
            "  inflating: data/22229.jpg          \n",
            "  inflating: __MACOSX/data/._22229.jpg  \n",
            "  inflating: data/35755.jpg          \n",
            "  inflating: __MACOSX/data/._35755.jpg  \n",
            "  inflating: data/24880.jpg          \n",
            "  inflating: __MACOSX/data/._24880.jpg  \n",
            "  inflating: data/21720.jpg          \n",
            "  inflating: __MACOSX/data/._21720.jpg  \n",
            "  inflating: data/31533.jpg          \n",
            "  inflating: __MACOSX/data/._31533.jpg  \n",
            "  inflating: data/27351.jpg          \n",
            "  inflating: __MACOSX/data/._27351.jpg  \n",
            "  inflating: data/28062.jpg          \n",
            "  inflating: __MACOSX/data/._28062.jpg  \n",
            "  inflating: data/37142.jpg          \n",
            "  inflating: __MACOSX/data/._37142.jpg  \n",
            "  inflating: data/38271.jpg          \n",
            "  inflating: __MACOSX/data/._38271.jpg  \n",
            "  inflating: data/17292.jpg          \n",
            "  inflating: __MACOSX/data/._17292.jpg  \n",
            "  inflating: data/36248.jpg          \n",
            "  inflating: __MACOSX/data/._36248.jpg  \n",
            "  inflating: data/16198.jpg          \n",
            "  inflating: __MACOSX/data/._16198.jpg  \n",
            "  inflating: data/21734.jpg          \n",
            "  inflating: __MACOSX/data/._21734.jpg  \n",
            "  inflating: data/5919.jpg           \n",
            "  inflating: __MACOSX/data/._5919.jpg  \n",
            "  inflating: data/31527.jpg          \n",
            "  inflating: __MACOSX/data/._31527.jpg  \n",
            "  inflating: data/29368.jpg          \n",
            "  inflating: __MACOSX/data/._29368.jpg  \n",
            "  inflating: data/27345.jpg          \n",
            "  inflating: __MACOSX/data/._27345.jpg  \n",
            "  inflating: data/28076.jpg          \n",
            "  inflating: __MACOSX/data/._28076.jpg  \n",
            "  inflating: data/30639.jpg          \n",
            "  inflating: __MACOSX/data/._30639.jpg  \n",
            "  inflating: data/37156.jpg          \n",
            "  inflating: __MACOSX/data/._37156.jpg  \n",
            "  inflating: data/17286.jpg          \n",
            "  inflating: __MACOSX/data/._17286.jpg  \n",
            "  inflating: data/38265.jpg          \n",
            "  inflating: __MACOSX/data/._38265.jpg  \n",
            "  inflating: data/23123.jpg          \n",
            "  inflating: __MACOSX/data/._23123.jpg  \n",
            "  inflating: data/33330.jpg          \n",
            "  inflating: __MACOSX/data/._33330.jpg  \n",
            "  inflating: data/35999.jpg          \n",
            "  inflating: __MACOSX/data/._35999.jpg  \n",
            "  inflating: data/14957.jpg          \n",
            "  inflating: __MACOSX/data/._14957.jpg  \n",
            "  inflating: data/25552.jpg          \n",
            "  inflating: __MACOSX/data/._25552.jpg  \n",
            "  inflating: data/15491.jpg          \n",
            "  inflating: __MACOSX/data/._15491.jpg  \n",
            "  inflating: data/24894.jpg          \n",
            "  inflating: __MACOSX/data/._24894.jpg  \n",
            "  inflating: data/35741.jpg          \n",
            "  inflating: __MACOSX/data/._35741.jpg  \n",
            "  inflating: data/8583.jpg           \n",
            "  inflating: __MACOSX/data/._8583.jpg  \n",
            "  inflating: data/35027.jpg          \n",
            "  inflating: __MACOSX/data/._35027.jpg  \n",
            "  inflating: data/9845.jpg           \n",
            "  inflating: __MACOSX/data/._9845.jpg  \n",
            "  inflating: data/32748.jpg          \n",
            "  inflating: __MACOSX/data/._32748.jpg  \n",
            "  inflating: data/12498.jpg          \n",
            "  inflating: __MACOSX/data/._12498.jpg  \n",
            "  inflating: data/25234.jpg          \n",
            "  inflating: __MACOSX/data/._25234.jpg  \n",
            "  inflating: data/33456.jpg          \n",
            "  inflating: __MACOSX/data/._33456.jpg  \n",
            "  inflating: data/755.jpg            \n",
            "  inflating: __MACOSX/data/._755.jpg  \n",
            "  inflating: data/7868.jpg           \n",
            "  inflating: __MACOSX/data/._7868.jpg  \n",
            "  inflating: data/13786.jpg          \n",
            "  inflating: __MACOSX/data/._13786.jpg  \n",
            "  inflating: data/32990.jpg          \n",
            "  inflating: __MACOSX/data/._32990.jpg  \n",
            "  inflating: data/23645.jpg          \n",
            "  inflating: __MACOSX/data/._23645.jpg  \n",
            "  inflating: data/34339.jpg          \n",
            "  inflating: __MACOSX/data/._34339.jpg  \n",
            "  inflating: data/37630.jpg          \n",
            "  inflating: __MACOSX/data/._37630.jpg  \n",
            "  inflating: data/38503.jpg          \n",
            "  inflating: __MACOSX/data/._38503.jpg  \n",
            "  inflating: data/27423.jpg          \n",
            "  inflating: __MACOSX/data/._27423.jpg  \n",
            "  inflating: data/16826.jpg          \n",
            "  inflating: __MACOSX/data/._16826.jpg  \n",
            "  inflating: data/28710.jpg          \n",
            "  inflating: __MACOSX/data/._28710.jpg  \n",
            "  inflating: data/11191.jpg          \n",
            "  inflating: __MACOSX/data/._11191.jpg  \n",
            "  inflating: data/31241.jpg          \n",
            "  inflating: __MACOSX/data/._31241.jpg  \n",
            "  inflating: data/2910.jpg           \n",
            "  inflating: __MACOSX/data/._2910.jpg  \n",
            "  inflating: data/21052.jpg          \n",
            "  inflating: __MACOSX/data/._21052.jpg  \n",
            "  inflating: data/37803.jpg          \n",
            "  inflating: __MACOSX/data/._37803.jpg  \n",
            "  inflating: data/16615.jpg          \n",
            "  inflating: __MACOSX/data/._16615.jpg  \n",
            "  inflating: data/28923.jpg          \n",
            "  inflating: __MACOSX/data/._28923.jpg  \n",
            "  inflating: data/19526.jpg          \n",
            "  inflating: __MACOSX/data/._19526.jpg  \n",
            "  inflating: data/4352.jpg           \n",
            "  inflating: __MACOSX/data/._4352.jpg  \n",
            "  inflating: data/18638.jpg          \n",
            "  inflating: __MACOSX/data/._18638.jpg  \n",
            "  inflating: data/2723.jpg           \n",
            "  inflating: __MACOSX/data/._2723.jpg  \n",
            "  inflating: data/10264.jpg          \n",
            "  inflating: __MACOSX/data/._10264.jpg  \n",
            "  inflating: data/7883.jpg           \n",
            "  inflating: __MACOSX/data/._7883.jpg  \n",
            "  inflating: data/6545.jpg           \n",
            "  inflating: __MACOSX/data/._6545.jpg  \n",
            "  inflating: data/9676.jpg           \n",
            "  inflating: __MACOSX/data/._9676.jpg  \n",
            "  inflating: data/14002.jpg          \n",
            "  inflating: __MACOSX/data/._14002.jpg  \n",
            "  inflating: data/966.jpg            \n",
            "  inflating: __MACOSX/data/._966.jpg  \n",
            "  inflating: data/8568.jpg           \n",
            "  inflating: __MACOSX/data/._8568.jpg  \n",
            "  inflating: data/12473.jpg          \n",
            "  inflating: __MACOSX/data/._12473.jpg  \n",
            "  inflating: data/23876.jpg          \n",
            "  inflating: __MACOSX/data/._23876.jpg  \n",
            "  inflating: data/12315.jpg          \n",
            "  inflating: __MACOSX/data/._12315.jpg  \n",
            "  inflating: data/6223.jpg           \n",
            "  inflating: __MACOSX/data/._6223.jpg  \n",
            "  inflating: data/9110.jpg           \n",
            "  inflating: __MACOSX/data/._9110.jpg  \n",
            "  inflating: data/14764.jpg          \n",
            "  inflating: __MACOSX/data/._14764.jpg  \n",
            "  inflating: data/35972.jpg          \n",
            "  inflating: __MACOSX/data/._35972.jpg  \n",
            "  inflating: data/21907.jpg          \n",
            "  inflating: __MACOSX/data/._21907.jpg  \n",
            "  inflating: data/2045.jpg           \n",
            "  inflating: __MACOSX/data/._2045.jpg  \n",
            "  inflating: data/10502.jpg          \n",
            "  inflating: __MACOSX/data/._10502.jpg  \n",
            "  inflating: data/39190.jpg          \n",
            "  inflating: __MACOSX/data/._39190.jpg  \n",
            "  inflating: data/16173.jpg          \n",
            "  inflating: __MACOSX/data/._16173.jpg  \n",
            "  inflating: data/19240.jpg          \n",
            "  inflating: __MACOSX/data/._19240.jpg  \n",
            "  inflating: data/4434.jpg           \n",
            "  inflating: __MACOSX/data/._4434.jpg  \n",
            "  inflating: data/29383.jpg          \n",
            "  inflating: __MACOSX/data/._29383.jpg  \n",
            "  inflating: data/2051.jpg           \n",
            "  inflating: __MACOSX/data/._2051.jpg  \n",
            "  inflating: data/21913.jpg          \n",
            "  inflating: __MACOSX/data/._21913.jpg  \n",
            "  inflating: data/28089.jpg          \n",
            "  inflating: __MACOSX/data/._28089.jpg  \n",
            "  inflating: data/10516.jpg          \n",
            "  inflating: __MACOSX/data/._10516.jpg  \n",
            "  inflating: data/17279.jpg          \n",
            "  inflating: __MACOSX/data/._17279.jpg  \n",
            "  inflating: data/16167.jpg          \n",
            "  inflating: __MACOSX/data/._16167.jpg  \n",
            "  inflating: data/39184.jpg          \n",
            "  inflating: __MACOSX/data/._39184.jpg  \n",
            "  inflating: data/4420.jpg           \n",
            "  inflating: __MACOSX/data/._4420.jpg  \n",
            "  inflating: data/19254.jpg          \n",
            "  inflating: __MACOSX/data/._19254.jpg  \n",
            "  inflating: data/29397.jpg          \n",
            "  inflating: __MACOSX/data/._29397.jpg  \n",
            "  inflating: data/11608.jpg          \n",
            "  inflating: __MACOSX/data/._11608.jpg  \n",
            "  inflating: data/12301.jpg          \n",
            "  inflating: __MACOSX/data/._12301.jpg  \n",
            "  inflating: data/7129.jpg           \n",
            "  inflating: __MACOSX/data/._7129.jpg  \n",
            "  inflating: data/6237.jpg           \n",
            "  inflating: __MACOSX/data/._6237.jpg  \n",
            "  inflating: data/14770.jpg          \n",
            "  inflating: __MACOSX/data/._14770.jpg  \n",
            "  inflating: data/9104.jpg           \n",
            "  inflating: __MACOSX/data/._9104.jpg  \n",
            "  inflating: data/35966.jpg          \n",
            "  inflating: __MACOSX/data/._35966.jpg  \n",
            "  inflating: data/1558.jpg           \n",
            "  inflating: __MACOSX/data/._1558.jpg  \n",
            "  inflating: data/13779.jpg          \n",
            "  inflating: __MACOSX/data/._13779.jpg  \n",
            "  inflating: data/7897.jpg           \n",
            "  inflating: __MACOSX/data/._7897.jpg  \n",
            "  inflating: data/6551.jpg           \n",
            "  inflating: __MACOSX/data/._6551.jpg  \n",
            "  inflating: data/14016.jpg          \n",
            "  inflating: __MACOSX/data/._14016.jpg  \n",
            "  inflating: data/9662.jpg           \n",
            "  inflating: __MACOSX/data/._9662.jpg  \n",
            "  inflating: data/15308.jpg          \n",
            "  inflating: __MACOSX/data/._15308.jpg  \n",
            "  inflating: data/972.jpg            \n",
            "  inflating: __MACOSX/data/._972.jpg  \n",
            "  inflating: data/12467.jpg          \n",
            "  inflating: __MACOSX/data/._12467.jpg  \n",
            "  inflating: data/23862.jpg          \n",
            "  inflating: __MACOSX/data/._23862.jpg  \n",
            "  inflating: data/3429.jpg           \n",
            "  inflating: __MACOSX/data/._3429.jpg  \n",
            "  inflating: data/37817.jpg          \n",
            "  inflating: __MACOSX/data/._37817.jpg  \n",
            "  inflating: data/28937.jpg          \n",
            "  inflating: __MACOSX/data/._28937.jpg  \n",
            "  inflating: data/16601.jpg          \n",
            "  inflating: __MACOSX/data/._16601.jpg  \n",
            "  inflating: data/4346.jpg           \n",
            "  inflating: __MACOSX/data/._4346.jpg  \n",
            "  inflating: data/19532.jpg          \n",
            "  inflating: __MACOSX/data/._19532.jpg  \n",
            "  inflating: data/5058.jpg           \n",
            "  inflating: __MACOSX/data/._5058.jpg  \n",
            "  inflating: data/2737.jpg           \n",
            "  inflating: __MACOSX/data/._2737.jpg  \n",
            "  inflating: data/10270.jpg          \n",
            "  inflating: __MACOSX/data/._10270.jpg  \n",
            "  inflating: data/782.jpg            \n",
            "  inflating: __MACOSX/data/._782.jpg  \n",
            "  inflating: data/33481.jpg          \n",
            "  inflating: __MACOSX/data/._33481.jpg  \n",
            "  inflating: data/1216.jpg           \n",
            "  inflating: __MACOSX/data/._1216.jpg  \n",
            "  inflating: data/13751.jpg          \n",
            "  inflating: __MACOSX/data/._13751.jpg  \n",
            "  inflating: data/23692.jpg          \n",
            "  inflating: __MACOSX/data/._23692.jpg  \n",
            "  inflating: data/32947.jpg          \n",
            "  inflating: __MACOSX/data/._32947.jpg  \n",
            "  inflating: data/6579.jpg           \n",
            "  inflating: __MACOSX/data/._6579.jpg  \n",
            "  inflating: data/15320.jpg          \n",
            "  inflating: __MACOSX/data/._15320.jpg  \n",
            "  inflating: data/8554.jpg           \n",
            "  inflating: __MACOSX/data/._8554.jpg  \n",
            "  inflating: data/7667.jpg           \n",
            "  inflating: __MACOSX/data/._7667.jpg  \n",
            "  inflating: data/13989.jpg          \n",
            "  inflating: __MACOSX/data/._13989.jpg  \n",
            "  inflating: data/9892.jpg           \n",
            "  inflating: __MACOSX/data/._9892.jpg  \n",
            "  inflating: data/11146.jpg          \n",
            "  inflating: __MACOSX/data/._11146.jpg  \n",
            "  inflating: data/31296.jpg          \n",
            "  inflating: __MACOSX/data/._31296.jpg  \n",
            "  inflating: data/3401.jpg           \n",
            "  inflating: __MACOSX/data/._3401.jpg  \n",
            "  inflating: data/16629.jpg          \n",
            "  inflating: __MACOSX/data/._16629.jpg  \n",
            "  inflating: data/21085.jpg          \n",
            "  inflating: __MACOSX/data/._21085.jpg  \n",
            "  inflating: data/26932.jpg          \n",
            "  inflating: __MACOSX/data/._26932.jpg  \n",
            "  inflating: data/5070.jpg           \n",
            "  inflating: __MACOSX/data/._5070.jpg  \n",
            "  inflating: data/18604.jpg          \n",
            "  inflating: __MACOSX/data/._18604.jpg  \n",
            "  inflating: data/17537.jpg          \n",
            "  inflating: __MACOSX/data/._17537.jpg  \n",
            "  inflating: data/10258.jpg          \n",
            "  inflating: __MACOSX/data/._10258.jpg  \n",
            "  inflating: data/39812.jpg          \n",
            "  inflating: __MACOSX/data/._39812.jpg  \n",
            "  inflating: data/30188.jpg          \n",
            "  inflating: __MACOSX/data/._30188.jpg  \n",
            "  inflating: data/27392.jpg          \n",
            "  inflating: __MACOSX/data/._27392.jpg  \n",
            "  inflating: data/2079.jpg           \n",
            "  inflating: __MACOSX/data/._2079.jpg  \n",
            "  inflating: data/5716.jpg           \n",
            "  inflating: __MACOSX/data/._5716.jpg  \n",
            "  inflating: data/37181.jpg          \n",
            "  inflating: __MACOSX/data/._37181.jpg  \n",
            "  inflating: data/18162.jpg          \n",
            "  inflating: __MACOSX/data/._18162.jpg  \n",
            "  inflating: data/17251.jpg          \n",
            "  inflating: __MACOSX/data/._17251.jpg  \n",
            "  inflating: data/4408.jpg           \n",
            "  inflating: __MACOSX/data/._4408.jpg  \n",
            "  inflating: data/30836.jpg          \n",
            "  inflating: __MACOSX/data/._30836.jpg  \n",
            "  inflating: data/11620.jpg          \n",
            "  inflating: __MACOSX/data/._11620.jpg  \n",
            "  inflating: data/3367.jpg           \n",
            "  inflating: __MACOSX/data/._3367.jpg  \n",
            "  inflating: data/14980.jpg          \n",
            "  inflating: __MACOSX/data/._14980.jpg  \n",
            "  inflating: data/12329.jpg          \n",
            "  inflating: __MACOSX/data/._12329.jpg  \n",
            "  inflating: data/25585.jpg          \n",
            "  inflating: __MACOSX/data/._25585.jpg  \n",
            "  inflating: data/15446.jpg          \n",
            "  inflating: __MACOSX/data/._15446.jpg  \n",
            "  inflating: data/8232.jpg           \n",
            "  inflating: __MACOSX/data/._8232.jpg  \n",
            "  inflating: data/7101.jpg           \n",
            "  inflating: __MACOSX/data/._7101.jpg  \n",
            "  inflating: data/35796.jpg          \n",
            "  inflating: __MACOSX/data/._35796.jpg  \n",
            "  inflating: data/24843.jpg          \n",
            "  inflating: __MACOSX/data/._24843.jpg  \n",
            "  inflating: data/14758.jpg          \n",
            "  inflating: __MACOSX/data/._14758.jpg  \n",
            "  inflating: data/34488.jpg          \n",
            "  inflating: __MACOSX/data/._34488.jpg  \n",
            "  inflating: data/1570.jpg           \n",
            "  inflating: __MACOSX/data/._1570.jpg  \n",
            "  inflating: data/13037.jpg          \n",
            "  inflating: __MACOSX/data/._13037.jpg  \n",
            "  inflating: data/14994.jpg          \n",
            "  inflating: __MACOSX/data/._14994.jpg  \n",
            "  inflating: data/25591.jpg          \n",
            "  inflating: __MACOSX/data/._25591.jpg  \n",
            "  inflating: data/8226.jpg           \n",
            "  inflating: __MACOSX/data/._8226.jpg  \n",
            "  inflating: data/15452.jpg          \n",
            "  inflating: __MACOSX/data/._15452.jpg  \n",
            "  inflating: data/24857.jpg          \n",
            "  inflating: __MACOSX/data/._24857.jpg  \n",
            "  inflating: data/35782.jpg          \n",
            "  inflating: __MACOSX/data/._35782.jpg  \n",
            "  inflating: data/7115.jpg           \n",
            "  inflating: __MACOSX/data/._7115.jpg  \n",
            "  inflating: data/9138.jpg           \n",
            "  inflating: __MACOSX/data/._9138.jpg  \n",
            "  inflating: data/1564.jpg           \n",
            "  inflating: __MACOSX/data/._1564.jpg  \n",
            "  inflating: data/13023.jpg          \n",
            "  inflating: __MACOSX/data/._13023.jpg  \n",
            "  inflating: data/27386.jpg          \n",
            "  inflating: __MACOSX/data/._27386.jpg  \n",
            "  inflating: data/18176.jpg          \n",
            "  inflating: __MACOSX/data/._18176.jpg  \n",
            "  inflating: data/37195.jpg          \n",
            "  inflating: __MACOSX/data/._37195.jpg  \n",
            "  inflating: data/5702.jpg           \n",
            "  inflating: __MACOSX/data/._5702.jpg  \n",
            "  inflating: data/17245.jpg          \n",
            "  inflating: __MACOSX/data/._17245.jpg  \n",
            "  inflating: data/19268.jpg          \n",
            "  inflating: __MACOSX/data/._19268.jpg  \n",
            "  inflating: data/30822.jpg          \n",
            "  inflating: __MACOSX/data/._30822.jpg  \n",
            "  inflating: data/11634.jpg          \n",
            "  inflating: __MACOSX/data/._11634.jpg  \n",
            "  inflating: data/26098.jpg          \n",
            "  inflating: __MACOSX/data/._26098.jpg  \n",
            "  inflating: data/3373.jpg           \n",
            "  inflating: __MACOSX/data/._3373.jpg  \n",
            "  inflating: data/11152.jpg          \n",
            "  inflating: __MACOSX/data/._11152.jpg  \n",
            "  inflating: data/3415.jpg           \n",
            "  inflating: __MACOSX/data/._3415.jpg  \n",
            "  inflating: data/31282.jpg          \n",
            "  inflating: __MACOSX/data/._31282.jpg  \n",
            "  inflating: data/21091.jpg          \n",
            "  inflating: __MACOSX/data/._21091.jpg  \n",
            "  inflating: data/18610.jpg          \n",
            "  inflating: __MACOSX/data/._18610.jpg  \n",
            "  inflating: data/5064.jpg           \n",
            "  inflating: __MACOSX/data/._5064.jpg  \n",
            "  inflating: data/26926.jpg          \n",
            "  inflating: __MACOSX/data/._26926.jpg  \n",
            "  inflating: data/17523.jpg          \n",
            "  inflating: __MACOSX/data/._17523.jpg  \n",
            "  inflating: data/39806.jpg          \n",
            "  inflating: __MACOSX/data/._39806.jpg  \n",
            "  inflating: data/1202.jpg           \n",
            "  inflating: __MACOSX/data/._1202.jpg  \n",
            "  inflating: data/33495.jpg          \n",
            "  inflating: __MACOSX/data/._33495.jpg  \n",
            "  inflating: data/796.jpg            \n",
            "  inflating: __MACOSX/data/._796.jpg  \n",
            "  inflating: data/13745.jpg          \n",
            "  inflating: __MACOSX/data/._13745.jpg  \n",
            "  inflating: data/32953.jpg          \n",
            "  inflating: __MACOSX/data/._32953.jpg  \n",
            "  inflating: data/23686.jpg          \n",
            "  inflating: __MACOSX/data/._23686.jpg  \n",
            "  inflating: data/8540.jpg           \n",
            "  inflating: __MACOSX/data/._8540.jpg  \n",
            "  inflating: data/15334.jpg          \n",
            "  inflating: __MACOSX/data/._15334.jpg  \n",
            "  inflating: data/22598.jpg          \n",
            "  inflating: __MACOSX/data/._22598.jpg  \n",
            "  inflating: data/7673.jpg           \n",
            "  inflating: __MACOSX/data/._7673.jpg  \n",
            "  inflating: data/9886.jpg           \n",
            "  inflating: __MACOSX/data/._9886.jpg  \n",
            "  inflating: data/1955.jpg           \n",
            "  inflating: __MACOSX/data/._1955.jpg  \n",
            "  inflating: data/22017.jpg          \n",
            "  inflating: __MACOSX/data/._22017.jpg  \n",
            "  inflating: data/32204.jpg          \n",
            "  inflating: __MACOSX/data/._32204.jpg  \n",
            "  inflating: data/25778.jpg          \n",
            "  inflating: __MACOSX/data/._25778.jpg  \n",
            "  inflating: data/219.jpg            \n",
            "  inflating: __MACOSX/data/._219.jpg  \n",
            "  inflating: data/15863.jpg          \n",
            "  inflating: __MACOSX/data/._15863.jpg  \n",
            "  inflating: data/24466.jpg          \n",
            "  inflating: __MACOSX/data/._24466.jpg  \n",
            "  inflating: data/23309.jpg          \n",
            "  inflating: __MACOSX/data/._23309.jpg  \n",
            "  inflating: data/34675.jpg          \n",
            "  inflating: __MACOSX/data/._34675.jpg  \n",
            "  inflating: data/20600.jpg          \n",
            "  inflating: __MACOSX/data/._20600.jpg  \n",
            "  inflating: data/2284.jpg           \n",
            "  inflating: __MACOSX/data/._2284.jpg  \n",
            "  inflating: data/30413.jpg          \n",
            "  inflating: __MACOSX/data/._30413.jpg  \n",
            "  inflating: data/26271.jpg          \n",
            "  inflating: __MACOSX/data/._26271.jpg  \n",
            "  inflating: data/29142.jpg          \n",
            "  inflating: __MACOSX/data/._29142.jpg  \n",
            "  inflating: data/36062.jpg          \n",
            "  inflating: __MACOSX/data/._36062.jpg  \n",
            "  inflating: data/19081.jpg          \n",
            "  inflating: __MACOSX/data/._19081.jpg  \n",
            "  inflating: data/39351.jpg          \n",
            "  inflating: __MACOSX/data/._39351.jpg  \n",
            "  inflating: data/36704.jpg          \n",
            "  inflating: __MACOSX/data/._36704.jpg  \n",
            "  inflating: data/4193.jpg           \n",
            "  inflating: __MACOSX/data/._4193.jpg  \n",
            "  inflating: data/39437.jpg          \n",
            "  inflating: __MACOSX/data/._39437.jpg  \n",
            "  inflating: data/21278.jpg          \n",
            "  inflating: __MACOSX/data/._21278.jpg  \n",
            "  inflating: data/26517.jpg          \n",
            "  inflating: __MACOSX/data/._26517.jpg  \n",
            "  inflating: data/29624.jpg          \n",
            "  inflating: __MACOSX/data/._29624.jpg  \n",
            "  inflating: data/17912.jpg          \n",
            "  inflating: __MACOSX/data/._17912.jpg  \n",
            "  inflating: data/27609.jpg          \n",
            "  inflating: __MACOSX/data/._27609.jpg  \n",
            "  inflating: data/30375.jpg          \n",
            "  inflating: __MACOSX/data/._30375.jpg  \n",
            "  inflating: data/20166.jpg          \n",
            "  inflating: __MACOSX/data/._20166.jpg  \n",
            "  inflating: data/3824.jpg           \n",
            "  inflating: __MACOSX/data/._3824.jpg  \n",
            "  inflating: data/38729.jpg          \n",
            "  inflating: __MACOSX/data/._38729.jpg  \n",
            "  inflating: data/34113.jpg          \n",
            "  inflating: __MACOSX/data/._34113.jpg  \n",
            "  inflating: data/6784.jpg           \n",
            "  inflating: __MACOSX/data/._6784.jpg  \n",
            "  inflating: data/8971.jpg           \n",
            "  inflating: __MACOSX/data/._8971.jpg  \n",
            "  inflating: data/24300.jpg          \n",
            "  inflating: __MACOSX/data/._24300.jpg  \n",
            "  inflating: data/32562.jpg          \n",
            "  inflating: __MACOSX/data/._32562.jpg  \n",
            "  inflating: data/22771.jpg          \n",
            "  inflating: __MACOSX/data/._22771.jpg  \n",
            "  inflating: data/6790.jpg           \n",
            "  inflating: __MACOSX/data/._6790.jpg  \n",
            "  inflating: data/34107.jpg          \n",
            "  inflating: __MACOSX/data/._34107.jpg  \n",
            "  inflating: data/8965.jpg           \n",
            "  inflating: __MACOSX/data/._8965.jpg  \n",
            "  inflating: data/33668.jpg          \n",
            "  inflating: __MACOSX/data/._33668.jpg  \n",
            "  inflating: data/24314.jpg          \n",
            "  inflating: __MACOSX/data/._24314.jpg  \n",
            "  inflating: data/32576.jpg          \n",
            "  inflating: __MACOSX/data/._32576.jpg  \n",
            "  inflating: data/6948.jpg           \n",
            "  inflating: __MACOSX/data/._6948.jpg  \n",
            "  inflating: data/22765.jpg          \n",
            "  inflating: __MACOSX/data/._22765.jpg  \n",
            "  inflating: data/35219.jpg          \n",
            "  inflating: __MACOSX/data/._35219.jpg  \n",
            "  inflating: data/4187.jpg           \n",
            "  inflating: __MACOSX/data/._4187.jpg  \n",
            "  inflating: data/36710.jpg          \n",
            "  inflating: __MACOSX/data/._36710.jpg  \n",
            "  inflating: data/39423.jpg          \n",
            "  inflating: __MACOSX/data/._39423.jpg  \n",
            "  inflating: data/26503.jpg          \n",
            "  inflating: __MACOSX/data/._26503.jpg  \n",
            "  inflating: data/17906.jpg          \n",
            "  inflating: __MACOSX/data/._17906.jpg  \n",
            "  inflating: data/29630.jpg          \n",
            "  inflating: __MACOSX/data/._29630.jpg  \n",
            "  inflating: data/30361.jpg          \n",
            "  inflating: __MACOSX/data/._30361.jpg  \n",
            "  inflating: data/5299.jpg           \n",
            "  inflating: __MACOSX/data/._5299.jpg  \n",
            "  inflating: data/3830.jpg           \n",
            "  inflating: __MACOSX/data/._3830.jpg  \n",
            "  inflating: data/20172.jpg          \n",
            "  inflating: __MACOSX/data/._20172.jpg  \n",
            "  inflating: data/37368.jpg          \n",
            "  inflating: __MACOSX/data/._37368.jpg  \n",
            "  inflating: data/20614.jpg          \n",
            "  inflating: __MACOSX/data/._20614.jpg  \n",
            "  inflating: data/4839.jpg           \n",
            "  inflating: __MACOSX/data/._4839.jpg  \n",
            "  inflating: data/30407.jpg          \n",
            "  inflating: __MACOSX/data/._30407.jpg  \n",
            "  inflating: data/2290.jpg           \n",
            "  inflating: __MACOSX/data/._2290.jpg  \n",
            "  inflating: data/28248.jpg          \n",
            "  inflating: __MACOSX/data/._28248.jpg  \n",
            "  inflating: data/26265.jpg          \n",
            "  inflating: __MACOSX/data/._26265.jpg  \n",
            "  inflating: data/29156.jpg          \n",
            "  inflating: __MACOSX/data/._29156.jpg  \n",
            "  inflating: data/31719.jpg          \n",
            "  inflating: __MACOSX/data/._31719.jpg  \n",
            "  inflating: data/19095.jpg          \n",
            "  inflating: __MACOSX/data/._19095.jpg  \n",
            "  inflating: data/36076.jpg          \n",
            "  inflating: __MACOSX/data/._36076.jpg  \n",
            "  inflating: data/39345.jpg          \n",
            "  inflating: __MACOSX/data/._39345.jpg  \n",
            "  inflating: data/22003.jpg          \n",
            "  inflating: __MACOSX/data/._22003.jpg  \n",
            "  inflating: data/1941.jpg           \n",
            "  inflating: __MACOSX/data/._1941.jpg  \n",
            "  inflating: data/32210.jpg          \n",
            "  inflating: __MACOSX/data/._32210.jpg  \n",
            "  inflating: data/15877.jpg          \n",
            "  inflating: __MACOSX/data/._15877.jpg  \n",
            "  inflating: data/1799.jpg           \n",
            "  inflating: __MACOSX/data/._1799.jpg  \n",
            "  inflating: data/24472.jpg          \n",
            "  inflating: __MACOSX/data/._24472.jpg  \n",
            "  inflating: data/34661.jpg          \n",
            "  inflating: __MACOSX/data/._34661.jpg  \n",
            "  inflating: data/38073.jpg          \n",
            "  inflating: __MACOSX/data/._38073.jpg  \n",
            "  inflating: data/17090.jpg          \n",
            "  inflating: __MACOSX/data/._17090.jpg  \n",
            "  inflating: data/37340.jpg          \n",
            "  inflating: __MACOSX/data/._37340.jpg  \n",
            "  inflating: data/28260.jpg          \n",
            "  inflating: __MACOSX/data/._28260.jpg  \n",
            "  inflating: data/27153.jpg          \n",
            "  inflating: __MACOSX/data/._27153.jpg  \n",
            "  inflating: data/4811.jpg           \n",
            "  inflating: __MACOSX/data/._4811.jpg  \n",
            "  inflating: data/31731.jpg          \n",
            "  inflating: __MACOSX/data/._31731.jpg  \n",
            "  inflating: data/21522.jpg          \n",
            "  inflating: __MACOSX/data/._21522.jpg  \n",
            "  inflating: data/10927.jpg          \n",
            "  inflating: __MACOSX/data/._10927.jpg  \n",
            "  inflating: data/35557.jpg          \n",
            "  inflating: __MACOSX/data/._35557.jpg  \n",
            "  inflating: data/1969.jpg           \n",
            "  inflating: __MACOSX/data/._1969.jpg  \n",
            "  inflating: data/15687.jpg          \n",
            "  inflating: __MACOSX/data/._15687.jpg  \n",
            "  inflating: data/25744.jpg          \n",
            "  inflating: __MACOSX/data/._25744.jpg  \n",
            "  inflating: data/34891.jpg          \n",
            "  inflating: __MACOSX/data/._34891.jpg  \n",
            "  inflating: data/32238.jpg          \n",
            "  inflating: __MACOSX/data/._32238.jpg  \n",
            "  inflating: data/225.jpg            \n",
            "  inflating: __MACOSX/data/._225.jpg  \n",
            "  inflating: data/33126.jpg          \n",
            "  inflating: __MACOSX/data/._33126.jpg  \n",
            "  inflating: data/34649.jpg          \n",
            "  inflating: __MACOSX/data/._34649.jpg  \n",
            "  inflating: data/14599.jpg          \n",
            "  inflating: __MACOSX/data/._14599.jpg  \n",
            "  inflating: data/23335.jpg          \n",
            "  inflating: __MACOSX/data/._23335.jpg  \n",
            "  inflating: data/12856.jpg          \n",
            "  inflating: __MACOSX/data/._12856.jpg  \n",
            "  inflating: data/23453.jpg          \n",
            "  inflating: __MACOSX/data/._23453.jpg  \n",
            "  inflating: data/13590.jpg          \n",
            "  inflating: __MACOSX/data/._13590.jpg  \n",
            "  inflating: data/33640.jpg          \n",
            "  inflating: __MACOSX/data/._33640.jpg  \n",
            "  inflating: data/543.jpg            \n",
            "  inflating: __MACOSX/data/._543.jpg  \n",
            "  inflating: data/22995.jpg          \n",
            "  inflating: __MACOSX/data/._22995.jpg  \n",
            "  inflating: data/6960.jpg           \n",
            "  inflating: __MACOSX/data/._6960.jpg  \n",
            "  inflating: data/25022.jpg          \n",
            "  inflating: __MACOSX/data/._25022.jpg  \n",
            "  inflating: data/35231.jpg          \n",
            "  inflating: __MACOSX/data/._35231.jpg  \n",
            "  inflating: data/33898.jpg          \n",
            "  inflating: __MACOSX/data/._33898.jpg  \n",
            "  inflating: data/8795.jpg           \n",
            "  inflating: __MACOSX/data/._8795.jpg  \n",
            "  inflating: data/21244.jpg          \n",
            "  inflating: __MACOSX/data/._21244.jpg  \n",
            "  inflating: data/36738.jpg          \n",
            "  inflating: __MACOSX/data/._36738.jpg  \n",
            "  inflating: data/31057.jpg          \n",
            "  inflating: __MACOSX/data/._31057.jpg  \n",
            "  inflating: data/29618.jpg          \n",
            "  inflating: __MACOSX/data/._29618.jpg  \n",
            "  inflating: data/11387.jpg          \n",
            "  inflating: __MACOSX/data/._11387.jpg  \n",
            "  inflating: data/28506.jpg          \n",
            "  inflating: __MACOSX/data/._28506.jpg  \n",
            "  inflating: data/30349.jpg          \n",
            "  inflating: __MACOSX/data/._30349.jpg  \n",
            "  inflating: data/10099.jpg          \n",
            "  inflating: __MACOSX/data/._10099.jpg  \n",
            "  inflating: data/19903.jpg          \n",
            "  inflating: __MACOSX/data/._19903.jpg  \n",
            "  inflating: data/27635.jpg          \n",
            "  inflating: __MACOSX/data/._27635.jpg  \n",
            "  inflating: data/3818.jpg           \n",
            "  inflating: __MACOSX/data/._3818.jpg  \n",
            "  inflating: data/38715.jpg          \n",
            "  inflating: __MACOSX/data/._38715.jpg  \n",
            "  inflating: data/37426.jpg          \n",
            "  inflating: __MACOSX/data/._37426.jpg  \n",
            "  inflating: data/21250.jpg          \n",
            "  inflating: __MACOSX/data/._21250.jpg  \n",
            "  inflating: data/31043.jpg          \n",
            "  inflating: __MACOSX/data/._31043.jpg  \n",
            "  inflating: data/11393.jpg          \n",
            "  inflating: __MACOSX/data/._11393.jpg  \n",
            "  inflating: data/28512.jpg          \n",
            "  inflating: __MACOSX/data/._28512.jpg  \n",
            "  inflating: data/27621.jpg          \n",
            "  inflating: __MACOSX/data/._27621.jpg  \n",
            "  inflating: data/19917.jpg          \n",
            "  inflating: __MACOSX/data/._19917.jpg  \n",
            "  inflating: data/38701.jpg          \n",
            "  inflating: __MACOSX/data/._38701.jpg  \n",
            "  inflating: data/37432.jpg          \n",
            "  inflating: __MACOSX/data/._37432.jpg  \n",
            "  inflating: data/12842.jpg          \n",
            "  inflating: __MACOSX/data/._12842.jpg  \n",
            "  inflating: data/23447.jpg          \n",
            "  inflating: __MACOSX/data/._23447.jpg  \n",
            "  inflating: data/13584.jpg          \n",
            "  inflating: __MACOSX/data/._13584.jpg  \n",
            "  inflating: data/24328.jpg          \n",
            "  inflating: __MACOSX/data/._24328.jpg  \n",
            "  inflating: data/8959.jpg           \n",
            "  inflating: __MACOSX/data/._8959.jpg  \n",
            "  inflating: data/22981.jpg          \n",
            "  inflating: __MACOSX/data/._22981.jpg  \n",
            "  inflating: data/557.jpg            \n",
            "  inflating: __MACOSX/data/._557.jpg  \n",
            "  inflating: data/33654.jpg          \n",
            "  inflating: __MACOSX/data/._33654.jpg  \n",
            "  inflating: data/25036.jpg          \n",
            "  inflating: __MACOSX/data/._25036.jpg  \n",
            "  inflating: data/6974.jpg           \n",
            "  inflating: __MACOSX/data/._6974.jpg  \n",
            "  inflating: data/35225.jpg          \n",
            "  inflating: __MACOSX/data/._35225.jpg  \n",
            "  inflating: data/8781.jpg           \n",
            "  inflating: __MACOSX/data/._8781.jpg  \n",
            "  inflating: data/22759.jpg          \n",
            "  inflating: __MACOSX/data/._22759.jpg  \n",
            "  inflating: data/35543.jpg          \n",
            "  inflating: __MACOSX/data/._35543.jpg  \n",
            "  inflating: data/15693.jpg          \n",
            "  inflating: __MACOSX/data/._15693.jpg  \n",
            "  inflating: data/34885.jpg          \n",
            "  inflating: __MACOSX/data/._34885.jpg  \n",
            "  inflating: data/25750.jpg          \n",
            "  inflating: __MACOSX/data/._25750.jpg  \n",
            "  inflating: data/33132.jpg          \n",
            "  inflating: __MACOSX/data/._33132.jpg  \n",
            "  inflating: data/231.jpg            \n",
            "  inflating: __MACOSX/data/._231.jpg  \n",
            "  inflating: data/25988.jpg          \n",
            "  inflating: __MACOSX/data/._25988.jpg  \n",
            "  inflating: data/23321.jpg          \n",
            "  inflating: __MACOSX/data/._23321.jpg  \n",
            "  inflating: data/17084.jpg          \n",
            "  inflating: __MACOSX/data/._17084.jpg  \n",
            "  inflating: data/38067.jpg          \n",
            "  inflating: __MACOSX/data/._38067.jpg  \n",
            "  inflating: data/20628.jpg          \n",
            "  inflating: __MACOSX/data/._20628.jpg  \n",
            "  inflating: data/37354.jpg          \n",
            "  inflating: __MACOSX/data/._37354.jpg  \n",
            "  inflating: data/28274.jpg          \n",
            "  inflating: __MACOSX/data/._28274.jpg  \n",
            "  inflating: data/4805.jpg           \n",
            "  inflating: __MACOSX/data/._4805.jpg  \n",
            "  inflating: data/27147.jpg          \n",
            "  inflating: __MACOSX/data/._27147.jpg  \n",
            "  inflating: data/31725.jpg          \n",
            "  inflating: __MACOSX/data/._31725.jpg  \n",
            "  inflating: data/26259.jpg          \n",
            "  inflating: __MACOSX/data/._26259.jpg  \n",
            "  inflating: data/21536.jpg          \n",
            "  inflating: __MACOSX/data/._21536.jpg  \n",
            "  inflating: data/39379.jpg          \n",
            "  inflating: __MACOSX/data/._39379.jpg  \n",
            "  inflating: data/10933.jpg          \n",
            "  inflating: __MACOSX/data/._10933.jpg  \n",
            "  inflating: data/29181.jpg          \n",
            "  inflating: __MACOSX/data/._29181.jpg  \n",
            "  inflating: data/3159.jpg           \n",
            "  inflating: __MACOSX/data/._3159.jpg  \n",
            "  inflating: data/19042.jpg          \n",
            "  inflating: __MACOSX/data/._19042.jpg  \n",
            "  inflating: data/4636.jpg           \n",
            "  inflating: __MACOSX/data/._4636.jpg  \n",
            "  inflating: data/39392.jpg          \n",
            "  inflating: __MACOSX/data/._39392.jpg  \n",
            "  inflating: data/16371.jpg          \n",
            "  inflating: __MACOSX/data/._16371.jpg  \n",
            "  inflating: data/5528.jpg           \n",
            "  inflating: __MACOSX/data/._5528.jpg  \n",
            "  inflating: data/31916.jpg          \n",
            "  inflating: __MACOSX/data/._31916.jpg  \n",
            "  inflating: data/10700.jpg          \n",
            "  inflating: __MACOSX/data/._10700.jpg  \n",
            "  inflating: data/2247.jpg           \n",
            "  inflating: __MACOSX/data/._2247.jpg  \n",
            "  inflating: data/13209.jpg          \n",
            "  inflating: __MACOSX/data/._13209.jpg  \n",
            "  inflating: data/9312.jpg           \n",
            "  inflating: __MACOSX/data/._9312.jpg  \n",
            "  inflating: data/14566.jpg          \n",
            "  inflating: __MACOSX/data/._14566.jpg  \n",
            "  inflating: data/6021.jpg           \n",
            "  inflating: __MACOSX/data/._6021.jpg  \n",
            "  inflating: data/25963.jpg          \n",
            "  inflating: __MACOSX/data/._25963.jpg  \n",
            "  inflating: data/15678.jpg          \n",
            "  inflating: __MACOSX/data/._15678.jpg  \n",
            "  inflating: data/1996.jpg           \n",
            "  inflating: __MACOSX/data/._1996.jpg  \n",
            "  inflating: data/12117.jpg          \n",
            "  inflating: __MACOSX/data/._12117.jpg  \n",
            "  inflating: data/12671.jpg          \n",
            "  inflating: __MACOSX/data/._12671.jpg  \n",
            "  inflating: data/33867.jpg          \n",
            "  inflating: __MACOSX/data/._33867.jpg  \n",
            "  inflating: data/7459.jpg           \n",
            "  inflating: __MACOSX/data/._7459.jpg  \n",
            "  inflating: data/9474.jpg           \n",
            "  inflating: __MACOSX/data/._9474.jpg  \n",
            "  inflating: data/14200.jpg          \n",
            "  inflating: __MACOSX/data/._14200.jpg  \n",
            "  inflating: data/6747.jpg           \n",
            "  inflating: __MACOSX/data/._6747.jpg  \n",
            "  inflating: data/1028.jpg           \n",
            "  inflating: __MACOSX/data/._1028.jpg  \n",
            "  inflating: data/10066.jpg          \n",
            "  inflating: __MACOSX/data/._10066.jpg  \n",
            "  inflating: data/2521.jpg           \n",
            "  inflating: __MACOSX/data/._2521.jpg  \n",
            "  inflating: data/17709.jpg          \n",
            "  inflating: __MACOSX/data/._17709.jpg  \n",
            "  inflating: data/27812.jpg          \n",
            "  inflating: __MACOSX/data/._27812.jpg  \n",
            "  inflating: data/19724.jpg          \n",
            "  inflating: __MACOSX/data/._19724.jpg  \n",
            "  inflating: data/4150.jpg           \n",
            "  inflating: __MACOSX/data/._4150.jpg  \n",
            "  inflating: data/16417.jpg          \n",
            "  inflating: __MACOSX/data/._16417.jpg  \n",
            "  inflating: data/11378.jpg          \n",
            "  inflating: __MACOSX/data/._11378.jpg  \n",
            "  inflating: data/38932.jpg          \n",
            "  inflating: __MACOSX/data/._38932.jpg  \n",
            "  inflating: data/10072.jpg          \n",
            "  inflating: __MACOSX/data/._10072.jpg  \n",
            "  inflating: data/2535.jpg           \n",
            "  inflating: __MACOSX/data/._2535.jpg  \n",
            "  inflating: data/4144.jpg           \n",
            "  inflating: __MACOSX/data/._4144.jpg  \n",
            "  inflating: data/19730.jpg          \n",
            "  inflating: __MACOSX/data/._19730.jpg  \n",
            "  inflating: data/27806.jpg          \n",
            "  inflating: __MACOSX/data/._27806.jpg  \n",
            "  inflating: data/16403.jpg          \n",
            "  inflating: __MACOSX/data/._16403.jpg  \n",
            "  inflating: data/38926.jpg          \n",
            "  inflating: __MACOSX/data/._38926.jpg  \n",
            "  inflating: data/12665.jpg          \n",
            "  inflating: __MACOSX/data/._12665.jpg  \n",
            "  inflating: data/33873.jpg          \n",
            "  inflating: __MACOSX/data/._33873.jpg  \n",
            "  inflating: data/14214.jpg          \n",
            "  inflating: __MACOSX/data/._14214.jpg  \n",
            "  inflating: data/9460.jpg           \n",
            "  inflating: __MACOSX/data/._9460.jpg  \n",
            "  inflating: data/6753.jpg           \n",
            "  inflating: __MACOSX/data/._6753.jpg  \n",
            "  inflating: data/14572.jpg          \n",
            "  inflating: __MACOSX/data/._14572.jpg  \n",
            "  inflating: data/9306.jpg           \n",
            "  inflating: __MACOSX/data/._9306.jpg  \n",
            "  inflating: data/25977.jpg          \n",
            "  inflating: __MACOSX/data/._25977.jpg  \n",
            "  inflating: data/6035.jpg           \n",
            "  inflating: __MACOSX/data/._6035.jpg  \n",
            "  inflating: data/1982.jpg           \n",
            "  inflating: __MACOSX/data/._1982.jpg  \n",
            "  inflating: data/8018.jpg           \n",
            "  inflating: __MACOSX/data/._8018.jpg  \n",
            "  inflating: data/12103.jpg          \n",
            "  inflating: __MACOSX/data/._12103.jpg  \n",
            "  inflating: data/29195.jpg          \n",
            "  inflating: __MACOSX/data/._29195.jpg  \n",
            "  inflating: data/4622.jpg           \n",
            "  inflating: __MACOSX/data/._4622.jpg  \n",
            "  inflating: data/19056.jpg          \n",
            "  inflating: __MACOSX/data/._19056.jpg  \n",
            "  inflating: data/16365.jpg          \n",
            "  inflating: __MACOSX/data/._16365.jpg  \n",
            "  inflating: data/39386.jpg          \n",
            "  inflating: __MACOSX/data/._39386.jpg  \n",
            "  inflating: data/18348.jpg          \n",
            "  inflating: __MACOSX/data/._18348.jpg  \n",
            "  inflating: data/31902.jpg          \n",
            "  inflating: __MACOSX/data/._31902.jpg  \n",
            "  inflating: data/38098.jpg          \n",
            "  inflating: __MACOSX/data/._38098.jpg  \n",
            "  inflating: data/10714.jpg          \n",
            "  inflating: __MACOSX/data/._10714.jpg  \n",
            "  inflating: data/2253.jpg           \n",
            "  inflating: __MACOSX/data/._2253.jpg  \n",
            "  inflating: data/13235.jpg          \n",
            "  inflating: __MACOSX/data/._13235.jpg  \n",
            "  inflating: data/24499.jpg          \n",
            "  inflating: __MACOSX/data/._24499.jpg  \n",
            "  inflating: data/1772.jpg           \n",
            "  inflating: __MACOSX/data/._1772.jpg  \n",
            "  inflating: data/7303.jpg           \n",
            "  inflating: __MACOSX/data/._7303.jpg  \n",
            "  inflating: data/35594.jpg          \n",
            "  inflating: __MACOSX/data/._35594.jpg  \n",
            "  inflating: data/15644.jpg          \n",
            "  inflating: __MACOSX/data/._15644.jpg  \n",
            "  inflating: data/8030.jpg           \n",
            "  inflating: __MACOSX/data/._8030.jpg  \n",
            "  inflating: data/25787.jpg          \n",
            "  inflating: __MACOSX/data/._25787.jpg  \n",
            "  inflating: data/34852.jpg          \n",
            "  inflating: __MACOSX/data/._34852.jpg  \n",
            "  inflating: data/20827.jpg          \n",
            "  inflating: __MACOSX/data/._20827.jpg  \n",
            "  inflating: data/3165.jpg           \n",
            "  inflating: __MACOSX/data/._3165.jpg  \n",
            "  inflating: data/11422.jpg          \n",
            "  inflating: __MACOSX/data/._11422.jpg  \n",
            "  inflating: data/17053.jpg          \n",
            "  inflating: __MACOSX/data/._17053.jpg  \n",
            "  inflating: data/5514.jpg           \n",
            "  inflating: __MACOSX/data/._5514.jpg  \n",
            "  inflating: data/37383.jpg          \n",
            "  inflating: __MACOSX/data/._37383.jpg  \n",
            "  inflating: data/18360.jpg          \n",
            "  inflating: __MACOSX/data/._18360.jpg  \n",
            "  inflating: data/27190.jpg          \n",
            "  inflating: __MACOSX/data/._27190.jpg  \n",
            "  inflating: data/36923.jpg          \n",
            "  inflating: __MACOSX/data/._36923.jpg  \n",
            "  inflating: data/17735.jpg          \n",
            "  inflating: __MACOSX/data/._17735.jpg  \n",
            "  inflating: data/29803.jpg          \n",
            "  inflating: __MACOSX/data/._29803.jpg  \n",
            "  inflating: data/20199.jpg          \n",
            "  inflating: __MACOSX/data/._20199.jpg  \n",
            "  inflating: data/5272.jpg           \n",
            "  inflating: __MACOSX/data/._5272.jpg  \n",
            "  inflating: data/18406.jpg          \n",
            "  inflating: __MACOSX/data/._18406.jpg  \n",
            "  inflating: data/21287.jpg          \n",
            "  inflating: __MACOSX/data/._21287.jpg  \n",
            "  inflating: data/19718.jpg          \n",
            "  inflating: __MACOSX/data/._19718.jpg  \n",
            "  inflating: data/31094.jpg          \n",
            "  inflating: __MACOSX/data/._31094.jpg  \n",
            "  inflating: data/3603.jpg           \n",
            "  inflating: __MACOSX/data/._3603.jpg  \n",
            "  inflating: data/11344.jpg          \n",
            "  inflating: __MACOSX/data/._11344.jpg  \n",
            "  inflating: data/7465.jpg           \n",
            "  inflating: __MACOSX/data/._7465.jpg  \n",
            "  inflating: data/15122.jpg          \n",
            "  inflating: __MACOSX/data/._15122.jpg  \n",
            "  inflating: data/8756.jpg           \n",
            "  inflating: __MACOSX/data/._8756.jpg  \n",
            "  inflating: data/12895.jpg          \n",
            "  inflating: __MACOSX/data/._12895.jpg  \n",
            "  inflating: data/23490.jpg          \n",
            "  inflating: __MACOSX/data/._23490.jpg  \n",
            "  inflating: data/9448.jpg           \n",
            "  inflating: __MACOSX/data/._9448.jpg  \n",
            "  inflating: data/13553.jpg          \n",
            "  inflating: __MACOSX/data/._13553.jpg  \n",
            "  inflating: data/33683.jpg          \n",
            "  inflating: __MACOSX/data/._33683.jpg  \n",
            "  inflating: data/1014.jpg           \n",
            "  inflating: __MACOSX/data/._1014.jpg  \n",
            "  inflating: data/22956.jpg          \n",
            "  inflating: __MACOSX/data/._22956.jpg  \n",
            "  inflating: data/580.jpg            \n",
            "  inflating: __MACOSX/data/._580.jpg  \n",
            "  inflating: data/12659.jpg          \n",
            "  inflating: __MACOSX/data/._12659.jpg  \n",
            "  inflating: data/32589.jpg          \n",
            "  inflating: __MACOSX/data/._32589.jpg  \n",
            "  inflating: data/7471.jpg           \n",
            "  inflating: __MACOSX/data/._7471.jpg  \n",
            "  inflating: data/8742.jpg           \n",
            "  inflating: __MACOSX/data/._8742.jpg  \n",
            "  inflating: data/15136.jpg          \n",
            "  inflating: __MACOSX/data/._15136.jpg  \n",
            "  inflating: data/12881.jpg          \n",
            "  inflating: __MACOSX/data/._12881.jpg  \n",
            "  inflating: data/14228.jpg          \n",
            "  inflating: __MACOSX/data/._14228.jpg  \n",
            "  inflating: data/23484.jpg          \n",
            "  inflating: __MACOSX/data/._23484.jpg  \n",
            "  inflating: data/13547.jpg          \n",
            "  inflating: __MACOSX/data/._13547.jpg  \n",
            "  inflating: data/594.jpg            \n",
            "  inflating: __MACOSX/data/._594.jpg  \n",
            "  inflating: data/22942.jpg          \n",
            "  inflating: __MACOSX/data/._22942.jpg  \n",
            "  inflating: data/1000.jpg           \n",
            "  inflating: __MACOSX/data/._1000.jpg  \n",
            "  inflating: data/33697.jpg          \n",
            "  inflating: __MACOSX/data/._33697.jpg  \n",
            "  inflating: data/2509.jpg           \n",
            "  inflating: __MACOSX/data/._2509.jpg  \n",
            "  inflating: data/36937.jpg          \n",
            "  inflating: __MACOSX/data/._36937.jpg  \n",
            "  inflating: data/29817.jpg          \n",
            "  inflating: __MACOSX/data/._29817.jpg  \n",
            "  inflating: data/17721.jpg          \n",
            "  inflating: __MACOSX/data/._17721.jpg  \n",
            "  inflating: data/18412.jpg          \n",
            "  inflating: __MACOSX/data/._18412.jpg  \n",
            "  inflating: data/5266.jpg           \n",
            "  inflating: __MACOSX/data/._5266.jpg  \n",
            "  inflating: data/21293.jpg          \n",
            "  inflating: __MACOSX/data/._21293.jpg  \n",
            "  inflating: data/4178.jpg           \n",
            "  inflating: __MACOSX/data/._4178.jpg  \n",
            "  inflating: data/3617.jpg           \n",
            "  inflating: __MACOSX/data/._3617.jpg  \n",
            "  inflating: data/31080.jpg          \n",
            "  inflating: __MACOSX/data/._31080.jpg  \n",
            "  inflating: data/11350.jpg          \n",
            "  inflating: __MACOSX/data/._11350.jpg  \n",
            "  inflating: data/3171.jpg           \n",
            "  inflating: __MACOSX/data/._3171.jpg  \n",
            "  inflating: data/20833.jpg          \n",
            "  inflating: __MACOSX/data/._20833.jpg  \n",
            "  inflating: data/11436.jpg          \n",
            "  inflating: __MACOSX/data/._11436.jpg  \n",
            "  inflating: data/16359.jpg          \n",
            "  inflating: __MACOSX/data/._16359.jpg  \n",
            "  inflating: data/36089.jpg          \n",
            "  inflating: __MACOSX/data/._36089.jpg  \n",
            "  inflating: data/17047.jpg          \n",
            "  inflating: __MACOSX/data/._17047.jpg  \n",
            "  inflating: data/18374.jpg          \n",
            "  inflating: __MACOSX/data/._18374.jpg  \n",
            "  inflating: data/37397.jpg          \n",
            "  inflating: __MACOSX/data/._37397.jpg  \n",
            "  inflating: data/5500.jpg           \n",
            "  inflating: __MACOSX/data/._5500.jpg  \n",
            "  inflating: data/10728.jpg          \n",
            "  inflating: __MACOSX/data/._10728.jpg  \n",
            "  inflating: data/27184.jpg          \n",
            "  inflating: __MACOSX/data/._27184.jpg  \n",
            "  inflating: data/13221.jpg          \n",
            "  inflating: __MACOSX/data/._13221.jpg  \n",
            "  inflating: data/1766.jpg           \n",
            "  inflating: __MACOSX/data/._1766.jpg  \n",
            "  inflating: data/15888.jpg          \n",
            "  inflating: __MACOSX/data/._15888.jpg  \n",
            "  inflating: data/6009.jpg           \n",
            "  inflating: __MACOSX/data/._6009.jpg  \n",
            "  inflating: data/35580.jpg          \n",
            "  inflating: __MACOSX/data/._35580.jpg  \n",
            "  inflating: data/7317.jpg           \n",
            "  inflating: __MACOSX/data/._7317.jpg  \n",
            "  inflating: data/8024.jpg           \n",
            "  inflating: __MACOSX/data/._8024.jpg  \n",
            "  inflating: data/15650.jpg          \n",
            "  inflating: __MACOSX/data/._15650.jpg  \n",
            "  inflating: data/34846.jpg          \n",
            "  inflating: __MACOSX/data/._34846.jpg  \n",
            "  inflating: data/25793.jpg          \n",
            "  inflating: __MACOSX/data/._25793.jpg  \n",
            "  inflating: data/6196.jpg           \n",
            "  inflating: __MACOSX/data/._6196.jpg  \n",
            "  inflating: data/34701.jpg          \n",
            "  inflating: __MACOSX/data/._34701.jpg  \n",
            "  inflating: data/15917.jpg          \n",
            "  inflating: __MACOSX/data/._15917.jpg  \n",
            "  inflating: data/24512.jpg          \n",
            "  inflating: __MACOSX/data/._24512.jpg  \n",
            "  inflating: data/32370.jpg          \n",
            "  inflating: __MACOSX/data/._32370.jpg  \n",
            "  inflating: data/22163.jpg          \n",
            "  inflating: __MACOSX/data/._22163.jpg  \n",
            "  inflating: data/1821.jpg           \n",
            "  inflating: __MACOSX/data/._1821.jpg  \n",
            "  inflating: data/7288.jpg           \n",
            "  inflating: __MACOSX/data/._7288.jpg  \n",
            "  inflating: data/4781.jpg           \n",
            "  inflating: __MACOSX/data/._4781.jpg  \n",
            "  inflating: data/36116.jpg          \n",
            "  inflating: __MACOSX/data/._36116.jpg  \n",
            "  inflating: data/39225.jpg          \n",
            "  inflating: __MACOSX/data/._39225.jpg  \n",
            "  inflating: data/26305.jpg          \n",
            "  inflating: __MACOSX/data/._26305.jpg  \n",
            "  inflating: data/29036.jpg          \n",
            "  inflating: __MACOSX/data/._29036.jpg  \n",
            "  inflating: data/31679.jpg          \n",
            "  inflating: __MACOSX/data/._31679.jpg  \n",
            "  inflating: data/4959.jpg           \n",
            "  inflating: __MACOSX/data/._4959.jpg  \n",
            "  inflating: data/30567.jpg          \n",
            "  inflating: __MACOSX/data/._30567.jpg  \n",
            "  inflating: data/28328.jpg          \n",
            "  inflating: __MACOSX/data/._28328.jpg  \n",
            "  inflating: data/37208.jpg          \n",
            "  inflating: __MACOSX/data/._37208.jpg  \n",
            "  inflating: data/20774.jpg          \n",
            "  inflating: __MACOSX/data/._20774.jpg  \n",
            "  inflating: data/29988.jpg          \n",
            "  inflating: __MACOSX/data/._29988.jpg  \n",
            "  inflating: data/3950.jpg           \n",
            "  inflating: __MACOSX/data/._3950.jpg  \n",
            "  inflating: data/20012.jpg          \n",
            "  inflating: __MACOSX/data/._20012.jpg  \n",
            "  inflating: data/30201.jpg          \n",
            "  inflating: __MACOSX/data/._30201.jpg  \n",
            "  inflating: data/2496.jpg           \n",
            "  inflating: __MACOSX/data/._2496.jpg  \n",
            "  inflating: data/26463.jpg          \n",
            "  inflating: __MACOSX/data/._26463.jpg  \n",
            "  inflating: data/38885.jpg          \n",
            "  inflating: __MACOSX/data/._38885.jpg  \n",
            "  inflating: data/17866.jpg          \n",
            "  inflating: __MACOSX/data/._17866.jpg  \n",
            "  inflating: data/29750.jpg          \n",
            "  inflating: __MACOSX/data/._29750.jpg  \n",
            "  inflating: data/3788.jpg           \n",
            "  inflating: __MACOSX/data/._3788.jpg  \n",
            "  inflating: data/19693.jpg          \n",
            "  inflating: __MACOSX/data/._19693.jpg  \n",
            "  inflating: data/36670.jpg          \n",
            "  inflating: __MACOSX/data/._36670.jpg  \n",
            "  inflating: data/39543.jpg          \n",
            "  inflating: __MACOSX/data/._39543.jpg  \n",
            "  inflating: data/22605.jpg          \n",
            "  inflating: __MACOSX/data/._22605.jpg  \n",
            "  inflating: data/35379.jpg          \n",
            "  inflating: __MACOSX/data/._35379.jpg  \n",
            "  inflating: data/32416.jpg          \n",
            "  inflating: __MACOSX/data/._32416.jpg  \n",
            "  inflating: data/6828.jpg           \n",
            "  inflating: __MACOSX/data/._6828.jpg  \n",
            "  inflating: data/8805.jpg           \n",
            "  inflating: __MACOSX/data/._8805.jpg  \n",
            "  inflating: data/33708.jpg          \n",
            "  inflating: __MACOSX/data/._33708.jpg  \n",
            "  inflating: data/24274.jpg          \n",
            "  inflating: __MACOSX/data/._24274.jpg  \n",
            "  inflating: data/34067.jpg          \n",
            "  inflating: __MACOSX/data/._34067.jpg  \n",
            "  inflating: data/22611.jpg          \n",
            "  inflating: __MACOSX/data/._22611.jpg  \n",
            "  inflating: data/32402.jpg          \n",
            "  inflating: __MACOSX/data/._32402.jpg  \n",
            "  inflating: data/8811.jpg           \n",
            "  inflating: __MACOSX/data/._8811.jpg  \n",
            "  inflating: data/24260.jpg          \n",
            "  inflating: __MACOSX/data/._24260.jpg  \n",
            "  inflating: data/34073.jpg          \n",
            "  inflating: __MACOSX/data/._34073.jpg  \n",
            "  inflating: data/18599.jpg          \n",
            "  inflating: __MACOSX/data/._18599.jpg  \n",
            "  inflating: data/20006.jpg          \n",
            "  inflating: __MACOSX/data/._20006.jpg  \n",
            "  inflating: data/3944.jpg           \n",
            "  inflating: __MACOSX/data/._3944.jpg  \n",
            "  inflating: data/38649.jpg          \n",
            "  inflating: __MACOSX/data/._38649.jpg  \n",
            "  inflating: data/27769.jpg          \n",
            "  inflating: __MACOSX/data/._27769.jpg  \n",
            "  inflating: data/2482.jpg           \n",
            "  inflating: __MACOSX/data/._2482.jpg  \n",
            "  inflating: data/30215.jpg          \n",
            "  inflating: __MACOSX/data/._30215.jpg  \n",
            "  inflating: data/26477.jpg          \n",
            "  inflating: __MACOSX/data/._26477.jpg  \n",
            "  inflating: data/29744.jpg          \n",
            "  inflating: __MACOSX/data/._29744.jpg  \n",
            "  inflating: data/17872.jpg          \n",
            "  inflating: __MACOSX/data/._17872.jpg  \n",
            "  inflating: data/38891.jpg          \n",
            "  inflating: __MACOSX/data/._38891.jpg  \n",
            "  inflating: data/36664.jpg          \n",
            "  inflating: __MACOSX/data/._36664.jpg  \n",
            "  inflating: data/19687.jpg          \n",
            "  inflating: __MACOSX/data/._19687.jpg  \n",
            "  inflating: data/39557.jpg          \n",
            "  inflating: __MACOSX/data/._39557.jpg  \n",
            "  inflating: data/21318.jpg          \n",
            "  inflating: __MACOSX/data/._21318.jpg  \n",
            "  inflating: data/36102.jpg          \n",
            "  inflating: __MACOSX/data/._36102.jpg  \n",
            "  inflating: data/4795.jpg           \n",
            "  inflating: __MACOSX/data/._4795.jpg  \n",
            "  inflating: data/39231.jpg          \n",
            "  inflating: __MACOSX/data/._39231.jpg  \n",
            "  inflating: data/26311.jpg          \n",
            "  inflating: __MACOSX/data/._26311.jpg  \n",
            "  inflating: data/29022.jpg          \n",
            "  inflating: __MACOSX/data/._29022.jpg  \n",
            "  inflating: data/30573.jpg          \n",
            "  inflating: __MACOSX/data/._30573.jpg  \n",
            "  inflating: data/20760.jpg          \n",
            "  inflating: __MACOSX/data/._20760.jpg  \n",
            "  inflating: data/23269.jpg          \n",
            "  inflating: __MACOSX/data/._23269.jpg  \n",
            "  inflating: data/34715.jpg          \n",
            "  inflating: __MACOSX/data/._34715.jpg  \n",
            "  inflating: data/6182.jpg           \n",
            "  inflating: __MACOSX/data/._6182.jpg  \n",
            "  inflating: data/379.jpg            \n",
            "  inflating: __MACOSX/data/._379.jpg  \n",
            "  inflating: data/15903.jpg          \n",
            "  inflating: __MACOSX/data/._15903.jpg  \n",
            "  inflating: data/24506.jpg          \n",
            "  inflating: __MACOSX/data/._24506.jpg  \n",
            "  inflating: data/32364.jpg          \n",
            "  inflating: __MACOSX/data/._32364.jpg  \n",
            "  inflating: data/25618.jpg          \n",
            "  inflating: __MACOSX/data/._25618.jpg  \n",
            "  inflating: data/1835.jpg           \n",
            "  inflating: __MACOSX/data/._1835.jpg  \n",
            "  inflating: data/22177.jpg          \n",
            "  inflating: __MACOSX/data/._22177.jpg  \n",
            "  inflating: data/21456.jpg          \n",
            "  inflating: __MACOSX/data/._21456.jpg  \n",
            "  inflating: data/39219.jpg          \n",
            "  inflating: __MACOSX/data/._39219.jpg  \n",
            "  inflating: data/10853.jpg          \n",
            "  inflating: __MACOSX/data/._10853.jpg  \n",
            "  inflating: data/31645.jpg          \n",
            "  inflating: __MACOSX/data/._31645.jpg  \n",
            "  inflating: data/20990.jpg          \n",
            "  inflating: __MACOSX/data/._20990.jpg  \n",
            "  inflating: data/11595.jpg          \n",
            "  inflating: __MACOSX/data/._11595.jpg  \n",
            "  inflating: data/26339.jpg          \n",
            "  inflating: __MACOSX/data/._26339.jpg  \n",
            "  inflating: data/28314.jpg          \n",
            "  inflating: __MACOSX/data/._28314.jpg  \n",
            "  inflating: data/4965.jpg           \n",
            "  inflating: __MACOSX/data/._4965.jpg  \n",
            "  inflating: data/27027.jpg          \n",
            "  inflating: __MACOSX/data/._27027.jpg  \n",
            "  inflating: data/38107.jpg          \n",
            "  inflating: __MACOSX/data/._38107.jpg  \n",
            "  inflating: data/20748.jpg          \n",
            "  inflating: __MACOSX/data/._20748.jpg  \n",
            "  inflating: data/37234.jpg          \n",
            "  inflating: __MACOSX/data/._37234.jpg  \n",
            "  inflating: data/23241.jpg          \n",
            "  inflating: __MACOSX/data/._23241.jpg  \n",
            "  inflating: data/9299.jpg           \n",
            "  inflating: __MACOSX/data/._9299.jpg  \n",
            "  inflating: data/13382.jpg          \n",
            "  inflating: __MACOSX/data/._13382.jpg  \n",
            "  inflating: data/33052.jpg          \n",
            "  inflating: __MACOSX/data/._33052.jpg  \n",
            "  inflating: data/351.jpg            \n",
            "  inflating: __MACOSX/data/._351.jpg  \n",
            "  inflating: data/25630.jpg          \n",
            "  inflating: __MACOSX/data/._25630.jpg  \n",
            "  inflating: data/35423.jpg          \n",
            "  inflating: __MACOSX/data/._35423.jpg  \n",
            "  inflating: data/8187.jpg           \n",
            "  inflating: __MACOSX/data/._8187.jpg  \n",
            "  inflating: data/35345.jpg          \n",
            "  inflating: __MACOSX/data/._35345.jpg  \n",
            "  inflating: data/15095.jpg          \n",
            "  inflating: __MACOSX/data/._15095.jpg  \n",
            "  inflating: data/22639.jpg          \n",
            "  inflating: __MACOSX/data/._22639.jpg  \n",
            "  inflating: data/25156.jpg          \n",
            "  inflating: __MACOSX/data/._25156.jpg  \n",
            "  inflating: data/6814.jpg           \n",
            "  inflating: __MACOSX/data/._6814.jpg  \n",
            "  inflating: data/24248.jpg          \n",
            "  inflating: __MACOSX/data/._24248.jpg  \n",
            "  inflating: data/8839.jpg           \n",
            "  inflating: __MACOSX/data/._8839.jpg  \n",
            "  inflating: data/437.jpg            \n",
            "  inflating: __MACOSX/data/._437.jpg  \n",
            "  inflating: data/33734.jpg          \n",
            "  inflating: __MACOSX/data/._33734.jpg  \n",
            "  inflating: data/12922.jpg          \n",
            "  inflating: __MACOSX/data/._12922.jpg  \n",
            "  inflating: data/23527.jpg          \n",
            "  inflating: __MACOSX/data/._23527.jpg  \n",
            "  inflating: data/17682.jpg          \n",
            "  inflating: __MACOSX/data/._17682.jpg  \n",
            "  inflating: data/38661.jpg          \n",
            "  inflating: __MACOSX/data/._38661.jpg  \n",
            "  inflating: data/37552.jpg          \n",
            "  inflating: __MACOSX/data/._37552.jpg  \n",
            "  inflating: data/28472.jpg          \n",
            "  inflating: __MACOSX/data/._28472.jpg  \n",
            "  inflating: data/27741.jpg          \n",
            "  inflating: __MACOSX/data/._27741.jpg  \n",
            "  inflating: data/36894.jpg          \n",
            "  inflating: __MACOSX/data/._36894.jpg  \n",
            "  inflating: data/19877.jpg          \n",
            "  inflating: __MACOSX/data/._19877.jpg  \n",
            "  inflating: data/31123.jpg          \n",
            "  inflating: __MACOSX/data/._31123.jpg  \n",
            "  inflating: data/21330.jpg          \n",
            "  inflating: __MACOSX/data/._21330.jpg  \n",
            "  inflating: data/27999.jpg          \n",
            "  inflating: __MACOSX/data/._27999.jpg  \n",
            "  inflating: data/3978.jpg           \n",
            "  inflating: __MACOSX/data/._3978.jpg  \n",
            "  inflating: data/38675.jpg          \n",
            "  inflating: __MACOSX/data/._38675.jpg  \n",
            "  inflating: data/17696.jpg          \n",
            "  inflating: __MACOSX/data/._17696.jpg  \n",
            "  inflating: data/37546.jpg          \n",
            "  inflating: __MACOSX/data/._37546.jpg  \n",
            "  inflating: data/28466.jpg          \n",
            "  inflating: __MACOSX/data/._28466.jpg  \n",
            "  inflating: data/30229.jpg          \n",
            "  inflating: __MACOSX/data/._30229.jpg  \n",
            "  inflating: data/19863.jpg          \n",
            "  inflating: __MACOSX/data/._19863.jpg  \n",
            "  inflating: data/36880.jpg          \n",
            "  inflating: __MACOSX/data/._36880.jpg  \n",
            "  inflating: data/27755.jpg          \n",
            "  inflating: __MACOSX/data/._27755.jpg  \n",
            "  inflating: data/31137.jpg          \n",
            "  inflating: __MACOSX/data/._31137.jpg  \n",
            "  inflating: data/29778.jpg          \n",
            "  inflating: __MACOSX/data/._29778.jpg  \n",
            "  inflating: data/16588.jpg          \n",
            "  inflating: __MACOSX/data/._16588.jpg  \n",
            "  inflating: data/21324.jpg          \n",
            "  inflating: __MACOSX/data/._21324.jpg  \n",
            "  inflating: data/36658.jpg          \n",
            "  inflating: __MACOSX/data/._36658.jpg  \n",
            "  inflating: data/35351.jpg          \n",
            "  inflating: __MACOSX/data/._35351.jpg  \n",
            "  inflating: data/15081.jpg          \n",
            "  inflating: __MACOSX/data/._15081.jpg  \n",
            "  inflating: data/6800.jpg           \n",
            "  inflating: __MACOSX/data/._6800.jpg  \n",
            "  inflating: data/25142.jpg          \n",
            "  inflating: __MACOSX/data/._25142.jpg  \n",
            "  inflating: data/33720.jpg          \n",
            "  inflating: __MACOSX/data/._33720.jpg  \n",
            "  inflating: data/423.jpg            \n",
            "  inflating: __MACOSX/data/._423.jpg  \n",
            "  inflating: data/12936.jpg          \n",
            "  inflating: __MACOSX/data/._12936.jpg  \n",
            "  inflating: data/23533.jpg          \n",
            "  inflating: __MACOSX/data/._23533.jpg  \n",
            "  inflating: data/34729.jpg          \n",
            "  inflating: __MACOSX/data/._34729.jpg  \n",
            "  inflating: data/23255.jpg          \n",
            "  inflating: __MACOSX/data/._23255.jpg  \n",
            "  inflating: data/13396.jpg          \n",
            "  inflating: __MACOSX/data/._13396.jpg  \n",
            "  inflating: data/345.jpg            \n",
            "  inflating: __MACOSX/data/._345.jpg  \n",
            "  inflating: data/33046.jpg          \n",
            "  inflating: __MACOSX/data/._33046.jpg  \n",
            "  inflating: data/12088.jpg          \n",
            "  inflating: __MACOSX/data/._12088.jpg  \n",
            "  inflating: data/25624.jpg          \n",
            "  inflating: __MACOSX/data/._25624.jpg  \n",
            "  inflating: data/32358.jpg          \n",
            "  inflating: __MACOSX/data/._32358.jpg  \n",
            "  inflating: data/35437.jpg          \n",
            "  inflating: __MACOSX/data/._35437.jpg  \n",
            "  inflating: data/1809.jpg           \n",
            "  inflating: __MACOSX/data/._1809.jpg  \n",
            "  inflating: data/8193.jpg           \n",
            "  inflating: __MACOSX/data/._8193.jpg  \n",
            "  inflating: data/21442.jpg          \n",
            "  inflating: __MACOSX/data/._21442.jpg  \n",
            "  inflating: data/10847.jpg          \n",
            "  inflating: __MACOSX/data/._10847.jpg  \n",
            "  inflating: data/20984.jpg          \n",
            "  inflating: __MACOSX/data/._20984.jpg  \n",
            "  inflating: data/31651.jpg          \n",
            "  inflating: __MACOSX/data/._31651.jpg  \n",
            "  inflating: data/11581.jpg          \n",
            "  inflating: __MACOSX/data/._11581.jpg  \n",
            "  inflating: data/28300.jpg          \n",
            "  inflating: __MACOSX/data/._28300.jpg  \n",
            "  inflating: data/27033.jpg          \n",
            "  inflating: __MACOSX/data/._27033.jpg  \n",
            "  inflating: data/4971.jpg           \n",
            "  inflating: __MACOSX/data/._4971.jpg  \n",
            "  inflating: data/31889.jpg          \n",
            "  inflating: __MACOSX/data/._31889.jpg  \n",
            "  inflating: data/38113.jpg          \n",
            "  inflating: __MACOSX/data/._38113.jpg  \n",
            "  inflating: data/37220.jpg          \n",
            "  inflating: __MACOSX/data/._37220.jpg  \n",
            "  inflating: data/10674.jpg          \n",
            "  inflating: __MACOSX/data/._10674.jpg  \n",
            "  inflating: data/2333.jpg           \n",
            "  inflating: __MACOSX/data/._2333.jpg  \n",
            "  inflating: data/18228.jpg          \n",
            "  inflating: __MACOSX/data/._18228.jpg  \n",
            "  inflating: data/31862.jpg          \n",
            "  inflating: __MACOSX/data/._31862.jpg  \n",
            "  inflating: data/4742.jpg           \n",
            "  inflating: __MACOSX/data/._4742.jpg  \n",
            "  inflating: data/19136.jpg          \n",
            "  inflating: __MACOSX/data/._19136.jpg  \n",
            "  inflating: data/16205.jpg          \n",
            "  inflating: __MACOSX/data/._16205.jpg  \n",
            "  inflating: data/12063.jpg          \n",
            "  inflating: __MACOSX/data/._12063.jpg  \n",
            "  inflating: data/8178.jpg           \n",
            "  inflating: __MACOSX/data/._8178.jpg  \n",
            "  inflating: data/14412.jpg          \n",
            "  inflating: __MACOSX/data/._14412.jpg  \n",
            "  inflating: data/9266.jpg           \n",
            "  inflating: __MACOSX/data/._9266.jpg  \n",
            "  inflating: data/25817.jpg          \n",
            "  inflating: __MACOSX/data/._25817.jpg  \n",
            "  inflating: data/6155.jpg           \n",
            "  inflating: __MACOSX/data/._6155.jpg  \n",
            "  inflating: data/14374.jpg          \n",
            "  inflating: __MACOSX/data/._14374.jpg  \n",
            "  inflating: data/9500.jpg           \n",
            "  inflating: __MACOSX/data/._9500.jpg  \n",
            "  inflating: data/6633.jpg           \n",
            "  inflating: __MACOSX/data/._6633.jpg  \n",
            "  inflating: data/33913.jpg          \n",
            "  inflating: __MACOSX/data/._33913.jpg  \n",
            "  inflating: data/12705.jpg          \n",
            "  inflating: __MACOSX/data/._12705.jpg  \n",
            "  inflating: data/38846.jpg          \n",
            "  inflating: __MACOSX/data/._38846.jpg  \n",
            "  inflating: data/29793.jpg          \n",
            "  inflating: __MACOSX/data/._29793.jpg  \n",
            "  inflating: data/4024.jpg           \n",
            "  inflating: __MACOSX/data/._4024.jpg  \n",
            "  inflating: data/19650.jpg          \n",
            "  inflating: __MACOSX/data/._19650.jpg  \n",
            "  inflating: data/27966.jpg          \n",
            "  inflating: __MACOSX/data/._27966.jpg  \n",
            "  inflating: data/16563.jpg          \n",
            "  inflating: __MACOSX/data/._16563.jpg  \n",
            "  inflating: data/39580.jpg          \n",
            "  inflating: __MACOSX/data/._39580.jpg  \n",
            "  inflating: data/3993.jpg           \n",
            "  inflating: __MACOSX/data/._3993.jpg  \n",
            "  inflating: data/10112.jpg          \n",
            "  inflating: __MACOSX/data/._10112.jpg  \n",
            "  inflating: data/19888.jpg          \n",
            "  inflating: __MACOSX/data/._19888.jpg  \n",
            "  inflating: data/2455.jpg           \n",
            "  inflating: __MACOSX/data/._2455.jpg  \n",
            "  inflating: data/11218.jpg          \n",
            "  inflating: __MACOSX/data/._11218.jpg  \n",
            "  inflating: data/29787.jpg          \n",
            "  inflating: __MACOSX/data/._29787.jpg  \n",
            "  inflating: data/38852.jpg          \n",
            "  inflating: __MACOSX/data/._38852.jpg  \n",
            "  inflating: data/27972.jpg          \n",
            "  inflating: __MACOSX/data/._27972.jpg  \n",
            "  inflating: data/19644.jpg          \n",
            "  inflating: __MACOSX/data/._19644.jpg  \n",
            "  inflating: data/4030.jpg           \n",
            "  inflating: __MACOSX/data/._4030.jpg  \n",
            "  inflating: data/39594.jpg          \n",
            "  inflating: __MACOSX/data/._39594.jpg  \n",
            "  inflating: data/16577.jpg          \n",
            "  inflating: __MACOSX/data/._16577.jpg  \n",
            "  inflating: data/17669.jpg          \n",
            "  inflating: __MACOSX/data/._17669.jpg  \n",
            "  inflating: data/3987.jpg           \n",
            "  inflating: __MACOSX/data/._3987.jpg  \n",
            "  inflating: data/10106.jpg          \n",
            "  inflating: __MACOSX/data/._10106.jpg  \n",
            "  inflating: data/2441.jpg           \n",
            "  inflating: __MACOSX/data/._2441.jpg  \n",
            "  inflating: data/28499.jpg          \n",
            "  inflating: __MACOSX/data/._28499.jpg  \n",
            "  inflating: data/1148.jpg           \n",
            "  inflating: __MACOSX/data/._1148.jpg  \n",
            "  inflating: data/9514.jpg           \n",
            "  inflating: __MACOSX/data/._9514.jpg  \n",
            "  inflating: data/14360.jpg          \n",
            "  inflating: __MACOSX/data/._14360.jpg  \n",
            "  inflating: data/6627.jpg           \n",
            "  inflating: __MACOSX/data/._6627.jpg  \n",
            "  inflating: data/33907.jpg          \n",
            "  inflating: __MACOSX/data/._33907.jpg  \n",
            "  inflating: data/7539.jpg           \n",
            "  inflating: __MACOSX/data/._7539.jpg  \n",
            "  inflating: data/12711.jpg          \n",
            "  inflating: __MACOSX/data/._12711.jpg  \n",
            "  inflating: data/12077.jpg          \n",
            "  inflating: __MACOSX/data/._12077.jpg  \n",
            "  inflating: data/15718.jpg          \n",
            "  inflating: __MACOSX/data/._15718.jpg  \n",
            "  inflating: data/9272.jpg           \n",
            "  inflating: __MACOSX/data/._9272.jpg  \n",
            "  inflating: data/14406.jpg          \n",
            "  inflating: __MACOSX/data/._14406.jpg  \n",
            "  inflating: data/6141.jpg           \n",
            "  inflating: __MACOSX/data/._6141.jpg  \n",
            "  inflating: data/25803.jpg          \n",
            "  inflating: __MACOSX/data/._25803.jpg  \n",
            "  inflating: data/13369.jpg          \n",
            "  inflating: __MACOSX/data/._13369.jpg  \n",
            "  inflating: data/10660.jpg          \n",
            "  inflating: __MACOSX/data/._10660.jpg  \n",
            "  inflating: data/2327.jpg           \n",
            "  inflating: __MACOSX/data/._2327.jpg  \n",
            "  inflating: data/5448.jpg           \n",
            "  inflating: __MACOSX/data/._5448.jpg  \n",
            "  inflating: data/31876.jpg          \n",
            "  inflating: __MACOSX/data/._31876.jpg  \n",
            "  inflating: data/19122.jpg          \n",
            "  inflating: __MACOSX/data/._19122.jpg  \n",
            "  inflating: data/4756.jpg           \n",
            "  inflating: __MACOSX/data/._4756.jpg  \n",
            "  inflating: data/16211.jpg          \n",
            "  inflating: __MACOSX/data/._16211.jpg  \n",
            "  inflating: data/3039.jpg           \n",
            "  inflating: __MACOSX/data/._3039.jpg  \n",
            "  inflating: data/34926.jpg          \n",
            "  inflating: __MACOSX/data/._34926.jpg  \n",
            "  inflating: data/7277.jpg           \n",
            "  inflating: __MACOSX/data/._7277.jpg  \n",
            "  inflating: data/8144.jpg           \n",
            "  inflating: __MACOSX/data/._8144.jpg  \n",
            "  inflating: data/15730.jpg          \n",
            "  inflating: __MACOSX/data/._15730.jpg  \n",
            "  inflating: data/6169.jpg           \n",
            "  inflating: __MACOSX/data/._6169.jpg  \n",
            "  inflating: data/23282.jpg          \n",
            "  inflating: __MACOSX/data/._23282.jpg  \n",
            "  inflating: data/13341.jpg          \n",
            "  inflating: __MACOSX/data/._13341.jpg  \n",
            "  inflating: data/1606.jpg           \n",
            "  inflating: __MACOSX/data/._1606.jpg  \n",
            "  inflating: data/33091.jpg          \n",
            "  inflating: __MACOSX/data/._33091.jpg  \n",
            "  inflating: data/392.jpg            \n",
            "  inflating: __MACOSX/data/._392.jpg  \n",
            "  inflating: data/30598.jpg          \n",
            "  inflating: __MACOSX/data/._30598.jpg  \n",
            "  inflating: data/10648.jpg          \n",
            "  inflating: __MACOSX/data/._10648.jpg  \n",
            "  inflating: data/17127.jpg          \n",
            "  inflating: __MACOSX/data/._17127.jpg  \n",
            "  inflating: data/18214.jpg          \n",
            "  inflating: __MACOSX/data/._18214.jpg  \n",
            "  inflating: data/5460.jpg           \n",
            "  inflating: __MACOSX/data/._5460.jpg  \n",
            "  inflating: data/16239.jpg          \n",
            "  inflating: __MACOSX/data/._16239.jpg  \n",
            "  inflating: data/21495.jpg          \n",
            "  inflating: __MACOSX/data/._21495.jpg  \n",
            "  inflating: data/10890.jpg          \n",
            "  inflating: __MACOSX/data/._10890.jpg  \n",
            "  inflating: data/3011.jpg           \n",
            "  inflating: __MACOSX/data/._3011.jpg  \n",
            "  inflating: data/31686.jpg          \n",
            "  inflating: __MACOSX/data/._31686.jpg  \n",
            "  inflating: data/20953.jpg          \n",
            "  inflating: __MACOSX/data/._20953.jpg  \n",
            "  inflating: data/11556.jpg          \n",
            "  inflating: __MACOSX/data/._11556.jpg  \n",
            "  inflating: data/3777.jpg           \n",
            "  inflating: __MACOSX/data/._3777.jpg  \n",
            "  inflating: data/17899.jpg          \n",
            "  inflating: __MACOSX/data/._17899.jpg  \n",
            "  inflating: data/11230.jpg          \n",
            "  inflating: __MACOSX/data/._11230.jpg  \n",
            "  inflating: data/4018.jpg           \n",
            "  inflating: __MACOSX/data/._4018.jpg  \n",
            "  inflating: data/29977.jpg          \n",
            "  inflating: __MACOSX/data/._29977.jpg  \n",
            "  inflating: data/17641.jpg          \n",
            "  inflating: __MACOSX/data/._17641.jpg  \n",
            "  inflating: data/18572.jpg          \n",
            "  inflating: __MACOSX/data/._18572.jpg  \n",
            "  inflating: data/37591.jpg          \n",
            "  inflating: __MACOSX/data/._37591.jpg  \n",
            "  inflating: data/5306.jpg           \n",
            "  inflating: __MACOSX/data/._5306.jpg  \n",
            "  inflating: data/2469.jpg           \n",
            "  inflating: __MACOSX/data/._2469.jpg  \n",
            "  inflating: data/27782.jpg          \n",
            "  inflating: __MACOSX/data/._27782.jpg  \n",
            "  inflating: data/36857.jpg          \n",
            "  inflating: __MACOSX/data/._36857.jpg  \n",
            "  inflating: data/13427.jpg          \n",
            "  inflating: __MACOSX/data/._13427.jpg  \n",
            "  inflating: data/22822.jpg          \n",
            "  inflating: __MACOSX/data/._22822.jpg  \n",
            "  inflating: data/1160.jpg           \n",
            "  inflating: __MACOSX/data/._1160.jpg  \n",
            "  inflating: data/34098.jpg          \n",
            "  inflating: __MACOSX/data/._34098.jpg  \n",
            "  inflating: data/14348.jpg          \n",
            "  inflating: __MACOSX/data/._14348.jpg  \n",
            "  inflating: data/35386.jpg          \n",
            "  inflating: __MACOSX/data/._35386.jpg  \n",
            "  inflating: data/7511.jpg           \n",
            "  inflating: __MACOSX/data/._7511.jpg  \n",
            "  inflating: data/8622.jpg           \n",
            "  inflating: __MACOSX/data/._8622.jpg  \n",
            "  inflating: data/15056.jpg          \n",
            "  inflating: __MACOSX/data/._15056.jpg  \n",
            "  inflating: data/12739.jpg          \n",
            "  inflating: __MACOSX/data/._12739.jpg  \n",
            "  inflating: data/25195.jpg          \n",
            "  inflating: __MACOSX/data/._25195.jpg  \n",
            "  inflating: data/13433.jpg          \n",
            "  inflating: __MACOSX/data/._13433.jpg  \n",
            "  inflating: data/1174.jpg           \n",
            "  inflating: __MACOSX/data/._1174.jpg  \n",
            "  inflating: data/22836.jpg          \n",
            "  inflating: __MACOSX/data/._22836.jpg  \n",
            "  inflating: data/9528.jpg           \n",
            "  inflating: __MACOSX/data/._9528.jpg  \n",
            "  inflating: data/7505.jpg           \n",
            "  inflating: __MACOSX/data/._7505.jpg  \n",
            "  inflating: data/35392.jpg          \n",
            "  inflating: __MACOSX/data/._35392.jpg  \n",
            "  inflating: data/15042.jpg          \n",
            "  inflating: __MACOSX/data/._15042.jpg  \n",
            "  inflating: data/8636.jpg           \n",
            "  inflating: __MACOSX/data/._8636.jpg  \n",
            "  inflating: data/25181.jpg          \n",
            "  inflating: __MACOSX/data/._25181.jpg  \n",
            "  inflating: data/3763.jpg           \n",
            "  inflating: __MACOSX/data/._3763.jpg  \n",
            "  inflating: data/11224.jpg          \n",
            "  inflating: __MACOSX/data/._11224.jpg  \n",
            "  inflating: data/26488.jpg          \n",
            "  inflating: __MACOSX/data/._26488.jpg  \n",
            "  inflating: data/19678.jpg          \n",
            "  inflating: __MACOSX/data/._19678.jpg  \n",
            "  inflating: data/17655.jpg          \n",
            "  inflating: __MACOSX/data/._17655.jpg  \n",
            "  inflating: data/29963.jpg          \n",
            "  inflating: __MACOSX/data/._29963.jpg  \n",
            "  inflating: data/5312.jpg           \n",
            "  inflating: __MACOSX/data/._5312.jpg  \n",
            "  inflating: data/37585.jpg          \n",
            "  inflating: __MACOSX/data/._37585.jpg  \n",
            "  inflating: data/18566.jpg          \n",
            "  inflating: __MACOSX/data/._18566.jpg  \n",
            "  inflating: data/36843.jpg          \n",
            "  inflating: __MACOSX/data/._36843.jpg  \n",
            "  inflating: data/27796.jpg          \n",
            "  inflating: __MACOSX/data/._27796.jpg  \n",
            "  inflating: data/17133.jpg          \n",
            "  inflating: __MACOSX/data/._17133.jpg  \n",
            "  inflating: data/5474.jpg           \n",
            "  inflating: __MACOSX/data/._5474.jpg  \n",
            "  inflating: data/18200.jpg          \n",
            "  inflating: __MACOSX/data/._18200.jpg  \n",
            "  inflating: data/21481.jpg          \n",
            "  inflating: __MACOSX/data/._21481.jpg  \n",
            "  inflating: data/10884.jpg          \n",
            "  inflating: __MACOSX/data/._10884.jpg  \n",
            "  inflating: data/20947.jpg          \n",
            "  inflating: __MACOSX/data/._20947.jpg  \n",
            "  inflating: data/31692.jpg          \n",
            "  inflating: __MACOSX/data/._31692.jpg  \n",
            "  inflating: data/3005.jpg           \n",
            "  inflating: __MACOSX/data/._3005.jpg  \n",
            "  inflating: data/11542.jpg          \n",
            "  inflating: __MACOSX/data/._11542.jpg  \n",
            "  inflating: data/34932.jpg          \n",
            "  inflating: __MACOSX/data/._34932.jpg  \n",
            "  inflating: data/7263.jpg           \n",
            "  inflating: __MACOSX/data/._7263.jpg  \n",
            "  inflating: data/15724.jpg          \n",
            "  inflating: __MACOSX/data/._15724.jpg  \n",
            "  inflating: data/8150.jpg           \n",
            "  inflating: __MACOSX/data/._8150.jpg  \n",
            "  inflating: data/22188.jpg          \n",
            "  inflating: __MACOSX/data/._22188.jpg  \n",
            "  inflating: data/23296.jpg          \n",
            "  inflating: __MACOSX/data/._23296.jpg  \n",
            "  inflating: data/13355.jpg          \n",
            "  inflating: __MACOSX/data/._13355.jpg  \n",
            "  inflating: data/386.jpg            \n",
            "  inflating: __MACOSX/data/._386.jpg  \n",
            "  inflating: data/33085.jpg          \n",
            "  inflating: __MACOSX/data/._33085.jpg  \n",
            "  inflating: data/1612.jpg           \n",
            "  inflating: __MACOSX/data/._1612.jpg  \n",
            "  inflating: data/91.jpg             \n",
            "  inflating: __MACOSX/data/._91.jpg  \n",
            "  inflating: data/34265.jpg          \n",
            "  inflating: __MACOSX/data/._34265.jpg  \n",
            "  inflating: data/23719.jpg          \n",
            "  inflating: __MACOSX/data/._23719.jpg  \n",
            "  inflating: data/24076.jpg          \n",
            "  inflating: __MACOSX/data/._24076.jpg  \n",
            "  inflating: data/7934.jpg           \n",
            "  inflating: __MACOSX/data/._7934.jpg  \n",
            "  inflating: data/609.jpg            \n",
            "  inflating: __MACOSX/data/._609.jpg  \n",
            "  inflating: data/25368.jpg          \n",
            "  inflating: __MACOSX/data/._25368.jpg  \n",
            "  inflating: data/9919.jpg           \n",
            "  inflating: __MACOSX/data/._9919.jpg  \n",
            "  inflating: data/32614.jpg          \n",
            "  inflating: __MACOSX/data/._32614.jpg  \n",
            "  inflating: data/13802.jpg          \n",
            "  inflating: __MACOSX/data/._13802.jpg  \n",
            "  inflating: data/22407.jpg          \n",
            "  inflating: __MACOSX/data/._22407.jpg  \n",
            "  inflating: data/28894.jpg          \n",
            "  inflating: __MACOSX/data/._28894.jpg  \n",
            "  inflating: data/39741.jpg          \n",
            "  inflating: __MACOSX/data/._39741.jpg  \n",
            "  inflating: data/19491.jpg          \n",
            "  inflating: __MACOSX/data/._19491.jpg  \n",
            "  inflating: data/36472.jpg          \n",
            "  inflating: __MACOSX/data/._36472.jpg  \n",
            "  inflating: data/29552.jpg          \n",
            "  inflating: __MACOSX/data/._29552.jpg  \n",
            "  inflating: data/26661.jpg          \n",
            "  inflating: __MACOSX/data/._26661.jpg  \n",
            "  inflating: data/18957.jpg          \n",
            "  inflating: __MACOSX/data/._18957.jpg  \n",
            "  inflating: data/39999.jpg          \n",
            "  inflating: __MACOSX/data/._39999.jpg  \n",
            "  inflating: data/30003.jpg          \n",
            "  inflating: __MACOSX/data/._30003.jpg  \n",
            "  inflating: data/2694.jpg           \n",
            "  inflating: __MACOSX/data/._2694.jpg  \n",
            "  inflating: data/20210.jpg          \n",
            "  inflating: __MACOSX/data/._20210.jpg  \n",
            "  inflating: data/20576.jpg          \n",
            "  inflating: __MACOSX/data/._20576.jpg  \n",
            "  inflating: data/38339.jpg          \n",
            "  inflating: __MACOSX/data/._38339.jpg  \n",
            "  inflating: data/11973.jpg          \n",
            "  inflating: __MACOSX/data/._11973.jpg  \n",
            "  inflating: data/30765.jpg          \n",
            "  inflating: __MACOSX/data/._30765.jpg  \n",
            "  inflating: data/27219.jpg          \n",
            "  inflating: __MACOSX/data/._27219.jpg  \n",
            "  inflating: data/29234.jpg          \n",
            "  inflating: __MACOSX/data/._29234.jpg  \n",
            "  inflating: data/5845.jpg           \n",
            "  inflating: __MACOSX/data/._5845.jpg  \n",
            "  inflating: data/26107.jpg          \n",
            "  inflating: __MACOSX/data/._26107.jpg  \n",
            "  inflating: data/39027.jpg          \n",
            "  inflating: __MACOSX/data/._39027.jpg  \n",
            "  inflating: data/21668.jpg          \n",
            "  inflating: __MACOSX/data/._21668.jpg  \n",
            "  inflating: data/4583.jpg           \n",
            "  inflating: __MACOSX/data/._4583.jpg  \n",
            "  inflating: data/36314.jpg          \n",
            "  inflating: __MACOSX/data/._36314.jpg  \n",
            "  inflating: data/22361.jpg          \n",
            "  inflating: __MACOSX/data/._22361.jpg  \n",
            "  inflating: data/32172.jpg          \n",
            "  inflating: __MACOSX/data/._32172.jpg  \n",
            "  inflating: data/24710.jpg          \n",
            "  inflating: __MACOSX/data/._24710.jpg  \n",
            "  inflating: data/6394.jpg           \n",
            "  inflating: __MACOSX/data/._6394.jpg  \n",
            "  inflating: data/34503.jpg          \n",
            "  inflating: __MACOSX/data/._34503.jpg  \n",
            "  inflating: data/35609.jpg          \n",
            "  inflating: __MACOSX/data/._35609.jpg  \n",
            "  inflating: data/22375.jpg          \n",
            "  inflating: __MACOSX/data/._22375.jpg  \n",
            "  inflating: data/32166.jpg          \n",
            "  inflating: __MACOSX/data/._32166.jpg  \n",
            "  inflating: data/24704.jpg          \n",
            "  inflating: __MACOSX/data/._24704.jpg  \n",
            "  inflating: data/33278.jpg          \n",
            "  inflating: __MACOSX/data/._33278.jpg  \n",
            "  inflating: data/34517.jpg          \n",
            "  inflating: __MACOSX/data/._34517.jpg  \n",
            "  inflating: data/6380.jpg           \n",
            "  inflating: __MACOSX/data/._6380.jpg  \n",
            "  inflating: data/20562.jpg          \n",
            "  inflating: __MACOSX/data/._20562.jpg  \n",
            "  inflating: data/11967.jpg          \n",
            "  inflating: __MACOSX/data/._11967.jpg  \n",
            "  inflating: data/5689.jpg           \n",
            "  inflating: __MACOSX/data/._5689.jpg  \n",
            "  inflating: data/30771.jpg          \n",
            "  inflating: __MACOSX/data/._30771.jpg  \n",
            "  inflating: data/29220.jpg          \n",
            "  inflating: __MACOSX/data/._29220.jpg  \n",
            "  inflating: data/26113.jpg          \n",
            "  inflating: __MACOSX/data/._26113.jpg  \n",
            "  inflating: data/5851.jpg           \n",
            "  inflating: __MACOSX/data/._5851.jpg  \n",
            "  inflating: data/39033.jpg          \n",
            "  inflating: __MACOSX/data/._39033.jpg  \n",
            "  inflating: data/36300.jpg          \n",
            "  inflating: __MACOSX/data/._36300.jpg  \n",
            "  inflating: data/4597.jpg           \n",
            "  inflating: __MACOSX/data/._4597.jpg  \n",
            "  inflating: data/2858.jpg           \n",
            "  inflating: __MACOSX/data/._2858.jpg  \n",
            "  inflating: data/39755.jpg          \n",
            "  inflating: __MACOSX/data/._39755.jpg  \n",
            "  inflating: data/28880.jpg          \n",
            "  inflating: __MACOSX/data/._28880.jpg  \n",
            "  inflating: data/36466.jpg          \n",
            "  inflating: __MACOSX/data/._36466.jpg  \n",
            "  inflating: data/19485.jpg          \n",
            "  inflating: __MACOSX/data/._19485.jpg  \n",
            "  inflating: data/29546.jpg          \n",
            "  inflating: __MACOSX/data/._29546.jpg  \n",
            "  inflating: data/31309.jpg          \n",
            "  inflating: __MACOSX/data/._31309.jpg  \n",
            "  inflating: data/18943.jpg          \n",
            "  inflating: __MACOSX/data/._18943.jpg  \n",
            "  inflating: data/26675.jpg          \n",
            "  inflating: __MACOSX/data/._26675.jpg  \n",
            "  inflating: data/2680.jpg           \n",
            "  inflating: __MACOSX/data/._2680.jpg  \n",
            "  inflating: data/30017.jpg          \n",
            "  inflating: __MACOSX/data/._30017.jpg  \n",
            "  inflating: data/28658.jpg          \n",
            "  inflating: __MACOSX/data/._28658.jpg  \n",
            "  inflating: data/20204.jpg          \n",
            "  inflating: __MACOSX/data/._20204.jpg  \n",
            "  inflating: data/37778.jpg          \n",
            "  inflating: __MACOSX/data/._37778.jpg  \n",
            "  inflating: data/34271.jpg          \n",
            "  inflating: __MACOSX/data/._34271.jpg  \n",
            "  inflating: data/85.jpg             \n",
            "  inflating: __MACOSX/data/._85.jpg  \n",
            "  inflating: data/7920.jpg           \n",
            "  inflating: __MACOSX/data/._7920.jpg  \n",
            "  inflating: data/24062.jpg          \n",
            "  inflating: __MACOSX/data/._24062.jpg  \n",
            "  inflating: data/1389.jpg           \n",
            "  inflating: __MACOSX/data/._1389.jpg  \n",
            "  inflating: data/32600.jpg          \n",
            "  inflating: __MACOSX/data/._32600.jpg  \n",
            "  inflating: data/13816.jpg          \n",
            "  inflating: __MACOSX/data/._13816.jpg  \n",
            "  inflating: data/22413.jpg          \n",
            "  inflating: __MACOSX/data/._22413.jpg  \n",
            "  inflating: data/2870.jpg           \n",
            "  inflating: __MACOSX/data/._2870.jpg  \n",
            "  inflating: data/21132.jpg          \n",
            "  inflating: __MACOSX/data/._21132.jpg  \n",
            "  inflating: data/37988.jpg          \n",
            "  inflating: __MACOSX/data/._37988.jpg  \n",
            "  inflating: data/31321.jpg          \n",
            "  inflating: __MACOSX/data/._31321.jpg  \n",
            "  inflating: data/27543.jpg          \n",
            "  inflating: __MACOSX/data/._27543.jpg  \n",
            "  inflating: data/16946.jpg          \n",
            "  inflating: __MACOSX/data/._16946.jpg  \n",
            "  inflating: data/28670.jpg          \n",
            "  inflating: __MACOSX/data/._28670.jpg  \n",
            "  inflating: data/37750.jpg          \n",
            "  inflating: __MACOSX/data/._37750.jpg  \n",
            "  inflating: data/26885.jpg          \n",
            "  inflating: __MACOSX/data/._26885.jpg  \n",
            "  inflating: data/17480.jpg          \n",
            "  inflating: __MACOSX/data/._17480.jpg  \n",
            "  inflating: data/38463.jpg          \n",
            "  inflating: __MACOSX/data/._38463.jpg  \n",
            "  inflating: data/14189.jpg          \n",
            "  inflating: __MACOSX/data/._14189.jpg  \n",
            "  inflating: data/23725.jpg          \n",
            "  inflating: __MACOSX/data/._23725.jpg  \n",
            "  inflating: data/34259.jpg          \n",
            "  inflating: __MACOSX/data/._34259.jpg  \n",
            "  inflating: data/33536.jpg          \n",
            "  inflating: __MACOSX/data/._33536.jpg  \n",
            "  inflating: data/635.jpg            \n",
            "  inflating: __MACOSX/data/._635.jpg  \n",
            "  inflating: data/7908.jpg           \n",
            "  inflating: __MACOSX/data/._7908.jpg  \n",
            "  inflating: data/9925.jpg           \n",
            "  inflating: __MACOSX/data/._9925.jpg  \n",
            "  inflating: data/32628.jpg          \n",
            "  inflating: __MACOSX/data/._32628.jpg  \n",
            "  inflating: data/25354.jpg          \n",
            "  inflating: __MACOSX/data/._25354.jpg  \n",
            "  inflating: data/15297.jpg          \n",
            "  inflating: __MACOSX/data/._15297.jpg  \n",
            "  inflating: data/35147.jpg          \n",
            "  inflating: __MACOSX/data/._35147.jpg  \n",
            "  inflating: data/8385.jpg           \n",
            "  inflating: __MACOSX/data/._8385.jpg  \n",
            "  inflating: data/35621.jpg          \n",
            "  inflating: __MACOSX/data/._35621.jpg  \n",
            "  inflating: data/14837.jpg          \n",
            "  inflating: __MACOSX/data/._14837.jpg  \n",
            "  inflating: data/25432.jpg          \n",
            "  inflating: __MACOSX/data/._25432.jpg  \n",
            "  inflating: data/153.jpg            \n",
            "  inflating: __MACOSX/data/._153.jpg  \n",
            "  inflating: data/33250.jpg          \n",
            "  inflating: __MACOSX/data/._33250.jpg  \n",
            "  inflating: data/13180.jpg          \n",
            "  inflating: __MACOSX/data/._13180.jpg  \n",
            "  inflating: data/23043.jpg          \n",
            "  inflating: __MACOSX/data/._23043.jpg  \n",
            "  inflating: data/37036.jpg          \n",
            "  inflating: __MACOSX/data/._37036.jpg  \n",
            "  inflating: data/38305.jpg          \n",
            "  inflating: __MACOSX/data/._38305.jpg  \n",
            "  inflating: data/10489.jpg          \n",
            "  inflating: __MACOSX/data/._10489.jpg  \n",
            "  inflating: data/27225.jpg          \n",
            "  inflating: __MACOSX/data/._27225.jpg  \n",
            "  inflating: data/28116.jpg          \n",
            "  inflating: __MACOSX/data/._28116.jpg  \n",
            "  inflating: data/30759.jpg          \n",
            "  inflating: __MACOSX/data/._30759.jpg  \n",
            "  inflating: data/5879.jpg           \n",
            "  inflating: __MACOSX/data/._5879.jpg  \n",
            "  inflating: data/11797.jpg          \n",
            "  inflating: __MACOSX/data/._11797.jpg  \n",
            "  inflating: data/31447.jpg          \n",
            "  inflating: __MACOSX/data/._31447.jpg  \n",
            "  inflating: data/29208.jpg          \n",
            "  inflating: __MACOSX/data/._29208.jpg  \n",
            "  inflating: data/36328.jpg          \n",
            "  inflating: __MACOSX/data/._36328.jpg  \n",
            "  inflating: data/21654.jpg          \n",
            "  inflating: __MACOSX/data/._21654.jpg  \n",
            "  inflating: data/30981.jpg          \n",
            "  inflating: __MACOSX/data/._30981.jpg  \n",
            "  inflating: data/37022.jpg          \n",
            "  inflating: __MACOSX/data/._37022.jpg  \n",
            "  inflating: data/38311.jpg          \n",
            "  inflating: __MACOSX/data/._38311.jpg  \n",
            "  inflating: data/27231.jpg          \n",
            "  inflating: __MACOSX/data/._27231.jpg  \n",
            "  inflating: data/21898.jpg          \n",
            "  inflating: __MACOSX/data/._21898.jpg  \n",
            "  inflating: data/28102.jpg          \n",
            "  inflating: __MACOSX/data/._28102.jpg  \n",
            "  inflating: data/11783.jpg          \n",
            "  inflating: __MACOSX/data/._11783.jpg  \n",
            "  inflating: data/31453.jpg          \n",
            "  inflating: __MACOSX/data/._31453.jpg  \n",
            "  inflating: data/30995.jpg          \n",
            "  inflating: __MACOSX/data/._30995.jpg  \n",
            "  inflating: data/21640.jpg          \n",
            "  inflating: __MACOSX/data/._21640.jpg  \n",
            "  inflating: data/8391.jpg           \n",
            "  inflating: __MACOSX/data/._8391.jpg  \n",
            "  inflating: data/22349.jpg          \n",
            "  inflating: __MACOSX/data/._22349.jpg  \n",
            "  inflating: data/35635.jpg          \n",
            "  inflating: __MACOSX/data/._35635.jpg  \n",
            "  inflating: data/14823.jpg          \n",
            "  inflating: __MACOSX/data/._14823.jpg  \n",
            "  inflating: data/25426.jpg          \n",
            "  inflating: __MACOSX/data/._25426.jpg  \n",
            "  inflating: data/33244.jpg          \n",
            "  inflating: __MACOSX/data/._33244.jpg  \n",
            "  inflating: data/147.jpg            \n",
            "  inflating: __MACOSX/data/._147.jpg  \n",
            "  inflating: data/13194.jpg          \n",
            "  inflating: __MACOSX/data/._13194.jpg  \n",
            "  inflating: data/24738.jpg          \n",
            "  inflating: __MACOSX/data/._24738.jpg  \n",
            "  inflating: data/23057.jpg          \n",
            "  inflating: __MACOSX/data/._23057.jpg  \n",
            "  inflating: data/23731.jpg          \n",
            "  inflating: __MACOSX/data/._23731.jpg  \n",
            "  inflating: data/621.jpg            \n",
            "  inflating: __MACOSX/data/._621.jpg  \n",
            "  inflating: data/33522.jpg          \n",
            "  inflating: __MACOSX/data/._33522.jpg  \n",
            "  inflating: data/9931.jpg           \n",
            "  inflating: __MACOSX/data/._9931.jpg  \n",
            "  inflating: data/25340.jpg          \n",
            "  inflating: __MACOSX/data/._25340.jpg  \n",
            "  inflating: data/15283.jpg          \n",
            "  inflating: __MACOSX/data/._15283.jpg  \n",
            "  inflating: data/35153.jpg          \n",
            "  inflating: __MACOSX/data/._35153.jpg  \n",
            "  inflating: data/21126.jpg          \n",
            "  inflating: __MACOSX/data/._21126.jpg  \n",
            "  inflating: data/2864.jpg           \n",
            "  inflating: __MACOSX/data/._2864.jpg  \n",
            "  inflating: data/39769.jpg          \n",
            "  inflating: __MACOSX/data/._39769.jpg  \n",
            "  inflating: data/26649.jpg          \n",
            "  inflating: __MACOSX/data/._26649.jpg  \n",
            "  inflating: data/31335.jpg          \n",
            "  inflating: __MACOSX/data/._31335.jpg  \n",
            "  inflating: data/27557.jpg          \n",
            "  inflating: __MACOSX/data/._27557.jpg  \n",
            "  inflating: data/28664.jpg          \n",
            "  inflating: __MACOSX/data/._28664.jpg  \n",
            "  inflating: data/16952.jpg          \n",
            "  inflating: __MACOSX/data/._16952.jpg  \n",
            "  inflating: data/26891.jpg          \n",
            "  inflating: __MACOSX/data/._26891.jpg  \n",
            "  inflating: data/37744.jpg          \n",
            "  inflating: __MACOSX/data/._37744.jpg  \n",
            "  inflating: data/38477.jpg          \n",
            "  inflating: __MACOSX/data/._38477.jpg  \n",
            "  inflating: data/17494.jpg          \n",
            "  inflating: __MACOSX/data/._17494.jpg  \n",
            "  inflating: data/20238.jpg          \n",
            "  inflating: __MACOSX/data/._20238.jpg  \n",
            "  inflating: data/2657.jpg           \n",
            "  inflating: __MACOSX/data/._2657.jpg  \n",
            "  inflating: data/10310.jpg          \n",
            "  inflating: __MACOSX/data/._10310.jpg  \n",
            "  inflating: data/5138.jpg           \n",
            "  inflating: __MACOSX/data/._5138.jpg  \n",
            "  inflating: data/28857.jpg          \n",
            "  inflating: __MACOSX/data/._28857.jpg  \n",
            "  inflating: data/16761.jpg          \n",
            "  inflating: __MACOSX/data/._16761.jpg  \n",
            "  inflating: data/39782.jpg          \n",
            "  inflating: __MACOSX/data/._39782.jpg  \n",
            "  inflating: data/4226.jpg           \n",
            "  inflating: __MACOSX/data/._4226.jpg  \n",
            "  inflating: data/19452.jpg          \n",
            "  inflating: __MACOSX/data/._19452.jpg  \n",
            "  inflating: data/29591.jpg          \n",
            "  inflating: __MACOSX/data/._29591.jpg  \n",
            "  inflating: data/3549.jpg           \n",
            "  inflating: __MACOSX/data/._3549.jpg  \n",
            "  inflating: data/37977.jpg          \n",
            "  inflating: __MACOSX/data/._37977.jpg  \n",
            "  inflating: data/18994.jpg          \n",
            "  inflating: __MACOSX/data/._18994.jpg  \n",
            "  inflating: data/12507.jpg          \n",
            "  inflating: __MACOSX/data/._12507.jpg  \n",
            "  inflating: data/23902.jpg          \n",
            "  inflating: __MACOSX/data/._23902.jpg  \n",
            "  inflating: data/15268.jpg          \n",
            "  inflating: __MACOSX/data/._15268.jpg  \n",
            "  inflating: data/812.jpg            \n",
            "  inflating: __MACOSX/data/._812.jpg  \n",
            "  inflating: data/6431.jpg           \n",
            "  inflating: __MACOSX/data/._6431.jpg  \n",
            "  inflating: data/52.jpg             \n",
            "  inflating: __MACOSX/data/._52.jpg  \n",
            "  inflating: data/14176.jpg          \n",
            "  inflating: __MACOSX/data/._14176.jpg  \n",
            "  inflating: data/9702.jpg           \n",
            "  inflating: __MACOSX/data/._9702.jpg  \n",
            "  inflating: data/13619.jpg          \n",
            "  inflating: __MACOSX/data/._13619.jpg  \n",
            "  inflating: data/35806.jpg          \n",
            "  inflating: __MACOSX/data/._35806.jpg  \n",
            "  inflating: data/1438.jpg           \n",
            "  inflating: __MACOSX/data/._1438.jpg  \n",
            "  inflating: data/6357.jpg           \n",
            "  inflating: __MACOSX/data/._6357.jpg  \n",
            "  inflating: data/14610.jpg          \n",
            "  inflating: __MACOSX/data/._14610.jpg  \n",
            "  inflating: data/9064.jpg           \n",
            "  inflating: __MACOSX/data/._9064.jpg  \n",
            "  inflating: data/7049.jpg           \n",
            "  inflating: __MACOSX/data/._7049.jpg  \n",
            "  inflating: data/12261.jpg          \n",
            "  inflating: __MACOSX/data/._12261.jpg  \n",
            "  inflating: data/11768.jpg          \n",
            "  inflating: __MACOSX/data/._11768.jpg  \n",
            "  inflating: data/5886.jpg           \n",
            "  inflating: __MACOSX/data/._5886.jpg  \n",
            "  inflating: data/0.jpg              \n",
            "  inflating: __MACOSX/data/._0.jpg   \n",
            "  inflating: data/16007.jpg          \n",
            "  inflating: __MACOSX/data/._16007.jpg  \n",
            "  inflating: data/4540.jpg           \n",
            "  inflating: __MACOSX/data/._4540.jpg  \n",
            "  inflating: data/19334.jpg          \n",
            "  inflating: __MACOSX/data/._19334.jpg  \n",
            "  inflating: data/17319.jpg          \n",
            "  inflating: __MACOSX/data/._17319.jpg  \n",
            "  inflating: data/2131.jpg           \n",
            "  inflating: __MACOSX/data/._2131.jpg  \n",
            "  inflating: data/21873.jpg          \n",
            "  inflating: __MACOSX/data/._21873.jpg  \n",
            "  inflating: data/10476.jpg          \n",
            "  inflating: __MACOSX/data/._10476.jpg  \n",
            "  inflating: data/5892.jpg           \n",
            "  inflating: __MACOSX/data/._5892.jpg  \n",
            "  inflating: data/16013.jpg          \n",
            "  inflating: __MACOSX/data/._16013.jpg  \n",
            "  inflating: data/19320.jpg          \n",
            "  inflating: __MACOSX/data/._19320.jpg  \n",
            "  inflating: data/4554.jpg           \n",
            "  inflating: __MACOSX/data/._4554.jpg  \n",
            "  inflating: data/21867.jpg          \n",
            "  inflating: __MACOSX/data/._21867.jpg  \n",
            "  inflating: data/2125.jpg           \n",
            "  inflating: __MACOSX/data/._2125.jpg  \n",
            "  inflating: data/10462.jpg          \n",
            "  inflating: __MACOSX/data/._10462.jpg  \n",
            "  inflating: data/35812.jpg          \n",
            "  inflating: __MACOSX/data/._35812.jpg  \n",
            "  inflating: data/6343.jpg           \n",
            "  inflating: __MACOSX/data/._6343.jpg  \n",
            "  inflating: data/9070.jpg           \n",
            "  inflating: __MACOSX/data/._9070.jpg  \n",
            "  inflating: data/14604.jpg          \n",
            "  inflating: __MACOSX/data/._14604.jpg  \n",
            "  inflating: data/12275.jpg          \n",
            "  inflating: __MACOSX/data/._12275.jpg  \n",
            "  inflating: data/12513.jpg          \n",
            "  inflating: __MACOSX/data/._12513.jpg  \n",
            "  inflating: data/23916.jpg          \n",
            "  inflating: __MACOSX/data/._23916.jpg  \n",
            "  inflating: data/806.jpg            \n",
            "  inflating: __MACOSX/data/._806.jpg  \n",
            "  inflating: data/8408.jpg           \n",
            "  inflating: __MACOSX/data/._8408.jpg  \n",
            "  inflating: data/46.jpg             \n",
            "  inflating: __MACOSX/data/._46.jpg  \n",
            "  inflating: data/6425.jpg           \n",
            "  inflating: __MACOSX/data/._6425.jpg  \n",
            "  inflating: data/9716.jpg           \n",
            "  inflating: __MACOSX/data/._9716.jpg  \n",
            "  inflating: data/14162.jpg          \n",
            "  inflating: __MACOSX/data/._14162.jpg  \n",
            "  inflating: data/2643.jpg           \n",
            "  inflating: __MACOSX/data/._2643.jpg  \n",
            "  inflating: data/10304.jpg          \n",
            "  inflating: __MACOSX/data/._10304.jpg  \n",
            "  inflating: data/38488.jpg          \n",
            "  inflating: __MACOSX/data/._38488.jpg  \n",
            "  inflating: data/18758.jpg          \n",
            "  inflating: __MACOSX/data/._18758.jpg  \n",
            "  inflating: data/39796.jpg          \n",
            "  inflating: __MACOSX/data/._39796.jpg  \n",
            "  inflating: data/16775.jpg          \n",
            "  inflating: __MACOSX/data/._16775.jpg  \n",
            "  inflating: data/28843.jpg          \n",
            "  inflating: __MACOSX/data/._28843.jpg  \n",
            "  inflating: data/19446.jpg          \n",
            "  inflating: __MACOSX/data/._19446.jpg  \n",
            "  inflating: data/4232.jpg           \n",
            "  inflating: __MACOSX/data/._4232.jpg  \n",
            "  inflating: data/29585.jpg          \n",
            "  inflating: __MACOSX/data/._29585.jpg  \n",
            "  inflating: data/18980.jpg          \n",
            "  inflating: __MACOSX/data/._18980.jpg  \n",
            "  inflating: data/37963.jpg          \n",
            "  inflating: __MACOSX/data/._37963.jpg  \n",
            "  inflating: data/25397.jpg          \n",
            "  inflating: __MACOSX/data/._25397.jpg  \n",
            "  inflating: data/8420.jpg           \n",
            "  inflating: __MACOSX/data/._8420.jpg  \n",
            "  inflating: data/15254.jpg          \n",
            "  inflating: __MACOSX/data/._15254.jpg  \n",
            "  inflating: data/35184.jpg          \n",
            "  inflating: __MACOSX/data/._35184.jpg  \n",
            "  inflating: data/7713.jpg           \n",
            "  inflating: __MACOSX/data/._7713.jpg  \n",
            "  inflating: data/32833.jpg          \n",
            "  inflating: __MACOSX/data/._32833.jpg  \n",
            "  inflating: data/1362.jpg           \n",
            "  inflating: __MACOSX/data/._1362.jpg  \n",
            "  inflating: data/13625.jpg          \n",
            "  inflating: __MACOSX/data/._13625.jpg  \n",
            "  inflating: data/24089.jpg          \n",
            "  inflating: __MACOSX/data/._24089.jpg  \n",
            "  inflating: data/27580.jpg          \n",
            "  inflating: __MACOSX/data/._27580.jpg  \n",
            "  inflating: data/39966.jpg          \n",
            "  inflating: __MACOSX/data/._39966.jpg  \n",
            "  inflating: data/16985.jpg          \n",
            "  inflating: __MACOSX/data/._16985.jpg  \n",
            "  inflating: data/18770.jpg          \n",
            "  inflating: __MACOSX/data/._18770.jpg  \n",
            "  inflating: data/37793.jpg          \n",
            "  inflating: __MACOSX/data/._37793.jpg  \n",
            "  inflating: data/5104.jpg           \n",
            "  inflating: __MACOSX/data/._5104.jpg  \n",
            "  inflating: data/26846.jpg          \n",
            "  inflating: __MACOSX/data/._26846.jpg  \n",
            "  inflating: data/17443.jpg          \n",
            "  inflating: __MACOSX/data/._17443.jpg  \n",
            "  inflating: data/11032.jpg          \n",
            "  inflating: __MACOSX/data/._11032.jpg  \n",
            "  inflating: data/3575.jpg           \n",
            "  inflating: __MACOSX/data/._3575.jpg  \n",
            "  inflating: data/11754.jpg          \n",
            "  inflating: __MACOSX/data/._11754.jpg  \n",
            "  inflating: data/3213.jpg           \n",
            "  inflating: __MACOSX/data/._3213.jpg  \n",
            "  inflating: data/31484.jpg          \n",
            "  inflating: __MACOSX/data/._31484.jpg  \n",
            "  inflating: data/19308.jpg          \n",
            "  inflating: __MACOSX/data/._19308.jpg  \n",
            "  inflating: data/21697.jpg          \n",
            "  inflating: __MACOSX/data/._21697.jpg  \n",
            "  inflating: data/30942.jpg          \n",
            "  inflating: __MACOSX/data/._30942.jpg  \n",
            "  inflating: data/18016.jpg          \n",
            "  inflating: __MACOSX/data/._18016.jpg  \n",
            "  inflating: data/5662.jpg           \n",
            "  inflating: __MACOSX/data/._5662.jpg  \n",
            "  inflating: data/17325.jpg          \n",
            "  inflating: __MACOSX/data/._17325.jpg  \n",
            "  inflating: data/20589.jpg          \n",
            "  inflating: __MACOSX/data/._20589.jpg  \n",
            "  inflating: data/190.jpg            \n",
            "  inflating: __MACOSX/data/._190.jpg  \n",
            "  inflating: data/1404.jpg           \n",
            "  inflating: __MACOSX/data/._1404.jpg  \n",
            "  inflating: data/33293.jpg          \n",
            "  inflating: __MACOSX/data/._33293.jpg  \n",
            "  inflating: data/13143.jpg          \n",
            "  inflating: __MACOSX/data/._13143.jpg  \n",
            "  inflating: data/23080.jpg          \n",
            "  inflating: __MACOSX/data/._23080.jpg  \n",
            "  inflating: data/9058.jpg           \n",
            "  inflating: __MACOSX/data/._9058.jpg  \n",
            "  inflating: data/8346.jpg           \n",
            "  inflating: __MACOSX/data/._8346.jpg  \n",
            "  inflating: data/15532.jpg          \n",
            "  inflating: __MACOSX/data/._15532.jpg  \n",
            "  inflating: data/24937.jpg          \n",
            "  inflating: __MACOSX/data/._24937.jpg  \n",
            "  inflating: data/7075.jpg           \n",
            "  inflating: __MACOSX/data/._7075.jpg  \n",
            "  inflating: data/33287.jpg          \n",
            "  inflating: __MACOSX/data/._33287.jpg  \n",
            "  inflating: data/1410.jpg           \n",
            "  inflating: __MACOSX/data/._1410.jpg  \n",
            "  inflating: data/184.jpg            \n",
            "  inflating: __MACOSX/data/._184.jpg  \n",
            "  inflating: data/13157.jpg          \n",
            "  inflating: __MACOSX/data/._13157.jpg  \n",
            "  inflating: data/14638.jpg          \n",
            "  inflating: __MACOSX/data/._14638.jpg  \n",
            "  inflating: data/23094.jpg          \n",
            "  inflating: __MACOSX/data/._23094.jpg  \n",
            "  inflating: data/15526.jpg          \n",
            "  inflating: __MACOSX/data/._15526.jpg  \n",
            "  inflating: data/8352.jpg           \n",
            "  inflating: __MACOSX/data/._8352.jpg  \n",
            "  inflating: data/7061.jpg           \n",
            "  inflating: __MACOSX/data/._7061.jpg  \n",
            "  inflating: data/24923.jpg          \n",
            "  inflating: __MACOSX/data/._24923.jpg  \n",
            "  inflating: data/32199.jpg          \n",
            "  inflating: __MACOSX/data/._32199.jpg  \n",
            "  inflating: data/12249.jpg          \n",
            "  inflating: __MACOSX/data/._12249.jpg  \n",
            "  inflating: data/11740.jpg          \n",
            "  inflating: __MACOSX/data/._11740.jpg  \n",
            "  inflating: data/31490.jpg          \n",
            "  inflating: __MACOSX/data/._31490.jpg  \n",
            "  inflating: data/3207.jpg           \n",
            "  inflating: __MACOSX/data/._3207.jpg  \n",
            "  inflating: data/4568.jpg           \n",
            "  inflating: __MACOSX/data/._4568.jpg  \n",
            "  inflating: data/30956.jpg          \n",
            "  inflating: __MACOSX/data/._30956.jpg  \n",
            "  inflating: data/21683.jpg          \n",
            "  inflating: __MACOSX/data/._21683.jpg  \n",
            "  inflating: data/5676.jpg           \n",
            "  inflating: __MACOSX/data/._5676.jpg  \n",
            "  inflating: data/18002.jpg          \n",
            "  inflating: __MACOSX/data/._18002.jpg  \n",
            "  inflating: data/11998.jpg          \n",
            "  inflating: __MACOSX/data/._11998.jpg  \n",
            "  inflating: data/17331.jpg          \n",
            "  inflating: __MACOSX/data/._17331.jpg  \n",
            "  inflating: data/2119.jpg           \n",
            "  inflating: __MACOSX/data/._2119.jpg  \n",
            "  inflating: data/10338.jpg          \n",
            "  inflating: __MACOSX/data/._10338.jpg  \n",
            "  inflating: data/27594.jpg          \n",
            "  inflating: __MACOSX/data/._27594.jpg  \n",
            "  inflating: data/16991.jpg          \n",
            "  inflating: __MACOSX/data/._16991.jpg  \n",
            "  inflating: data/39972.jpg          \n",
            "  inflating: __MACOSX/data/._39972.jpg  \n",
            "  inflating: data/26852.jpg          \n",
            "  inflating: __MACOSX/data/._26852.jpg  \n",
            "  inflating: data/5110.jpg           \n",
            "  inflating: __MACOSX/data/._5110.jpg  \n",
            "  inflating: data/37787.jpg          \n",
            "  inflating: __MACOSX/data/._37787.jpg  \n",
            "  inflating: data/18764.jpg          \n",
            "  inflating: __MACOSX/data/._18764.jpg  \n",
            "  inflating: data/17457.jpg          \n",
            "  inflating: __MACOSX/data/._17457.jpg  \n",
            "  inflating: data/36499.jpg          \n",
            "  inflating: __MACOSX/data/._36499.jpg  \n",
            "  inflating: data/16749.jpg          \n",
            "  inflating: __MACOSX/data/._16749.jpg  \n",
            "  inflating: data/11026.jpg          \n",
            "  inflating: __MACOSX/data/._11026.jpg  \n",
            "  inflating: data/3561.jpg           \n",
            "  inflating: __MACOSX/data/._3561.jpg  \n",
            "  inflating: data/25383.jpg          \n",
            "  inflating: __MACOSX/data/._25383.jpg  \n",
            "  inflating: data/15240.jpg          \n",
            "  inflating: __MACOSX/data/._15240.jpg  \n",
            "  inflating: data/8434.jpg           \n",
            "  inflating: __MACOSX/data/._8434.jpg  \n",
            "  inflating: data/7707.jpg           \n",
            "  inflating: __MACOSX/data/._7707.jpg  \n",
            "  inflating: data/35190.jpg          \n",
            "  inflating: __MACOSX/data/._35190.jpg  \n",
            "  inflating: data/32827.jpg          \n",
            "  inflating: __MACOSX/data/._32827.jpg  \n",
            "  inflating: data/6419.jpg           \n",
            "  inflating: __MACOSX/data/._6419.jpg  \n",
            "  inflating: data/1376.jpg           \n",
            "  inflating: __MACOSX/data/._1376.jpg  \n",
            "  inflating: data/13631.jpg          \n",
            "  inflating: __MACOSX/data/._13631.jpg  \n"
          ]
        }
      ],
      "source": [
        "!unzip \"/content/data.zip\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3K5-2UnsfNE",
        "outputId": "6bce1822-692f-42e7-e89d-503302c7a329"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting GPUtil\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "Building wheels for collected packages: GPUtil\n",
            "  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for GPUtil: filename=GPUtil-1.4.0-py3-none-any.whl size=7411 sha256=725d1ab4283309496f7a307a6af1646e03518565dfce0bcda50350733b4be19b\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/f8/83/534c52482d6da64622ddbf72cd93c35d2ef2881b78fd08ff0c\n",
            "Successfully built GPUtil\n",
            "Installing collected packages: GPUtil\n",
            "Successfully installed GPUtil-1.4.0\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from matplotlib import pyplot as plt\n",
        "from io import StringIO\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "import gc\n",
        "\n",
        "!pip install GPUtil\n",
        "from GPUtil import showUtilization as gpu_usage\n",
        "\n",
        "FILENAME_TRAIN = \"/content/train.csv\"\n",
        "FILENAME_TEST = \"/content/test.csv\"\n",
        "PICTURE_PATH = \"/content/data/\"\n",
        "\n",
        "with open(FILENAME_TRAIN) as file:\n",
        "    lines = [re.sub(r'([^,])\"(\\s*[^\\n])', r'\\1/\"\\2', line) for line in file]\n",
        "    lines = [re.sub(r'\\/\"\\n', '\"\\n', line) for line in lines]\n",
        "    df_train = pd.read_csv(StringIO(''.join(lines)), escapechar=\"/\")\n",
        "\n",
        "with open(FILENAME_TEST) as file:\n",
        "    lines = [re.sub(r'([^,])\"(\\s*[^\\n])', r'\\1/\"\\2', line) for line in file]\n",
        "    lines = [re.sub(r'\\/\"\\n', '\"\\n', line) for line in lines]\n",
        "    df_test = pd.read_csv(StringIO(''.join(lines)), escapechar=\"/\")\n",
        "\n",
        "\n",
        "x_train = df_train[['ImageID', 'Caption']]\n",
        "y_train = df_train[\"Labels\"]\n",
        "x_test = df_test[['ImageID', 'Caption']]\n",
        "\n",
        "\n",
        "# transform y_label \n",
        "y_train = y_train.apply(lambda x: x.split())\n",
        "y_train = y_train.apply(lambda x: [int(a) for a in x])\n",
        "y_train\n",
        "\n",
        "# flatten the labels and calculate number of class\n",
        "class_flatten = []\n",
        "for x in y_train.to_list():\n",
        "    class_flatten.extend(x)   \n",
        "num_class = max(np.unique(class_flatten))\n",
        "num_class "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "0YIUSzTOtHFW",
        "outputId": "56ceed54-7c0d-4486-d962-2eecd77cee53"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f61f9d38-4463-453e-b271-00b065e7d166\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29995</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29996</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29997</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29998</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29999</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30000 rows × 19 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f61f9d38-4463-453e-b271-00b065e7d166')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f61f9d38-4463-453e-b271-00b065e7d166 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f61f9d38-4463-453e-b271-00b065e7d166');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       1   2   3   4   5   6   7   8   9   10  11  12  13  14  15  16  17  18  \\\n",
              "0       1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
              "1       1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
              "2       1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
              "3       0   0   1   0   0   0   0   1   0   0   0   0   1   0   0   0   0   0   \n",
              "4       0   0   1   0   0   0   1   1   0   0   0   0   0   0   0   0   0   0   \n",
              "...    ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..   \n",
              "29995   1   1   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   \n",
              "29996   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
              "29997   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
              "29998   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
              "29999   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
              "\n",
              "       19  \n",
              "0       0  \n",
              "1       1  \n",
              "2       0  \n",
              "3       0  \n",
              "4       0  \n",
              "...    ..  \n",
              "29995   0  \n",
              "29996   0  \n",
              "29997   0  \n",
              "29998   0  \n",
              "29999   0  \n",
              "\n",
              "[30000 rows x 19 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# reconstructing y label \n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "labels = [x for x in range(1, num_class+1)]\n",
        "mlb = MultiLabelBinarizer(classes=labels)\n",
        "y_train_mlb = pd.DataFrame(mlb.fit_transform(y_train), columns=mlb.classes_)\n",
        "y_train_mlb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "rsyG0Hh8tOVQ",
        "outputId": "467a9d58-5dcb-4420-e8f6-cabf44bedca8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8fd2e8b3-1e69-44d7-a6e8-adb584604fa5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ImageID</th>\n",
              "      <th>Caption</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.jpg</td>\n",
              "      <td>Woman in swim suit holding parasol on sunny day.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.jpg</td>\n",
              "      <td>A couple of men riding horses on top of a gree...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.jpg</td>\n",
              "      <td>They are brave for riding in the jungle on tho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.jpg</td>\n",
              "      <td>a black and silver clock tower at an intersect...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.jpg</td>\n",
              "      <td>A train coming to a stop on the tracks out side.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29995</th>\n",
              "      <td>29995.jpg</td>\n",
              "      <td>A picture of a truck that is in the middle of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29996</th>\n",
              "      <td>29996.jpg</td>\n",
              "      <td>A plate topped with a pizza being cut with a s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29997</th>\n",
              "      <td>29997.jpg</td>\n",
              "      <td>A man riding a snowboard on top of  snow.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29998</th>\n",
              "      <td>29998.jpg</td>\n",
              "      <td>This photo shows people skiing in the mountains.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29999</th>\n",
              "      <td>29999.jpg</td>\n",
              "      <td>Two young men playing soccer and fighting for ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30000 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8fd2e8b3-1e69-44d7-a6e8-adb584604fa5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8fd2e8b3-1e69-44d7-a6e8-adb584604fa5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8fd2e8b3-1e69-44d7-a6e8-adb584604fa5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         ImageID                                            Caption\n",
              "0          0.jpg   Woman in swim suit holding parasol on sunny day.\n",
              "1          1.jpg  A couple of men riding horses on top of a gree...\n",
              "2          2.jpg  They are brave for riding in the jungle on tho...\n",
              "3          3.jpg  a black and silver clock tower at an intersect...\n",
              "4          4.jpg   A train coming to a stop on the tracks out side.\n",
              "...          ...                                                ...\n",
              "29995  29995.jpg  A picture of a truck that is in the middle of ...\n",
              "29996  29996.jpg  A plate topped with a pizza being cut with a s...\n",
              "29997  29997.jpg          A man riding a snowboard on top of  snow.\n",
              "29998  29998.jpg   This photo shows people skiing in the mountains.\n",
              "29999  29999.jpg  Two young men playing soccer and fighting for ...\n",
              "\n",
              "[30000 rows x 2 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AG5DcJy2tQ0I",
        "outputId": "11194866-d468-4f36-d949-6050db385a81"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0               [1]\n",
              "1           [1, 19]\n",
              "2               [1]\n",
              "3        [8, 3, 13]\n",
              "4         [8, 3, 7]\n",
              "            ...    \n",
              "29995     [8, 1, 2]\n",
              "29996           [1]\n",
              "29997           [1]\n",
              "29998           [1]\n",
              "29999           [1]\n",
              "Name: Labels, Length: 30000, dtype: object"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7n-TH1NwoipC"
      },
      "outputs": [],
      "source": [
        "pos_sample = y_train_mlb.sum(axis = 0)\n",
        "nega_sample = y_train_mlb.shape[0] - pos_sample\n",
        "# pos_weight = negative_sample/positive sample\n",
        "pos_weight = (nega_sample/pos_sample)\n",
        "pos_weight = torch.tensor(np.nan_to_num(pos_weight,posinf=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kf_nkEN8tVz5",
        "outputId": "27ae5355-b1eb-4020-fa57-26a84b4435ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import re\n",
        "import gensim.downloader as api\n",
        "from nltk.corpus import stopwords as sw\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem import PorterStemmer\n",
        "nltk.download('stopwords')\n",
        "stop_words = sw.words('english')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "def transform_text(x, extract_nouns = False):\n",
        "    # # https://stackoverflow.com/questions/33587667/extracting-all-nouns-from-a-text-file-using-nltk\n",
        "    is_noun = lambda pos: pos[:2] == 'NN'\n",
        "    x = re.sub(r'[^\\w\\s]','',x)\n",
        "    x = x.lower()\n",
        "    x = re.sub(r'[0-9]+', '', x)\n",
        "    x = word_tokenize(x)\n",
        "    if extract_nouns:\n",
        "        x = [word for (word, pos) in nltk.pos_tag(x) if is_noun(pos)]\n",
        "    x = [lemmatizer.lemmatize(a) for a in x if a not in stop_words]\n",
        "    return x\n",
        "x_train['Caption'] = x_train[\"Caption\"].apply(lambda x: transform_text(x, False))\n",
        "x_test[\"Caption\"] = x_test[\"Caption\"].apply(lambda x: transform_text(x, False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJmm0nDStWFW",
        "outputId": "e9746b53-2483-4aa5-c1e8-cf9de7d76141"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0        [woman, swim, suit, holding, parasol, sunny, day]\n",
              "1          [couple, men, riding, horse, top, green, field]\n",
              "2                        [brave, riding, jungle, elephant]\n",
              "3        [black, silver, clock, tower, intersection, ne...\n",
              "4                       [train, coming, stop, track, side]\n",
              "                               ...                        \n",
              "29995                       [picture, truck, middle, road]\n",
              "29996                   [plate, topped, pizza, cut, spoon]\n",
              "29997                  [man, riding, snowboard, top, snow]\n",
              "29998              [photo, show, people, skiing, mountain]\n",
              "29999    [two, young, men, playing, soccer, fighting, s...\n",
              "Name: Caption, Length: 30000, dtype: object"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train['Caption']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGQv9DieuBgv"
      },
      "source": [
        "# EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "jI4dH4aHtYIT",
        "outputId": "098e2b48-0c90-4b39-8fcd-58fbdb0ccf37"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Counts')"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 864x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "counts = y_train.apply(lambda x: len(x)).value_counts()\n",
        "plt.figure(figsize=(12, 5))\n",
        "sns.barplot(x = counts.index, y = counts.values)\n",
        "plt.xlabel(\"Number of targets per image\")\n",
        "plt.ylabel(\"Counts\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "bEHlzFgvuDuo",
        "outputId": "1b6a5700-8694-436f-97de-d73bf6aafc42"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Counts')"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 864x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "from collections import Counter\n",
        "plt.figure(figsize=(12, 5))\n",
        "count_dict = dict(Counter(class_flatten))\n",
        "sns.barplot(x = list(count_dict.keys()), y = list(count_dict.values()))\n",
        "plt.xlabel(\"Number of classes\")\n",
        "plt.ylabel(\"Counts\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "SaLBmL35uE7g",
        "outputId": "648deaed-5539-440b-f082-5556532ad8eb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Counts')"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtoAAAE9CAYAAAA1R8WUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAc2klEQVR4nO3de7htdV3v8fdHtngB5SI7QsA2KpnmScUt4jUVE0QTUDTP8SgZRafwgpUdyfNkZXSyvJTnSYoERSMRERWRwyUFs04gm5tcjZ2AbOJWoKQ+qeD3/DF/G1e7tdZewPyutdfm/Xqe9awxf2PM8f2NvecY87PG/M0xUlVIkiRJmq4HLHUHJEmSpM2RQVuSJElqYNCWJEmSGhi0JUmSpAYGbUmSJKmBQVuSJElqsGKpO9Bhhx12qFWrVi11NyRJkrSZu+CCC/6lqlbONm+zDNqrVq1izZo1S90NSZIkbeaSXDfXPIeOSJIkSQ0M2pIkSVIDg7YkSZLUwKAtSZIkNTBoS5IkSQ0M2pIkSVIDg7YkSZLUwKAtSZIkNTBoS5IkSQ0M2pIkSVIDg7YkSZLUYMVSd0CazxnH7Ney3n0OOa1lvZIkSet5RluSJElq4BltaYaPf2jflvX+3OtPb1mvJEnadHlGW5IkSWpg0JYkSZIaGLQlSZKkBgZtSZIkqYFBW5IkSWpg0JYkSZIaGLQlSZKkBgZtSZIkqYFBW5IkSWpg0JYkSZIaGLQlSZKkBgZtSZIkqYFBW5IkSWpg0JYkSZIaGLQlSZKkBgZtSZIkqYFBW5IkSWrQGrSTvCXJ5UkuS/KxJA9OsluS85KsTfLxJFuOZR80Hq8d81fNWM8Ro/2rSfbp7LMkSZI0DW1BO8nOwJuA1VX1RGAL4NXAu4D3VdVjgduBQ8ZTDgFuH+3vG8uR5AnjeT8J7At8IMkWXf2WJEmSpqF76MgK4CFJVgAPBW4EXgCcNOYfBxwwpvcfjxnz906S0X5CVX23qq4B1gJ7NvdbkiRJuk/agnZV3QC8G/g6k4D9TeAC4BtVdedYbB2w85jeGbh+PPfOsfwjZrbP8hxJkiRpk9Q5dGQ7JmejdwMeCWzFZOhHV71Dk6xJsubWW2/tKiNJkiQtSOfQkRcC11TVrVX1feBk4FnAtmMoCcAuwA1j+gZgV4AxfxvgX2e2z/Kcu1XV0VW1uqpWr1y5smN7JEmSpAXrDNpfB/ZK8tAx1npv4ArgbOCgsczBwGfG9CnjMWP+F6qqRvurx1VJdgN2B77c2G9JkiTpPlux8UXunao6L8lJwIXAncBFwNHA54ATkvz+aDtmPOUY4KNJ1gK3MbnSCFV1eZITmYT0O4HDququrn5LkiRJ09AWtAGq6h3AOzZo/hqzXDWkqv4deOUc6zkSOHLqHZQkSZKaeGdISZIkqYFBW5IkSWpg0JYkSZIaGLQlSZKkBgZtSZIkqYFBW5IkSWpg0JYkSZIaGLQlSZKkBgZtSZIkqYFBW5IkSWpg0JYkSZIaGLQlSZKkBgZtSZIkqYFBW5IkSWpg0JYkSZIaGLQlSZKkBgZtSZIkqYFBW5IkSWpg0JYkSZIaGLQlSZKkBgZtSZIkqYFBW5IkSWpg0JYkSZIaGLQlSZKkBgZtSZIkqYFBW5IkSWpg0JYkSZIaGLQlSZKkBgZtSZIkqYFBW5IkSWpg0JYkSZIaGLQlSZKkBgZtSZIkqYFBW5IkSWpg0JYkSZIaGLQlSZKkBgZtSZIkqYFBW5IkSWpg0JYkSZIaGLQlSZKkBgZtSZIkqYFBW5IkSWpg0JYkSZIaGLQlSZKkBgZtSZIkqYFBW5IkSWpg0JYkSZIaGLQlSZKkBgZtSZIkqYFBW5IkSWrQGrSTbJvkpCRXJbkyyTOSbJ/krCRXj9/bjWWT5P1J1ib5SpI9Zqzn4LH81UkO7uyzJEmSNA3dZ7T/FDi9qn4CeBJwJfA24PNVtTvw+fEY4MXA7uPnUOAogCTbA+8Ang7sCbxjfTiXJEmSNlVtQTvJNsBzgWMAqup7VfUNYH/guLHYccABY3p/4CM1cS6wbZKdgH2As6rqtqq6HTgL2Ler35IkSdI0dJ7R3g24FfhQkouSfDDJVsCOVXXjWOYmYMcxvTNw/Yznrxttc7X/B0kOTbImyZpbb711ypsiSZIk3TOdQXsFsAdwVFU9Bfg2PxwmAkBVFVDTKFZVR1fV6qpavXLlymmsUpIkSbrXOoP2OmBdVZ03Hp/EJHjfPIaEMH7fMubfAOw64/m7jLa52iVJkqRNVlvQrqqbgOuTPG407Q1cAZwCrL9yyMHAZ8b0KcDrxtVH9gK+OYaYnAG8KMl240uQLxptkiRJ0iZrRfP63wgcn2RL4GvA65mE+xOTHAJcB7xqLHsasB+wFvjOWJaqui3JO4Hzx3K/V1W3NfdbkiRJuk9ag3ZVXQysnmXW3rMsW8Bhc6znWODY6fZOkiRJ6uOdISVJkqQGBm1JkiSpgUFbkiRJamDQliRJkhoYtCVJkqQGBm1JkiSpgUFbkiRJamDQliRJkhoYtCVJkqQGBm1JkiSpgUFbkiRJamDQliRJkhoYtCVJkqQGBm1JkiSpgUFbkiRJamDQliRJkhoYtCVJkqQGBm1JkiSpgUFbkiRJanCPg3aS7ZL8VEdnJEmSpM3FgoJ2knOSPDzJ9sCFwF8meW9v1yRJkqTla6FntLepqjuAlwMfqaqnAy/s65YkSZK0vC00aK9IshPwKuDUxv5IkiRJm4WFBu3fBc4A1lbV+UkeDVzd1y1JkiRpeVuxwOVurKq7vwBZVV9zjLYkSZI0t4We0f4/C2yTJEmSxEbOaCd5BvBMYGWSX5sx6+HAFp0dkyRJkpazjQ0d2RLYeiz3sBntdwAHdXVKkiRJWu7mDdpV9UXgi0k+XFXXLVKfpPuNv/joPi3r/eXXntGyXkmStHAL/TLkg5IcDaya+ZyqekFHpyRJkqTlbqFB+xPAnwMfBO7q644kSZK0eVho0L6zqo5q7YkkSZK0GVno5f0+m+RXk+yUZPv1P609kyRJkpaxhZ7RPnj8fuuMtgIePd3uSJIkSZuHBQXtqtqtuyOSJEnS5mRBQTvJ62Zrr6qPTLc7kiRJ0uZhoUNHnjZj+sHA3sCFgEFbkiRJmsVCh468cebjJNsCJ7T0SJIkSdoMLPSqIxv6NuC4bUmSJGkOCx2j/VkmVxkB2AJ4PHBiV6ckSZKk5W6hY7TfPWP6TuC6qlrX0B9JkiRps7CgoSNV9UXgKuBhwHbA9zo7JUmSJC13CwraSV4FfBl4JfAq4LwkB3V2TJIkSVrOFjp05O3A06rqFoAkK4G/AU7q6pgkSZK0nC30qiMPWB+yh3+9B8+VJEmS7ncWekb79CRnAB8bj38OOK2nS5IkSdLyN2/QTvJYYMeqemuSlwPPHrP+ATi+u3OSJEnScrWxM9p/AhwBUFUnAycDJPkvY97PtvZOkiRJWqY2Ns56x6q6dMPG0baqpUeSJEnSZmBjQXvbeeY9ZCEFkmyR5KIkp47HuyU5L8naJB9PsuVof9B4vHbMXzVjHUeM9q8m2WchdSVJkqSltLGgvSbJL23YmOQXgQsWWOPNwJUzHr8LeF9VPRa4HThktB8C3D7a3zeWI8kTgFcDPwnsC3wgyRYLrC1JkiQtiY0F7cOB1yc5J8l7xs8XmYTiN29s5Ul2AV4CfHA8DvACfnj97eOAA8b0/uMxY/7eY/n9gROq6rtVdQ2wFthzoRsoSZIkLYV5vwxZVTcDz0zyfOCJo/lzVfWFBa7/T4DfZHLrdoBHAN+oqjvH43XAzmN6Z+D6UffOJN8cy+8MnDtjnTOfI0mSJG2SFnQd7ao6Gzj7nqw4yUuBW6rqgiTPuxd9u0eSHAocCvCoRz2qu5wkSZI0r867Oz4LeFmSa4ETmAwZ+VNg2yTrA/4uwA1j+gZgV4Axfxsmd6C8u32W59ytqo6uqtVVtXrlypXT3xpJkiTpHmgL2lV1RFXtUlWrmHyZ8QtV9RomZ8YPGosdDHxmTJ8yHjPmf6GqarS/elyVZDdgd+DLXf2WJEmSpmGht2Cfpv8JnJDk94GLgGNG+zHAR5OsBW5jEs6pqsuTnAhcAdwJHFZVdy1+tyVJkqSFW5SgXVXnAOeM6a8xy1VDqurfgVfO8fwjgSP7eihJkiRNV+cYbUmSJOl+aymGjmgZO/8vfrZlvU/75c+2rFeSJGmpeEZbkiRJamDQliRJkhoYtCVJkqQGBm1JkiSpgUFbkiRJamDQliRJkhoYtCVJkqQGBm1JkiSpgUFbkiRJamDQliRJkhoYtCVJkqQGBm1JkiSpgUFbkiRJamDQliRJkhoYtCVJkqQGBm1JkiSpgUFbkiRJamDQliRJkhoYtCVJkqQGBm1JkiSpgUFbkiRJamDQliRJkhoYtCVJkqQGBm1JkiSpgUFbkiRJamDQliRJkhoYtCVJkqQGBm1JkiSpgUFbkiRJamDQliRJkhoYtCVJkqQGBm1JkiSpgUFbkiRJamDQliRJkhoYtCVJkqQGBm1JkiSpgUFbkiRJamDQliRJkhoYtCVJkqQGBm1JkiSpgUFbkiRJamDQliRJkhoYtCVJkqQGBm1JkiSpgUFbkiRJamDQliRJkhoYtCVJkqQGBm1JkiSpQVvQTrJrkrOTXJHk8iRvHu3bJzkrydXj93ajPUnen2Rtkq8k2WPGug4ey1+d5OCuPkuSJEnT0nlG+07g16vqCcBewGFJngC8Dfh8Ve0OfH48BngxsPv4ORQ4CibBHHgH8HRgT+Ad68O5JEmStKlqC9pVdWNVXTim/w24EtgZ2B84bix2HHDAmN4f+EhNnAtsm2QnYB/grKq6rapuB84C9u3qtyRJkjQNizJGO8kq4CnAecCOVXXjmHUTsOOY3hm4fsbT1o22udolSZKkTVZ70E6yNfBJ4PCqumPmvKoqoKZU59Aka5KsufXWW6exSkmSJOleW9G58iQPZBKyj6+qk0fzzUl2qqobx9CQW0b7DcCuM56+y2i7AXjeBu3nbFirqo4GjgZYvXr1VMK7tDk58uP7tK377T93Rtu6JUlarjqvOhLgGODKqnrvjFmnAOuvHHIw8JkZ7a8bVx/ZC/jmGGJyBvCiJNuNL0G+aLRJkiRJm6zOM9rPAl4LXJrk4tH2W8AfAicmOQS4DnjVmHcasB+wFvgO8HqAqrotyTuB88dyv1dVtzX2W5IkSbrP2oJ2Vf0dkDlm7z3L8gUcNse6jgWOnV7vJEmSpF7eGVKSJElqYNCWJEmSGhi0JUmSpAYGbUmSJKmBQVuSJElqYNCWJEmSGhi0JUmSpAYGbUmSJKmBQVuSJElqYNCWJEmSGhi0JUmSpAYGbUmSJKmBQVuSJElqYNCWJEmSGhi0JUmSpAYGbUmSJKmBQVuSJElqYNCWJEmSGhi0JUmSpAYGbUmSJKmBQVuSJElqYNCWJEmSGhi0JUmSpAYGbUmSJKmBQVuSJElqYNCWJEmSGhi0JUmSpAYGbUmSJKmBQVuSJElqYNCWJEmSGhi0JUmSpAYGbUmSJKmBQVuSJElqYNCWJEmSGqxY6g5I2jy9/lP7tq37Qwee3rZuSZKmxaC9zH39/Qe1rPdRbzqpZb2SJEn3Fw4dkSRJkhoYtCVJkqQGBm1JkiSpgUFbkiRJamDQliRJkhoYtCVJkqQGBm1JkiSpgUFbkiRJamDQliRJkhoYtCVJkqQGBm1JkiSpwYql7oAkTcN+n/71tnWfdsB72tYtSdp8eUZbkiRJamDQliRJkhosm6CdZN8kX02yNsnblro/kiRJ0nyWxRjtJFsAfwb8DLAOOD/JKVV1xdL2TNL91Us+9cct6/3cgW9tWa8kafEti6AN7AmsraqvASQ5AdgfMGhLul94ySePblnv515xaMt6JUnLJ2jvDFw/4/E64OlL1Jd53XxUz1muHX/Fs1ySFs9LTzq+Zb2nHvSaWdt/9qRPt9T77EEHtKxXkhYiVbXUfdioJAcB+1bVL47HrwWeXlVvmLHMocD6UzOPA756L0rtAPzLfeyu9axnvU27lvWsZ737T73Nedust+nU+7GqWjnbjOVyRvsGYNcZj3cZbXerqqOB+/TZapI1VbX6vqzDetaz3qZdy3rWs979p97mvG3WWx71lstVR84Hdk+yW5ItgVcDpyxxnyRJkqQ5LYsz2lV1Z5I3AGcAWwDHVtXlS9wtSZIkaU7LImgDVNVpwGnNZXq+1m8961lvU6plPetZ7/5Tb3PeNustg3rL4suQkiRJ0nKzXMZoS5IkScuKQRtIcmySW5Jctkj1dk1ydpIrklye5M3N9R6c5MtJLhn1frez3qi5RZKLkpy6CLWuTXJpkouTrFmEetsmOSnJVUmuTPKMxlqPG9u1/ueOJId31Rs13zJeJ5cl+ViSBzfXe/OodXnHts22fyfZPslZSa4ev7drrvfKsX0/SDLVb7TPUe+Px+vzK0k+lWTb5nrvHLUuTnJmkkd21psx79eTVJIdOusl+Z0kN8zYD/frrDfa3zj+Dy9P8kddtZJ8fMZ2XZvk4mnUmqfek5Ocu/54nWTP5npPSvIP4z3is0kePsV6s76Xdx1f5qnXsr/PU69lf5+r3oz5U9vf59m26b8+q+p+/wM8F9gDuGyR6u0E7DGmHwb8I/CExnoBth7TDwTOA/Zq3sZfA/4aOHUR/j2vBXZYxNfLccAvjuktgW0Xqe4WwE1MrtfZVWNn4BrgIePxicDPN9Z7InAZ8FAm3xn5G+CxU67xn/Zv4I+At43ptwHvaq73eCbX9z8HWL0I2/ciYMWYftcibN/DZ0y/CfjzznqjfVcmX5C/bpr7/xzb9zvAb0zz/20j9Z4/9oUHjcc/0vlvOWP+e4Dfbt62M4EXj+n9gHOa650P/PSY/gXgnVOsN+t7edfxZZ56Lfv7PPVa9ve56o3HU93f59m2qb8+PaMNVNXfArctYr0bq+rCMf1vwJVMAk5Xvaqqb42HDxw/bYPzk+wCvAT4YFeNpZJkGyYH82MAqup7VfWNRSq/N/BPVXVdc50VwEOSrGASgP+5sdbjgfOq6jtVdSfwReDl0ywwx/69P5M/mBi/p3b7wNnqVdWVVXVvbqJ1b+udOf49Ac5lcu+Bznp3zHi4FVM8vsxzfH4f8JvTrLWRei3mqPcrwB9W1XfHMrc01gIgSYBXAR+bRq156hWw/qzyNkzx+DJHvR8H/nZMnwW8Yor15novbzm+zFWva3+fp17L/r6RbDTV/X2eWlN/fRq0l1iSVcBTmJxl7qyzxfhI8BbgrKrqrPcnTHaIHzTWmKmAM5NckMkdQjvtBtwKfCiToTEfTLJVc831Xs0U3wRnU1U3AO8Gvg7cCHyzqs5sLHkZ8Jwkj0jyUCZnEHbdyHOmYcequnFM3wTsuAg1l8ovAP+3u0iSI5NcD7wG+O3mWvsDN1TVJZ11NvCG8XH5sdMaCjCPH2eyX5yX5ItJntZcD+A5wM1VdXVzncOBPx6vlXcDRzTXu5xJ8AV4JU3Hlw3ey9uPL/Nkh5b9fcN63fv7zHrd+/sG2zb116dBewkl2Rr4JHD4Bn8hTl1V3VVVT2byl+6eSZ7YUSfJS4FbquqCjvXP4dlVtQfwYuCwJM9trLWCyUeTR1XVU4BvM/losFUmN2p6GfCJ5jrbMXlT2g14JLBVkv/eVa+qrmTyUeeZwOnAxcBdXfXm6EPR+AnPUkryduBO4PjuWlX19qraddR6Q1ed8QfZb9Ec5jdwFPAY4MlM/gB9T3O9FcD2wF7AW4ETxxnnTv+V5j/kh18B3jJeK29hfDrY6BeAX01yAZMhAt+bdoH53ss7ji9z1eva32er17m/z6zHZHva9vdZtm3qr0+D9hJJ8kAm/7nHV9XJi1V3DHM4G9i3qcSzgJcluRY4AXhBkr9qqgXcfRZ2/cernwKm9uWaWawD1s34ROAkJsG724uBC6vq5uY6LwSuqapbq+r7wMnAMzsLVtUxVfXUqnoucDuTsXLdbk6yE8D4PZWP5jclSX4eeCnwmvFmv1iOZ4ofz8/iMUz+ELxkHGd2AS5M8qNdBavq5nGy4gfAX9J7jIHJcebkMezvy0w+HZzaFz43NIaJvRz4eFeNGQ5mclyByYmD1n/Lqrqqql5UVU9l8ofEP01z/XO8l7cdX+bKDl37+wKyylT391nqte3vc2zb1F+fBu0lMM5MHANcWVXvXYR6K9d/CznJQ4CfAa7qqFVVR1TVLlW1islQhy9UVdsZ0SRbJXnY+mkmXwppu3pMVd0EXJ/kcaNpb+CKrnozLNbZpq8DeyV56Hid7s1k7FqbJD8yfj+KyZv9X3fWG05hckBl/P7MItRcNEn2ZTJ862VV9Z1FqLf7jIf703R8AaiqS6vqR6pq1TjOrGPypaabumquD03DgTQeY4ZPM/lCJEl+nMmXrv+lsd4Lgauqal1jjfX+GfjpMf0CoHWoyozjywOA/wX8+RTXPdd7ecvxZa56Xfv7PPVa9vfZ6nXt7/P8303/9VlT+vbtcv5hEmBuBL7P5D/xkOZ6z2byUdJXmHxUfjGwX2O9nwIuGvUuY4rfKt9I3efRfNUR4NHAJePncuDti7BdTwbWjH/PTwPbNdfbCvhXYJtF+n/7XSYHzsuAjzKufNBY70tM/li5BNi7Yf3/af8GHgF8fhxE/wbYvrnegWP6u8DNwBnN9dYC1884vkzzKiCz1fvkeL18Bfgsky9MtdXbYP61TPeqI7Nt30eBS8f2nQLs1FxvS+Cvxr/phcALOv8tgQ8D/2Na27SRbXs2cMHY388Dntpc781MPiX7R+APGTfqm1K9Wd/Lu44v89Rr2d/nqdeyv89Vb4NlprK/z7NtU399emdISZIkqYFDRyRJkqQGBm1JkiSpgUFbkiRJamDQliRJkhoYtCVJkqQGBm1JWiJJfjTJCUn+KckFSU4b102+N+s6fNw1cf3j09ZfP/8+9vF3kvzGfV3PLOvdsL/fmnYNSVpqBm1JWgLjhgmfAs6pqsfU5M51RwA73stVHg7cHVyrar+a3Al2U/Uf+itJmyODtiQtjecD36+qu+9UV1WXVNWXkmyd5PNJLkxyaZL9AZKsSnJVkuOTXJnkpHEXzzcBjwTOTnL2WPbaJDuM6V9Lctn4OXzGuq5M8pdJLk9y5rhz7JySPCbJ6ePs+5eS/MRo/3CS9yf5f0m+luSg0f6AJB8YfT5rnGU/aLb+juWPTHJJknOT3Ns/OCRpk2HQlqSl8UQmdyCbzb8DB1bVHkwC+XvGGXCAxwEfqKrHA3cAv1pV72dy6+DnV9XzZ64oyVOB1wNPB/YCfinJU8bs3YE/q6qfBL4BvGIjfT4aeOM4+/4bwAdmzNuJyV3VXsrkDnwALwdWAU8AXgs8A2CO/m4FnFtVTwL+FviljfRFkjZ5Bm1J2vQE+IMkX2FyC+ed+eGQkuur6u/H9F8xCbfzeTbwqar6dlV9CzgZeM6Yd01VXTymL2ASimfvULI18EzgE0kuBv6CSbhe79NV9YOqumJGX58NfGK03wSczdy+B5y6kL5I0nKxYqk7IEn3U5cDB80x7zXASuCpVfX9JNcCDx7zaoNlN3x8T3x3xvRdwHxDRx4AfKOqnryAdWWOZebz/apavy134fuTpM2AZ7QlaWl8AXhQkkPXNyT5qSTPAbYBbhkh+/nAj8143qOSPGNM/zfg78b0vwEPm6XOl4ADxljurYADR9s9UlV3ANckeeXoa5I8aSNP+3vgFWOs9o7A82bMm6u/krTZMGhL0hIYZ28PBF44Lu93OfC/gZuA44HVSS4FXgdcNeOpXwUOS3IlsB1w1Gg/Gjh95pcLR50LgQ8DXwbOAz5YVRfdy26/BjgkySVMzsjvv5HlPwmsA65gMszlQuCb8/VXkjYn+eEndZKkTVmSVcCpVfXEJe7KgiXZuqq+leQRTML+s8Z4bUna7DkGTpLU6dRx45wtgXcasiXdn3hGW5IkSWrgGG1JkiSpgUFbkiRJamDQliRJkhoYtCVJkqQGBm1JkiSpgUFbkiRJavD/ATznva/eTriuAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 864x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# check the Caption length\n",
        "caption_list = x_train[\"Caption\"].to_list()\n",
        "caption_len = [len(x) for x in caption_list]\n",
        "count_caption = dict(Counter(caption_len))\n",
        "plt.figure(figsize=(12, 5))\n",
        "sns.barplot(x = list(count_caption.keys()), y = list(count_caption.values()))\n",
        "plt.xlabel(\"Caption length\")\n",
        "plt.ylabel(\"Counts\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uB3Tbi4tpk76"
      },
      "outputs": [],
      "source": [
        "class Tokenizer(nn.Module):\n",
        "    def __init__(self, seq_length):\n",
        "        super(Tokenizer, self).__init__()\n",
        "        self.seq_length = seq_length \n",
        "        self.word_list = None\n",
        "        self.word_index = None\n",
        "        self.inverse_word_index = None\n",
        "        self.word = None\n",
        "        \n",
        "    def index(self, x):\n",
        "        # x: all training sentences\n",
        "        self.word = x\n",
        "        word_set = set() \n",
        "        for sent in x:\n",
        "            for word in sent:\n",
        "                word_set.add(word)\n",
        "\n",
        "        # Normally we add the special tokens for representing the padding and unknown words separately\n",
        "        # Sometimes we can also use same token to present padding and unknown words if we don't have to differentiate them\n",
        "        word_set.add('[PAD]')\n",
        "        word_set.add('[UNKNOWN]')\n",
        "\n",
        "        word_list = list(word_set) \n",
        "        word_list.sort()\n",
        "        self.word_list = word_list\n",
        "        \n",
        "        word_index = {}\n",
        "        ind = 0\n",
        "        for word in word_list:\n",
        "            word_index[word] = ind\n",
        "            ind += 1\n",
        "        self.word_index = word_index\n",
        "        inv_map = {v: k for k, v in word_index.items()}\n",
        "        self.inverse_word_index = inv_map\n",
        "        return word_list, word_index, inv_map\n",
        "\n",
        "    def all_zeros(self, x):\n",
        "        return np.count_nonzero(x) == 0\n",
        "\n",
        "    def encode_and_add_padding(self, x):\n",
        "        seq_length = self.seq_length\n",
        "        word_index = self.word_index\n",
        "        temp_encoded = [word_index[word] if word in word_index else word_index['[UNKNOWN]'] for word in x]\n",
        "        if len(temp_encoded) < seq_length:\n",
        "            temp_encoded += [word_index['[PAD]']] * (seq_length - len(temp_encoded))\n",
        "        elif len(temp_encoded) > seq_length:\n",
        "            temp_encoded = temp_encoded[0:seq_length]\n",
        "        return temp_encoded\n",
        "seq_len = max(caption_len)\n",
        "tokenizer = Tokenizer(seq_len)\n",
        "word_list, word_index, inverse_word_index = tokenizer.index(x_train[\"Caption\"])\n",
        "x_train[\"Caption_encoded\"] = x_train[\"Caption\"].apply(lambda x: tokenizer.encode_and_add_padding(x))\n",
        "x_test[\"Caption_encoded\"] = x_test[\"Caption\"].apply(lambda x: tokenizer.encode_and_add_padding(x))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DO4j8X9zuGNL"
      },
      "outputs": [],
      "source": [
        "# https://pytorch.org/tutorials/recipes/recipes/custom_dataset_transforms_loader.html\n",
        "# https://www.kaggle.com/code/harshjain123/bert-for-everyone-tutorial-implementation/notebook\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "from skimage import io, transform\n",
        "class Text_Image_Dataset(Dataset):\n",
        "    def __init__(self, image_file, text_file, target = None, img_transform = None):\n",
        "        self.text_file = text_file\n",
        "        self.image_file = image_file\n",
        "        self.target = target\n",
        "        # image transform \n",
        "        self.img_transform = img_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_file)\n",
        " \n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "        # get target\n",
        "        if self.target is not None:\n",
        "            target = self.target.iloc[idx].to_list()\n",
        "            target = torch.from_numpy(np.array(target))\n",
        "        # get image\n",
        "        img_name = self.image_file[idx]\n",
        "        image_path = PICTURE_PATH + str(img_name)\n",
        "        img = Image.fromarray(io.imread(image_path))\n",
        "\n",
        "        if self.img_transform:\n",
        "            img = self.img_transform(img)\n",
        "        \n",
        "        # get text\n",
        "        text = torch.Tensor(self.text_file[idx]).to(torch.int64)\n",
        "        # text = self.text_file[idx]\n",
        "        if self.target is not None:\n",
        "            sample = {'image_path':img_name, 'image': img, 'text': text, 'target': target}\n",
        "        else:\n",
        "            sample = {'image_path':img_name, 'image': img, 'text': text}\n",
        "        return sample\n",
        "\n",
        "# print sample\n",
        "def show_image(img):\n",
        "    # https://zhuanlan.zhihu.com/p/424638008\n",
        "    img = img.swapaxes(0, 1)\n",
        "    img = img.swapaxes(1, 2)\n",
        "    plt.imshow(img)\n",
        "    return \n",
        "\n",
        "def show_sample(dataset, idx, is_training_sample = True):\n",
        "    sample = dataset[idx]\n",
        "    print(sample['image_path'])\n",
        "    print(sample['image'].size(), sample['image'])\n",
        "    print(show_image(sample['image']))\n",
        "    print(sample['text'])\n",
        "    if is_training_sample:\n",
        "        print(sample['target'])\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 779
        },
        "id": "8e8OF74DxxLu",
        "outputId": "5eb18139-651e-4255-f009-0768c15df176"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4.jpg\n",
            "torch.Size([3, 224, 224]) tensor([[[ 0.0227,  0.0227,  0.0227,  ...,  0.0056,  0.0056,  0.0056],\n",
            "         [ 0.0227,  0.0227,  0.0227,  ...,  0.0056,  0.0056,  0.0056],\n",
            "         [ 0.0227,  0.0227,  0.0227,  ...,  0.0056,  0.0056,  0.0056],\n",
            "         ...,\n",
            "         [-1.7240, -1.5699, -1.3302,  ..., -0.4739, -0.4226, -0.3712],\n",
            "         [-1.6727, -1.4843, -1.1418,  ..., -0.4054, -0.3712, -0.4054],\n",
            "         [-1.6555, -1.4158, -1.0390,  ..., -0.3541, -0.3712, -0.4739]],\n",
            "\n",
            "        [[ 0.7829,  0.7829,  0.7829,  ...,  0.9405,  0.9405,  0.9405],\n",
            "         [ 0.7829,  0.7829,  0.7829,  ...,  0.9405,  0.9405,  0.9405],\n",
            "         [ 0.7829,  0.7829,  0.7829,  ...,  0.9405,  0.9405,  0.9405],\n",
            "         ...,\n",
            "         [-1.6331, -1.4755, -1.2304,  ..., -0.3550, -0.3025, -0.2500],\n",
            "         [-1.5805, -1.3880, -1.0378,  ..., -0.2850, -0.2500, -0.2850],\n",
            "         [-1.5630, -1.3179, -0.9328,  ..., -0.2325, -0.2500, -0.3550]],\n",
            "\n",
            "        [[ 1.6291,  1.6291,  1.6291,  ...,  1.7511,  1.7511,  1.7511],\n",
            "         [ 1.6291,  1.6291,  1.6291,  ...,  1.7511,  1.7511,  1.7511],\n",
            "         [ 1.6291,  1.6291,  1.6291,  ...,  1.7511,  1.7511,  1.7511],\n",
            "         ...,\n",
            "         [-1.4036, -1.2467, -1.0027,  ..., -0.1312, -0.0790, -0.0267],\n",
            "         [-1.3513, -1.1596, -0.8110,  ..., -0.0615, -0.0267, -0.0615],\n",
            "         [-1.3339, -1.0898, -0.7064,  ..., -0.0092, -0.0267, -0.1312]]])\n",
            "None\n",
            "tensor([5490, 1114, 5063, 5482, 4667,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0])\n",
            "tensor([0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD8CAYAAAB3lxGOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOy9eZQk113n+7mxZEautWZtvW9qba1dliVLwouwsWGw8bAZGGDMAId5vIHzYGY88Jjl+Mw84JlheDyeB8MYbBZjDBa2ZdlarcWyllZvavVS3VXdVdVde1VWVe6Zsdz3x43qrs6M7M5SVXaXWvk9J7srIyNu3Lhx7+/+9p+QUtJCCy28c6Fd6w600EIL1xYtItBCC+9wtIhACy28w9EiAi208A5Hiwi00MI7HC0i0EIL73A0jQgIIX5ACDEohBgSQnyqWfdpoYUW1gbRDD8BIYQOnAK+HzgP7Ac+IaU8vu43a6GFFtaEZnEC7wKGpJRnpJQV4O+AjzbpXi200MIaYDSp3U3AuRXfzwP31TtZtHdL0b/9io1KANFgD1bJ4Kyq2aCTtVU00kJdCNnYMHrQ+HhrNGe7c1n1PLsiBMFzyfPv1cj96j3v4QNzUspU9eFmEYErQgjxS8AvAdC3FeMvXr/iNVKA02iPXfyZ0kBfaHwg7KCTNSAChBpspIVA6AJigFl13HGgWmrNArKRlyaAEIjYunTxEsgcYLO+hEAHoiCqBkGWgSKNzekIiEjtYdkhRoNOb5Y4MA5sWfF9s3/sYoek/JyU8h4p5T2ivYY4tfAOhK6BFQYrculHtDispqJZRGA/sEcIsUMIEQJ+Evh6k+7VwnUCXQfDqP20iEBz0RRxQErpCCF+FXgCxeB8Xkp5rBn3auH6geuCbVOzNbUCXZuLpukEpJSPA483q/0Wrj+4LuTLoFctenHhnxaagWumGGyhhWq4RSjkUErdFbASYIZaYkGzsHGIQDXLtx4vPKiNOqxlwxNMBLQbdKyF+hBV/y+jAnoehANuFmQFSIKWAE2rbaJhKaFR09pGQVB/V9P/VT7vhiAC0gO7eOkxYYJRbStaDUJgaEohsRKVnLpf9b0iASaVQAioVI+aoPZGLdSHQNkBq8exBAObIBSC8T92KR1w4WcNIjENo8r8WrKh3MhEl4ANsnjFM1eP9TYP4rdXAelUHXdo2OSNs7rn3RBEAA8or/guQGrUGoxXAw3MMJhVu41jg1c1mKYOYevKm7kEXAGV1oJfOwwQ4UsPySLkZsGTUHmuAC/NwLs3wS0WeuTS96NL1MJolBCU1q3nzYUHVNbYhuN/GsTGIALLO0P1sSYgGqdm4ujNu10Lq4CQsDgOcgGImLC7C3Sjhmi3sL7YMETgEg8pAaJJu200WitfStuXP1u4pggNQLgdijNg/7CF5lqYd4OV9HU2bye5/m2EDUEEhAYh69JjkubYh00TtCoC43g1CukWrgGsCEQEODFwbgEjCm1dSjckvRYNaBY2BhEQSn6/AKlsxs4q5JpGUanUWgJct6XX2wgolsDOgF1SirFKAZZ0aO9QnoMtNAcbYmg132d8GRIoNUObC+QCrAO6DrEWFbjmcGyIGBDvhYVxsNPgmLWK3BbWFxuCCAiUhn4ZEvAM8Ko4AU+As4rwUcmlVpVl4uLZl54aCkOkgSizDW9ubrRzzdSCBvUh6H7LobErDxVVpKgVBz0H9hi4BoieJvTzcmj0GVaD1fiSXGWityGIgCYgXqWsi4bBrjpmazBrNii/ayrsd+W5HuBZQJVpqqJBvsGRsP22G8IqwpnRV9FukGls2WS2zvfS6kzewN05qA9BodfL41JFjClBQSqfkcoMKnRWKrOsXtVfjYB71YGmgVHF6UkJjhugd6r3zoLGzAw4xmWub2SOeZfpQ5OwMYgAtUSAAD+BogYL4cbGR3rgBin86vgeFBrp6GrhgKie6HUgdRpWTIgKtQtABjiY1IOnlLGNQK8zQwLvFdQHoUx/NQgYF+GPQWnJp3EpECkgDF7V2Gg0PraGCVaVs5HngnSVPuiSR6izAIVH7YIPEzifAscmyDkqCB6KcF5FTfWGIALXK+ptuNKr3YHcVcgZ9RLHNLp5rIYz1bzVccJBfVhNvLrmKWeh5eHQUY5BWrUex1Pr6krDtuyCUr1WXdTkr362eiJf0DOsSm9dLZte7rzVYB04hrcVEdAAi8bTT11r+d0IYGNBLfjqvq1moZhagK+DBLdBTkILuH61MOpc71RHANYZg8vBWU6vpUFIUwu4+tEc1G+NIKTXnuuhvFKria+H0j1VQ9drrUoGwXMsaBO3V0FJNRpjCj0P3AprJgRvPyLgNbZgXPfaa5UNLkMEqief8FnRBmASsIhl7QKsh/UgAvVQ/byrJQKaBp4JRV1xTJYJll7bX09TnytBoIhmeDVEIKAdXaslAh7BJ9sB79Gupz+ohgeahHADc8F1oZRvfN7Uw1smAkKILcAXgV4UQfyclPKPhBD/GfhFYNY/9bf83AJrhgAs0VinXRFM0a8m9IAAJvDzU1ZNHqkpzfiVIFAcRo1H5SqIgK43rhNYLZzq4Cyh7tcodB1cDcqGmuRhAZYW0IauxqAhcUCDcNX1nj+G1evHE3WIQAAnIOv4m9fs+kKFAzTilLrM7UYbmAu2hEoZ3DX606yFE3CA35BSHhRCJIADQoin/N/+UEr5mbV1rRYaEPYaZ5W8aywPGKjkmSvheWqh1GilV9FXUwRsKsJnoxtA0K5WD15QX6m/sKv7IETtGFwOQqrFovlWgZCAcIBOAE0Rsit5lQqhiIBV1S9XquvdqnY9Ecxh6CKAEwjg6KA2KQoSQi5UGhgH3VNz3GpgPgjXVxI3qCCth7dMBKSUk8Ck/3dWCHEClWq8eZBqcjQSXOjK2t32aiNEgELK37EDFYMNEoIwwS9uNRbCRtdl9c6+jHoTJ8hCuCo/LE35gmh+rEAYtSC0OkFfjSoGq7zScQlWwtcVBwhIf+AFc2+imssTYPqL+0owpDrXbOBcT4LmKmLQCOqN1broBIQQ24E7gVeB9wC/KoT4WeB1FLewsC73oTFZCernr3fXQWNYvQsKocxQZgPUSUrFvlVzKZoW3N8gE50k4Nw6u1IQtAAZux6cOuG6geJEQB+EqG9mDLpXOAwJC+YmwClCV4cy79W0KyGcaKxdIWqf19QhZAToZjxlPqyGHpDwVBi1xMFxYSF96XkScC3llHYlGBLaNUhU9aFQgmLxUvnf8KDDaFzsna1zfM1EQAgRB/4R+HUpZUYI8Vng06hn/zTwB8AnA667UHfAHNja0L00CaEGt7t6LG+QUm5VCNBJaJqKfA1V2aIdLZhFD7q/USFwsZkBb8g2anew5ZoVNfeidmfT8HfaBlBvrBrVRQkaFwfsCsQiQFSFfLsOtEdBC4Nd9d4NQ+lG1h0BlhsInkvRsBJXVqJUqk12spyHohEFaQhoF7VEQCuCU7rUr0HHJ2QNslpNIQJCCBNFAP5GSvlVACnl9Irf/wx4LOhaKeXngM8BRPfd09Cy1CSE7MbYy3rKLzegkMWqEEAEdAkRD0JVq801lKa7IdgE8vNmwDPYATYkSfAOFrQL1pPzA1FnoTWq7KvXr3r3sgRoJkR1KAuIaIrDsgN4/2pHn3XBKghL2KslAtKFSNV7lEJxOY2w7SZqHlVzvJbfbjOC6tZiHRDA/wJOSCn/+4rj/b6+AOBHgDfX1sUV9yTYZhwEvY6spLE2aUBI0KsUMboOpl2Vxci3b8sGXXTd5WurOmcEKH0Mi1plgwyOq9BEbei0565dadpoVJ+UK57tCtA8FUq8XNCppCtZPqwp7qe6yw3HkTQJZrmWZhilAJ2VhFCpMe7JRG0q1XNXLys9QTOMOmvhBN4D/AvgqBDisH/st4BPCCHuQL2zEeCX19TDFRCoSdEIEag3PxrxMlttu5pUspyxsmFPTWpN0tDbr2veC5KxnYA2ZfAuoWm1E8dbBx+KRlnxZR1II9BdCMkVyjxPEYOwBMMNIAJN2BVXA7HMva3omHBUn6v7mq005hWq4b+bag9JR41DM3Tda7EOfJfgNdG0WgMaSmZqqORfvWKRa80lFrCodU2xapd4pWn+YnNpiHzXzXMaoG53lvtRhSD9AQHn6trqvfiu1GY9CEBrlGvwlPizTAQ0ebE2pwi4Z93nvUpwyih75op+GU6tJQKfiDVCtARcDCJaAdNParqhiMC1QD0/8CB4BLO86/HANa6xKz7VxxtFkB87BKgJ6iy+eqa4IEZkPXIqNroJr8ZEKLn4bo0Vn3p9vdaT15UgAzIOB0hqqw7wCrJdriLGbFW41uP4lrDWCbxWRqAh+OKAqGd4XkOfDJuaNydEbbgsKEJYI1+uh9twgxO6Xr+CILm46A3AMnyOwFG5JaqVmdeaEyg7KhFKNQLfpROs36mGjnpnQa7HzcLGIAJ15NlqlD1I2w26DRO89gxnDUTAn53VSjGhqdD3mrnuoH5oAIZDoOdX4LAEtCs0ZWNvCEEyJxCnVnKp91oaDeNFNO7OLOXFDbDMxbT+DsFtiIDOWXUmR/X88jyVzqyyhsXmFIPLpgdB2JcR+VZAR7kzO2tJt79KbAgi4HqQzTZ2bvrKpzQNAmUBiNfLQhRUMKIZqKMAjAXFwTco/4dRcmuoakI7ztWLxvQspfEvA1kHSn5iGMfwy1KslL1L1BTYEIBIXEqkJcr/oJS/9NxKBebmlAPOW8YqBsYAGvJt0kFaUKxRLDQPG4IIwLUP+20Ul/XuvYYP4Um/om8VhFabkCMIGlAq1/rSX01UBIiIYrOLJeV4U/JlaceuGl6bQM6pejOR/rjkcpcedxwol9foM3KdYMMQgRbWCFnrVQeKQ2gkhkJDLZZqv/erCceDQlmJfcUilEtQ9JR5zK52X16uslO1iINcdu1KLREQQZGJ71C0iMB1AimDlVRao5yAo3bealv21Uz1XXZAFKFQgXIGciXlM2+JxjmBYrGKGEqo2JCvIgKaBpForav3OxEtInCdQEq1iKuhNbjjea7KxFytgLuaRCAPoCtuwM0qX/lc9iJLvxJOEYwAed4O0Ng7du2xRoOa3gloDcV1AlnHwiK0xrwDNdffQavPvYoyc9lWiTLyZXAyQAnyGTBDKk5gpfwu64gDgkujOaUfMFZd4XrNzlLXEVpE4DqARC1g264lBJpWGzsQBI9gJVmpdPXoQLGiOPxiWdUgoOTrBYq1wUJGUXEDKyFQpcyqYVRqr1+N/8L1jo1DBFYz0xpMw9Ws26+pTdmE+8mLO171QpaXNWdc2q26118luK5Kl+UsOwZ44DpCReA1+EINvWrXl4oQOm+jYpNB76GZ2BBEwHFgoYG0I7oOsVhj8pxpKsVPI2xfaTlhw5VPDYSUwWGt5TKUqxLLub4Cbr2ToNbrQ6MIA+FyYxltmgYLLAv6UrD01CLW7jjhuHlx115JCOokW8nmao+/neC6UMg1rwxfEDYEEWga6iSIqDltNas/oM3VUO7lQqvXOhPyRsZyUs+g5J4trD+uWyLgusr5pZEMOo2GpC7L3tVUermkVTVaC33taPnyNB/XLREAxXqvuygYYK66LCve2sla2OC4bolAtUnpchBBccB1EGSzrkcEdL0xzXwL9dGioc3HeiQaHQGyqE3XkVLeI4ToBL4MbEdlF/rx9co43ChcVy3WRgiBYfi25QZmXJBTTj0bfTjsV75pzeS3jJY40Hysl8vE+6SUd0gp7/G/fwp4Rkq5B3jG/35V4XlqYdr2lT8NV3CR9dt0nNrPariRFlq4VmiWOPBR4L3+318AngP+/eUuqM5IKwJShkupFncjWVs9r/F6hJ7RuBLPDSpnLWuvF0Ids51LE3g4fmWk6qxHIaPWnBlUvbguArIKr/QfuBIMVFJUeQ096YSfTNS2QToqG+ryeIvqCkAyOIGpFiTaBYz31YaQjQVnSUFD5ejWE+tBBCTwpBBCAn/qpxLvXZFxeApVr/ASrKw7QGrrJXHdAuUqalYFd0hPseKNZMVZTVptx2k8rjyIa6hXb6/sQDEgmUUQh9DTBvHwpRPdsZWvQSMQGkSjtfeqVBrjdDSA0OpKpK83QhHlOjw/D5WlIlolTj6vNgjDrFrbLoG5tqJhEFXOQq6jLEXXEiFb5Wu4EtwGC62uJ9aDCDwopRwXQvQATwkhTq78UUopfQJB1fELdQfErnukW+VUoxnBudqakWE2aHdfD9iOKlXVCKImtEWqiICpkms0Ak1X16+E60JRKn/8hnCNlZhaSOXsK+TAKdoYjoddURySJxtTrYTDtUFPrlCeiNcSjeZ1vBZW5TUTASnluP//jBDiUeBdwPRy/QEhRD8ws9b7vB0RVPijhRY2GtY0RYUQMb8iMUKIGPBBVLGRrwM/55/2c8DX1nKftyt0DUJ6Y5/VVO5toYX1xFo5gV7gUVWMCAP4Wynlt4UQ+4G/F0L8AjAK/Pga7/O2xOXSZVejxTC0cK2wJiIgpTwD3B5wfB74wFravh6gicYr9QRW+W2hhauA69ZjcCPAEL6zUAMQLaeiFq4RNi4RWGNo7LWGhl9F2bdvL5dE1/zvGhcXvutXl2m4em8dVI/X2zGASV8uPKopR5G3olh9O8+ba4ENSwScBu3bGxUCpRhsi6tklum0coJJJFTlnEgEojE/frwAdlllxX2r8DzVTs3xt9mC6OmBzBK4sSShkEF7uyKSjT7HmuoIvEOxYYmA59KEEMCrDEOV2jYliJJKmaWHVJWcuAHJsO9RWIL8Wot81Mk2/HZDJOL7beghpBCYIVVpqOLR0ABdD2NwtdFSRzURhoSQB6aj8txpZUUMQq5fctuDkKO+6293grcOWHaztm2QtoNry4uxHa0YjKahRQSaCF0o1l/XVdKRSkX9r+tK9hV+YVChtawDsCLHYAkoVSiXFBG41n7/1ztaU6+JMFC16k0XtLKHk6tAwSMCRAVYnuIUwg0GRV3vcH1CKW2g4uBVPMqlxiootfDW0SICTYIGhDQICz95Z7mEm88hyw5hoarqWDqE8HUGrd1OZW2qgFsEShUoSZxKSxJoNlpEoIkQQlkJpAeOXcG2C0jPVWmxDd9ciFKCtia6sgLYzjInYIPtqfJjrcFpKlpEoInQfJlfTWIX6ZRw/YykywQCWpP8AvywX2mjlCdeizheDWwIE6GwwZpr5EQaDnd1TZAharzwotEAJdxySavqNqqOSVRNjHKA/L6cU8DzJ65lABX1bLvMHNujr2C2vcbutg72dD3MqLiZ58YtTlswfB4qCejsAG05ftoBDIgH1Kk3csCKFGdSgKtf/F91yC+66YBeAaes5O2K74tgmFWZmHVwY40nFbEC/jaE6q8pIJNRKdviSTg9r9oNh9V5ZVslEIlHIe77UeDBZAiGlyBvVMAboautm53hGFoBIt1QTMHpLEzbYJRgW6nWydIADAvCxsUMT54DSZT50BDKVyOfVzqIlSXLPJQpsuK/Qw2lq9GlqnsghLLivBXRTaCsRVdCRYMFDRZ1pS+y/PG1KqAXodMCZwEmhiDWBoUomEl/bpbU/I7EIV9QPheRCAweU+fWw8YgAh6Y+UZOpOEea5bKGFTN60SM2uSfrvBr21XBqb6XVIvaDbBFC6HyHywnHTX92WmWoTc0S4dxhG7zRfpLDp2zOYrJGMXsLkY9g0JOLZKsBYajHtPxiYBucelMl6oE14VinP6YLPdVCrB19UympiaPVlQ+CnYRSgXVVxmuCnPWwdFBVidxqAMd1dcL3yXkFiBbUsSskgMzDNEQxCzVrmmqpDClgno+zQMrBGFTjVtO+kVgvBzoC3RGHJIlKOXUMxYtmE6DnVHPGLOqiICEkyegmFfENGIpIpOIqXEx/WxVmgkyB4am8jgsw0PVZJSO+lv31NwMoRakEJc+82rRiFe4o0NRQNaAmKP0SZoHegmMJegUICpQycOmFJyTYHhqAyoLiGnQHYOxOWAe4imIO9BxGeXqhiACq8IqqHDgoIva48s7Rs2t6oxOzWFP0RpDV38LqSr6dAApN0dXeYx4aZRIaYKZwfOcnXXR7n8Q6e2gkgcZUY0ulwyTwv/bCSZOF8qQG/j5uPxhMQDdj16UoDtqUovlUmQrU41Vpx2TVf83Aj/Rh2GoXU73VN/bY0AIYjp0J6GsQ1nzPf8Kyl/CLUHJg6UK2BHlRBXuAtMCN9UO23fQl7JIeJBqAy+iSqx3R2EqD7IIS9nad7l1QI2NcCHZBVsGINUFlq24ISlVzcOI4WeNXvEyPZQUYvh/65oi5gaXck3NVOIK6b9Gf2w11DvUNPVqXAmJCAz0wd49UM6Ba0EkBBW/sE1nCkbG4Pw4pPoglQIzoEbjMt5+RKAJcICsfen8r8d0mEJNoJWQfg4701BKQIHKGTgQybKvbZK9chwRmcGw5nnjaJFDB17h5h3jOJaLLAIJQFPppy5EHfqLv2bnkcr5CN/Hfvnn5cV44TRfPAlyQtKXFZNVnIAnVkcDHEM5PYHaJbu6oDMKW3sUVyArKq1Wbg5KhtqJNVtZTAxTjaWogNDVmA6YUArBUkSjENbw0h6jQ4Pcdet2vGiYfgdCm+FMCmbPgD1YtSAFbNmpdn+J4jpmRsCZh1t2Q14qP4TMrHLZjpoXxaNlGKwgAtQWr2l2qXbTzy8R0SAsFRHQTTXOWghwIJeB9DwsLoLZBtJSIkBMg/FxWMrDQlYZWNpTao5MTta/Z4sI+AiqyF0JWBEuSt5cCSEV22b4AUHChbAOu+MZHu4eZ6ucITedppzNcyDnMTQIvbMZKr2uUoIZ/g4gA3IQVIkeK38TvjPSMqpf5lXR+ppcoEaWoRb++GmPE0dyZGcmiCbjDOZdQl1t9G9tpzsFvb4eQAi1c0Wi0NmpRIbpoQrTr5/EffZbvPx6FPnmG8x/3wewO5Ikb7qF7d+/m20pnY4IJLbUdie/ACFTiSGvH3U48fn9iMGDfHNLCFkoQ0cHmqGx7WMf4OH39hCpEg2Xx6wu97yyNFoTYluWNx8DFXwW8v+OW77sX4DhM3DsWyMMnU1x+8/FCIUh1g2WCWMT8PIhOL3/NH237MJMapw7Aa/sz9a951smAkKIvajaAsvYCfxHoB34RWDWP/5bUsrH3+p9rgZsuDiZVyJIPpZK2XYJhEpuafq7sysgYcANsTl2d57EKp0mpI2QcYuEbcXKzs9PUbIWkZEIGDqGrXZ9c+UEW971q2BE1KeqC5e+TOkrtTRwl2eV4T+T7v9fXeBzFaHMjnnxfsLfqQwbcrMeI4dmGHri6zA/jRgYQM7NUd66jfkHHyAV20pvF7R3KVEns6jKiW9OQTwBi8dyjJ8bxp44jjcVhcLLnHx2CYo23PYutvT/Jqnb4kSyAsul5p1pRcVRJOKwf6KCPPBFJJ+DE/4Jo+CZW6m0fZrY/T+jlJI+PKDoXeQElo/ZOjg+l+QYF7MBG2L9RQNNU/qHiKs4pjBqbCOmGie3AJPDZ8if/BOGDifY/MFfwTR6abMVdzVyfpHTn/9LvEOHmPjRn+Tpvg9x+Ov/hDx6tO493zIRkFIOAncACCF0YBx4FPiXwB9KKT/zVtveMKijAIwEEAchlOJL+qmwIyYkOI9VfAWRfgN7fJa5MypasDsF+dwk5cUp4qkeFqSutP3hFQ36kyuI/YyYAQve8bXP1eHE1Kbm1nRFsFZaSdyqHbEhGBeMGERCkOoAz/M4uzQP6RmSHW3cevN2vvfYYZgsw+IO9EqKmBYhYYDtQt6R6I4gqsEdIYhv6sDp6eDVTTt48NabGD7YDkLjzPAQ3dLmrnadLZ1waERy9GitefXM8Bkm9ndiRiKceOJx4AVq9nXpEhE2W+OXigMeUPQ/nj8mjlCvpqj7WYBXEIRV0s2G4AnFyYSFEgcimrIOSD9DdTQKemUUnCehfJznHtPBSPLKLTcTaYsx95d/iffqF8CtwP96mUN/0wWlV4H65oH1Egc+AAxLKUfF27GM7PIuWY0AIqCJ4IWpaRePCwGGJtGz56D0InJ6kunBEieOQSEDfQMwW5ylvDRHKuKSddUuGtEU+wcXFZU1XAfK7GOY/uyXQukNDOVpt3ItS5TJ6QIHsCx6LH9fw6taqVMTpmouLiVLeZf8xBmM/By33L+HH/zQTXzvjf0IYRAxBcmKSzgrMXVwy+BOezhhgUgKolFITk4RHhlkqyzzoTtuo7hzC/NzCzxZKZCMauxyHLrTMJLOMSCNSxkBCTOFaQqZaaSUJHDIhj5K+12/zb/6pffzmU/+MvB1cF1Mu0i7rhb8SnYi5AkMTy14FyijFJKOBsv0YjmeyTFWP4TLd6p3nYvS9kdQcyGC2hsqeYlwobsTwr0VFXWW9+Cv/yOgSoDVMvynoXTa/3uxbp/Wiwj8JPClFd9/VQjxs8DrwG80UoLMiFyUb21/lNeSXlzXUSa2kFqgy5WDBEphpOvKXpzLA0WlyLNRrDqOOiZ6QGYB3/ZazkHCUqy+IxU7u+xLsOzC4HrglCTZvEOGcZzyKAtDHm8egaeOwGt5mAemjz+Ffd/N7L7jXQjXAltghaEtoXb65Uc3TD9G3lachpUA25BML0J+0SEZNUglIBwCpEDYSrFkGlAsQM5RpiMpIRaHaPxiyW/pXfy7UFaacdNU9R7KJXXf5d+X6y+aPlua9Uu3RQx/EhWhUJSMHV1g6tgBTGcMI7eXDk8japlUigX06fMsnAB7LEmiLYnt2MzNzmNZEeTUZtLeApn9zzL07BMMz77E2Old2AWHD334B+mO6wyePk1h6E3eOJxlaCjNngf/GclojM5OwIRsGj58//0sLEhFlBL3Y8sf5+Z90GOVOPBTn+Q7fzsK8hzu0gT2jCQahsV5l0ymQiJhEombmB4sZiUVA5L9YJhC1aaQkHMkWgyWipD0YCAlyCxBoahEEPxNolj0NfWdfoUqv1JVNqfG07LUvIxFL0ZOep5SAsaFMi1LV3Ftti1Jn09z7viblNPjZJ79NixNvfXFUYX1qEUYAn4Y+A/+oc8Cn0YRvU8DfwB8MuC6C8VHRMdWTAM6OtVkzWZry39fDpoWUPjTgFAU4u3qpWQyUMirwV9ahLYO6OuHsTEozUD3FgFJByEAACAASURBVEUcciXlXCLKkIpLZgYhvBu2dMN4CdotiKPMTMWCWiwu0JaEuCGolCGXKzM5O8rZyhgvnvLY/wy8OAPfAy5Qw8U8PPV1Zm79EbStd5Lq1OnsgI4OScSSCKEm0kIa0hNqQvVsEuxIwekJm8Gv/QW8egSx81bO3fsIPW3bkLaBITV29AkSbUo7XLYVNxAOq+cNhSBXhMU02B6E40prn7NVgY5wFOIxRSDm5nznKgHpWcCGpC+7C1OZ9pDK/yCXhc1JQarDoq3NIiI2kyxnKYyPE5MFioUc06eOMn3iKNJxaOvuJJ6M47kuyWSS6eMHyBx9mR/a1c0Hb7+Zr7y2nzPHDzM4PM6v/eeP85Gf/ihPf+EQ08OTfOfrj/KVo4+y6bkX2XXjHu5/4GEilsHLL+9nIZ3m5VefJmr1EItZzM4fAjSMcA9dW/aBvhXdTFDQojz9T08Qi8eZm56hkC/wnofexa5te5iZkRw5MMgSOvf/8DYifSFCCKYnJAdPzqF1JimcHaVr6zZu+okQti1YWIBUP+BAZw8MD6t5vHUX2AWYnFUWpLkFRYzbutT7betWc7OypLgPy1JFaBbmIZ8BTFicWWTw+WdIf/N3YepQ4wujQawHJ/Bh4KCUchpg+X8AIcSfAY8FXbSy+Ii18x5pGMrsUSqpj2lC2Kq+pvFsQ66rqveEKxfLe+m6egHbdqid03Whu1vF+hfSko4IbO2GeEISj0mODwo4MUy5OMBkOkJhxmFhQCceLVIsXvwYhs6m1Bb6OnXKtrISZDzBse9KTj8NL83CRFAnvSXC2TPc1ncLd7zXYm5O8vwz00y8cVRRLMNQ20S2BMkEuTtuJar3sf/A1+Hx/w7Dp5Cvhcj+3S1kza3QvZvQPT+Md/eDuJs0OlOQ2KSckAoFZTaam1VZjkxTiRWTU2oHMiPKSUU3L7o79/dzodhqLKkmZTanqioN3AnYqq3sAnQsQVmTRJwsETtLws6QKKXpsRweeeBO0nmbUCiM49gUi0XiyRghy8TzPBLJJJ7n0t2nsbM4RTRmcGpoH4VskRtuvAFRsjj5vXmef/IbkMkzO3gI5CLnpr7F0tQB3IlBwObFUy9y3/YH6WQRu7TAbGkcmCFk3sGNN91Bb28fp91FRs5OM3bwi4wd/G0ghm7s5fY7f5D+6B0sjpziqa8f4Y1j3yPthinaP8ruB28jvivM0Pdep/iF34XFQWCIuc5f4NmB32XfPXH69goiHXDmpCKOkS7lG3FmArLFi3N6003Kk6+7C+YXlLeoY0M0qTiJRBRCFVg6r3QCW/tgaG6O8pmDsNSc8h3rQQQ+wQpRYLnoiP/1R1B1CC4L11WTqVSCWAw2bVY7USZTdeIqNLFuBSpF5XwipWrPdRR1jsXUZJ6cUEq6jgRUjk9hhHXm8mWOjY8iJ6dJ7NkOZ/fDUie52QHkQprcfJLBUI5yqYgsFhU5LxaYerrgl0J2YWEJFidwtQNslSpsOCQvypQXcZ6ZN77JrTfvorxwI4dePcPUn/zfcOoffLnkUsz/bRfPd98L+nGYHvOPVoBDYB+CSYvKs8eZLn2KrR98mGQ/LPrl2CIRpQTTDbWzp1LQ2wdDQ5DNwKZNMJNX3EGpBB0dkGxThDSbUdcvRNT42WVIZ6GUAbEAfQI298KWdslZu0CkmCZSyhKxY5QnxvnOl/6GqfQ8gohyDCAHcgLJDOAiiCDx6NTaCJMnLiXjskjFEDzwwE8Q6oDpdIaCXaBdq7BvZz8Tg6MIL4KkhJkepVAsIBlmakSyyDCeP1kMTPaFOunSNfJjZ7HT48AYMIOgH40BXGecg/s/zcH9/40I+4iwjzxTxLp2sWMgzrY+k9MTFcoHXofCS4C/z6X/P978i7vA/AR7b7PQdUGuLKhMw403waatMDEBnaZi6cenwLY9piY8Js5JNNNgdlojnvCJclTNTVNCuwFOGLSiy9zZEfKjz0FxvPEFsAqsiQj4BUe+H/jlFYd/XwhxB2rJjlT9FgjXBTevatH19MCu3ZDLKcLwVmFXoOyBEVIcwLIWeXICkklYWAA3rX67pw/ec28HumnwwgsvMvXZ/wM4fImiZZn+rCYN4DH/Ux8SXvkiz77yRZ695X0wOQ3pk9S3Us/D3Lcv014J8q9gjT7Jlp6HiZlwbAQyHdDZDrou2bYNImGP9nZJb6/GxKhDwZV0dZpoSY1CST2raSoRQvj6BMuC9g71Xko2jJXBq0BbDLZ3wr1bYJchGXkig2lnsewMoUqUtkqO7oiL1xWiK9lJOBLBcRwcZxe5whK27dCeaMP1PO7f3MEt7SbnZs7z+MhBPvJTv8Kv//a/pr+nA0f2UPYqTI6fpc3weHfPNtJFj3QuS8ieZDE/C3iktAwVT5BBkgdips5Dd27n2Px5Tp84RJoplJLMQzKJy/J+JdCIUCJDkZNAgb7IZnb3uIycPM3T/++fsTj2baBqUn7rd3mzNM/wBz/GBz++h0RScbSuC1sMyVzIJR6XCEPwyosLnD96GE4ch6UlrI9/nFvvvhXDkpQcSa4kkK6gw4ZtAzA36fLKkwcZ/Mbfw8TIZWfSWrDWugN5oKvq2L9YbTuhEPTuQNnFQ2qhZjO1isF6hT8D+1YBSlCOQMi6qLl3crBoqx0x1KfMZKZwuGtHmS09LlYhzkFO+a0kCNK5NgXHvrNODS1i6PvpiHmEdQ0jDO2dMD/nMHqqSCIpsN98k2OzBaVqfv0QzM7x3IkfovehXUQ6TCJxge4rtzxPcVG5DOAphyAjDH1tKgQ66UDSVBJL3pEYpSyGU0TYBcxShrv29XH0f/xTsM/FZfDGa0Ps2DtAok1VWZXtcGL0LGeOPMVOV2Mg1I3r5lh00+SWlK7FBL5v902cHjnDUOUco4Br25w68F0OF3PMcq7u/SLE6aYftAg5HQpugdHzR/m7L36ZufEnWZo9QHDSyyH4zqcoDr7B4C1/zr0PhJG6YP8rBcZ6JU//46swP4fo60L+5efg3JPAIkS7YM82uO9GpieKZBeXiLXFSXUl2BvR6W6TzJ47w+BXPkvljS9xScTYOmNDeAwaOmzdqtjQyQkYH1SLM9lfe27DYbc+EahYKvAk5ruSsujgZBxie8PsvUmwMA+Pf+ElTo59hltuvpGlpSVApe0NR8qU33bZayWZhQyHX5pg7x39DGzXWYi5nPraYfJ/9VXyRghK34WpZy697NSfMP36Z+DO99HxYAddmzU8X4zILMG5A2U4V1QBAn0Gm38iSlvKoN0BZwqODUuElAinhOEUsJwcVimCbpdwPQ9s7YILrirlLtVxJGLZYcFz0JEUK2W+9dSTPBJ+H5u3baIrEacjrnHHg/dhTo8TmZ7mlr07kZUKPcPDALjC4ay3RKfhcdgnAAoujxdPcCV4Rhk9WuK+vndz0+b7eXH4KC+NvsTw4c8Dc1w+662Eib9n8NR/4AMfuZnzUx5Hf/8zHC0V4bU/Aoq1kqxjUx4d5uhLr1E+ehgmJtD23Ej+wffRnuwne6TAsa9+l9LR52kmAYANQgTyMw6vPlXhxneFaO+A2Zgyj0SqvOI8zy8x3QghsIE8ajP3z3cckK8MwRtHyT/0fvI7Ohl9sYT32X/PMec1jn1N6TB1E9rakrz3xx7gsc8/QaX89opqz0+d4pW/+gPmM79OX3QzJ4+eZ/aJf4DzfwoMsGwdvxSjsP/XYP9Ps+D9W7RHupGGwDRg4hzwN8/BiS+hOKNNnD/1CXh4H3vui7OpDbQYGHnfo8UpI7DRHZfSdIYTj51FtsVJRCWudMnlXfJ5l8XFHI7jkEwmFXGfOk2nyPD04Vf54298iT9++mkSN+/jK7/zb5gVBrc/eB+7NMmpx75FT1cb8XAI185j6gbRiMmWuVlCoswkEAWS0Rilcpms66DrBn3d/WimTqVYRkqJ53ksZZcouWXu2n4n/+bj/zsRrY2JkUX659qJmh4le57GhEAbmc+SycGhlyfghf+En1Im+PRKAfndr1Aeeg3GXgcKeGffj7N7J7N5i6G/+DLpV/4IOLO6l/8WsCGIAJlx7L96msn2O7jrbgu3L0t20cGwk2iawPM8DMPACMfIyDClisRzQdMEhnExJtxxfEcdQ2mqbSRhQ2DpAq/sUp7IIF/5Csw9C99Oc+rWn0T+/XPgHmLly7rzfo1P/vSH2bfvTuYGv8sL38mtLrJmFWgzoKcDMjbMLK2C07ks0pTmvsH5l/aSTezj3P4X4Oi3UbJwlEAvKEDZML4KR+4kt/lujO42Qp0ptNki7umvAF/kwkD89fNw7F9yrueTfPCRBD2WR/sYzMoydlijIqEQk4zNTfLY7/8e52bnKdsV5pfSZN0sm7oGSMVTOK5DR0cHruvizA2RXngTa9NmXBlh7uxp7N52XsiUee0bjzJQyBLPzjI4cpD8RAQrYTE0NU4cQXsoRq6S4xN3fZSHRy22h8L8/Pt/gP0HD/KF2XHcni187tN/Rue2XoZffZNivkg2k+OLj/4VL43v5+C5A/zi//h5ko5Ov7edWfIsMqGim7QoaIb6VGy1Q6GjiEMURVRDoNmMTXgsPvlPXHQ+NuqMtwOVkzB28uKh0lnk3ATZTIX02W/CBbG0udgYRIA5mPgR0n/9Ic7tv4WTzzyDKKTpefADxKIW+WyeVKqbXbc/xGTXg0yVdfI5SSJusbnXJN7mkp7KMzNnE++Ik0qFOVMqULFz7Oy36O6Lc+ilGZy/+htY+CwwBfMW8pluGP5iTbzu7/y7KDfFvoye+zIfexheeJngzXMd8LFu+L1fg386B7/xecivG+c3zMLJX2HhZPXxQGPlJdex/6co799N+aYH6fzF36D9zJvMyhUEAIA34PB/QjvZhXPrjzJfKZB1c4x2ZTi/p50cMeyONrq6Q+yKTLMtOouhmWidBlY4RSIZI19eolAusrUvhOu5jFUyGG09DJbmMAqTtOlhdjod/LOExwMf2ceff+r/JHd+jC63yFKbyWNWiWnAQhKt5LCA2+dO8Qt37GB3rI0t+hI79vbRvTXKb8Y8fvbRf0tvVzdRYeIu5RDFCpUtOfZGepHFCrrtsSVdoTs7zUlKpBHkzBRYAxDthngnnJuBchoVInMOuBOl/jVgeJpXv/wqPP04yk23DPTQ8G6eXWTmyX9kJjsM0/sbu2YdsEGIAEAF79g3OHHsG4CabtPfGb7w6xxw4qkvw7v/Nwj3IbQwsmcLMbmJyUKW8y+8gJ2eIvXwBynl9pAeGsIePcbxIy6pvXdTGhmDyX8Ad9Zv/dvw9DRwhGptfIQcXUkVj7+9VznUNEs30GNCOAV3W34+gg2DITgxxPO/86YyewY6aGRxJ09hL47RHgoToUzEhFgshFZ2KRRtpqbmGDv8OvmlKd97WaCjpNwJPMpINgsdB8mC9OgXghEpSQO2bVOeXUC6LhG7xKmDR/DGZ9ElFCaWWE5GpaO0OBXg2P4hXOkx4bmEgBjKIJjy7znnH4v7/3cAm/EDhfw2Ro0IS9E4IU3D8GwcbQK8NBTCKkOHWQGxpBIiyP1+8gYBf/t/UarMAhn13QVCSV+a0Lg4z6LKmcTJ+d81QCqXx4Pf4XIuvs3ABiICDSAzAk/+NpBC0sZSZAtLvZuU6970y8ASs5VhZtt3wPAgpF8DeZ7ZJ+4EVwP5BpfGfwZ7X+1IaXTe4CHzsPs89EVYoWhaX9xzD0R0aIvpiA2Td9xC7WIS8q9f9swOPcwm3WJrop1ibhZmp+iyHUIORLwK/eEQoW27KE2GEFIAQrlY6xqbpU1FVui0EkjPxbYLbElanM7mmJpL48UFuzp7MHWDrXv3cc+tezGkIJIvs2RLpvNFHHTu72qnVHHp1jR+UrdoK8wxW8rjofbjB4F/jsk4LnFM+gCLClEkfj4XXBSz9z10TvXegHnvg7zR3sF3Sg4jXhQ70QvJPji3AMNTEG6HbFSJCwlDOfynz8HcSZXGKWXB0jz0JeD0pFKa2DkVIRS/EZIxmNqvnMLMNvxstGrMZbl5rzYAby8iACiyOq4+xePKE2ElTj2KUsgUuEB5ndWxVrtSJvnJMtEB2N4NvVZziEAUuO2HIdwNsbSFoJEca2vFMrtRh+C0bSLSdhOluZPIwgSXiawHCYXDB3mzs5d0WxvF6TkmXtuPlV6iv62T7mQ79+25AcNeIjOxCdtxcOwKruegazqelHieJBQKg5RstQz27d7KkaFTnH7heWaExCq4CE+CHueB299FV0c/xsh5ZqYKOGdHSWlt/NCtDxKeW2J7eweV48cYL42S9Z+0G9iDAeziVlOAlVKZRcongaULj2KgAnUSmES7e9l0552I7Ts5ny0yPV/ELRkYkQ7snES2lzCtduxbbwQtArftgnOjcLiMeGgfcvA12LcdSlnaBxK4bw6QLbl+brSKclSJxqCnF4ZPQHs/FHIwOQYsXvXye29DInAlrH0hzR4q8+Q/wM/8FoRj0NekUUoCekRAp0SfX/+w1FoYiPAAyDKyMkO1tlN072DTez/Jllvu5Mg3H6Nw6EvgLgU3BYAk8+yjPHroCAnLIiwl3uISe+IptnWm2N3Zw96+Lbz47NcYGjpO3q5QKFcoORWy5TIV20EHyp5EA97f20tK6CyMT7NUrrBULjE9dB6n4lAaHSV/dpLkUpnSxCz5iUU6ydHmaZROnWYpnyNV2URyoUgXEcKUMfDoQIDeBQMfgE27YcsOGBuCw1+B8kGqlXa6EcOLtbMUCjEvNTIhA6svhd25AyPRh7tpDrd3EivUjpOzkSNTWMmdlArzUFxkz0c+zKmn/hbjjs24MZ1UR5zSrTeQPTcNnZ0IDeShI2iGIPmB78O89y6KFYfc/pfg/CRQ7SbbfFyHRGDtePNp+C9/Bz/zY8BW6GrS6pwC8i9K5MdhcaG0/qXEDUN9Sn7gr9GJNbAPr7REeaqASmvkm1Y0g867P86D7/8IkWiUE93dFLQOcDNc0TSycOZCKGsInTa9gx5Ho0/ohITO6TNnOTB4lAySDIpM5/07mygfPA2IjSyyJV1krJhmwS4RMSz6kykMXac8dI5zh4ewswW0qSkc6aHjMUua5ydfIw10ZKZp07bQyTY6WQQvD5TB6oGP7IUbboStO+CQhMkeGAuxkghIwLEsspaFZ+i03bCLH9nZz3FN5+uncsw7As8KQzhCLmShdXXhHnmTzi4P9/6dTBcneOSRbkbfczdbbt7F0EtPc+boM7iZBQh1Ie5/D117biC+Zxuxnm623X8P8VCI08eGOXTmEJDjWqBFBALQ1w3bBFAGkVdZX5uF/Jvg3QijJ9z1LyN+IcmBC4TAjKmySLahwgAlKEcKQEQw82XOHDlMKbNI/tiB4LTKl4EFdAiNAStBouziTk+hL8yT7Oyirasfr5THLhWxXRsNSSoUxkJHr5TQgRgmxZxDyVfqJfUEW/q2YhomyS07mcgskJmZYbuUREmQoUIaDx0Vd999zwfgtndDRKrkivM5mDoF7Un42M3Q1q4eN9kJ0XfDRM/FmGrXAcel00vSmdzCrBBUXJsbY5CMw6AdZcYVlLqS2O0aEStCd3uIg385Ql+Xx0fv6OLPMzcxP1nBoIyZnobXnsE9/gogIdQFWpGILnn4V36ReFzn9OBJso5N4fRRGH2Ty4peTcT1TwRMXYVn2Y5Kxt5AdcubboFP7UMJ7QWINYkTCMGFCIvMbBMKb64sNKAZaBGdUBxs6SlTRCWnwgfdEpgaU0deYer0IBQWVXZQKVF69Cu7TmvANpLsjnawKdGGl1lkITuPPTFJV38/N+gelYpNqZhjen6WXLlEf6qXZDTGXs/BqzikRufoMLuYyUmKpTKbe7cirA4QGmJrHzLRTtjV0BfyzDll9uOwORJne3eK7eEIqf/ym/Due1WXDWDehZGzSJFH3nM7ICnh4N3ag/P9m2mnA0RYeaE5NsJ2uKUAAxmXV2dLvCpizDiSAeDhAY0lILfFoLCjnWQI7jDg7Pvu4QM3GvzrJMx9+AYOHJsg/9X/yYlXUnDqtRXvYh75wmNMnR3k/A/cT9z0ePr3/hhRLOKdOal0A9cI1w8RsEKENm9ChkzsSgUyWZXho7MDujpgaQkmpv1MGaZKWh+JQDgCs+dU7msfC2fgoe8D0iDiYIXr33YtiKAy1sg49HRpaKKJO0EojDWQYuedN1AplzgbcikMHyPc04szP064b4DShMSbngLKoLf75tQYik3VUGSriNJmLMuuKmWRrunct/Mebu/bjlbMM39+hFJlgbOnh5jLZwl1Jhno6qYn1cPw8BCTk1O0d7STSCTYvXsPuUyG41/7NqY1gOvaLJbmuPH+h4l2bVJOOlHYd9cj3NfWz6mvfY3B+WO86UCqO4nY0ke5IwUfvPfSGZ3SKcf6ePwL/w/HZl6hf9NmzpwbwS1kkU6O77/lQzxy+0MXHy0EIqZyQ3R5S8j5Esfmy+QiGtmwxqSfO6KcgUwe+tvAuPcOCvM6L4XALSxw/sBLkBuBU2cDXoLEnh3jlS/+KZF4AvnS08hcQWWruYbYoETgMu6Wdc7vuOFGuh56kLmzZ8iWSniLWWQmh9bXT6g9iRbrpGS24eUzqv1wSO2GRggKs+hOBdfXKebnoaMXCm9CaNv6P10USOnQ5oI0QG4FK60jmkkE3CJuaZ5iJY0ImwjLVQnt4wK5BDI3A24noLTgIhzHXppeEdKcRMWKDbEyGWJIdJCI6nRYFu/9wQ/TLSzGjx8jPTLEyfwE1v7nmGnXcS2d6dwSMhGlEgmRxWHk3AiL+Ry3ZRbxymVyxTJTlsWYDFFA5/C5OXqsPmypAsrGKrAn2s4bTp4J3WLege/mljh85hSJyDj/ysghiF/y2LZj89qRlxkv76G9rY2lkQn0go3I5pgwT8PtD6kTV+b9KnnYmTyFhTQvP/9dnkmPU+rqYrGgo5Ul3pSHk3c41msxf2aQrz6+mRd3hJk+9CLTxw9z2blbLlP45jcpRCIqQYPdRFmzQWxQIrBKvliEae/eQ3f7ThYyY+zedCPRXR3MnB3Fam+jI9VNyAhTLORZTKcpF1R4nFsp4tkexo4uuqMLnH7uVbCVEdIuwNnjsLPDrwK0HvDFiptvSvHAVo3I5DzRTgcZg9k5d/0VgyvhVTBMl1BUZ3ExTWF8BAo5ytPnoJinuJhGqehM2truJ97WzblsF5670m9+WS66qMEOpzZx0+6d7Orv59aH38PwgaOcL+QYzqU5VMmTmzrNbf13YZsaw1OzRFLTdHV3s+OWfYTn55k6cpiz0zNEwiY3334fntfH5OQ8Fdr5zoHXuX3rDdhC42wGnj41RmaywGuLo3h42MDYwrKacZ5nvvcEjzzwzy957HAkxk/80r8j2t5Hb08Pua0PoEuBVy4j6hQR0EKCtpjFjp5unLOPc/rv/gLoBDcJdgkqOkg4Hw5D+TiT1lYmrSIsvs4V566UMD19+XOuMjYoEVgdOjffwM7dD9IV3UboJsF7Hrqdvi3bGRuaQQhBNBIBoWFXKszPp3EdB9M0CYVNDCNEuZynXDhOZewsxcEZhiaVk9wrh8HboZI7rAnxNh766I9x97vvZXR4iJQ2y8ceTtKXPkJ84lW0cokDB1UF3qZBgofHYmaBzPBZZDqtJuTC4gplhFrcFpKBtg5K7TvI56PkSmmUXmDZiSV24e9KV5LI9u107t5N5803k7NdDhw9hJ5KsTkruOPuu3nvhx/CbE8wPjbG5s2b6B8YwIpEyWSzbNu9G9fzKJcK7Om4kZCdYnbwLKW0ht2/lcS7H0CPRIjHYNdHfpB2J0R0ZoRcdgRml70/Ff7nZz9LItxBJBIhlUphhE0KmQK7YptIhHdCBdq8NqV/C6NcSaZR7gLdKGbHgLmhs5zZfwqndxPW5s2Ivh1ImYDkFrWAQ0kIt4G+CAtlSHTD8BU4gA2MhoiAEOLzwA8BM1LKW/1jnai6A9tRLjs/LqVcECrd8B8BH0EN889LKQ9erv3eHTv4pf/6Xzldgv2v5YmEQpw6cZTKU3+IksIuLx6ErS6y8waZ+XFCZoLshElpIc1ixiGby7Ewd5psNotTKmEvLIL00IWHaQh0Q1AxEhSSZWbnCzjA84fg1jj89RQceRxG34LWflfPACIaZ2jyHG079/GRT/wsH33kAV4/PcP4yf3svHs7W6N57LO/S/nIE4TCFeV+etl51AUkodOD9CrdlzxJcWyc8+lFZDYPZX+Hd2tvaBeKLE3NUSzOsalnF/8/d+8dJ1d13v+/z507vW7vRdu06tJKQoAQAgECRLMBGzDFGIxr+LoksZ04v/gbt7gkTmLzNbFjxzbGBkzH9KJeUW8r7Wp7352d3mdu+f1xZ1khJCFAEJPP6zWa1Z2Zc8+9557nPOcpn+fYYABN78awB1ipqT6XwaEXAJ1MJMz+vm4mUgkuveZqqha2knmpiLJ5C1lcUsJNt9xA+bxyZJuFVCKJxWrFarUiJImckqNh3mwUVSWbTuMwuzFJTq4oKSC2cxEfu2oJFyxfisNhQciw6KY1lEQlOvtHqAzuo3PDIQLHZVz1r93B0/J9KIDN6WR0wk8inqUtY+VW6wxS5hTxTBpdkyiVzCg5FatDJpvSqHZWgKOSRL2PXIWD5tJy6uqLMDeuQLW5ODSUQBTWouzcj24vxuutIJrpRO8VBnlFl/8t9/HDgjPVBH4L3IeRRjaFbwCv6br+AyHEN/L//zoG52Bz/rUMg3h02ekaLyosZPZNN/PYv20htG8TFV/9CivOX8FrG7cbbqqaWujrAn0SRB3oaQzV1UjMCA4fJBoI4nDPZ+l511PuqieezmBR06SCcYY7w/gDEyRiSTKjB9CVYaZzxHWD6thphohhoHmuG7Iu2KEbzDxOGXAUQNKU/900CoqLWXXlVSydP48im4O1jz/D1te3Uur0oFtsdCkKaamEcbmALskE1eWUmldgL3QhHCYsjlUczWPoAQAAIABJREFUWbsR2aoixNvsD6WlNMxbhntJlv2dT8HhoxB8B6tPIoWWePskCJOiMDC6m3huiCa5gRnF8xnwg4yEjJ3WpjYGhzYACfB3MREdJGi28A/+AF6nld4jr4OqUegpYFSJcema5cyfP5tAMEQ0FCKXU0mnUzicDswWC5N+P51Hj9LV10siLTEWTjESCPCynGHH9iOoCxaRLShg4rm1mP0xxva9Qn0O1sh25iw5h2AkDiY4dmQf81JOQrEkHX3t7D66h0ENBhDEsTJEjjgqGoLzkGgA3JjIYKXUuxhL8SyGdweR7r6CllWLEIUO6mTBpFyAejiA2e3j6PAETkclVcVV9ETjRCM9cGQvKB9svP/ZxBkJAV3XNwoh6k84fB1wUf7v3wHrMYTAdcADuq7rwHYhhO8E3sG3wArMAMLJImLIXLvCTNeIh9dyx/K0txOgR5HMPhwFlyFiURLpQ2i6IQQyyUmcllbuuvkGbrl9BUVFXlRVI6uopFI1JBPzyWazKIqKmgmDniSSztDTY9Ru2z8SZlPXQcyhA7SYDtLm6GV5swXXaIb9/QJrXQsrl32etQcVBl+4HzASm+qamvjnn93HkpkzKSksxGoyUecrYXxsjKN93VDQBGUrab3wWmY311NhglkuQa+5gDGRxquZCB7188fHVLYfVcm+jcYhvE3MWrCC+qvsVFxewrHNW+n+6WNnMoQAmGqLodCG2ueH8Mni031ADLfTzmRgGIgyNtKPLNkoc9XhtDsY84/TP9jNG1uDXAJyCRRg7+Zn8u0Yn/UPC472HGXdtucoLCwgncmQy2TQdB1VUZFlE5LJRDqdJhIOE43HUFTBlHCe6O0wSggXFYHFajDOZHKQCxPEwsckmduvuZOs040+OsL/Pbgbb0eA0HiAULQbNV9RWDPpjJRrdA6rmACrQ4ZKL72BOH2hDJLdwqyFNupnuujevh/T3u0UNzcyUVmJ1lqJVbLSUlNBcaXMoNOMRzZRIASV5YXEJzxok6NnKwf8fwTvxSZQdtzEHgPK8n9XwZt4nIbyx04pBKIYCa61dbUEmhopKDGR6tCMzC0WQ2wQCKApVlKRMCIXQNPtQDnGA+NHyTmIhSoZ6yukwAbVtSZMZjNGCIvvLefMqUaN+lQaIqkck/GLkXIRXCKK15Sg0CVxYVolHN9FNteEqF0B61L8YSRCfcVRhgf68M2s5eJLL6E8b2BKRhJ4PUUsnbMYNarRHTdBNkk8ZmZ/xMzkOCwtgEAK1q1dywWFYdqfeIpH2hN85/qr+c4d9yJZ7fzwFw/w3B9/jX6ipVAoWCwWdFWhoLCcgrrmdzRgmj9qVKtMnsT4UODBGashpXThcDsRoSLQUkykRxFMUuZahsPlJe5fR7L/GCcvxHeiYNFJZWJ098boPpnH7LRwQjIAqBB/K8Gmio1eLc5Pfv0jBiwWlqZThNEozzlIp2LMSxSytGQmhWWlhAoSPC5toUeBIh8UWtxkl8+mY89Rdu2boMCl0NOUpmSuwkLLbCy+WXTvPUDHsR4Wl65maXkZhwMpcnET+vAEw9kUui+NmKkaRIuJXj6s9gA4S4ZBXdd1Id5ZVbbj6w74yov5/b9+kZ6t/Zw7cyktqWtYu3kdxoPWgTGRHaBPoGZ+nz8+VVLHCECNJzt5+NEv8PxLOk6H4f6fKobkW/F16uZdROefvkBqshSazmP2RRdxxVWVnF8lkZLMQDHnUcw+oJa8HVzXKWQBumJBl218+xoPdy79K1yWDKRTOGxmimSZOIbjLGizoZ+7mI/Oa2JRIMG69hB724ewFDcz0iNY/9P1/OrQI6jZCPHQPh6SoywIjVOV0Bh6eRs3lt1E0GZn77qX3yoAcKHHu9jcvYmKP9dT1tzCzIJF7OJZ4GR15mTjSoQT9IOAFV1thFQCcifaEwSYFlJz3pX07d9Ox3CQnHk+VKxC8RZTXl+D5CijY8duVBKoymmGWrJgal5DycXnMvaf3zijZ+Hk8GCMs5q/ljcLnSyFPEwRme7DmGjlJY6SAcL+DLGsiWHGMYfDFCYthPwdpBfnGPM5maxZgLwtSKffTCq+EFvuECtDo5Q9swteacdkEoir4sy8+gokTzU/fPJRtptKmXDPonZ1C6k7riG9Q5BoszBfgi9c38w3D+wivf9ZQ2v9EELoZ6jG5LcDzx5nGOwALtJ1fVQIUQGs13V9phDiF/m/Hzrxe6dq22w16xaXlXQ6i9PpobS4nEl/iMjkFAGGCUPSHn+TRf6lAfXgOA/ohOTut7RvOu+fmLn8Bnof+ASpiV6wOrF7PHh9ZtwWgSJAYy5rvvnfvPi9O3EWLINwiIX33ktFRSmyGbxeI+7o3JnQgqHeyEBFvndpDBubpBvFPHIaxNMKqVQWhIwkmUmFYnRHAmx6ZpTJLeuIb/kDi9VelEyaB3RY4KnALRz8NtKDgg6WhdiuWUN67UbAAqHDCGcDvkU34Sisw2m30vnioxD5LW9diSSM0DkBRKBsEZSthOEtEDg+q9IExcuheC42SyGZkXF0u4Oy5hawO5gYGkPWJERlJbXVNXT9+uKTnAuE2Urrbf/EI1+9GmHzkfa4eHp8gI4DB3j0tttONfSnwVS4s467/FLi/i3oqmHPaFl8N4mREP7RDrIcRsKGlufhay2+GoTgqH8bkoB67yLGcrtxLA8yecgJjQuNSjCUA1nM7OF2BD/CRAEp4iUS+urFxJZcwP7SRjY465mYNY+XfrWJoKOWnFaDPiIhe4qp9B1j89/MZt/YOB+b20Im9RdPSLlb1/UlJx58L5rAM8AngR/k358+7vhfCSEexjAIRk4nAACUrIISNCR9LBkg5g+c8I2TbZZ1ph/GYTyNNpou/jnXXeLhylkm7MCOAOzrAdlVyNbtY6iKAsQhEyPlHyPlN/YxBhyMBwS9h54B6WXQVLq+8SCyWUaIfBi+rYDiC/8va1Yt5fFv/xBLoZ1ln7qdG69vwazD3DJwC2PN8krQL2QSTplam8GGW+bz0KB7WD6jBuWeuUw+WIN593OkOrdy+OAIQ9FRJnGw1L2Mkapq+rMamVc2Qe1Mypaew/gjv0FP7Cayq4+IpBmZ+ekkJ1dFdQznjAJIRumb8E5QTmTcVY0QyegQab0JVDc0FhGRJJTuLvS+18kpE9A1l9LP/i1dUxzkJ8Bms/DNH32BTi3DN5ZfhUaQmNVLpmAWp/buFFNecxnewkZG+l8jFt7Nmyv+GapcYnIc/TgvhtlTjv/gIB6plEnt8BsCAApQFDORWBhQ0HUriYRC2oTh4Qwr4B/D2IC6gQQ5cuQkHzZ7AZI2gWwGIbswKRIJf4SiMh+t5SXsUjXGOifB6YPiBpSJHJNBP3ZV5/KGakyihg+KDuxs40xdhA9hGAGLhRBDwLcwJv+fhBB3Y6Tbfzz/9ecx3INdGE/hp86oF5UY0anvqtZAjtjRP3Go/0V6HzHxC4tAAtJqLVmlEuFpIJXUyUZaWPmV+2mcW4fHIygqBpcLHn1khN6eUW6/3cIT99aCZgxmOnhizLxMcOSbDP65jWTgYZAEgx2/4oXvmBEYNQAN/aSG82/8CsXLWvEVm/nU8pk02gyNwSTA4pXB68Ha0ECkqwgKnXyt+Uo8M5ZgX30pYmUzgTIzezSN3X0K5zdaOM9qRf32R4hpaboUwYsv53jphW24PW68bjebnvoDjD6Uv+UWDC1gKhxVA3UQ1GFOKlDVkfzhYUCCXpn0gGyQNqoZYCF4ivGoJ2N5XQAcwCwWcn2xG1V1sPS1J5jIqXxjQy+vffb/AE0YFRiPH1wzReWLuf2ee/jkLUvw2u+lYzjD3/3159m5+fn8eYqAMJqiItdegTJ8AFQ7c5Yu5uimlwlqB99oC3IIaumLHEbTE0AEHRl/bgyNMMkIRl22/gEMU7TK1BYjqukEkkmcpMhlLQh3CaXnXoyrP8ALjz2DbcLGZNYCtXWQciBsZhx1dlKHE4zoOu9TVPkHhjP1Dtxyio8uOcl3deCL76gXJozxOG3ZUgcwD/BzMs42PZcgm0uQjR7fzAgggT9/mbrGtl9u4nXZ9EapLSE8pFIlqDTzi/saQVpEwcWfp7p+BvMXLuDogYPsXrcJjh0CUxa58Ryq5zTR+af/Bg0ykQSZt6TcR4jHu8lu6+C3v/sJv7TImCjCyBYoZ+Wqu5jr1glu/C2topMZYoLRngw3rb4L2yeXItwWiiVBA3BduZH4ZxGgFzjRdcP3uupOne/cUoUQEpIQJP9pCSHt+2g5ncd3hfj5j19lcv9uSHaCvg9DOJzK/aDl72/a+FvhTVvwugtu5bpLr6K8sJCXmINOEiO6pg9Ka2HiIDgLsAP+lMJV/7mBsV9/hajuxNp0IQWe2Yy9/jRGNUZAauGKG/6WOz9/I7MbnMysMSNLbsrLobJ0DrAZI4InmO9bB8pwAtRRQOOZh/6Aqh5jioq7wLmCdCpNSptE0bvJF/PGCI8SRg7JBEZQVCqHISTNgA8rbtKkWa8nmYeGO5HDPhDBE8gw0j/OwEtPMXR4HEWrpvqGc/C/1kUmOULNsqV0p9J89oebsZizpHNDp7i3f/n4y4gY1DF8B6c1T+QwRvKd2B9V46VPW8OziRMt2BMYQmUXr37nSVAzhNcfIGrS6dj7CaweNyWNDchNjWiaSkl5BS6rHSrvhpEuDD44hTfXGoqyd/s2hGQiFQ7mOUr9TOkJTz62nmcE6EqWq4XGMofGT7JRXvvPb/JFhxPP5RdQvsJBgSSwHsc7KDCMnRbAYhO4j8ts8rndVOAGHRrKSrjtkhlMKncRCaoMDiiM+pPs7xhnQsnS9cqzjB08AtleyB7BmEzF+XtxPNNpMRAglc2QDE4wcLQLXXdxYf0V9NoSDA76qGhsZNTvhfp64kCh08JT/3ADO756BS8HYfhoDvOmfnaEegge2woUsHj5Ldz7pTtYscxCQjJq9skYqRySHmbayzBVnDsCqhksCyEbJD3UxU1fvY8FFdW4XW5u+ngzOQ3+38+38f1/vBJjVbEARQjJadjr3rTA5G1LUjmKFmaCSV4nxQhQlVIJvbABhz/HurSJwOgEuVId3AVcttjKCzthLJJj1WydmeWr6Os/jLd4BqLoChh7iv+pdOD3gjM2DL6vnXAIg1rmbUmBpmLX3+8+588jyYBATLkZACGMmucaTYiSRVTPncPVa67EbDWTymTY8MJLZKIJvvy3N9K760F++s/fO+2ZVmP4Vh8DsggsZiuYTEgmkfduzOWejVv58kJBDbBtAmaUGQbJU0E/7oWeryKUp/LSgKiikNQ0tuka3/uXtRz576cN1T+wCXJ9TGsMxl5eSBdhMgVA01HUI8wQKxlxuZF8Tkqb6hgNjtGwdBm3fv5uShtlQipk7VBu1TFF4Oi6FDufXMv6px/F2tBK25LFzJszj+7uTlKZFDW1tXg9PiKxMTb+4SuMHjVqBUIpNLQxZ8VKKqtncO1HVrBndye7du5n47/fjsNqRiCQZWN80pmcESL+xkQ0Y/h6pglrDdjAOhdcxRB4hVapkCskJxZlkFFU9gKVJU1YSprZNnyM8JwrsLVeyrf/fiV/un+IYr2Gz93iYWMHHOru5erbatm4bohHP9eC9r7Gfr9nnNQw+JchBCx5IfDB8iu+RwhAQkgCSTIZhJN6IZpWgLOqmSs+8RlSw50MtB9mwQXXsq8nzZFNz6FGXsPwLRgT7eZyHz3+KFFV4xgnU9gFJosVWTIoOiV5Pj99YTur2hRu/fpurrliGX931Tvr+dSIazooioqmauxAp1/XOIhOTwqGd8DeR9eSe/B3BkEmL2NMLh2BZLQhihFSOfK8c7CUl2EvK+cjd95GQZ2PsjpYLAEp2NujM9EZYMuWLrLpHAP9ffh8bmRZprauDkXR2PfMk/iPPIGmHgO9CGMrkAZRgJDsCBFEvuhe1K1PomX6+drvDhLvHqCmuoannnyS2tpaVl+xmk9fW3KScdJ5s3HSBu4FUFQKfX9mbtkc7ppzFYGR3fz+6GsMAreefwNtK2/gN8/ez8FuAYs+yh2fu5UNf3idy+Yv59L5Xu79l98RGO7jkz/4BmkpxSM/+Xs0uwKv/+okoyhodJdRVFDAjoH/Me6Av2AhYBb6SWNPJBmKmsCf4v3j+30/IBCSBLqOjsDhuwhv3bV4auZTU9tEpU8l2P4s0YNPUSN3YfYPUld8NT/uepGkenpJaLbYeOJgiolUiLvbSpCEGUlUY/XOZdldf8+XP7OUa5reeY+n1s4AsFmHMR1kTUN0aczIwtj6IBWaTkkOdu/bz5eev59oeAToBHkWFBdhX7SQv/nxt6lqFVRLUC8gq8L+CIx16XQcztLX28OR9g6cLieNTQ2UlJWwe+MmOp77JwidSAhrw9gG5kWjkN7wxUsm2fBSCKM4jUAgpGVo6tYzuFoB7nooaoG+lwCBSdhB11FJUY6b+sKFJEpb6Rk9RiISA99iRMks9MHdiOw4kuhGVQeBG6i78U6Gnvl31OxBcM2H+AsnPavZZObKBauYDAfY2mOwOFuQKcTDOMGzpt/OuPpusqrO8Eu/Y4qu6ocvH+Drq+f/BQuBMwo0MmFYvE9HfPmXDENzQMwCaT7eQhNyeDveXC9rlrgxqavombCyeXyUkHKUUwVYymYr//FcmsFwiB98vPCEUwiEkBBUgGcNrauu4uu3r2Zpg42hSaipg9bG0/dSx/ApOIzeTi+eJzwnmq5zNKzz4mY/vspSsi6dvkAW2WMn48QI0jQbo+YYAjUMiaROPAGJaI5IOEpRsYU5c910dkzy7E/+yNiO/wDt+NDCd8or8U4gYfTureq7l3oUsiQIYlQskICGfF8OMW2wBKz/AKXlMPQo6CGMwK0z63ORp4i/vuVrnLd8OZs3buFXD95Pf7rvjc8dJQUsWr2KyOAYhzZuOW1bF9zz93QNjDC+Ywf+7q34fB5cpQtIB9r5zb5R7phfgkmSznqcwAcMFUMA2MA6AxxWCHXwvpUGOuvQMYyUh0A9RCSfdBYA7tsVAh4HSvniN37F0tuuZK9i4vmd+zj26GPw8kPA1OTw4nPBwMnyVXQdXVfRGYLwL2l/4pd88gmAUs4953N877v3UtFQxL/+vpM59W6uX1GBPGX/ENPhV1O0HOKNf5gOv8zDhGB2oc7sa8uYmqwqNrqAAzrsjED7kRyJaJhFBSVIqo4/mmNkOMjEuJ/x8XGqqyupap5F/exi2u78KFsaColsexXiEQjvA8cMiO0G9f2oDK3xViNeAVBMBA3DIFmPsUe1YaRPg2EsjUz/NvNdTlPs+PSQZNIWDwe6R9jefpT+9MSbPq6va+Cj113PYDTCyISf4NFTxyFsfvppcHohFuUQ8MqT28hFOwGNsbFRDs8/cZs0jQ+JJvB2K4KU/85fSvGO9wjnxTB3PtRXsfDmm1kxq4q5bkFsb5D+jev5ux9cz5FwmEsKC9++rTza5t7Md7/zz+zpHuSfv//3JEzFrLz12yy+bA6fPReafCIvCATHyYU3MPWYTMkCneng7Te+k39XgHYdXshBz4ROjS6YHNZ4fcc4+zduInW4HTJprM3NVC9dipAkhnftJrX9KQivx1id0+A7B2IHQT2b9FsmjEl9ohVaArEE3CtB7TRIJNzNEPcb/AGq1eCCy2aNbFbGMTxCzRhBQgPH3YWzM6daFrZx7ac+yUAkxAu/fYBYz5mVM5txzafpe/536FNEsb5ZUFUFh1/9MGsCp7+pNmcxQrKTio1w6mKbHyIk1sGOdbAD9j3yNfbVfJQV93waU98Qmx94iBlLrubi1XZE209hZAAxsRlEBF3vRNf1k8awW2QLVrOVyPifSQQ3A7Dh359iw7/DT5wfpfy6e1j26eUsP8fB1VZBgxDIYspDIeiI68x0AbpxTPBmAWB8y4AJKBFQJEO0RODUwGqVuMBZQeOcjxMKgUWGkrym3dk5yWR3IWmLQBf5SEddN7SB98VaPCUIjneHukAqhYQwgqfwAiqoJoOlOJLM16KTkSmhihKGKKF0+ZcoLC2j/Zn/QrfJeJY2Et3wL6AfwdBSDWPqqT1bxx+3YQRIZcEUJp7OsH3b6/Qdayc22HfGV9f75xMMk+EjxusU+JBoAoBJBrcHwu8qpPB/EQRCbqP149+jt72dT3/5r2hrE8xvMrF5X4L7f/g4PS98F10fMFyCqgpoXNh2J9/77g94Zt19/PjHP+S0wlK6guLrb2PpORdywdISbLqJB+5/kb/+2hpuWyy9eWuQ50HRdTBJxqEcRrhoO4Z7vh6jLGcFhjJ9vIaRw1hHN0dg3eEUa194mcnBXvSXX0K4XOjD6yAZ5OzaBmQMq8eJhT7qMIwZ3RhRhT7ABublRhk7bQQjqjKEMbmjwPnAMhAZ0KNQXIxoKkOfOAi5IJTZjdrucgEEsxAfwmCwLcDsdlG27CqGDh+EkQEwyQifDXdBBLc5RM2MGRRWV7D/aDvDBw5CJN/fdz9nP8yaAAYvfCRicOfnTh9Q4PWUoOoyqUQCj9eLSQgi0XEUNctfgtB7b9DRld0c+eMVgMx9dz2OrXYVV9x9M7feWs+DD92C03QHh8cFrzw6wKbf/pTezpeR9Ho0RcOIzy7mNJndoL3I5GMv8sJjYNi5LwTa+UXdy9zStpBJVcedzZKUJDyyzLO9OQbDgv+z1AifloFZ+debe/5mZVlgrMnNQLEXys63k5PPxR8+h87Zs6lqqKd//SaSL76EOv4aipJC13RjDBUFo0T4u4HCySv99GOo9b58L/sxEo3MYC6HbCRv/BvMt3EthqYSxtxyOTkthoh2G0WuFQukVXCXQaUZc3ENuUAYdvaBrMPslSgFHob8E0Y+g6yBpxjdoqETx2mzUVJaiq+klAolS660lMDwIKoGdPVA4MT8mqmbKuXfJHRVNcJi36agxYdHE4CTmAZOZyuwYJddyCYzFosVh92OLMuMhwbI5tIoinKa335Y4aWg+lNc9dV7mb+gmBKrhVXlMqEDcXZsDrLwMh8vbNnEj/7lO6Qyh9D1HO8kwq3uM6/y5/tX8c8PKTz0xRtYsGQBN91zJz/4yb9R2FDH87/+ElWyCYvJlA/JNn43ZbHJME3pV4CRLJzMf2bBWHsnMRTiNIZCbsn/5hngmd0JRgZH6e3pQf31f8PwS+R0jZwCqqqgZ5Kn6b2F6drEp5hAABSC6aOg+0F7FUOHuZhpDWGaZg2uAeFFMnnRlKOAi5aP3cB4sI9YvA891I91Zi3prqNgcRiMtQcOgnkS5l9mMNqMHQOtD2y1UDofclGIHoLcIHWtczF57PSMDWItL0czQc7qgu5u6O0xBCECJJPxLgTyrJVoWYWGefPofvVVipcswb/26bzAjH/IXYQy4BWYomZ0BCaTHYvVSTIxiUDPR2qdpBnhRugydpuVpuaZLFl6LpFgkLXrNxCO9OYnwlm9mvy7Ef8kJNBM+TH4QCNKS6ms/jgXLLmI3NAEZruLu756KSvXlPPTXxziZ//+KonwwwjRQyqtkU6l0LU0pxOMn3kwyXc+YeP8u1+k+zdr3vSZkK2UX/N9lqxcwaxzZ1PXKuMS4DVJ1NrNOCRjx2sHzDqQ5yQwywJZGMNrwgjCdjAtDGwYDrl2DLPvwqk28j19ENiwPs3GrVuZ+LebyACZtArpTL7K71SuwBIMnWMcePFt7t0lGKJqD8Z41uTb8WP4TqYSyJ1Q8llmXngZx174EkIv4hfb/x+H2yXW7tmLPzRIU30F+w7sIbr/ADS3GivzZABKimD/Xpg11xAGZgt43DA4AEP7Id0H5hIQOcgN5e08KhTOMAojjB2FVByohBnLwOpFdrlYfemlDPR2U15RxdrHH2fVDdfz6m//G8LDwMEPuRAAbG4f1UsuJJnWGGk/ANkkpfPOwWm10b9rI1pq8i2/sbjrURQZLT0Eepq5S6+mvqEFRYWdr79OdGwvuezZqgYsky8zihBJrE6dwlkO3HVWxjvChDsTkDWCC4Uk0BT9AxQMlSxa8SXu+OInGB6aJKe4+eRHaimoNvPwY2P84T8eYGTod2SzfpLJJFrurSnKD++K8fE2J5d99kFe+687Tn4ayYGv/jMsWLgITdPw1ZfSeudyqmosNFotNFtMuFKwa1uItKyyamUxJpOR6VskjPXVhBE0XABvytCbwLDp+5guiRIHPDpEddiUhRclnccfHkF76GFyu/agpV+CrATZZowtwKF3eN8EhihSMQTBidGHIF9yHzZ3Fa3zZ/Lgt1qpFXD3bxJk0mnalhSTSeX40V1fIyMSRlk4SSCamsDvx1JTQyYWM1iMM1nQXDBaAZFSI5nCJoFdgvQwxDtB7wMGwZQEk25QZOlzwb4cXIVGgYZ0D0hVUNds8OYzimGZ+caHXwgYkDAmWz7v3F2Cb2YbcipM4OieabcIpnyE2ZTa7wWRZqr2e3XzSlZcdCldXcc4sP0pMqkEZ8/FaMbpq+WSmy/gb75yJ2X1pfx/P/wmT/3sWVSh4Wty4ilwMdYeIDWYPTlT1/uGaozipI2svvHL3P7pNs6b5aG0wMGuUYmduzp45I8P4z/8CPFojEg4gpbNAhlu+8fn+N23rmTN5x/kpV+eQgi8BQXguQrnkqWcu2IJN19QT63LzG/ue4Cwkuab3/sGSr2JDgHnShCPpiiTzFQ5ZIOcBUMQTMUwxIHtQCGGdeNJYFdKZ2RSZ99elcYmM3NbjbmwZbvCxL4DOA4cxrXtITLaEXJpkCXIpjOEwn7e/ubbMGwiYYxAoOPjUo4TBs7P8fDoz/iYSyYnpkvMhdM6qYzOJ366lw3f/ppBeeWwwMw5MDBgCIVkEuIxkM1gLoBkPaTKjQI5djNYTeCUIBSCSDuoKaidD3UtcGi3wQfBOIaQ0zBsFpUY2k9+nlhbIPPVD7lh8A1oTBNPADE/se4DFLQsomz2EoJd+8mmkiAX4PBVYzNFiQaHUHK3xdKzAAAgAElEQVQ5JEcdLkucbCbB0LE9HCsvo6KqFpZ9hI59e0kkulFzp9tXTsHE6QVGjkRkjM5DhzjUfgjN1kowEEHRFSpaSmi7cBE2q41dYicD8XEkVSIXVk6qFfi8LuLRBMpZE9b5lFelj5cffo2XH57NnOV3ctNdq5jf5uajy4v5q+v/gajpW7ywdoxf3P9fhNvbGZ3YQjRqGNOszneSQR+C6IMk1j7Ia2strLW0IuRatOQBZrady9qdRyixNJMssLLbCr/72fO4rDXcedMC2qqsdEvGozwVQKxjrGk+DHvCINB5AEKBLFpwgth4LYtmwwwvFF8q09vSxoVfXMhV8evYOZGkb0eOFqfEsb2H+Lf7/xGFXpKZNKqa4uQCIY2RN3Ey5ItVooOWZbIvwGhNCcNeQZsQpNH5/gaNwwf8bPjWZ4EMJD2g2SEVhUTEiDvI5Qx132UHuwzpEdDHIeMExQYZO5gLocANlkUQi8FwCsLtRs2DuB9yXSAUsJbnCZmchlFGNYOmQO7UbMgfQk3g5KictZjFV1zPUPseDq5/HiWTYvH5V7H84qt46o/3MdDbjr2gmcuvupF4PMHerc8Q9Pej6wUsvehqGpqa2L1zJ0PHNpFOno4+WgIKECKEyWxDyZ5eaMhlEjXzKtFlDVVXKCwqwmK1omka/X19hENxZjTUMrxpkGzCqEKk519o8LHrV7Hhha1MpNI4rWZcLg/jp7IMv2c4mHfpXXzlGzczr6gAi9VFWXk5JT4zd33nJSqra/nup2bxgz9186//5yqCk5PT5b/fFazINZfQev1XuOzu5Tiddh6+5wa6tvRw87/8kk/csZiYR6JCgaSAMQl8wqAxKcaIoTyMIRgcGFuFUQynXSmwS4O1o9B7OEX4+ecY3rqDoslJWmyFVFhsVFbXMKRkWNu+n/6xneSUAYyyazmMDYcp3+qZaIhNUHspl9/xSW653kaNgIAOP38owuaN61F2fB9Df/GAyQ7Vs2FyFMwOI83TaofSEnC4oa8f/MP5q3JjbIySgAvKloBcBv5uyHaA7AA1a2wNfPUws9UoKBOPg9MJwSCE/JCNAT9/d5rAKQqP/Bi4BmNJ7gY+pet6OM9DeASDHRRgu67rnzuDO/ieMXLkEF5fGdUL26jwTzB88HV2b30Om82G3VlEYUkN4WAvW9a/wA03f4qGxi/z1EM/ZWK0n727tlFQVEjbksWUlpWxb9uTJGNTvuAToQEBTLIDb3EjgZGTkXxOQxnX6B0fonlFC4sumEsikcDvnwBMyMKB3aJhlV3MWCaRCqqkEsZ4pVMgUrBhy1ZSsjHJGssLOWfJcn71+BMYQ5cPRT5rSHLw1fu469X7gEqstQu4857PcOvFZUTGu8mms8SVWVxzVSMi9Ay//93jpIMHmPTvJhYawXhQ3wkyKIPPc+gJK6VzymlbNhdJ0yGzjwPrX6FhjpfyuhIOKg4cFRYqXII48IIKLgWaLXCOMMx9YNgVptgonUCjBM0V8FBWJ1gLy1yzWF3dTJPqRh6LkAwl6ZqMItfovKJ46JkcQM11AKMgzgPdC+zEMBLGMbQCiekAoOPRBQODvPTjp3jpu1nj+8KNyeVE16e01zHjpcrQH8MweeYjJ2QriLBBdaUOgTwBeEDPf64HQQ/AeBfQiJGAXg7KfsANBS1QWwEOE6gWUFSQslBfBiVuY+txMq8oZ6AJCCEuzN+BB44TAquBtbquK0KIHwLouv71E8lIzxRnQxMwIFHdtoKChtkM791KqK8dXc1x4x1/Q1FpLU/88Wf4R7tpnH0Bf/WVb7Jv3z5efPIBJicmsHpruOiSVdTX13Ng/34O7HiFaKjvTHqff3+bS7CDu9yF2WqiflYDlZUVTPj9DPYPYraaqa0cwWpSSccNo286BXIOaiurGegZ4+gxBdlITCSVAiSPcU4tBkhIZhktlz19H94rvOfx89//GxaHl/PqKtjdqxMK2nn8T0+z89XfUFwcJp1O4R/pZpra7O0ht97Krf/6LRobmvn9Z6/n2MYngTqYcR5F8+ZTUjuPi26aw9UN1VjcMs8kBJEkrKqGagnmmgzmpQ4MDSBp/Bonxg7+D4EgD37160i9Q1w/YyGFIyk8gQxV7lpCaRPbh0OsDwTZn4kQNlvQdAUdr+HWUQcwJn07xuZjKtIwHzQtF4CSp0ZnDo651+FMJEA9itm1CFtzE2gqPc//reEi0nXDTiXZQMsXx30DVsAB1hzYsqC7QCsCrQzMrZAOQWYDhpcCYBaYW0BxG9qF1WFYnTXNSP92FcN554LPCwNDsPn2d6cJnKzwiK7rx2+StgM3vl07ZwVCMiRm7hTGGTTGR4eRCyvxVbeSDIZJhwYZ6O1g9rw25i6+jB0bk3Qf3sSf/vBfnHfh5ay54U7Wr1uPf3SUaCRKKpWipqYWSbqC1zc+Rjr+Vo/DWyHxtityCmK9xsTIxo6RnJnD5fFgtxZgMsmoyXFyQiWXBiVr1L2c9MNI/xAWq2DuIjOyUEhGdQ4dBZTjxLpkRnZ5UNNx1EyG962yaWQbX7j2Y8jlM1l+3pWoWZXaugXEgsMU1V7A7ffcTTI+wbqnf0k208nI8DCRyeMKlZwCzvJSSgp9WDMcty3vh95+Ar0PE6Caoy+v4uXL1zCj2U3YvYDKlkrWJxQ0NcPcSifNJYKUMCIASjFi+rIY03eN103Ll+9m20OPUZMD+0CUeoebGougfzSCN9iHKd2NIIrZcw6KVoISPIix4QhjbAmmDM5xpieuA+xtENsDTIDkoNAZpX5uPe6yy2loaiIaidLYWMEvhzaj6jFyqRTZ5CSS3Ut07KChtmtZjOcnbbwyU7csg3FFI1Agg1wD6jyERUVXTKCYjW3F2DikBgAXVLdATQ0kE2C2wdw6cLuNQKdT4GwYBu/CqEk4hRlCiL0Yysc/6Lq+6WQ/Or7uwBnDZANHGUT6MYZXyr+mDTq5cICBQ3toaJ5LcVkzY4kQr2/6M709PVxy5Y0UVswmFfezbd1jxGJRrrz2FpZfsJytW7biH+0mFQvh8BSiqgpuX80ZCIF3rpLHh+McDXdQWlWO2WWnvLIKr7OPoD9LKgF2G8g2MBdDWTlYLCZKSmzoZOjvyyJGQA+L6UKiegY1F0d2u1BVBRQdYTUj6QI1fbZj7wdRxgbZ8OSr+f+3AjnMthkMdp3HgqWtfOZrP0LTBOtfXcfOzb9nJDmEEgpAZAhDaX8zMjmFwbSCw/LmdXEaQ9D5AD2dDxjskkvvRVu9gkP+JJGwTsfqNXzkuhJqXYJgGMpkSLlg2GbEGsyUzRQ0thJvrCa7tR1lfAhJFCFnZeSJfmypHuwM4yNLIrYHRXdj6BVhTs3kDBCB2C6MqAWB1Rsg2PMiiWE7pfNuQSgR0hmVNVfM5La//SJp4kSjCcLBABaLmfYD+4kcaScdGMY/cAzZ68Usa6SS49NZzhlAiUNoHdAMvrs577KP45B9HDkSYqx0N2rsz5AeBXMVrLkQ57mLSQXCVLvTzKmtx65p4CziiVMUq3pPQkAI8U2MGfiH/KFRoFbX9YAQYjHwlBBijq7rb9mN6Lr+S+CX+XbOYDsgMNQlM0a4yCl8+6kQWiqEVllNSUUlkTEnsWwU//BhtmwqJhZNvzGGh3a9jKegmsbmFgKBSSLD2wEfZQ0LEUKg5aI4vRUkIqdlTH93SOSY6BwEpw2zcGNXFQ68DukotMwB2QIjw+D2wpEjCrUzYjS2yGAzuFZUbfqWmSwyJY1lxIYnUa06ihBIdismTaCm85Tj71ti1VEAcule/nj/JLt3rqSuvpHq2qXMaJ6Nr+G77JVTxI51EN+5jvDAdlKBPmN/m4fQBeGgIJjJoWTPQIvZ+TP27vxZ/j+V7AscxdE3h+IyO0rFNeyttVJUAgUOKNdAkWGWz8mKlZfQ3Rkk6RgmNjpAMh4nG+mhWcjcaKpiQMj8PnOYDpIYU+NM+AymFgkzNW0fRdUULBYrdmuGzr2bUSwyO7fX09pWja3AhKqqaDkNECxZ1MrQ4CAjvb289NDDNCxbhs+ncWzkORRnisRIitSRNNrw1Nh1Q/ZVlsyYR2lVMeH0MP6hLajx/aB3Q2oCtBiOAoHmq+GKNVa+ZxIUAeLyCxBfPfkVvGshIIS4E8NgeEmeYRhd199QZHRd3y2E6Mao1bHrjBq1lEH2VLXbTWDyGYaTqJQfm5PlhBuYHBsjl5FRjuN8G+7vRMP5JnV5z47X0IF0MmWcAwmTbMJkklly8Q0c6+ygY8/Tb2n/rCGRpu/gIbKlGbS8XW100OiKZAK7GzAbSWxDYwoDg4ab+HiYTBK1TSVYZlUzPjbK0JFhUuOxvH5izl+X8eC9f0EJGqqyj/bt+2jfbsFsX0bzvPmUtsyi8MJVlFxyEfZ5K8gdPYD/4Fq6Dj5OMDgIjmosnhqCAZmxyQS59Du1a4yQfe2HrH8NwMuc2/8RZYaTdt2LVriA2uaZdHp1nHVxaioaKK2ezbrRPxMa68QmFzJJhJhuwmn30WLyUK1VMVpUht1VTGxkkGSgnTPjrLDQ2lxFPJ5keHiAeW2t2NpmMzYyTG/nPix2P4VVnje+res6Skah1GtHqi6ldt5MLr3oPErrnPTn7CjuSbrbh+lfP8bIhmGS41HD2Jd8lZ/+OAO6xDTByVQG4jg8/B/4x45gK/XQO1TBo7PbKGlofIOH8WR4V0JACHEF8DVgpa7ryeOOlwBBXddVIUQDhuH2zJKgAWzNpxECkmFVTUzm3TinR3RigFQkgXpcPLmWnsDsbkKXSlCS44BGOtpPT3c3stlMxlyELPtAh2wmg8vtwmw2Y4R+vI9Gt2yGkaHp1NxYXm+qrTfy+202nVQC+odgdIy32NyUrMJI1xAzz2mmwlqMJOtEi+IkI0miY/F8AJUZM1YckhkhBAk1Tu59u6YsudQm2l/fRPu+YtixEU99CzNrFjKvsYVax9VMDnWBtYD65Z+iePlKLOVutIEImvJevB0RDv/+rw3eZ1GCqXkVC5edw4jTyoSvkC/ffDnYKulP6GzRkujZJBmMtbxcUmi1RikraqOo5UocJeUom58lGTjTgiJpbCLLrIUzmddaD8DgQDfJcIyZc1ohGaf/yDRFnq7rZDNZUqkk0XCETGCUWGAYn6+EpqpyvFVl1EiVJCpMDM+Pc2xzF9mISn/vuOGR0qMYLkcveEohLoHWBeF+eOo/SBPkFUp5ZdlqqhZdhNl86tiOM3ERnqzwyN9h6Oav5Jl4p1yBFwLfFkJMZaZ8Ttf1M8/9TZ+Ou10DJZRPJT4DlVGJkVPSvHm/riIEeIoaCGYm0VWjneDYMUqqZmG3z0TTNEKTkyjZENu32LDabRSWzSQ4fnpX4NnAiQq7y2Gm+1iORNIoa6blafVO1FA1RWO4fZRwKoin1kNpWSEFdRWoUQ152EZmPEfPUA/JTAaTsGPBjM1swWQVBNMhUkqa9w3ZSTj2J6LHrOy0zqCraiaFVitjY3spbWhj4fmXUHV+E3Ev+MdVdE1n2g33HqD7UTsfYXfnIyAcbC+cR7hzF55giMPxMV7HsLFLGA7AlaYEzZ4EOcYJ9GxnsjtLZmwPJ7NhnBwquzc8TWpyGY0tLdjtdrwWgbBo2Mkisjm0zHHxJzrkogn6e7rxj48z2tvDns1Wuo5YKarOUD7DgUVys2jBSq4/dylDKyOk02a2bTpK35F2Jsd6cfpmkXbaCMlOOl/bQG64D4pngv9Q/hmZgB0PMrzjBd7K/jCN/zXBQmcMkxd3wQziwcPo2vS0K2+8iJKSUsKRCINH9xnsMbKPpjnnAxpd+5/7wLo4hdpKM0P+3HSktBmsXkidjHNVAkrAVitRVOJENltxaG7mW+dSHC+hb6SPsdgksWiUyWgIdIHbZsdkMiHLEqORCHElhv4BZjk5fE1Uzb6eqkuvxrZwJuGtPRz5w1cQwTQeVwWYzYxOHiKn9HO24iFMyNhQSPAG6yMqcF0Z3NYAj2gtPNPnJjveyZkLgGlYrEWUlJdzyWXXsGDhQiLBEFklh61QQ3Ied291yGWyjI+P0t/Xx8jgMN7CAkLhCWLhAYTQ8Xg9rLzkIi48dzUWiw/Z4mJ4NExT1UwCsTSavYSQrZihiRDrnnianc/+muoll6P7B+jf8SK6NnFi9/635A6cjRO6QY9z/JJqcZRR23IOuZxC/+HtTFWrcBW0YJJUIoETuevff9jMkJ6SU/knVi4GJcx03OzUcyoBhWCpAk+xhCyb0aKCqnApbYWLmdk6CyRBZ0cHWw9u51hoGBWdIrsPp9WORS5gzOwh5j+ArrzToJ/3Ai9y5TysNcvQJwOkB1+kjHNZuug6zrtkDod6u9l1aDNdR3aiKnt4v2waa6rhlnnwvHk+fz7oJN57kHcS6wDgsHvxegsZHeujpraFGQ31FBVWcdGqiymt95AxHd+eQJZNSJJgcHCAeCyBjk5X+xGO7t5NX8cAyXSOmhmFVNZV4fIV4Pb5yOoan77rHpzFhQyOJIiEKpHNhVhlhS2bXqessoqCIieHN2whMNFJOptlYnSUY93dJAMH/rfkDpwF6MYe+fh9fjY5zkhvL0UVlWDNM8pkJoiH+viAM3zewBsCwIphblWNHRFgpMYfT3CpAZG8V0nWcdeYsMpW9KBKYNJPKFiM1WpDaCrzZ7RSXlzK3qFj+FNh/KkwRc4cOc0o4mmE2QT4YFIcIygjm1FGplh64wTZzZEhH9eWrWJVfRuz2i5g7+Fuuge2cbTzCOnhV0EfebuG3xZOjKDcMYwQ+5Qd0moGTZjfFdGxqio4bV6aG+bQ39vH4EAHXk8JQlW57rbLKapxv+n7QggSqSROm4WqijLQdRySoNZZQH9BB939fSRyMY7sOYJq1vGVWEnEoaTKhcWrEw/pyIElOC2lXHnlJdy8ejWaDiWFbuYVV5GIxTHJMh1HjvDSSy+z9pUDJ+33h0wTeCcjIzOdbXj8w+wAUZwXBAqGWWiqzWqKWpoJBiMGK0toKvJNgLUSJBVSY3zgkHmrHPJhaAEnaskSSG6wl0mYLRZMkzLWmBWb3YbP4aHQ5SWhpvGHAqi6RiqdIZAIk9OmTmBmOqE3xv9cWS0fC+ZchcN3ActWX4WruhLZnSQQneDgtiNs3PQMWueznJYh6W1QhCFLjwJryuHTs2Gts5E/9voIdvZDNsQ73YY47R685U24rDLJ2ARDw324HD5mzW/h3EvPo23xYqpratA1QSQSor9/kFw2RV19PbquE/QHKTJ7USIJOrs7GBwb5GhfD/FMHLtL0NM5hKPchprNoMsyjsxM1ESKeQvP5fwVK5kzbwE+r4dENEZhYQElFaUExgPs2rOTL9yz5sOuCbxd5t6JKGS6+myS6TRLHXR3/v8+jBUvLwQKvERUBd0sQXSANxFRml1gk/9nhMDJFJFT5Thp/397Zx4l11Um9t+terVXdXf1qu7W0pIty5JsyZZkLPAKdgz2wBgYwJ4MB05CYJgwB0hmTuIZTk5IyEyGOYFklhxy2IIdg20CA7YJYBsDxjZ4tyVrV0tqtXpfqrv25S03f9xX7kVd3dWbqqr7/c6pU9WvX1V99d5937v3W1U0ajpjgceOicimIA0+bYSQP0hGz5PL5wj5AwgLTGlBMAi5HFjTC3FU8gYxyaGjPwDXs/T0/4rIxlvZetc72XrFZUSv7eCG3VcRCX2Yo0dinH/8Ueh5eJHyukkRwBAFkAV847C9B46EhygMjoNRLBK6ONLZBJn+kzREwgTrvYTrBKnEJC+/+BK9F/roOWPw/g924vF4GR42yOUaaWioR1pN5HM5DMNHxhvB26RRb9aR9nWyxbvJ7nQlMI0TnD5zivTYEFJM4pKvY+l5hkbPcGzoeT7Z/GlCiRAD/f00NTXRPN5C0B8g3FXaE1QjM4Fi5bpyA1401AVuoE5kHjUjsAtC+K5Xudq+MIw9MVWrzrcR/GHVxTZ1mhmDyh1UxU4LJbIwKsZc0wSbYhJ+OWNZ09jYdS0jQ2MUUr1UV/l2H2itBDZ0EK77fQIHb2XTtVfScGUUn88ifraHN59/gZEXX4TDjwM9ZXymm1CohUjIy9BIL+8Fvnw5fF+D/3xyObU8p/D4PWDpbOqMcPZcEhBEoh1s23UzW7duxe/34/P7CAaDhEIhfD4fLpcKKCoU8ui6Tj5fQNcL5HN5kqkkY6Nj9Pf1MT46RC4fQzcHIKODBcLv4ob330prexvpVBqf34fX40G4XLhdLh7+2wdq2TC42EakxRKWxYE8633BG/G2b0Hz+8kcf8C++wFoIDTAD3K+dOJqYuW69AQarkS6/OQTY0hjgOrssNuCu6kVf91GtMZ30vTRD3H7bdvI6QX6jo2THxug+9hphh9/FIZ+SGl7joe2Ddvp6Gjg9dd+y43AX+2DX7jhS7O7oS2TUEgjnZ6Sw+UJE45Ead+6n507dyFcAk3TCIXCeL1eEvE4mUwGf8BPMBgiEPAzPDTM6OgoQgh0XSeZTJLJxEhzjrG+85gTBkgI1Afx+n0gJCIkwOfBG/CiaW4GXjxfy8uBxQ5yybzGvNw4er+BoYVnJdsYdiWi+YJo5rnzVoSVU+LZ+FmES0NaEdRyavFr4tVnFHN8lPT4STj/KqmBB/nxQ3+E6+B1uBtbOXjDfrZddxXxd95A96E/4djrL8KvHgH9tVmfI/D7QzQ0qAYuF7B7F6/CPXG6AgCw9BSJWBqQbOnqoq2tjXA4ghCQSqbQDR3N48HlciOlhWEYCCEIhUOEgiGklASDQSYTLkKajmkaxPQBrJRONp4hG7e9O27AJXAFXHgaG0rKV10zgbrLIBKG/kOr/I1++9nF4nPgV7M/XrVgV6/FQCmD+eK9mpi/eu8lwNUI4TDC00Vd/fV4330bN95xB9GoRfeJOH2Dr+HvHCT/8HFCr/VyePJ7gGDbtqvZfvnlPPHkD9GA+7pUMZ4vnbs0YguXm3DdBtq69nPTzTfT1NxEIp7A5RL4/H6Mt5YDOi6XC69XRXumUmni8UkSiTEK2jCJ1DhD/cPE+gaQyTkCvwQIzY3UzRqYCegSspeig9ByIuTWugKAmXf/OEohtKLq2M2muGyqoHK0YpCIIRkkPv46PPgTnjryxzTt30M8mcUIJXnbe/ezK3+AhmgvPT98jQTncHmiRDsCtHSqQj6jg/PF1S3MnW+HM30QN2C4DKeFtEySkwNkjsZIj5/iquvezcaNG4lGG/F4PGSlhFwew9BpaWmhrr6e0ZFRLMukvr6BDRui6DQTj4/T4G9hJNRMMpEgl80Rj8eRCdufLEHqpWd01aUEsr3Luz4dVoHi4MkTbrkGwzTIxU4yZaQtYXepCLZnI3mS1Av/kcxrfizZCq4Cv/tJmMH9n+ZD+kbqiZAnSLvvMjZevpFNZ7cw2n+eifzSLwg/sLcDXnoF7v2jA/zixfOcPD664PtAYupZhvpOkUym2HzF9XR1bUXzaPi8Prw+Hx6Pl0AggK7rTE5OYug6u6/ewe7dO8gZ45w9e4aTJ48TDNaTz+cJBALkslnO95yj58hJMOc3ZleXEsBY4bEURnkGZs8u/KjyTEFU3vhsA9h6mPIvBg8QJz1+FIkELK7c/z5OvPpz5vbYVPr4WaDHsfQ4MArCjZm/mraWDTTmouikEQiCvgCdmy+nrbMLOA8e+PC1EE/D/zsKG8OQKKjHdK4EbgAeRiW0XwFsD8Krv4YJHb7z/UPkCyYf+sTHGM16eeZ797OQZ0tKi9RkP91HnmVwYJBAMEBbWxubN2+hvaMdKSUTsQlGR4YJhkJs2bKFm6/bTta1g2ConmQyj6G71a+3LCBFc6tFfrubsdER9GQKCheFEQNVpwRWmrnCPjehfOBeoIQF3LcJ8r0Xb183zL6I1QCenmtx+tAT4O4AtxsKsxNFZzcaq6QhVVVtLQwe4rlv/XNeQpAljcQiW9fLgRv/PUOx0/zsoWcY1aFRg3/XDtt74VhStR8p8l7gvhtg5xbwjcBPfwPbCirYqCcDH9msyiSkM+o4PfbdR5BSoI6fh5mKQKBiFoMom4sqjV/IjKLrBunwJnTdwLIsTMvEsiTJZJJsNktdXT1Nzc2EAj6OvXqG0bNjpIfSGBMmG9rbibZGSafSxOpjNPijxBpjJBMJTh95as4jtMaVwFykmHIflpgmab7VaYZbMyx8FzeNAhDHE96EXmhFtQaZ63OqxJNimRj55Axp3jx6mG9++0F27qjjpgNdjL/Sw4le6LDgijTcex08NgDf6FcZh/VA/AXw90PwKlXtrtgZCeDhUzOPXGFGVafZMwEVIq3mEnLGdqnHKExM4m+8hssuu4lAMED36VOkkimC4RCBYJDfPf88x468SWIwSe+FXk4ePcFELEZf0xi7du/G6/Uisz58VgMNPi++cD2nSxyaNaoEijVn5/JzT6Aixmcf/CJeVeXToQwm0eMJlNGwFXWplFIg1TArmMnE0Hke/Jv/QLgxSL1bXZIP9SmfURtw09XQKcHXr/bfjvrbHQOZBORME6qxpLCKUsfLou/s6+TzBbZs349eKJBKp5mYmGCgv5+jR47Q1tzGLQdvpTnazkRrkki4jvqGJnJZk3Qqia4bID0EAnVoWqCkBGtUCSzk2w5RsjwZUbs//RrB6wJNQNacOd7mjL8SqPtdEBUrkWThKZGF8hrUoaI0J0rsV1TK1RRnITENg/hIgjgqyHwYNTIKQDIrSOryraiRnbthx37w9qM8y6scSyWlZKTvCKP9Z2nv2gtakNG+w+i5LJu3H+CaPQdob91OZvIU0Ug7zQ0deL0BxsaGiMWS+H0qf8Yf0AgEIiW/Z6l9B74IfJKp2sd/KaX8qf2/vwA+gboSPyulfGIZx2GF8aMGeAdqsM4xwN0eFTa8VtAtdf2FNdzBAD6vF83jwTRNhBB4PB4syyKd0jEmgvhDUQKhEIV8nnQyCbluFh7tEuVKDAIB8LZDIUOwNPoAABn1SURBVMbFCQ7FcnDFPsXVFYgUwY0XGMfkJPDVJyWHs1MLnafOgscDoQI0hVevauNspMwwcO53FBuyuUPtdGzeSlNTE+d7enjp+Zfo7+sjGo0iLYtsNotb05CBAIGAHyMLwrO88mLfAf4ReGDW9v8upfxv0zcIIXYB9wK7UVfaL4QQV0i55EbyK4trpwoRdvnAakCd3lnTMbNa7lIrhMT2nBmYZg5PexjTNEmPToBh4ItG0E0TayKLP9JMQ2MjoVCIfD6P5vEQH9wIslh4M4u62OeiHqVkE3MYCmdTnBE0MVXbZ5V7JpTBGCbTa0v/YFYM1Dez8M03lInvQx2QvuT3ijxoG9h99XVEo42cO3uWK1sbyEzmKaQtfE0hUpkUuq7h84dBF+hAVjfAU3pcL6nvwDzcDTxsFxw9J4ToBt4G/K7M9y+BEEUXlqLUGsuPGnCANV+ufLUlCK0gGZ340JhqcGlYoGnUNzZS0AskkgWCIWV08gcCuFzqWKWSEcyCD09ArSn1yRhqFlU8znb1Z3dAddHNF5hRmFOrh9AuiJ9g5lLBoOKRhktEBx4qZ8Xos30CK2lkNoY4/Oqz9F7YwvZtu7h1z/vYsGETbrePK3bsZnh4mPHxcXw+H6ZhvOVR0PXS85bl2AT+VAjxMVQl4T+TUk4AnahmJEX67G0XsaS+A3MSQLVyiqIGWanEHx9YJ1FGwRR218Y59suBeyOYSUrf9WqYjN38EsDtJhAMQlYghCDWf4GJWApfMEihkMfKZO3joGFoGprHYy+XNKaOTTOggamroBThwVO/B2nlMRKnwEhD/AKwDbXinq+O5BojrxRGZ7vAF7qSs93jzO1FWST6IJP9g/h27CCeiNN7oZfY+DhtGzYwOjKCEEIFDOVyZLM5kokk2Wzp8PilKoGvAV9CXUVfAr6CakJSNovvOzAXHtTdPYU63GH770kuvtMXB20ZJaP8AUiv0RmBdENBNdt0iyDpuA+BH+FShkCZHSeXNVHKtQ41gxLItIHhFrYCqAPNUKMnIEFPqs66AJbEaAgTCvlJHbVdhJ5+aJwA4YcJrz1bWMs0w7SFRf+gBPcICC/ehj34PBrJkRMsPm9lJs/98n5kTuNY3wk6Nm6kP9lNUsZwCy8bNzXT6osSaIOT3Qkmzk+WtPEuSQlIKd8KIhdCfAP4if1nPyoap8hGe9sqYaICLUzUTylGCC5zsZZOMHNZ4EW5t9aC69Cn2l0LH2YhwOSIgc/vJ1LfRVIfx9DHUL89gsfdgqZ5MQ1jas7k1kALYFzpRwuAnstCJgsTSfD6YCyLHO0hhV1j3w80STUj0NPKtuX1AlGVJ2KUX4y6JnBvBM0D+Vmdq8xxQKDHPfjbNtDQuZd0cgIj2Y2US7dDPf/bx4EYw5MZJnMDbGjvIKdnyBIjGG4irLm5zN9JXZuHF5+e+zOW2negXUpZTJH4AKoLAsBjwPeEEF9FGQa3Ay8t5TvKY3rzERN1ty+lAMoNZbW42M211u5cBZA5yGUxzAhIiek2aWhqAtmIYUjcFui6joFkdt8KXQOZTUCgjmAkQsaSqiXaRNaO0rZg0p555Zh5G9AAv8Db0ojIeckP2h181wpmBrQIc/eqkEirl8TgCJqnnU07dqK5ujh9+BnUgVrKhFgtL+JDrwNgmdcTqW9isH+AyYlJPB4P0cYozS27lq4ESvQduFUIcY0tdQ/wxwBSyqNCiO+jAqkM4DOXzjMw393fi7Je51G+74UO9lq76KejT3vOg+nFNH0Yepr6+hCNdXV4A0Hi8TiDA/1YloXmn51bZ0Asie7X8DdGVRmepJw6bBYwWeIYG0AqTyF1HDX8mlHLulJ9/2qNGOQXmt3kMM1BBvoC5CeHQEQQ7iiYwyz3chm78CJjw11IyyAYjrxVf8DnL918pLrqCawKLmAzaoQKlOZcrIe30gkxK40fNXOywN+J5qvHTCWQHkG0qYlQKMTERIz02BmQfkQwqhLtbSQGGOehOajaXk9MwsASl0oiCkRBjrKUOv+1j8DtCRNpvQqXzBAbWKlaGh7CrVexactWXC43uWyWM4d/UgP1BJbEQoEn7fb/izFhS7EXrCUFAG8pAExVX9EygTHIpZno72ECP1NVmrPIzOw1q/13fwYGM8szwcgJZiy/ytK3iy03V624gQZMw0ViYhyPR7L4grql0EmNvM45Q6e5uQ19nvZua0AJLDQCPfY+OqVDhdcb02ZC+UmMfI6ZpuPZRR3muUOvZMCMQK3cijqq5Gf77J1rzVDrwe3RMPUsCIHHG0YvuEDGELrAHdyIO9iFmRkAoeNyaao7tmXZGZyzD4iPqQK6c5OLHaEvNkbTpi0l96lhJVBuKV0L5eqaQA3+Wr97rDRpqkY5SpQu8qFWLFlK3BRrsfKMwOXrYtNlW+k59iQ+f5jdB97LiWOHyE7k0LwRInURPC6LjNVKfWMjoegGTMNgfGyEbLwHjNlxK+VGIQ0xfqFUo9+3QuhqES/KJbgQAkTxzuEogJogj3IYrLHT5fJKmhpDgMAfrGfn7p1s3rIJd6gNX6QOv8dFfPQMLa0Rfv9D9/Av/9Un2HPNXjSZBSOLcPtxe8IIsZR7d+mDWcMzAZPyDHwukCNUzd3OoXzWUB4XSIxkN68+1w1Cw6COZ556jL4zyoMebtjO1dfeTmJyHJfIo2djtLU20xDxo2k+hNZIqKEVzRciNX4SI7dy8RXrwDvQhJpXXsommw4Oi6OhqZ3d195GLl9gx649dHa08dMfPcjRN54DTDR/C5FoO/l8gWy8FyEgFKknkxzDNMr2dtVy85Hl4GHK0uRQ87go81QGcHk9WFXXMaoUAvDg0vyEop0IK01ivHSJu3DzLg7eeDsnDj3DQO9RrPKyX9eqi3AuPEzZABwFsKYo+1QG0bwhClWnBFwoe5bOTKunBApYRoHk6MIyu8nhkjrh+s243d3lKoE5WaMzAT9KvwnUMqA6yhk4rAblVCoSKJdDNXgVNFRyVo7llyWJ2J+XoMwxPudMoIa9A/ORsx8rkEzkUOW4UBfVQrhXW5AyMVBxFzrgBlcdS5bNJVmEAij9Mct6d9XiRmnIUjUDHNYOxXDw+ZBUrXdIFFu+LeW9EZQCFPbz0lb3a8wmUDwgxZBXRwGsD2rV82OCWaow63RKVM82i8VxYMmKhDWnBIoXvcniKto6gUQO1UypsZlmSjEsXRHWiBIoN6liqYYfRwE4rDZ+lI1qKWOtlF1rZexdNaIEykGg6t4Xq9eusarBDjWMC1Vwq4DKYVmK29JrP698/suChkEhxLeFECNCiCPTtj0ihHjDfvQIId6wt3cJIbLT/ve/VkbMhWYBblSSUNR+7XgEHKoJiao5KJkqirsYiqnyq2PoXlLfASnlPcXXQoivMLMs7xkp5TUrJWB5qLx3Vc22aBR0cKgWJGoGkEbFK4TBfw0IHbJHy3z/6sW6LDgTkFL+BlXN8yKEEAL4CPDQCsu1SFS0lTrIl6ovjMMMXG78u6+n5cAtU9uEG7Q6AuF6OrZdXTnZLqLYF/FSU2ztNg56HxSqo6T9cuMEbgKGpZTTG55uFUK8LoR4Rghx0zI/v0w8KA3rUCk0j4c7/uAeDv6z90xtdLkhGEEC0l1NxldpPyoVQFQAcwzMwYV3vQQs1zD4h8ycBQwCm6WU40KI/cCPhRC7pZQXWUJWrvlIhKnGI+u6n3hFsSyLvr4+krFppbZNHdIj5KXJ6PlSjbErRXHJ6EXdRCoRTFQl4exSygUfQBdwZNY2DbUI3zjP+34NHCjj8+XSH0EJjRLcy/gM57ESD29dg9RCkYrLsbiHkHb87Xp4vDLX9becmcDtwAkp5Vt9pYQQLUBMSmkKIbah+g4s1J1ymRTzBBxjYKUpJEq1gKtmitfH+qUcF+FDqIaiO4QQfUKIT9j/upeLDYI3A4dtl+EPgE9LKVe5xcy8FSlXABdquujgsDZZo6nEDg5LpWhgXpP2pbWYSryYpAmNqYhCB4dS5FmjCqAkNRg2PD3ZZzETCIPSbcsdHNYvNXZb9KDu5g5rj2Ln52rEB64O1mosSg0pATfQCIQqLYjDUljQvlpgpt986fnxS0bU2YU6ZpMHa4C1ukyoISVgosISih7JCgwSh6VT7AS3EP6NaNvejti6B7z+xX1HyDv1Wrih6zYI7pu2gwfVm3LuG8n2d9/Nv37gd9z12QcIbdizuO+uYWrEO1BNhSIdVg8BRMAVACvGsvJA3B6ab/gk0aZOTqeScN0+6DkHA/3w/M9BP6X269wDLVvhjUeh4xoI7+Lyzi1cvnMngWCQgf5+jj79EKmR14FWVB+LfmCcGoxNqfWS4yZOBaC1jgQSYK1AmXDLYqL7NNu2X8073vF2fttUD34/dG6Bujp45nGIH8ITieDedIDc6VMwcAa8gh03v4vP/JsPsH1rkGd+M8DfHHue7pE3gAvAKCpUfTMqeXaSWh+TNTAT8KFWLXmU8Wip1Vkc1h8arsZ30njHuxgbHQNDQnM9tDTCZApeeBJ6XkUtDwYBDw2X3cI177yHdDLJ0WeeITP8HMjxOT67C7Z1wfnnVY5EbVCLHYgEqunoPK2xHRzmxY2KXrdQFX0SgAfcG5SJIHdy1v5h1E0nxfzT/aKnqlgspCaoRSXg4FAj+DZDvnTbsCphLUYMOjhUCflepjxWdZWUZNE4SsDBYcUoTmhra/nqKAGHdcJy4koW+96iMqiN7FNHCTisA1xA/QL7FOsOzr7gNSDI0i7ootegui+z6pbOwWFFkMxv6XehLvQoqknI7PcWmNnHwm4vLryUhauZao5wLaeoyCYhxK+EEMeEEEeFEJ+ztzcKIZ4SQpy2n6P2diGE+HshRLcQ4rAQYt/833DRN5YjlkNFqd4BPTd2EFJJLFSNwTFU6frpmFzc8MMPdIFvC2WN1WCIak4+KudqM4A/k1LuAg4CnxFC7ALuA56WUm4Hnrb/BrgT5Zjdjiok+rXFiVTs3+5QvZTr0RXgKjGNdmngCajni94ToHozCkH1/RuH3CBlhQ6nzlHNIe/l9B0YlFK+Zr9OAseBTuBu4H57t/uB99uv7wYekIoXgAYhRHv5IhlUbRtph8UhXOApkfXpDUC4FTzhWf/QQAtOKYeqnXSMowKKap9F5Q4IIbqAa4EXgTYpZbFw+hDQZr/uRAVZF+mzt5VZZN2JG1ozSBPyJQq55JKQmx5uW7zadShMC9N1hsOqU7YSEEKEgR8Cn5dSJlTzIYWUUi426m/l+g441CRCg0Cdmi1kY2pW7a8DJOTjIKuxoawLtbaXrKUclrIscEIID0oBfFdK+U/25uHiNN9+HrG396NasBbZaG+bgZTy61LKA3OFMTqsA4QH4Y0g/A3g8itl4A+Dv1n9XZXGYTfKKFhMaquNOICFKMc7IIBvAcellF+d9q/HgI/brz8OPDpt+8dsL8FBID5t2eCw7rFrQ1gacnICOT6uzEBSh8k+mDwPZp7qNAboqE5XcdQsIMCcl1A1ij4PCyYQCSFuBJ4F3mTKFPqXKLvA91GJ1eeBj0gpY7bS+EfgPSgz6r+QUr6ywHesjXmVwwJo4AqrhylBFqfUOZRrrpqLdLhRF3xxqLqYSnGXU6UuBKoKXgw0qfYolPX5wn6s6jFwsggdKo0XXHXgdqm7vZVHDXqTqunLVxKNiy/SaTLPoQQ8Us0VMrgxyvp9LiqhBGqospBD7aODNQmWydxGteKdthrvCQsYKqdXwbedGzpKJ9QRJkY5bcgrMxOqRuuLwxrBBYRnxPxIbANAiXf4UFV+qjlQaHEUgMKMBUH1/TZHCTisGhJV0etiBGoSOmv4aSEItYK7gakKP7VPakYocrBicpTCWQ44rBoSyM05w3WBKwIYYCWntvlCUN8I0UZCkTC6nqHQ2wMIqKsj0tZGKpFA9h0BWc1GxPmovt4FNapq3VRzQobDQlgqmlAWfWkaUAfeEOg66AYFoWFkLTBzYCYha5Ef7kVODkIVGLMVGmw+oHoclE15voJLSQ3PBGrMGevAlAldgsww8xwWINWnlAOgJ85BQQczq/ZPX6CQXokLyE4DXpGEHo3N+27kwuCbSL3avRulqVElYFLdPmWHuZnvDp4HPTP150XG+LkUgAaeFtAXE4tmlfishfBycUpxkFCkrua7YdSgEph2N3GoXVxBEB40j0aooYNAwE98dIhsqp9yL9KWd/weoUiUnie+s8gvX8oNJIjKGjRmbPN6fUzPo7l0CJQnJctyYyxq0CbgXPxrAkuCFcQf2sCOXXv54D0fZe9td+KtK7/rdMqAwb6L0lJWiSQXT0906hvqYQElELqoWtFKIFEBuctfhtTQTKBYA64as8scFk8KZJbM5CjZRDs7d+7isn17EdEwp7u7mZycxOh+WaUclyB76CkwL9WycK6LbQyf17OgdSq3ah6BlfntNaQEioEmDmsDdT4t0+DE8SOc7+lh7y03cPtd7+NTOzrZ3xKmL53nB4/9kp//7AmGnv0VVn4IkPj33k7u8C8hn1noS1YZk9HRERYKvTerfPZaQ0oAlLhhVBNIh7WCnh7gwrk3sUJBTg4PUN/USNv2zVy5wU3wY/ewY8+1/PXwGPGjY2DpfPnv/oE/v+su9My5SovOiRMnMM3a9QxATSkBH9CFMoSUUgIRaN0P/hYYGwXNVFaPZD+YCZRhp3prva1fLFKFLJYWorl1J80tLbg0FwUBkaiPT92yi/5/+zm+/rmXyPk3kHFTNU1Ac+epeUdVDSmBPHBq/l2iu6FhL0QbYHM7yEYYT4DWB01BOP8k5J7DUQRVhr+VbOsmMvWbafVvweWK8L+fFTz0yI85fehlPvtfP0+6roPIhz9NfuAs/+OR+9GZVpsw1AjpWIkPdwOXA7Mbj87HJtQYGbX/bkDZBNKApP2v/wujfjfGI83QXQfyBWAM/vB5GOmBp38E/F/mr3C8WgRQ14rFW+mMC1BDSgDm9wy4Yece2HsbjE9AOgiuNgg0QsgHXhMupKj+lNV1SFsbGa+XbC5PNCTI5QS5DJjSRe5sL1++cw9YE5iWCdJiWLjBnGYfKqkAUGXMGnbARJlKYPOdsPteOPk9OPsE0Mnb9r0f3QvH3/w+ufQogz/4MezYAp4PQjyN6ldwGUTbofuEyn8w7oH8/Vz6CMEsUxWPFlYAUBNKwI3SbgtVdm2Hpl3Q2gaJJKRTYLghKyFfgNgg6OeY6grjUC3s3LWLG2+4gR2X76SzJUhzFNzXQsfW9/Lkzi6efnkvsVOvQ8/rEDsJ1iLOoczDxONl797xtusJ3/J79I89SfoswDAuV57Lt19N79k2culxeO1lOHMUNr0LZA8qkOggmCa8+gpYpyHcDvlWVJ3dS83ixniVKwGB0rIaCysBC46+Cd0XYGICkn7IuO3JQx54A8egWJ0cf+EFfBt+gv7udk7KLWgu2HMNNLe62Hfwaj76yauI5eCxn/6Cxx/4GvqvH1cXXNmUb50PhwWNTQFGvMXuQgYvvPIkea+GsekqSPRCLgHxDPhHQf4amIT6zTAxBvKXwMuQcgHbUO3PyqklUDmqXAnAVPmp+bBbQZ99EhXUIVDrumITCwEcoxozuByAifO88cg36D2RJjvaTDZvcOvdd7D/lms5dvwQ/+lPvk32xEuQP8Jqu4k72+G6dwRIP+qbdsvo5ULvCeqv3k2220ehOByHh4CjQBiiYRgYAfkqasyagICGP4DJB6nGxKEi1VJebJSpPlC1SjO1LT/U/m+odflhdX/DFilly+yNVaEEAIQQr9Ry+fFalx9q/zfUuvxQmd9Qg7kDDg4OK4mjBBwc1jnVpAS+XmkBlkmtyw+1/xtqXX6owG+oGpuAg4NDZaimmYCDg0MFqLgSEEK8RwhxUgjRLYS4r9LylIsQokcI8aYQ4g0hxCv2tkYhxFNCiNP2c7TSck5HCPFtIcSIEOLItG1zymz3kvx7+7wcFkLsq5zkb8k6l/xfFEL02+fhDSHEXdP+9xe2/CeFEO+ujNRTCCE2CSF+JYQ4JoQ4KoT4nL29sudASlmxByqS5wwqtMoLHAJ2VVKmRcjeAzTP2va3wH326/uAL1dazlny3QzsA44sJDNwF/AzVKTVQeDFKpX/i8Cfz7HvLns8+YCt9jhzV1j+dmCf/TqCyojbVelzUOmZwNuAbinlWSllAXgYuLvCMi2Hu4H77df3A++voCwXIaX8DRdnlZSS+W7gAal4AWgotqKvFCXkL8XdwMNSyryU8hzQjRpvFUNKOSilfM1+nQSOA51U+BxUWgl0Ahem/d1nb6sFJPCkEOJVIcSn7G1tcqoN+xDQVhnRFkUpmWvp3PypPV3+9rQlWFXLL4ToAq5Fdfeu6DmotBKoZW6UUu4D7gQ+I4S4efo/pZrP1ZTrpRZlBr4GXAZcAwwCX6msOAsjhAgDPwQ+L6WcUXSgEueg0kqgH5XpU2Sjva3qkVL2288jwI9QU83h4nTNfh6pnIRlU0rmmjg3UsphKaUppbSAbzA15a9K+YUQHpQC+K6U8p/szRU9B5VWAi8D24UQW4UQXuBe4LEKy7QgQoiQECJSfA3cARxByf5xe7ePA49WRsJFUUrmx4CP2Rbqg0B82pS1api1Rv4A6jyAkv9eIYRPCLEV2A68dKnlm45QDQq+BRyXUn512r8qew4qaS2dZgE9hbLefqHS8pQp8zaU5fkQKpf0C/b2JuBp4DTwC6Cx0rLOkvsh1JRZR60vP1FKZpRF+n/a5+VN4ECVyv9/bPkO2xdN+7T9v2DLfxK4swrkvxE11T+MKnDxhj3+K3oOnIhBB4d1TqWXAw4ODhXGUQIODuscRwk4OKxzHCXg4LDOcZSAg8M6x1ECDg7rHEcJODiscxwl4OCwzvn/Mmz/LdBngcMAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "train_transform = transforms.Compose([\n",
        "        transforms.Resize([224, 224]), \n",
        "        # data augmentation\n",
        "        transforms.RandomHorizontalFlip(0.3),\n",
        "        # Random vertical flip\n",
        "        transforms.RandomVerticalFlip(0.3),\n",
        "        # transform to tensors\n",
        "        transforms.ToTensor(),\n",
        "        # Normalize the pixel values (in R, G, and B channels)\n",
        "        # https://stackoverflow.com/questions/58151507/why-pytorch-officially-use-mean-0-485-0-456-0-406-and-std-0-229-0-224-0-2\n",
        "        transforms.Normalize(mean = [0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
        "\n",
        "# increase robustness for prediction (without data augmentatioin step)\n",
        "test_transform = transforms.Compose([\n",
        "        transforms.Resize([224, 224]), \n",
        "        # transform to tensors\n",
        "        transforms.ToTensor(),\n",
        "        # Normalize the pixel values (in R, G, and B channels)\n",
        "        # https://stackoverflow.com/questions/58151507/why-pytorch-officially-use-mean-0-485-0-456-0-406-and-std-0-229-0-224-0-2\n",
        "        transforms.Normalize(mean = [0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
        "\n",
        "transformed_train_dataset = Text_Image_Dataset(image_file = x_train['ImageID'],\n",
        "                                        text_file = x_train['Caption_encoded'],\n",
        "                                        target = y_train_mlb,\n",
        "                                        img_transform = train_transform\n",
        "                                        )\n",
        "\n",
        "transformed_test_dataset = Text_Image_Dataset(image_file = x_test['ImageID'],\n",
        "                                        text_file = x_test['Caption_encoded'],\n",
        "                                        img_transform = test_transform\n",
        "                                        )\n",
        "show_sample(transformed_train_dataset,4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1S8I-KVMx2M5"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "def train_val_loader(dataset, val_ratio, batch_size):\n",
        "    total_size = len(dataset)\n",
        "    train_size = int(total_size * (1- val_ratio))\n",
        "    test_size = int(total_size * val_ratio)\n",
        "\n",
        "    train_set, val_set = random_split(dataset, [train_size, test_size])\n",
        "    \n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_set,\n",
        "        batch_size=batch_size,\n",
        "        num_workers=2,\n",
        "        shuffle=True\n",
        "    )\n",
        "    val_loader = torch.utils.data.DataLoader(\n",
        "        val_set,\n",
        "        batch_size=batch_size,\n",
        "        num_workers=2,\n",
        "        shuffle=False\n",
        "    )\n",
        "    return train_loader, val_loader\n",
        "\n",
        "def test_loader(test_dataset, batch_size):\n",
        "    testloader = torch.utils.data.DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        num_workers=2,\n",
        "        shuffle=False\n",
        "    )\n",
        "    return testloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azt4X2kezLap"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "VAL_RATIO = 0.2\n",
        "train_loader, val_loader = train_val_loader(transformed_train_dataset, val_ratio=VAL_RATIO, batch_size=BATCH_SIZE)\n",
        "testloader = test_loader(transformed_test_dataset, BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2tmc8qEyzMou"
      },
      "outputs": [],
      "source": [
        "# Pretrained Resnext50 \n",
        "# https://learnopencv.com/multi-label-image-classification-with-pytorch-image-tagging/\n",
        "from torchvision import models\n",
        "class Resnext50(nn.Module):\n",
        "    def __init__(self, n_class):\n",
        "        super(Resnext50, self).__init__()\n",
        "        resnet = models.resnext50_32x4d(pretrained=True)\n",
        "        self.in_features = resnet.fc.in_features\n",
        "        resnet.fc = nn.Linear(resnet.fc.in_features, n_class)\n",
        "        self.base_model = resnet\n",
        "        self.activation = nn.Sigmoid() \n",
        "        self.out_features = n_class\n",
        "        \n",
        "    def forward(self, x, is_feature_extractor = True):\n",
        "        if is_feature_extractor == False:\n",
        "            # act as normal pretrained Resnet model\n",
        "            return self.activation(self.base_model(x))\n",
        "        # act as a feature extractor\n",
        "        # https://stackoverflow.com/questions/55083642/extract-features-from-last-hidden-layer-pytorch-resnet18\n",
        "        self.out_features = self.in_features \n",
        "        self.base_model.fc = nn.Identity()\n",
        "        features = self.base_model(x)\n",
        "        return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DEjEQH-TzON-"
      },
      "outputs": [],
      "source": [
        "from gensim.models import Word2Vec, FastText\n",
        "class Text_Embedding(nn.Module):\n",
        "    def __init__(self, word_list, training_data):\n",
        "        super(Text_Embedding, self).__init__()\n",
        "        # self.tokenizer = tokenizer\n",
        "        self.emb_table = None\n",
        "        self.training_data = training_data\n",
        "        # self.model = api.load(\"glove-twitter-25\")\n",
        "        self.model = FastText(sentences=self.training_data, size=150, window=5, min_count=1, workers=4, sg=1)\n",
        "        self.keys = list(self.model.wv.vocab.keys())\n",
        "        # self.keys = self.model # for glove model\n",
        "        self.emb_dim = self.model.vector_size\n",
        "\n",
        "    def get_embedding(self):\n",
        "        # training model\n",
        "        model = self.model\n",
        "        assert(model is not None)\n",
        "        emb_table = []\n",
        "        for i, word in enumerate(word_list):\n",
        "            if word in self.keys:\n",
        "                word_emb = model.wv[word] # for word2vec\n",
        "                # word_emb = model[word]\n",
        "                emb_table.append(word_emb)\n",
        "            else:\n",
        "                word_emb = [0]* self.emb_dim\n",
        "                emb_table.append(word_emb)\n",
        "        emb_table = np.array(emb_table)\n",
        "        self.emb_table = emb_table\n",
        "        return emb_table\n",
        "    \n",
        "training_data = x_train[\"Caption\"].to_list()\n",
        "embedding =  Text_Embedding(word_list, training_data)\n",
        "emb_table = embedding.get_embedding()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NhOfYn271yy3"
      },
      "outputs": [],
      "source": [
        "# model for Text\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "class Bi_GRU_Attention(nn.Module):\n",
        "    def __init__(self, emb_table,n_hidden, n_emb):\n",
        "        super(Bi_GRU_Attention, self).__init__()\n",
        "        self.n_hidden = n_hidden\n",
        "        self.n_emb = n_emb\n",
        "        # initialize the bi-direction model\n",
        "        self.emb = nn.Embedding(emb_table.shape[0],emb_table.shape[1])\n",
        "        self.emb.weight.data.copy_(torch.from_numpy(emb_table))\n",
        "        self.gru = nn.GRU(emb_table.shape[1], n_hidden, batch_first = True, bidirectional=True)\n",
        "        self.encoder_fc = nn.Linear(2*n_hidden, n_emb)\n",
        "        self.activation = nn.ReLU()\n",
        "    \n",
        "    # https://colab.research.google.com/github/ngduyanhece/nlp-tutorial/blob/master/4-3.Bi-LSTM%28Attention%29/Bi_LSTM%28Attention%29_Torch.ipynb\n",
        "    # output : [batch_size, n_step, n_hidden * num_directions(=2)], F matrix\n",
        "    def attention_net(self, output, final_state):\n",
        "        hidden = final_state.view(-1, self.n_hidden * 2, 1)   # hidden : [batch_size, n_hidden * num_directions(=2), 1(=n_layer)]\n",
        "        attn_weights = torch.bmm(output, hidden).squeeze(2) # attn_weights : [batch_size, n_step]\n",
        "        soft_attn_weights = F.softmax(attn_weights, 1).to(device)\n",
        "        # [batch_size, n_hidden * num_directions(=2), n_step] * [batch_size, n_step, 1] = [batch_size, n_hidden * num_directions(=2), 1]\n",
        "        context = torch.bmm(output.transpose(1, 2), soft_attn_weights.unsqueeze(2)).squeeze(2).to(device)\n",
        "        return context, soft_attn_weights # context : [batch_size, n_hidden * num_directions(=2)]\n",
        "    \n",
        "#     def forward(self, x):\n",
        "#         # x should be 3 dimension [batch size, seq_len, n_features]\n",
        "#         if torch.is_tensor(x) == False:\n",
        "#             x = torch.Tensor(x).to(torch.int64)\n",
        "#         # Get the embeded tensor\n",
        "#         x = self.emb(x)\n",
        "#         lstm_out, (h_n, c_n) = self.lstm(x)\n",
        "#         hidden_out = torch.cat((h_n[0,:,:],h_n[1,:,:]),1)\n",
        "#         emb = self.activation(self.encoder_fc(hidden_out)).to(device)\n",
        "#         return emb\n",
        "\n",
        "    def forward(self, X):\n",
        "        x = self.emb(X) # input : [batch_size, len_seq, embedding_dim]\n",
        "        # 32, 28, 100\n",
        "#         x = x.permute(1, 0, 2) # input : [len_seq, batch_size, embedding_dim]\n",
        "        hidden_state = Variable(torch.zeros(1*2, x.shape[1], self.n_hidden)).to(device) # [num_layers(=1) * num_directions(=2), batch_size, n_hidden]\n",
        "        cell_state = Variable(torch.zeros(1*2,  x.shape[1], self.n_hidden)).to(device) # [num_layers(=1) * num_directions(=2), batch_size, n_hidden]\n",
        "        \n",
        "        # final_hidden_state, final_cell_state : [num_layers(=1) * num_directions(=2), batch_size, n_hidden]\n",
        "        output, final_hidden_state = self.gru(x)\n",
        "        attn_output, attention = self.attention_net(output, final_hidden_state)\n",
        "        features = self.activation(self.encoder_fc(attn_output)) # model : [batch_size, num_classes]\n",
        "        return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0QdODfD37du"
      },
      "outputs": [],
      "source": [
        "# text_embedding_size = train_embeddings.shape[1]\n",
        "class Concatenate_Embed_Model(nn.Module):\n",
        "    def __init__(self, img_emb_model, text_emb_model, emb_dim, n_classes):\n",
        "        super(Concatenate_Embed_Model, self).__init__()\n",
        "        self.img_emb_model = img_emb_model\n",
        "        self.text_emb_model = text_emb_model\n",
        "        self.n_classes = n_classes\n",
        "        self.emb_dim = emb_dim\n",
        "        self.img_fc = None\n",
        "        self.text_fc = None\n",
        "        self.fc = None\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        \n",
        "    def forward(self, img, text, is_attention = False):\n",
        "        # receive the embeddings \n",
        "        img_emb = self.img_emb_model.forward(img, is_feature_extractor = True).to(device)\n",
        "        text_emb = self.text_emb_model.forward(text).to(device)\n",
        "        # batch norm \n",
        "        img_norm = nn.BatchNorm1d(img_emb.shape[1]).to(device)\n",
        "        text_norm = nn.BatchNorm1d(text_emb.shape[1]).to(device)\n",
        "        img_emb = img_norm(img_emb).to(device)\n",
        "        text_emb = text_norm(text_emb).to(device)\n",
        "        img_emb_dim = img_emb.shape[1]\n",
        "        text_emb_dim = text_emb.shape[1] \n",
        "            \n",
        "        if self.img_fc is None:\n",
        "            # transform embedding to specific embedding dimension\n",
        "            self.img_fc = nn.Sequential(nn.Linear(img_emb.shape[1], 256),\n",
        "                                        nn.ReLU(),\n",
        "                                        nn.Linear(256, self.emb_dim)\n",
        "                                       ).to(device)\n",
        "                            \n",
        "            self.text_fc = nn.Sequential(nn.Linear(text_emb.shape[1], 256),\n",
        "                                        nn.ReLU(),\n",
        "                                        nn.Linear(256, self.emb_dim)\n",
        "                                       ).to(device)\n",
        "            \n",
        "        img_emb = self.img_fc(img_emb).to(device)\n",
        "        text_emb = self.text_fc(text_emb).to(device)\n",
        "    \n",
        "                \n",
        "        if is_attention == False:\n",
        "            if self.fc is None:\n",
        "                self.fc =  nn.Sequential(\n",
        "                                nn.Linear(2* self.emb_dim, 512),\n",
        "                                nn.ReLU(),\n",
        "                                nn.Dropout(0.2),\n",
        "                                nn.Linear(512, self.n_classes)\n",
        "                                ).to(device)\n",
        "            concate_emb = torch.cat((img_emb,text_emb), 1).to(device)\n",
        "            output_before_sigmoid = self.fc(concate_emb).to(device)\n",
        "            output = self.sigmoid(output_before_sigmoid).to(device)\n",
        "            return output_before_sigmoid, output\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AoLQQybv4Pc6"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "import time\n",
        "\n",
        "def train_iter(log_interval, model, optimizer, loss_func, img, text_inputs, target):\n",
        "    '''\n",
        "    Train the model for a single iteration.\n",
        "    An iteration is when a single batch of data is passed forward and \n",
        "    backward through the neural network.\n",
        "    '''\n",
        "    optimizer.zero_grad()  # Zero out the old gradients (so we only use new gradients for a new update iteration).\n",
        "    output_before_sigmoid, output = model(img, text_inputs)  # Forward the data through the model.\n",
        "    if loss_func.__class__.__name__ == 'BCELoss':\n",
        "        loss = loss_func(output, target.float())  # Calculate the loss \n",
        "    else:\n",
        "        loss = loss_func(output_before_sigmoid, target.float())\n",
        "    loss.backward()  # Backward the loss and calculate gradients for parameters.\n",
        "    optimizer.step()  # Update the parameters.\n",
        "    return loss\n",
        "\n",
        "def no_prediction(pred, output):\n",
        "    for i in range(pred.shape[0]):\n",
        "        if np.all(pred[i,] == 0):\n",
        "            argmax_label = np.argmax(output[i,])\n",
        "            pred[i, argmax_label] = 1\n",
        "    return pred\n",
        "\n",
        "def validation(model, device, val_loader, loss_func, threshold):\n",
        "    '''\n",
        "    Testing the model on the entire test set.\n",
        "    '''\n",
        "    model.eval()  # Switch the model to evaluation mode, which prevents the dropout behavior.\n",
        "    val_loss = 0\n",
        "    correct = 0\n",
        "    # n = 1\n",
        "    all_preds = None\n",
        "    all_targets = None\n",
        "    with torch.no_grad():  \n",
        "        for sample in val_loader:  \n",
        "            img = sample['image'].to(device)\n",
        "            text_inputs = sample['text'].to(device)\n",
        "            target = sample['target'].to(device)\n",
        "            output_before_sigmoid, output = model(img, text_inputs)  \n",
        "            pred = np.where(output.cpu().data.numpy() >= threshold, 1, 0)\n",
        "            # pred = no_prediction(pred, output.cpu().data.numpy())\n",
        "            # if n == 2:\n",
        "            #     print(\"output\", output)\n",
        "            #     print(\"pred\", pred)\n",
        "            #     print(\"target\", target)\n",
        "            # n+=1\n",
        "            if all_preds is None:\n",
        "                all_preds = pred\n",
        "                all_targets = target.cpu().data.numpy()\n",
        "            else:\n",
        "                all_preds = np.concatenate((all_preds, pred), axis=0)\n",
        "                all_targets = np.concatenate((all_targets, target.cpu().data.numpy()), axis=0)\n",
        "            val_loss += target.size(0)* loss_func(output, target.float()).item() # Sum up batch loss\n",
        "            correct += accuracy_score(target.cpu().data.numpy(), pred) * target.size(0)  # Count the correct predictions.\n",
        "    f1score = f1_score(all_targets, all_preds, average='samples')\n",
        "    val_loss /= len(val_loader.dataset)  # Average the loss on the entire testing set.\n",
        "    print(classification_report(all_targets, all_preds))\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n, F1 score: {:.4f}'.format(\n",
        "        val_loss, correct, len(val_loader.dataset),\n",
        "        100. * correct / len(val_loader.dataset),\n",
        "        f1score))\n",
        "    \n",
        "    return f1score\n",
        "\n",
        "def train_epoch(log_interval, model, train_loader, optimizer, epoch, loss_func):\n",
        "    '''\n",
        "    Train the model for an epoch.\n",
        "    An epoch is when the entire dataset is passed forward and \n",
        "    backward through the neural network for once.\n",
        "    The number of batches in a dataset is equal to number of iterations for one epoch.\n",
        "    '''\n",
        "    start_time = time.time()\n",
        "    model.train()\n",
        "    train_loss_batch = 0\n",
        "    for batch_idx, sample in enumerate(train_loader):  \n",
        "        img = sample['image'].to(device)\n",
        "        text_inputs = sample['text'].to(device)\n",
        "        target = sample['target'].to(device)\n",
        "        loss = train_iter(log_interval, model, optimizer, loss_func, img, text_inputs, target)\n",
        "        train_loss_batch += loss.item()\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f} \\t Time: {: 2f}'.format(\n",
        "                epoch, batch_idx * len(target), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item(),\n",
        "                time.time() - start_time))\n",
        "    return train_loss_batch/len(train_loader)\n",
        "\n",
        "def test_pred(model, testloader, threshold):\n",
        "    model.eval()\n",
        "    img_paths = []\n",
        "    pred_labels = []\n",
        "    with torch.no_grad():  # Because this is testing and no optimization is required, the gradients are not needed.\n",
        "        for batch, sample in enumerate(testloader):  # Iterate through the entire test set.\n",
        "            img = sample['image'].to(device)\n",
        "            text_inputs = sample['text'].to(device)\n",
        "            path = sample['image_path']\n",
        "            img_paths.extend(path)\n",
        "            output_before_sigmoid, output = model(img, text_inputs)  # Forward the data through the model.\n",
        "            pred = np.where(output.cpu().data.numpy() >= threshold, 1, 0)\n",
        "            # pred = no_prediction(pred, output.cpu().data.numpy() )\n",
        "            for line in pred:\n",
        "                label_list = [str(x+1) for x in range(len(line)) if line[x]== 1]\n",
        "                labels = ' '.join(label_list)\n",
        "                pred_labels.append(labels)            \n",
        "    assert(len(img_paths) == len(pred_labels))\n",
        "    submission_df = pd.DataFrame({'ImageID': img_paths, 'Labels': pred_labels})\n",
        "    return submission_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256,
          "referenced_widgets": [
            "e600667c592d4b8fa9346ed7bd2df604",
            "8df3763ef0ae4c53be78c9be76bcfceb",
            "4d4bd7967ad3447fa4ea98aa6d73adc9",
            "ff68dbfccef84777b9c3fa5da6809c2b",
            "6ebb6da5634a4b1fbc0377591ec1d550",
            "86b84161439848279403d6d1d470fa80",
            "af69a79a0e084d2db28e40858d7ef96e",
            "130c68e2fee049168983783b681b1ee9",
            "458208829c0f4b56b9ba526c09ffe66b",
            "56ca59c8bf62419e840417b4df31d123",
            "8ae34a953aed4c92ae5e8a07c77b2541"
          ]
        },
        "id": "ZlKPgCF34085",
        "outputId": "1f8be123-7afb-4ede-d194-c698339c56c5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth\" to /root/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e600667c592d4b8fa9346ed7bd2df604",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0.00/95.8M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| ID | GPU | MEM |\n",
            "------------------\n",
            "|  0 |  5% |  6% |\n",
            "| ID | GPU | MEM |\n",
            "------------------\n",
            "|  0 |  0% |  6% |\n",
            "| ID | GPU | MEM |\n",
            "------------------\n",
            "|  0 |  0% |  6% |\n",
            "Model initialized.\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available else 'cpu')\n",
        "img_model = Resnext50(num_class).to(device)\n",
        "# img_model = DenseNet121(num_class).to(device)\n",
        "gpu_usage() \n",
        "# text_model = Bi_LSTM_Attention(emb_table, 256, n_emb = 2048).to(device)\n",
        "n_hidden = 128\n",
        "text_model = Bi_GRU_Attention(emb_table, n_hidden, n_emb = 256).to(device)\n",
        "gpu_usage() \n",
        "n_emb = 256\n",
        "model = Concatenate_Embed_Model(img_model, text_model, n_emb, num_class).to(device)\n",
        "gpu_usage() \n",
        "print('Model initialized.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XAbQBlt454y",
        "outputId": "b9e4b02b-bdf1-41a5-ea3c-7e7bab01678d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [0/24000 (0%)]\tLoss: 0.586949 \t Time:  2.566388\n",
            "Train Epoch: 0 [3200/24000 (13%)]\tLoss: 0.121897 \t Time:  75.332726\n",
            "Train Epoch: 0 [6400/24000 (27%)]\tLoss: 0.119246 \t Time:  147.832104\n",
            "Train Epoch: 0 [9600/24000 (40%)]\tLoss: 0.071525 \t Time:  220.113331\n",
            "Train Epoch: 0 [12800/24000 (53%)]\tLoss: 0.096505 \t Time:  292.507978\n",
            "Train Epoch: 0 [16000/24000 (67%)]\tLoss: 0.087353 \t Time:  364.853069\n",
            "Train Epoch: 0 [19200/24000 (80%)]\tLoss: 0.068662 \t Time:  437.155896\n",
            "Train Epoch: 0 [22400/24000 (93%)]\tLoss: 0.084889 \t Time:  509.618891\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.93      0.93      4539\n",
            "           1       1.00      0.00      0.01       231\n",
            "           2       0.73      0.24      0.36       846\n",
            "           3       0.86      0.64      0.73       252\n",
            "           4       0.99      0.92      0.95       236\n",
            "           5       0.97      0.67      0.80       269\n",
            "           6       0.97      0.85      0.91       244\n",
            "           7       0.91      0.30      0.45       433\n",
            "           8       0.97      0.57      0.72       202\n",
            "           9       0.76      0.24      0.36       300\n",
            "          10       1.00      0.62      0.76       115\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.87      0.49      0.63       124\n",
            "          13       0.00      0.00      0.00        48\n",
            "          14       0.96      0.26      0.40       386\n",
            "          15       0.99      0.51      0.67       214\n",
            "          16       0.99      0.85      0.91       287\n",
            "          17       0.94      0.68      0.79       304\n",
            "          18       0.99      0.87      0.93       201\n",
            "\n",
            "   micro avg       0.92      0.70      0.80      9231\n",
            "   macro avg       0.83      0.51      0.60      9231\n",
            "weighted avg       0.91      0.70      0.75      9231\n",
            " samples avg       0.92      0.81      0.83      9231\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0895, Accuracy: 3904.0/6000 (65.07%)\n",
            ", F1 score: 0.8346\n",
            "Train Epoch: 1 [0/24000 (0%)]\tLoss: 0.094756 \t Time:  1.962059\n",
            "Train Epoch: 1 [3200/24000 (13%)]\tLoss: 0.092149 \t Time:  74.356905\n",
            "Train Epoch: 1 [6400/24000 (27%)]\tLoss: 0.081421 \t Time:  146.687521\n",
            "Train Epoch: 1 [9600/24000 (40%)]\tLoss: 0.107190 \t Time:  219.087573\n",
            "Train Epoch: 1 [12800/24000 (53%)]\tLoss: 0.071378 \t Time:  291.514907\n",
            "Train Epoch: 1 [16000/24000 (67%)]\tLoss: 0.084315 \t Time:  363.976327\n",
            "Train Epoch: 1 [19200/24000 (80%)]\tLoss: 0.076304 \t Time:  436.300461\n",
            "Train Epoch: 1 [22400/24000 (93%)]\tLoss: 0.105455 \t Time:  508.730065\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.94      0.93      4539\n",
            "           1       0.71      0.35      0.47       231\n",
            "           2       0.63      0.45      0.53       846\n",
            "           3       0.96      0.62      0.75       252\n",
            "           4       0.98      0.94      0.96       236\n",
            "           5       0.95      0.69      0.80       269\n",
            "           6       0.96      0.88      0.91       244\n",
            "           7       0.83      0.37      0.52       433\n",
            "           8       0.96      0.60      0.74       202\n",
            "           9       0.70      0.27      0.39       300\n",
            "          10       1.00      0.62      0.76       115\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.90      0.45      0.60       124\n",
            "          13       0.96      0.52      0.68        48\n",
            "          14       0.92      0.28      0.43       386\n",
            "          15       0.92      0.56      0.70       214\n",
            "          16       0.98      0.88      0.93       287\n",
            "          17       0.96      0.71      0.81       304\n",
            "          18       0.99      0.89      0.94       201\n",
            "\n",
            "   micro avg       0.90      0.75      0.82      9231\n",
            "   macro avg       0.85      0.58      0.68      9231\n",
            "weighted avg       0.89      0.75      0.79      9231\n",
            " samples avg       0.91      0.83      0.85      9231\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0837, Accuracy: 3929.0/6000 (65.48%)\n",
            ", F1 score: 0.8479\n",
            "Train Epoch: 2 [0/24000 (0%)]\tLoss: 0.099066 \t Time:  1.972060\n",
            "Train Epoch: 2 [3200/24000 (13%)]\tLoss: 0.089778 \t Time:  74.374399\n",
            "Train Epoch: 2 [6400/24000 (27%)]\tLoss: 0.067624 \t Time:  146.715489\n",
            "Train Epoch: 2 [9600/24000 (40%)]\tLoss: 0.084658 \t Time:  219.052256\n",
            "Train Epoch: 2 [12800/24000 (53%)]\tLoss: 0.087642 \t Time:  291.355180\n",
            "Train Epoch: 2 [16000/24000 (67%)]\tLoss: 0.073355 \t Time:  363.710142\n",
            "Train Epoch: 2 [19200/24000 (80%)]\tLoss: 0.079625 \t Time:  435.924006\n",
            "Train Epoch: 2 [22400/24000 (93%)]\tLoss: 0.062442 \t Time:  508.222376\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.92      0.93      4539\n",
            "           1       0.74      0.39      0.51       231\n",
            "           2       0.68      0.37      0.48       846\n",
            "           3       0.99      0.63      0.77       252\n",
            "           4       0.99      0.95      0.97       236\n",
            "           5       0.98      0.67      0.80       269\n",
            "           6       0.96      0.87      0.91       244\n",
            "           7       0.66      0.50      0.57       433\n",
            "           8       0.86      0.65      0.74       202\n",
            "           9       0.83      0.26      0.40       300\n",
            "          10       0.99      0.61      0.75       115\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.77      0.62      0.69       124\n",
            "          13       1.00      0.48      0.65        48\n",
            "          14       0.95      0.27      0.42       386\n",
            "          15       0.93      0.59      0.73       214\n",
            "          16       0.98      0.88      0.93       287\n",
            "          17       0.98      0.74      0.84       304\n",
            "          18       0.99      0.89      0.94       201\n",
            "\n",
            "   micro avg       0.92      0.74      0.82      9231\n",
            "   macro avg       0.85      0.59      0.69      9231\n",
            "weighted avg       0.90      0.74      0.80      9231\n",
            " samples avg       0.92      0.83      0.85      9231\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0821, Accuracy: 4018.0/6000 (66.97%)\n",
            ", F1 score: 0.8543\n",
            "Train Epoch: 3 [0/24000 (0%)]\tLoss: 0.096862 \t Time:  1.971736\n",
            "Train Epoch: 3 [3200/24000 (13%)]\tLoss: 0.059825 \t Time:  74.312927\n",
            "Train Epoch: 3 [6400/24000 (27%)]\tLoss: 0.079469 \t Time:  146.609608\n",
            "Train Epoch: 3 [9600/24000 (40%)]\tLoss: 0.080847 \t Time:  218.899976\n",
            "Train Epoch: 3 [12800/24000 (53%)]\tLoss: 0.075922 \t Time:  291.218971\n",
            "Train Epoch: 3 [16000/24000 (67%)]\tLoss: 0.088774 \t Time:  363.579988\n",
            "Train Epoch: 3 [19200/24000 (80%)]\tLoss: 0.080419 \t Time:  435.964624\n",
            "Train Epoch: 3 [22400/24000 (93%)]\tLoss: 0.098930 \t Time:  508.309019\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.94      0.94      4539\n",
            "           1       0.91      0.31      0.46       231\n",
            "           2       0.68      0.49      0.57       846\n",
            "           3       0.88      0.67      0.76       252\n",
            "           4       0.99      0.95      0.97       236\n",
            "           5       0.98      0.67      0.79       269\n",
            "           6       0.97      0.86      0.91       244\n",
            "           7       0.71      0.46      0.56       433\n",
            "           8       0.95      0.61      0.74       202\n",
            "           9       0.69      0.37      0.48       300\n",
            "          10       1.00      0.61      0.76       115\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.82      0.56      0.66       124\n",
            "          13       0.96      0.52      0.68        48\n",
            "          14       0.96      0.28      0.43       386\n",
            "          15       0.89      0.65      0.75       214\n",
            "          16       0.96      0.90      0.93       287\n",
            "          17       0.98      0.76      0.86       304\n",
            "          18       0.99      0.90      0.94       201\n",
            "\n",
            "   micro avg       0.91      0.76      0.83      9231\n",
            "   macro avg       0.86      0.61      0.69      9231\n",
            "weighted avg       0.90      0.76      0.81      9231\n",
            " samples avg       0.92      0.84      0.86      9231\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0789, Accuracy: 4060.0/6000 (67.67%)\n",
            ", F1 score: 0.8622\n",
            "Train Epoch: 4 [0/24000 (0%)]\tLoss: 0.080220 \t Time:  1.963963\n",
            "Train Epoch: 4 [3200/24000 (13%)]\tLoss: 0.074502 \t Time:  74.318248\n",
            "Train Epoch: 4 [6400/24000 (27%)]\tLoss: 0.067322 \t Time:  146.591494\n",
            "Train Epoch: 4 [9600/24000 (40%)]\tLoss: 0.093114 \t Time:  218.931834\n",
            "Train Epoch: 4 [12800/24000 (53%)]\tLoss: 0.061549 \t Time:  291.273268\n",
            "Train Epoch: 4 [16000/24000 (67%)]\tLoss: 0.062348 \t Time:  363.544598\n",
            "Train Epoch: 4 [19200/24000 (80%)]\tLoss: 0.080027 \t Time:  435.781595\n",
            "Train Epoch: 4 [22400/24000 (93%)]\tLoss: 0.054845 \t Time:  508.099325\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.93      0.94      4539\n",
            "           1       0.92      0.30      0.46       231\n",
            "           2       0.61      0.60      0.61       846\n",
            "           3       0.99      0.63      0.77       252\n",
            "           4       0.99      0.94      0.97       236\n",
            "           5       0.95      0.66      0.78       269\n",
            "           6       0.96      0.87      0.91       244\n",
            "           7       0.79      0.42      0.55       433\n",
            "           8       0.82      0.67      0.74       202\n",
            "           9       0.67      0.41      0.51       300\n",
            "          10       0.99      0.63      0.77       115\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.89      0.56      0.69       124\n",
            "          13       0.96      0.52      0.68        48\n",
            "          14       0.93      0.27      0.42       386\n",
            "          15       0.84      0.69      0.76       214\n",
            "          16       0.98      0.90      0.94       287\n",
            "          17       1.00      0.75      0.86       304\n",
            "          18       0.98      0.89      0.93       201\n",
            "\n",
            "   micro avg       0.90      0.77      0.83      9231\n",
            "   macro avg       0.85      0.61      0.70      9231\n",
            "weighted avg       0.90      0.77      0.81      9231\n",
            " samples avg       0.91      0.84      0.86      9231\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0795, Accuracy: 3993.0/6000 (66.55%)\n",
            ", F1 score: 0.8569\n",
            "Counter 1 of 3\n",
            "Train Epoch: 5 [0/24000 (0%)]\tLoss: 0.096366 \t Time:  1.950813\n",
            "Train Epoch: 5 [3200/24000 (13%)]\tLoss: 0.050236 \t Time:  74.318931\n",
            "Train Epoch: 5 [6400/24000 (27%)]\tLoss: 0.091446 \t Time:  146.550709\n",
            "Train Epoch: 5 [9600/24000 (40%)]\tLoss: 0.060607 \t Time:  218.804365\n",
            "Train Epoch: 5 [12800/24000 (53%)]\tLoss: 0.053561 \t Time:  291.121954\n",
            "Train Epoch: 5 [16000/24000 (67%)]\tLoss: 0.060390 \t Time:  363.509946\n",
            "Train Epoch: 5 [19200/24000 (80%)]\tLoss: 0.060805 \t Time:  435.812007\n",
            "Train Epoch: 5 [22400/24000 (93%)]\tLoss: 0.065086 \t Time:  508.144465\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.92      0.93      4539\n",
            "           1       0.91      0.37      0.53       231\n",
            "           2       0.72      0.50      0.59       846\n",
            "           3       0.98      0.65      0.78       252\n",
            "           4       0.99      0.94      0.97       236\n",
            "           5       0.97      0.67      0.79       269\n",
            "           6       0.93      0.87      0.90       244\n",
            "           7       0.82      0.39      0.53       433\n",
            "           8       0.78      0.71      0.74       202\n",
            "           9       0.64      0.46      0.54       300\n",
            "          10       0.97      0.62      0.76       115\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.85      0.56      0.68       124\n",
            "          13       0.96      0.54      0.69        48\n",
            "          14       0.86      0.28      0.43       386\n",
            "          15       0.84      0.69      0.76       214\n",
            "          16       0.98      0.89      0.93       287\n",
            "          17       1.00      0.74      0.85       304\n",
            "          18       0.97      0.91      0.94       201\n",
            "\n",
            "   micro avg       0.92      0.76      0.83      9231\n",
            "   macro avg       0.85      0.62      0.70      9231\n",
            "weighted avg       0.91      0.76      0.81      9231\n",
            " samples avg       0.93      0.84      0.86      9231\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0787, Accuracy: 4054.0/6000 (67.57%)\n",
            ", F1 score: 0.8615\n",
            "Counter 2 of 3\n",
            "Train Epoch: 6 [0/24000 (0%)]\tLoss: 0.044861 \t Time:  1.928530\n",
            "Train Epoch: 6 [3200/24000 (13%)]\tLoss: 0.059250 \t Time:  74.274019\n",
            "Train Epoch: 6 [6400/24000 (27%)]\tLoss: 0.062091 \t Time:  146.571215\n",
            "Train Epoch: 6 [9600/24000 (40%)]\tLoss: 0.075278 \t Time:  218.821637\n",
            "Train Epoch: 6 [12800/24000 (53%)]\tLoss: 0.044599 \t Time:  291.085253\n",
            "Train Epoch: 6 [16000/24000 (67%)]\tLoss: 0.047611 \t Time:  363.382518\n",
            "Train Epoch: 6 [19200/24000 (80%)]\tLoss: 0.084838 \t Time:  435.670233\n",
            "Train Epoch: 6 [22400/24000 (93%)]\tLoss: 0.075115 \t Time:  507.866826\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.93      0.94      4539\n",
            "           1       0.93      0.36      0.52       231\n",
            "           2       0.70      0.49      0.57       846\n",
            "           3       0.88      0.68      0.77       252\n",
            "           4       0.99      0.94      0.97       236\n",
            "           5       0.97      0.67      0.79       269\n",
            "           6       0.95      0.88      0.91       244\n",
            "           7       0.75      0.42      0.54       433\n",
            "           8       0.90      0.65      0.76       202\n",
            "           9       0.63      0.49      0.55       300\n",
            "          10       0.97      0.62      0.76       115\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.97      0.54      0.69       124\n",
            "          13       0.93      0.54      0.68        48\n",
            "          14       0.89      0.28      0.43       386\n",
            "          15       0.90      0.68      0.77       214\n",
            "          16       0.96      0.90      0.93       287\n",
            "          17       0.97      0.78      0.86       304\n",
            "          18       0.95      0.91      0.93       201\n",
            "\n",
            "   micro avg       0.91      0.77      0.83      9231\n",
            "   macro avg       0.85      0.62      0.70      9231\n",
            "weighted avg       0.90      0.77      0.82      9231\n",
            " samples avg       0.92      0.85      0.86      9231\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0803, Accuracy: 4081.0/6000 (68.02%)\n",
            ", F1 score: 0.8645\n",
            "Train Epoch: 7 [0/24000 (0%)]\tLoss: 0.059475 \t Time:  1.976232\n",
            "Train Epoch: 7 [3200/24000 (13%)]\tLoss: 0.045937 \t Time:  74.204168\n",
            "Train Epoch: 7 [6400/24000 (27%)]\tLoss: 0.054324 \t Time:  146.376933\n",
            "Train Epoch: 7 [9600/24000 (40%)]\tLoss: 0.052529 \t Time:  218.677567\n",
            "Train Epoch: 7 [12800/24000 (53%)]\tLoss: 0.081971 \t Time:  290.882802\n",
            "Train Epoch: 7 [16000/24000 (67%)]\tLoss: 0.077959 \t Time:  363.123417\n",
            "Train Epoch: 7 [19200/24000 (80%)]\tLoss: 0.060145 \t Time:  435.420210\n",
            "Train Epoch: 7 [22400/24000 (93%)]\tLoss: 0.067377 \t Time:  507.690923\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.92      0.94      4539\n",
            "           1       0.83      0.38      0.52       231\n",
            "           2       0.67      0.51      0.58       846\n",
            "           3       0.91      0.67      0.78       252\n",
            "           4       0.99      0.94      0.97       236\n",
            "           5       0.97      0.67      0.80       269\n",
            "           6       0.94      0.89      0.92       244\n",
            "           7       0.71      0.44      0.55       433\n",
            "           8       0.92      0.67      0.77       202\n",
            "           9       0.70      0.45      0.55       300\n",
            "          10       1.00      0.61      0.76       115\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.95      0.56      0.70       124\n",
            "          13       0.96      0.52      0.68        48\n",
            "          14       0.78      0.28      0.41       386\n",
            "          15       0.84      0.70      0.76       214\n",
            "          16       0.97      0.90      0.93       287\n",
            "          17       0.98      0.75      0.85       304\n",
            "          18       0.93      0.91      0.92       201\n",
            "\n",
            "   micro avg       0.91      0.76      0.83      9231\n",
            "   macro avg       0.84      0.62      0.70      9231\n",
            "weighted avg       0.90      0.76      0.81      9231\n",
            " samples avg       0.92      0.84      0.86      9231\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0810, Accuracy: 4025.0/6000 (67.08%)\n",
            ", F1 score: 0.8587\n",
            "Counter 1 of 3\n",
            "Train Epoch: 8 [0/24000 (0%)]\tLoss: 0.037001 \t Time:  1.981627\n",
            "Train Epoch: 8 [3200/24000 (13%)]\tLoss: 0.062525 \t Time:  74.209957\n",
            "Train Epoch: 8 [6400/24000 (27%)]\tLoss: 0.054165 \t Time:  146.439072\n",
            "Train Epoch: 8 [9600/24000 (40%)]\tLoss: 0.061340 \t Time:  218.597889\n",
            "Train Epoch: 8 [12800/24000 (53%)]\tLoss: 0.054944 \t Time:  290.836516\n",
            "Train Epoch: 8 [16000/24000 (67%)]\tLoss: 0.065348 \t Time:  363.026899\n",
            "Train Epoch: 8 [19200/24000 (80%)]\tLoss: 0.051586 \t Time:  435.259064\n",
            "Train Epoch: 8 [22400/24000 (93%)]\tLoss: 0.055276 \t Time:  507.508007\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.95      0.93      4539\n",
            "           1       0.91      0.35      0.51       231\n",
            "           2       0.67      0.53      0.59       846\n",
            "           3       0.94      0.68      0.79       252\n",
            "           4       0.99      0.94      0.96       236\n",
            "           5       0.97      0.66      0.79       269\n",
            "           6       0.94      0.88      0.91       244\n",
            "           7       0.74      0.45      0.56       433\n",
            "           8       0.97      0.62      0.76       202\n",
            "           9       0.66      0.49      0.56       300\n",
            "          10       0.97      0.63      0.76       115\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.93      0.55      0.69       124\n",
            "          13       0.96      0.54      0.69        48\n",
            "          14       0.78      0.30      0.43       386\n",
            "          15       0.89      0.67      0.77       214\n",
            "          16       0.97      0.89      0.93       287\n",
            "          17       0.98      0.76      0.86       304\n",
            "          18       0.92      0.91      0.92       201\n",
            "\n",
            "   micro avg       0.89      0.78      0.83      9231\n",
            "   macro avg       0.85      0.62      0.71      9231\n",
            "weighted avg       0.88      0.78      0.82      9231\n",
            " samples avg       0.92      0.85      0.86      9231\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0851, Accuracy: 4019.0/6000 (66.98%)\n",
            ", F1 score: 0.8638\n",
            "Counter 2 of 3\n",
            "Train Epoch: 9 [0/24000 (0%)]\tLoss: 0.030102 \t Time:  1.979512\n",
            "Train Epoch: 9 [3200/24000 (13%)]\tLoss: 0.057334 \t Time:  74.277265\n",
            "Train Epoch: 9 [6400/24000 (27%)]\tLoss: 0.059964 \t Time:  146.474994\n",
            "Train Epoch: 9 [9600/24000 (40%)]\tLoss: 0.045925 \t Time:  218.713969\n",
            "Train Epoch: 9 [12800/24000 (53%)]\tLoss: 0.049542 \t Time:  290.817039\n",
            "Train Epoch: 9 [16000/24000 (67%)]\tLoss: 0.059097 \t Time:  363.147164\n",
            "Train Epoch: 9 [19200/24000 (80%)]\tLoss: 0.050604 \t Time:  435.394782\n",
            "Train Epoch: 9 [22400/24000 (93%)]\tLoss: 0.053166 \t Time:  507.666969\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.91      0.93      4539\n",
            "           1       0.73      0.41      0.52       231\n",
            "           2       0.72      0.46      0.56       846\n",
            "           3       0.90      0.67      0.77       252\n",
            "           4       0.99      0.94      0.97       236\n",
            "           5       0.96      0.65      0.77       269\n",
            "           6       0.94      0.89      0.91       244\n",
            "           7       0.74      0.40      0.52       433\n",
            "           8       0.85      0.69      0.76       202\n",
            "           9       0.74      0.39      0.51       300\n",
            "          10       0.97      0.62      0.76       115\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.95      0.56      0.70       124\n",
            "          13       0.90      0.54      0.68        48\n",
            "          14       0.81      0.28      0.42       386\n",
            "          15       0.86      0.67      0.75       214\n",
            "          16       0.96      0.89      0.92       287\n",
            "          17       0.92      0.77      0.84       304\n",
            "          18       0.91      0.90      0.91       201\n",
            "\n",
            "   micro avg       0.92      0.75      0.82      9231\n",
            "   macro avg       0.83      0.61      0.70      9231\n",
            "weighted avg       0.90      0.75      0.81      9231\n",
            " samples avg       0.92      0.84      0.86      9231\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0863, Accuracy: 4025.0/6000 (67.08%)\n",
            ", F1 score: 0.8564\n",
            "Counter 3 of 3\n",
            "Early stopping with best loss:  0.05630669927597046 and val_acc for this epoch:  0.8563903920153921\n"
          ]
        }
      ],
      "source": [
        "# from torch.optim.lr_scheduler import StepLR\n",
        "n_epochs = 15\n",
        "log_interval = 50\n",
        "lr = 3e-4\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr= lr)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "train_loss = []\n",
        "best_f1_score = -float(\"inf\") # record the best loss to get the best model\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    loss = train_epoch(log_interval, model, train_loader, optimizer, epoch, criterion)\n",
        "    train_loss.append(loss)\n",
        "    f1score = validation(model, device, val_loader, criterion, 0.5)\n",
        "\n",
        "    # https://www.kaggle.com/general/178486\n",
        "    if f1score > best_f1_score:\n",
        "        best_f1_score = f1score\n",
        "        es = 0\n",
        "        torch.save(model, \"model.pt\")\n",
        "    else:\n",
        "        es += 1\n",
        "        print(\"Counter {} of 3\".format(es))\n",
        "\n",
        "        if es >= 3:\n",
        "            print(\"Early stopping with best loss: \", loss, \"and val_acc for this epoch: \", f1score)\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1UaZ49JbF_-"
      },
      "outputs": [],
      "source": [
        "best_model = torch.load(\"default_model.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GykKiWntH-Nt"
      },
      "outputs": [],
      "source": [
        "testloader = test_loader(transformed_test_dataset, 20)\n",
        "submission_df = test_pred(best_model, testloader, 0.5)\n",
        "submission_df.to_csv('submission_gru_attention_Resnext50_v2.csv', index=False)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IEDwLVwaE5A",
        "outputId": "a46178eb-3909-4e0e-d63e-9ce014bf5362"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8645395622895623"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_f1_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### No need to run the below code for training and generating test file, it is for hyperparameter testing and ablation studies\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAGAcP2FFRRC"
      },
      "source": [
        "# Experiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkNlldlBtJxd"
      },
      "source": [
        "default model\n",
        "\n",
        "- learning rate: 3e-4\n",
        "- number of hidden nodes: 128\n",
        "- word embedding dimension: 150\n",
        "- batch size: 64\n",
        "- with attention on the text embedding\n",
        "- with text embedding type: fast text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRSIMxj-GUkh"
      },
      "source": [
        "## Hyperparameter analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3rgaz0dXgJq"
      },
      "source": [
        "# default model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gI8gSKcsXfe1"
      },
      "outputs": [],
      "source": [
        "def default_model():\n",
        "  # from torch.optim.lr_scheduler import StepLR\n",
        "  n_epochs = 15\n",
        "  log_interval = 50\n",
        "  lr = 3e-4\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr= lr)\n",
        "\n",
        "  criterion = nn.BCELoss()\n",
        "  train_loss = []\n",
        "  best_f1_score = -float(\"inf\") # record the best loss to get the best model\n",
        "\n",
        "  for epoch in range(n_epochs):\n",
        "      loss = train_epoch(log_interval, model, train_loader, optimizer, epoch, criterion)\n",
        "      train_loss.append(loss)\n",
        "      f1score = validation(model, device, val_loader, criterion, 0.5)\n",
        "\n",
        "      # https://www.kaggle.com/general/178486\n",
        "      if f1score > best_f1_score:\n",
        "          best_f1_score = f1score\n",
        "          es = 0\n",
        "          torch.save(model, \"default_model.pt\")\n",
        "      else:\n",
        "          es += 1\n",
        "          print(\"Counter {} of 3\".format(es))\n",
        "\n",
        "          if es >= 3:\n",
        "              print(\"Early stopping with best loss: \", loss, \"and val_acc for this epoch: \", f1score)\n",
        "              break\n",
        "\n",
        "  return best_f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rn0f_9z4Xrbm",
        "outputId": "98fe8a2e-6f74-4f4c-eb2c-cbd82c130271"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [0/24000 (0%)]\tLoss: 0.610882 \t Time:  1.437355\n",
            "Train Epoch: 0 [3200/24000 (13%)]\tLoss: 0.170946 \t Time:  25.996942\n",
            "Train Epoch: 0 [6400/24000 (27%)]\tLoss: 0.132523 \t Time:  50.943444\n",
            "Train Epoch: 0 [9600/24000 (40%)]\tLoss: 0.106274 \t Time:  76.323701\n",
            "Train Epoch: 0 [12800/24000 (53%)]\tLoss: 0.123204 \t Time:  100.874357\n",
            "Train Epoch: 0 [16000/24000 (67%)]\tLoss: 0.088359 \t Time:  125.426718\n",
            "Train Epoch: 0 [19200/24000 (80%)]\tLoss: 0.096608 \t Time:  149.975013\n",
            "Train Epoch: 0 [22400/24000 (93%)]\tLoss: 0.102495 \t Time:  174.558320\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.91      0.92      4537\n",
            "           1       0.00      0.00      0.00       228\n",
            "           2       0.69      0.54      0.60       917\n",
            "           3       0.80      0.62      0.70       221\n",
            "           4       0.99      0.93      0.96       223\n",
            "           5       0.96      0.70      0.81       291\n",
            "           6       0.97      0.87      0.92       250\n",
            "           7       0.64      0.41      0.50       462\n",
            "           8       0.94      0.56      0.70       210\n",
            "           9       0.84      0.16      0.27       317\n",
            "          10       0.99      0.61      0.76       137\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.96      0.28      0.43        98\n",
            "          13       0.00      0.00      0.00        48\n",
            "          14       0.96      0.19      0.32       400\n",
            "          15       0.86      0.50      0.63       200\n",
            "          16       1.00      0.83      0.91       293\n",
            "          17       0.91      0.74      0.81       286\n",
            "          18       0.99      0.83      0.91       191\n",
            "\n",
            "   micro avg       0.90      0.71      0.80      9309\n",
            "   macro avg       0.76      0.51      0.59      9309\n",
            "weighted avg       0.87      0.71      0.76      9309\n",
            " samples avg       0.90      0.81      0.83      9309\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0904, Accuracy: 3826.0/6000 (63.77%)\n",
            ", F1 score: 0.8306\n",
            "Train Epoch: 1 [0/24000 (0%)]\tLoss: 0.081128 \t Time:  1.205871\n",
            "Train Epoch: 1 [3200/24000 (13%)]\tLoss: 0.066406 \t Time:  25.818037\n",
            "Train Epoch: 1 [6400/24000 (27%)]\tLoss: 0.072990 \t Time:  50.387482\n",
            "Train Epoch: 1 [9600/24000 (40%)]\tLoss: 0.079414 \t Time:  74.901407\n",
            "Train Epoch: 1 [12800/24000 (53%)]\tLoss: 0.066586 \t Time:  99.502121\n",
            "Train Epoch: 1 [16000/24000 (67%)]\tLoss: 0.060109 \t Time:  124.080436\n",
            "Train Epoch: 1 [19200/24000 (80%)]\tLoss: 0.092341 \t Time:  148.637347\n",
            "Train Epoch: 1 [22400/24000 (93%)]\tLoss: 0.094914 \t Time:  173.199467\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.94      0.93      4537\n",
            "           1       1.00      0.13      0.23       228\n",
            "           2       0.71      0.56      0.62       917\n",
            "           3       0.96      0.65      0.78       221\n",
            "           4       1.00      0.94      0.97       223\n",
            "           5       0.95      0.73      0.82       291\n",
            "           6       0.97      0.86      0.91       250\n",
            "           7       0.73      0.35      0.48       462\n",
            "           8       0.91      0.62      0.74       210\n",
            "           9       0.66      0.49      0.56       317\n",
            "          10       1.00      0.63      0.77       137\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.98      0.48      0.64        98\n",
            "          13       1.00      0.50      0.67        48\n",
            "          14       0.96      0.27      0.42       400\n",
            "          15       0.92      0.52      0.66       200\n",
            "          16       0.98      0.85      0.91       293\n",
            "          17       0.98      0.69      0.81       286\n",
            "          18       0.99      0.84      0.91       191\n",
            "\n",
            "   micro avg       0.90      0.75      0.82      9309\n",
            "   macro avg       0.87      0.58      0.68      9309\n",
            "weighted avg       0.90      0.75      0.80      9309\n",
            " samples avg       0.91      0.83      0.85      9309\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0815, Accuracy: 3968.0/6000 (66.13%)\n",
            ", F1 score: 0.8526\n",
            "Train Epoch: 2 [0/24000 (0%)]\tLoss: 0.085886 \t Time:  1.188399\n",
            "Train Epoch: 2 [3200/24000 (13%)]\tLoss: 0.073585 \t Time:  25.800151\n",
            "Train Epoch: 2 [6400/24000 (27%)]\tLoss: 0.094041 \t Time:  50.301449\n",
            "Train Epoch: 2 [9600/24000 (40%)]\tLoss: 0.108493 \t Time:  74.825836\n",
            "Train Epoch: 2 [12800/24000 (53%)]\tLoss: 0.080564 \t Time:  99.341348\n",
            "Train Epoch: 2 [16000/24000 (67%)]\tLoss: 0.068678 \t Time:  123.834631\n",
            "Train Epoch: 2 [19200/24000 (80%)]\tLoss: 0.057148 \t Time:  148.346782\n",
            "Train Epoch: 2 [22400/24000 (93%)]\tLoss: 0.090657 \t Time:  172.843680\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.93      0.94      4537\n",
            "           1       0.82      0.35      0.49       228\n",
            "           2       0.76      0.53      0.62       917\n",
            "           3       0.86      0.70      0.77       221\n",
            "           4       1.00      0.92      0.96       223\n",
            "           5       0.96      0.72      0.82       291\n",
            "           6       0.97      0.86      0.92       250\n",
            "           7       0.80      0.37      0.51       462\n",
            "           8       0.93      0.63      0.75       210\n",
            "           9       0.69      0.42      0.52       317\n",
            "          10       1.00      0.63      0.77       137\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.91      0.50      0.64        98\n",
            "          13       0.96      0.56      0.71        48\n",
            "          14       0.97      0.29      0.45       400\n",
            "          15       0.89      0.54      0.67       200\n",
            "          16       1.00      0.87      0.93       293\n",
            "          17       0.96      0.75      0.84       286\n",
            "          18       0.96      0.85      0.90       191\n",
            "\n",
            "   micro avg       0.92      0.76      0.83      9309\n",
            "   macro avg       0.86      0.60      0.70      9309\n",
            "weighted avg       0.91      0.76      0.81      9309\n",
            " samples avg       0.93      0.84      0.86      9309\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0791, Accuracy: 4067.0/6000 (67.78%)\n",
            ", F1 score: 0.8617\n",
            "Train Epoch: 3 [0/24000 (0%)]\tLoss: 0.068660 \t Time:  1.133272\n",
            "Train Epoch: 3 [3200/24000 (13%)]\tLoss: 0.057676 \t Time:  25.737734\n",
            "Train Epoch: 3 [6400/24000 (27%)]\tLoss: 0.058535 \t Time:  50.290457\n",
            "Train Epoch: 3 [9600/24000 (40%)]\tLoss: 0.059483 \t Time:  74.857269\n",
            "Train Epoch: 3 [12800/24000 (53%)]\tLoss: 0.075978 \t Time:  99.457974\n",
            "Train Epoch: 3 [16000/24000 (67%)]\tLoss: 0.064333 \t Time:  124.008282\n",
            "Train Epoch: 3 [19200/24000 (80%)]\tLoss: 0.073759 \t Time:  148.545802\n",
            "Train Epoch: 3 [22400/24000 (93%)]\tLoss: 0.064018 \t Time:  173.154823\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.94      0.94      4537\n",
            "           1       0.80      0.39      0.53       228\n",
            "           2       0.71      0.64      0.67       917\n",
            "           3       0.99      0.67      0.80       221\n",
            "           4       0.99      0.93      0.96       223\n",
            "           5       0.97      0.71      0.82       291\n",
            "           6       0.97      0.88      0.92       250\n",
            "           7       0.74      0.43      0.54       462\n",
            "           8       0.92      0.62      0.74       210\n",
            "           9       0.73      0.48      0.58       317\n",
            "          10       1.00      0.62      0.77       137\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.83      0.50      0.62        98\n",
            "          13       1.00      0.56      0.72        48\n",
            "          14       0.96      0.30      0.46       400\n",
            "          15       0.90      0.56      0.69       200\n",
            "          16       0.96      0.88      0.92       293\n",
            "          17       0.96      0.78      0.86       286\n",
            "          18       0.95      0.87      0.91       191\n",
            "\n",
            "   micro avg       0.91      0.78      0.84      9309\n",
            "   macro avg       0.86      0.62      0.71      9309\n",
            "weighted avg       0.90      0.78      0.82      9309\n",
            " samples avg       0.92      0.85      0.87      9309\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0781, Accuracy: 4080.0/6000 (68.00%)\n",
            ", F1 score: 0.8650\n",
            "Train Epoch: 4 [0/24000 (0%)]\tLoss: 0.096458 \t Time:  1.205923\n",
            "Train Epoch: 4 [3200/24000 (13%)]\tLoss: 0.056373 \t Time:  25.760142\n",
            "Train Epoch: 4 [6400/24000 (27%)]\tLoss: 0.069026 \t Time:  50.136075\n",
            "Train Epoch: 4 [9600/24000 (40%)]\tLoss: 0.080850 \t Time:  74.545019\n",
            "Train Epoch: 4 [12800/24000 (53%)]\tLoss: 0.064893 \t Time:  98.952245\n",
            "Train Epoch: 4 [16000/24000 (67%)]\tLoss: 0.072734 \t Time:  123.384028\n",
            "Train Epoch: 4 [19200/24000 (80%)]\tLoss: 0.075745 \t Time:  147.837923\n",
            "Train Epoch: 4 [22400/24000 (93%)]\tLoss: 0.067164 \t Time:  172.277116\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.95      0.94      4537\n",
            "           1       0.89      0.37      0.52       228\n",
            "           2       0.74      0.59      0.65       917\n",
            "           3       0.98      0.67      0.80       221\n",
            "           4       0.99      0.92      0.96       223\n",
            "           5       0.94      0.73      0.82       291\n",
            "           6       0.97      0.87      0.92       250\n",
            "           7       0.70      0.40      0.51       462\n",
            "           8       0.89      0.62      0.73       210\n",
            "           9       0.66      0.57      0.61       317\n",
            "          10       1.00      0.63      0.77       137\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.91      0.50      0.64        98\n",
            "          13       0.97      0.60      0.74        48\n",
            "          14       0.91      0.32      0.47       400\n",
            "          15       0.94      0.58      0.72       200\n",
            "          16       1.00      0.88      0.94       293\n",
            "          17       0.97      0.76      0.85       286\n",
            "          18       0.98      0.86      0.91       191\n",
            "\n",
            "   micro avg       0.90      0.78      0.84      9309\n",
            "   macro avg       0.86      0.62      0.71      9309\n",
            "weighted avg       0.90      0.78      0.82      9309\n",
            " samples avg       0.92      0.85      0.87      9309\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0774, Accuracy: 4057.0/6000 (67.62%)\n",
            ", F1 score: 0.8659\n",
            "Train Epoch: 5 [0/24000 (0%)]\tLoss: 0.043083 \t Time:  1.153996\n",
            "Train Epoch: 5 [3200/24000 (13%)]\tLoss: 0.044899 \t Time:  25.666144\n",
            "Train Epoch: 5 [6400/24000 (27%)]\tLoss: 0.047659 \t Time:  50.067878\n",
            "Train Epoch: 5 [9600/24000 (40%)]\tLoss: 0.051803 \t Time:  74.515273\n",
            "Train Epoch: 5 [12800/24000 (53%)]\tLoss: 0.062124 \t Time:  98.964119\n",
            "Train Epoch: 5 [16000/24000 (67%)]\tLoss: 0.087467 \t Time:  123.365880\n",
            "Train Epoch: 5 [19200/24000 (80%)]\tLoss: 0.069997 \t Time:  147.799878\n",
            "Train Epoch: 5 [22400/24000 (93%)]\tLoss: 0.043434 \t Time:  172.191471\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.94      0.94      4537\n",
            "           1       0.88      0.40      0.55       228\n",
            "           2       0.77      0.53      0.63       917\n",
            "           3       0.96      0.71      0.82       221\n",
            "           4       1.00      0.91      0.95       223\n",
            "           5       0.97      0.70      0.81       291\n",
            "           6       0.98      0.87      0.92       250\n",
            "           7       0.74      0.43      0.54       462\n",
            "           8       0.87      0.68      0.76       210\n",
            "           9       0.90      0.36      0.51       317\n",
            "          10       1.00      0.63      0.77       137\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.75      0.57      0.65        98\n",
            "          13       1.00      0.60      0.75        48\n",
            "          14       0.87      0.33      0.48       400\n",
            "          15       0.96      0.54      0.69       200\n",
            "          16       0.94      0.89      0.92       293\n",
            "          17       0.97      0.77      0.86       286\n",
            "          18       0.99      0.84      0.91       191\n",
            "\n",
            "   micro avg       0.92      0.77      0.84      9309\n",
            "   macro avg       0.87      0.62      0.71      9309\n",
            "weighted avg       0.91      0.77      0.82      9309\n",
            " samples avg       0.93      0.85      0.86      9309\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0798, Accuracy: 4099.0/6000 (68.32%)\n",
            ", F1 score: 0.8647\n",
            "Counter 1 of 3\n",
            "Train Epoch: 6 [0/24000 (0%)]\tLoss: 0.045665 \t Time:  1.148028\n",
            "Train Epoch: 6 [3200/24000 (13%)]\tLoss: 0.056981 \t Time:  25.682062\n",
            "Train Epoch: 6 [6400/24000 (27%)]\tLoss: 0.070549 \t Time:  50.108115\n",
            "Train Epoch: 6 [9600/24000 (40%)]\tLoss: 0.082953 \t Time:  74.530230\n",
            "Train Epoch: 6 [12800/24000 (53%)]\tLoss: 0.063423 \t Time:  98.978468\n",
            "Train Epoch: 6 [16000/24000 (67%)]\tLoss: 0.052728 \t Time:  123.409124\n",
            "Train Epoch: 6 [19200/24000 (80%)]\tLoss: 0.080923 \t Time:  147.822434\n",
            "Train Epoch: 6 [22400/24000 (93%)]\tLoss: 0.089696 \t Time:  172.274165\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.94      0.94      4537\n",
            "           1       0.90      0.35      0.50       228\n",
            "           2       0.77      0.58      0.66       917\n",
            "           3       0.92      0.74      0.82       221\n",
            "           4       0.99      0.91      0.95       223\n",
            "           5       0.99      0.68      0.80       291\n",
            "           6       0.98      0.86      0.92       250\n",
            "           7       0.75      0.37      0.50       462\n",
            "           8       0.94      0.56      0.70       210\n",
            "           9       0.82      0.44      0.58       317\n",
            "          10       0.98      0.62      0.76       137\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.88      0.57      0.69        98\n",
            "          13       1.00      0.62      0.77        48\n",
            "          14       0.92      0.31      0.46       400\n",
            "          15       0.94      0.60      0.73       200\n",
            "          16       0.94      0.90      0.92       293\n",
            "          17       0.96      0.77      0.85       286\n",
            "          18       0.98      0.86      0.92       191\n",
            "\n",
            "   micro avg       0.92      0.77      0.84      9309\n",
            "   macro avg       0.87      0.62      0.71      9309\n",
            "weighted avg       0.91      0.77      0.82      9309\n",
            " samples avg       0.93      0.85      0.87      9309\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0801, Accuracy: 4095.0/6000 (68.25%)\n",
            ", F1 score: 0.8658\n",
            "Counter 2 of 3\n",
            "Train Epoch: 7 [0/24000 (0%)]\tLoss: 0.041973 \t Time:  1.140251\n",
            "Train Epoch: 7 [3200/24000 (13%)]\tLoss: 0.047663 \t Time:  25.745574\n",
            "Train Epoch: 7 [6400/24000 (27%)]\tLoss: 0.035559 \t Time:  50.121342\n",
            "Train Epoch: 7 [9600/24000 (40%)]\tLoss: 0.053571 \t Time:  74.532343\n",
            "Train Epoch: 7 [12800/24000 (53%)]\tLoss: 0.057277 \t Time:  98.920542\n",
            "Train Epoch: 7 [16000/24000 (67%)]\tLoss: 0.053473 \t Time:  123.335198\n",
            "Train Epoch: 7 [19200/24000 (80%)]\tLoss: 0.044975 \t Time:  147.788019\n",
            "Train Epoch: 7 [22400/24000 (93%)]\tLoss: 0.067775 \t Time:  172.216003\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.94      0.94      4537\n",
            "           1       0.85      0.43      0.57       228\n",
            "           2       0.76      0.58      0.66       917\n",
            "           3       0.92      0.72      0.81       221\n",
            "           4       1.00      0.92      0.96       223\n",
            "           5       0.97      0.72      0.83       291\n",
            "           6       0.97      0.87      0.92       250\n",
            "           7       0.71      0.44      0.55       462\n",
            "           8       0.91      0.64      0.75       210\n",
            "           9       0.83      0.49      0.62       317\n",
            "          10       0.97      0.63      0.76       137\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.90      0.54      0.68        98\n",
            "          13       0.91      0.62      0.74        48\n",
            "          14       0.89      0.33      0.48       400\n",
            "          15       0.89      0.63      0.74       200\n",
            "          16       0.97      0.89      0.93       293\n",
            "          17       0.95      0.78      0.86       286\n",
            "          18       0.97      0.87      0.92       191\n",
            "\n",
            "   micro avg       0.91      0.78      0.84      9309\n",
            "   macro avg       0.86      0.63      0.72      9309\n",
            "weighted avg       0.90      0.78      0.83      9309\n",
            " samples avg       0.93      0.85      0.87      9309\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0794, Accuracy: 4108.0/6000 (68.47%)\n",
            ", F1 score: 0.8714\n",
            "Train Epoch: 8 [0/24000 (0%)]\tLoss: 0.064568 \t Time:  1.152172\n",
            "Train Epoch: 8 [3200/24000 (13%)]\tLoss: 0.050037 \t Time:  25.715130\n",
            "Train Epoch: 8 [6400/24000 (27%)]\tLoss: 0.071218 \t Time:  50.228433\n",
            "Train Epoch: 8 [9600/24000 (40%)]\tLoss: 0.074270 \t Time:  74.670362\n",
            "Train Epoch: 8 [12800/24000 (53%)]\tLoss: 0.042084 \t Time:  99.092744\n",
            "Train Epoch: 8 [16000/24000 (67%)]\tLoss: 0.043525 \t Time:  123.524975\n",
            "Train Epoch: 8 [19200/24000 (80%)]\tLoss: 0.053081 \t Time:  147.942347\n",
            "Train Epoch: 8 [22400/24000 (93%)]\tLoss: 0.087579 \t Time:  172.401255\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.92      0.94      4537\n",
            "           1       0.79      0.42      0.54       228\n",
            "           2       0.80      0.57      0.66       917\n",
            "           3       0.90      0.73      0.80       221\n",
            "           4       0.99      0.93      0.96       223\n",
            "           5       0.95      0.72      0.82       291\n",
            "           6       0.96      0.87      0.91       250\n",
            "           7       0.75      0.43      0.55       462\n",
            "           8       0.90      0.63      0.74       210\n",
            "           9       0.90      0.37      0.52       317\n",
            "          10       1.00      0.62      0.77       137\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.88      0.51      0.65        98\n",
            "          13       1.00      0.60      0.75        48\n",
            "          14       0.92      0.32      0.47       400\n",
            "          15       0.89      0.62      0.73       200\n",
            "          16       0.97      0.89      0.93       293\n",
            "          17       0.95      0.78      0.86       286\n",
            "          18       0.97      0.87      0.92       191\n",
            "\n",
            "   micro avg       0.93      0.76      0.84      9309\n",
            "   macro avg       0.87      0.62      0.71      9309\n",
            "weighted avg       0.92      0.76      0.82      9309\n",
            " samples avg       0.93      0.84      0.87      9309\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0840, Accuracy: 4119.0/6000 (68.65%)\n",
            ", F1 score: 0.8663\n",
            "Counter 1 of 3\n",
            "Train Epoch: 9 [0/24000 (0%)]\tLoss: 0.030977 \t Time:  1.154138\n",
            "Train Epoch: 9 [3200/24000 (13%)]\tLoss: 0.057103 \t Time:  25.675748\n",
            "Train Epoch: 9 [6400/24000 (27%)]\tLoss: 0.038071 \t Time:  50.123648\n",
            "Train Epoch: 9 [9600/24000 (40%)]\tLoss: 0.057048 \t Time:  74.551846\n",
            "Train Epoch: 9 [12800/24000 (53%)]\tLoss: 0.054416 \t Time:  98.959759\n",
            "Train Epoch: 9 [16000/24000 (67%)]\tLoss: 0.048510 \t Time:  123.381550\n",
            "Train Epoch: 9 [19200/24000 (80%)]\tLoss: 0.027058 \t Time:  147.819095\n",
            "Train Epoch: 9 [22400/24000 (93%)]\tLoss: 0.059067 \t Time:  172.262768\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.93      0.94      4537\n",
            "           1       0.79      0.45      0.57       228\n",
            "           2       0.76      0.57      0.65       917\n",
            "           3       0.80      0.73      0.77       221\n",
            "           4       1.00      0.92      0.96       223\n",
            "           5       0.93      0.73      0.82       291\n",
            "           6       0.98      0.87      0.92       250\n",
            "           7       0.77      0.38      0.51       462\n",
            "           8       0.87      0.66      0.75       210\n",
            "           9       0.70      0.56      0.62       317\n",
            "          10       0.99      0.63      0.77       137\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.92      0.56      0.70        98\n",
            "          13       0.88      0.62      0.73        48\n",
            "          14       0.71      0.36      0.48       400\n",
            "          15       0.79      0.63      0.70       200\n",
            "          16       0.93      0.90      0.92       293\n",
            "          17       0.93      0.78      0.85       286\n",
            "          18       0.98      0.85      0.91       191\n",
            "\n",
            "   micro avg       0.90      0.78      0.83      9309\n",
            "   macro avg       0.82      0.64      0.71      9309\n",
            "weighted avg       0.89      0.78      0.82      9309\n",
            " samples avg       0.92      0.85      0.87      9309\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0857, Accuracy: 4087.0/6000 (68.12%)\n",
            ", F1 score: 0.8657\n",
            "Counter 2 of 3\n",
            "Train Epoch: 10 [0/24000 (0%)]\tLoss: 0.047705 \t Time:  1.148266\n",
            "Train Epoch: 10 [3200/24000 (13%)]\tLoss: 0.057200 \t Time:  25.742157\n",
            "Train Epoch: 10 [6400/24000 (27%)]\tLoss: 0.028912 \t Time:  50.162416\n",
            "Train Epoch: 10 [9600/24000 (40%)]\tLoss: 0.044489 \t Time:  74.598583\n",
            "Train Epoch: 10 [12800/24000 (53%)]\tLoss: 0.079977 \t Time:  99.051094\n",
            "Train Epoch: 10 [16000/24000 (67%)]\tLoss: 0.041953 \t Time:  123.471735\n",
            "Train Epoch: 10 [19200/24000 (80%)]\tLoss: 0.050734 \t Time:  147.905285\n",
            "Train Epoch: 10 [22400/24000 (93%)]\tLoss: 0.055846 \t Time:  172.353660\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.91      0.93      4537\n",
            "           1       0.75      0.47      0.58       228\n",
            "           2       0.79      0.54      0.64       917\n",
            "           3       0.94      0.70      0.80       221\n",
            "           4       0.99      0.91      0.95       223\n",
            "           5       0.94      0.70      0.80       291\n",
            "           6       0.93      0.88      0.91       250\n",
            "           7       0.70      0.42      0.53       462\n",
            "           8       0.81      0.71      0.75       210\n",
            "           9       0.76      0.54      0.63       317\n",
            "          10       0.92      0.63      0.75       137\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.86      0.57      0.69        98\n",
            "          13       0.94      0.60      0.73        48\n",
            "          14       0.80      0.31      0.45       400\n",
            "          15       0.92      0.61      0.74       200\n",
            "          16       0.92      0.89      0.91       293\n",
            "          17       0.92      0.77      0.84       286\n",
            "          18       0.95      0.86      0.90       191\n",
            "\n",
            "   micro avg       0.91      0.76      0.83      9309\n",
            "   macro avg       0.83      0.63      0.71      9309\n",
            "weighted avg       0.90      0.76      0.82      9309\n",
            " samples avg       0.92      0.84      0.86      9309\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0877, Accuracy: 4056.0/6000 (67.60%)\n",
            ", F1 score: 0.8589\n",
            "Counter 3 of 3\n",
            "Early stopping with best loss:  0.04604734095434348 and val_acc for this epoch:  0.8588544131794131\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "start = time.time()\n",
        "default_f1_score = default_model()\n",
        "end = time.time()\n",
        "\n",
        "default_model_time = end-start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V91PG1yrJYwP"
      },
      "outputs": [],
      "source": [
        "default_f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ek0DXaNZM0uS",
        "outputId": "51bc1538-6c43-481d-b29d-9620eb7d1c21"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2339.5213434696198"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "default_model_time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHwhbRwrGXtS"
      },
      "source": [
        "### Learning rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jW64jlz8sc0y"
      },
      "outputs": [],
      "source": [
        "def lr_tuning (lr = 3e-4):\n",
        "  # from torch.optim.lr_scheduler import StepLR\n",
        "  n_epochs = 15\n",
        "  log_interval = 50\n",
        "  lr = lr\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr= lr)\n",
        "\n",
        "  criterion = nn.BCELoss()\n",
        "  train_loss = []\n",
        "  best_f1_score = -float(\"inf\") # record the best loss to get the best model\n",
        "\n",
        "  for epoch in range(n_epochs):\n",
        "      loss = train_epoch(log_interval, model, train_loader, optimizer, epoch, criterion)\n",
        "      train_loss.append(loss)\n",
        "      f1score = validation(model, device, val_loader, criterion, 0.5)\n",
        "\n",
        "      # https://www.kaggle.com/general/178486\n",
        "      if f1score > best_f1_score:\n",
        "          best_f1_score = f1score\n",
        "          es = 0\n",
        "          torch.save(model, str(lr)+\"model.pt\")\n",
        "      else:\n",
        "          es += 1\n",
        "          print(\"Counter {} of 3\".format(es))\n",
        "\n",
        "          if es >= 3:\n",
        "              print(\"Early stopping with best loss: \", loss, \"and val_acc for this epoch: \", f1score)\n",
        "              break\n",
        "  return best_f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsRYfNz2FSwd",
        "outputId": "eb1b5adc-5a98-41b0-a30f-4abc8e9efdc8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [0/24000 (0%)]\tLoss: 0.061283 \t Time:  1.484229\n",
            "Train Epoch: 0 [3200/24000 (13%)]\tLoss: 0.130603 \t Time:  27.614033\n",
            "Train Epoch: 0 [6400/24000 (27%)]\tLoss: 0.093887 \t Time:  52.597935\n",
            "Train Epoch: 0 [9600/24000 (40%)]\tLoss: 0.095244 \t Time:  76.685468\n",
            "Train Epoch: 0 [12800/24000 (53%)]\tLoss: 0.090957 \t Time:  100.900410\n",
            "Train Epoch: 0 [16000/24000 (67%)]\tLoss: 0.085600 \t Time:  125.233398\n",
            "Train Epoch: 0 [19200/24000 (80%)]\tLoss: 0.056732 \t Time:  149.307569\n",
            "Train Epoch: 0 [22400/24000 (93%)]\tLoss: 0.101464 \t Time:  173.376546\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.89      0.92      4571\n",
            "           1       1.00      0.03      0.05       229\n",
            "           2       0.73      0.12      0.20       878\n",
            "           3       0.99      0.65      0.79       263\n",
            "           4       0.98      0.85      0.91       204\n",
            "           5       0.95      0.65      0.77       270\n",
            "           6       0.95      0.56      0.70       246\n",
            "           7       0.97      0.22      0.35       434\n",
            "           8       0.94      0.50      0.65       211\n",
            "           9       0.81      0.32      0.45       288\n",
            "          10       1.00      0.55      0.71       123\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       1.00      0.46      0.63       117\n",
            "          13       1.00      0.09      0.16        56\n",
            "          14       0.89      0.26      0.40       401\n",
            "          15       0.97      0.59      0.73       212\n",
            "          16       0.96      0.89      0.93       288\n",
            "          17       0.80      0.78      0.79       288\n",
            "          18       1.00      0.25      0.40       208\n",
            "\n",
            "   micro avg       0.94      0.65      0.77      9287\n",
            "   macro avg       0.89      0.46      0.56      9287\n",
            "weighted avg       0.93      0.65      0.72      9287\n",
            " samples avg       0.90      0.76      0.80      9287\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.1115, Accuracy: 3748.0/6000 (62.47%)\n",
            ", F1 score: 0.8011\n",
            "Train Epoch: 1 [0/24000 (0%)]\tLoss: 0.099027 \t Time:  1.023614\n",
            "Train Epoch: 1 [3200/24000 (13%)]\tLoss: 0.072632 \t Time:  25.282540\n",
            "Train Epoch: 1 [6400/24000 (27%)]\tLoss: 0.247509 \t Time:  49.349076\n",
            "Train Epoch: 1 [9600/24000 (40%)]\tLoss: 0.164536 \t Time:  73.410171\n",
            "Train Epoch: 1 [12800/24000 (53%)]\tLoss: 0.243808 \t Time:  97.487275\n",
            "Train Epoch: 1 [16000/24000 (67%)]\tLoss: 0.378736 \t Time:  121.585009\n",
            "Train Epoch: 1 [19200/24000 (80%)]\tLoss: 0.408733 \t Time:  145.924549\n",
            "Train Epoch: 1 [22400/24000 (93%)]\tLoss: 0.176239 \t Time:  170.042814\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.95      0.89      4571\n",
            "           1       0.75      0.19      0.30       229\n",
            "           2       0.29      0.50      0.36       878\n",
            "           3       0.99      0.36      0.53       263\n",
            "           4       0.99      0.53      0.69       204\n",
            "           5       0.99      0.30      0.46       270\n",
            "           6       0.93      0.52      0.67       246\n",
            "           7       0.92      0.16      0.27       434\n",
            "           8       0.90      0.35      0.51       211\n",
            "           9       0.74      0.23      0.35       288\n",
            "          10       0.89      0.39      0.54       123\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       1.00      0.26      0.41       117\n",
            "          13       1.00      0.21      0.35        56\n",
            "          14       0.81      0.16      0.26       401\n",
            "          15       0.98      0.42      0.58       212\n",
            "          16       0.99      0.44      0.61       288\n",
            "          17       0.93      0.51      0.66       288\n",
            "          18       0.97      0.48      0.64       208\n",
            "\n",
            "   micro avg       0.75      0.65      0.70      9287\n",
            "   macro avg       0.84      0.37      0.48      9287\n",
            "weighted avg       0.82      0.65      0.67      9287\n",
            " samples avg       0.80      0.74      0.74      9287\n",
            "\n",
            "\n",
            "Test set: Average loss: 1.6847, Accuracy: 3073.0/6000 (51.22%)\n",
            ", F1 score: 0.7409\n",
            "Counter 1 of 3\n",
            "Train Epoch: 2 [0/24000 (0%)]\tLoss: 0.423630 \t Time:  1.157901\n",
            "Train Epoch: 2 [3200/24000 (13%)]\tLoss: 4.461202 \t Time:  26.853035\n",
            "Train Epoch: 2 [6400/24000 (27%)]\tLoss: 1.193626 \t Time:  50.896296\n",
            "Train Epoch: 2 [9600/24000 (40%)]\tLoss: 0.436618 \t Time:  74.946746\n",
            "Train Epoch: 2 [12800/24000 (53%)]\tLoss: 0.344003 \t Time:  99.018270\n",
            "Train Epoch: 2 [16000/24000 (67%)]\tLoss: 0.384890 \t Time:  123.099270\n",
            "Train Epoch: 2 [19200/24000 (80%)]\tLoss: 0.343268 \t Time:  147.231073\n",
            "Train Epoch: 2 [22400/24000 (93%)]\tLoss: 0.242832 \t Time:  171.308008\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.94      0.90      4571\n",
            "           1       0.92      0.19      0.32       229\n",
            "           2       0.68      0.15      0.24       878\n",
            "           3       0.95      0.43      0.59       263\n",
            "           4       0.93      0.60      0.73       204\n",
            "           5       0.96      0.37      0.54       270\n",
            "           6       0.98      0.52      0.68       246\n",
            "           7       0.63      0.23      0.33       434\n",
            "           8       0.81      0.38      0.52       211\n",
            "           9       0.78      0.26      0.39       288\n",
            "          10       1.00      0.35      0.52       123\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.96      0.39      0.56       117\n",
            "          13       1.00      0.32      0.49        56\n",
            "          14       0.87      0.15      0.25       401\n",
            "          15       0.95      0.46      0.62       212\n",
            "          16       0.90      0.57      0.70       288\n",
            "          17       0.93      0.44      0.59       288\n",
            "          18       0.97      0.57      0.72       208\n",
            "\n",
            "   micro avg       0.86      0.63      0.73      9287\n",
            "   macro avg       0.85      0.38      0.51      9287\n",
            "weighted avg       0.85      0.63      0.68      9287\n",
            " samples avg       0.86      0.74      0.77      9287\n",
            "\n",
            "\n",
            "Test set: Average loss: 1.9652, Accuracy: 3522.0/6000 (58.70%)\n",
            ", F1 score: 0.7678\n",
            "Counter 2 of 3\n",
            "Train Epoch: 3 [0/24000 (0%)]\tLoss: 0.133552 \t Time:  1.023003\n",
            "Train Epoch: 3 [3200/24000 (13%)]\tLoss: 0.242035 \t Time:  25.128773\n",
            "Train Epoch: 3 [6400/24000 (27%)]\tLoss: 0.245770 \t Time:  49.197151\n",
            "Train Epoch: 3 [9600/24000 (40%)]\tLoss: 0.230917 \t Time:  73.284245\n",
            "Train Epoch: 3 [12800/24000 (53%)]\tLoss: 0.090219 \t Time:  97.378546\n",
            "Train Epoch: 3 [16000/24000 (67%)]\tLoss: 0.059171 \t Time:  121.466940\n",
            "Train Epoch: 3 [19200/24000 (80%)]\tLoss: 0.082011 \t Time:  145.528945\n",
            "Train Epoch: 3 [22400/24000 (93%)]\tLoss: 1.249955 \t Time:  170.015105\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.94      0.90      4571\n",
            "           1       0.75      0.27      0.40       229\n",
            "           2       0.23      0.19      0.21       878\n",
            "           3       0.99      0.45      0.62       263\n",
            "           4       0.96      0.79      0.87       204\n",
            "           5       0.97      0.54      0.69       270\n",
            "           6       0.94      0.72      0.82       246\n",
            "           7       0.79      0.29      0.43       434\n",
            "           8       0.95      0.42      0.58       211\n",
            "           9       0.72      0.26      0.38       288\n",
            "          10       0.73      0.57      0.64       123\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.47      0.48      0.47       117\n",
            "          13       1.00      0.39      0.56        56\n",
            "          14       0.91      0.17      0.29       401\n",
            "          15       0.67      0.68      0.67       212\n",
            "          16       0.91      0.82      0.86       288\n",
            "          17       0.94      0.62      0.75       288\n",
            "          18       0.98      0.68      0.80       208\n",
            "\n",
            "   micro avg       0.81      0.68      0.74      9287\n",
            "   macro avg       0.78      0.49      0.58      9287\n",
            "weighted avg       0.81      0.68      0.71      9287\n",
            " samples avg       0.85      0.78      0.78      9287\n",
            "\n",
            "\n",
            "Test set: Average loss: 1.1740, Accuracy: 3363.0/6000 (56.05%)\n",
            ", F1 score: 0.7850\n",
            "Counter 3 of 3\n",
            "Early stopping with best loss:  0.31279133367538453 and val_acc for this epoch:  0.7849809523809523\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "lr_3e_3 = lr_tuning(3e-3) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otPHPSQ_Yy-V",
        "outputId": "2cf2a005-06b4-48fa-fc4d-6681cf16f963"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [0/24000 (0%)]\tLoss: 0.568872 \t Time:  1.022168\n",
            "Train Epoch: 0 [3200/24000 (13%)]\tLoss: 5.345395 \t Time:  25.238584\n",
            "Train Epoch: 0 [6400/24000 (27%)]\tLoss: 5.509869 \t Time:  49.349750\n",
            "Train Epoch: 0 [9600/24000 (40%)]\tLoss: 5.180921 \t Time:  73.482382\n",
            "Train Epoch: 0 [12800/24000 (53%)]\tLoss: 5.756579 \t Time:  97.610274\n",
            "Train Epoch: 0 [16000/24000 (67%)]\tLoss: 5.838816 \t Time:  121.743311\n",
            "Train Epoch: 0 [19200/24000 (80%)]\tLoss: 4.851974 \t Time:  145.873258\n",
            "Train Epoch: 0 [22400/24000 (93%)]\tLoss: 5.427632 \t Time:  170.030422\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      1.00      0.87      4607\n",
            "           1       0.00      0.00      0.00       224\n",
            "           2       0.00      0.00      0.00       871\n",
            "           3       0.00      0.00      0.00       243\n",
            "           4       0.00      0.00      0.00       223\n",
            "           5       0.00      0.00      0.00       271\n",
            "           6       0.00      0.00      0.00       211\n",
            "           7       0.00      0.00      0.00       457\n",
            "           8       0.00      0.00      0.00       231\n",
            "           9       0.00      0.00      0.00       289\n",
            "          10       0.00      0.00      0.00       112\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.00      0.00      0.00       107\n",
            "          13       0.00      0.00      0.00        50\n",
            "          14       0.00      0.00      0.00       376\n",
            "          15       0.00      0.00      0.00       208\n",
            "          16       0.00      0.00      0.00       255\n",
            "          17       0.00      0.00      0.00       270\n",
            "          18       0.00      0.00      0.00       216\n",
            "\n",
            "   micro avg       0.77      0.50      0.61      9221\n",
            "   macro avg       0.04      0.05      0.05      9221\n",
            "weighted avg       0.38      0.50      0.43      9221\n",
            " samples avg       0.77      0.60      0.65      9221\n",
            "\n",
            "\n",
            "Test set: Average loss: 5.2693, Accuracy: 2904.0/6000 (48.40%)\n",
            ", F1 score: 0.6485\n",
            "Train Epoch: 1 [0/24000 (0%)]\tLoss: 3.536184 \t Time:  0.988158\n",
            "Train Epoch: 1 [3200/24000 (13%)]\tLoss: 5.921052 \t Time:  25.108134\n",
            "Train Epoch: 1 [6400/24000 (27%)]\tLoss: 5.509869 \t Time:  49.207117\n",
            "Train Epoch: 1 [9600/24000 (40%)]\tLoss: 5.756579 \t Time:  73.308101\n",
            "Train Epoch: 1 [12800/24000 (53%)]\tLoss: 4.276316 \t Time:  97.392758\n",
            "Train Epoch: 1 [16000/24000 (67%)]\tLoss: 4.934211 \t Time:  121.481232\n",
            "Train Epoch: 1 [19200/24000 (80%)]\tLoss: 4.194079 \t Time:  145.575154\n",
            "Train Epoch: 1 [22400/24000 (93%)]\tLoss: 6.167763 \t Time:  169.687769\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      1.00      0.87      4607\n",
            "           1       0.00      0.00      0.00       224\n",
            "           2       0.00      0.00      0.00       871\n",
            "           3       0.00      0.00      0.00       243\n",
            "           4       0.00      0.00      0.00       223\n",
            "           5       0.00      0.00      0.00       271\n",
            "           6       0.00      0.00      0.00       211\n",
            "           7       0.00      0.00      0.00       457\n",
            "           8       0.00      0.00      0.00       231\n",
            "           9       0.00      0.00      0.00       289\n",
            "          10       0.00      0.00      0.00       112\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.00      0.00      0.00       107\n",
            "          13       0.00      0.00      0.00        50\n",
            "          14       0.00      0.00      0.00       376\n",
            "          15       0.00      0.00      0.00       208\n",
            "          16       0.00      0.00      0.00       255\n",
            "          17       0.00      0.00      0.00       270\n",
            "          18       0.00      0.00      0.00       216\n",
            "\n",
            "   micro avg       0.77      0.50      0.61      9221\n",
            "   macro avg       0.04      0.05      0.05      9221\n",
            "weighted avg       0.38      0.50      0.43      9221\n",
            " samples avg       0.77      0.60      0.65      9221\n",
            "\n",
            "\n",
            "Test set: Average loss: 5.2693, Accuracy: 2904.0/6000 (48.40%)\n",
            ", F1 score: 0.6485\n",
            "Counter 1 of 3\n",
            "Train Epoch: 2 [0/24000 (0%)]\tLoss: 5.592105 \t Time:  0.999717\n",
            "Train Epoch: 2 [3200/24000 (13%)]\tLoss: 5.098684 \t Time:  25.135228\n",
            "Train Epoch: 2 [6400/24000 (27%)]\tLoss: 4.687500 \t Time:  49.236207\n",
            "Train Epoch: 2 [9600/24000 (40%)]\tLoss: 6.085526 \t Time:  73.354234\n",
            "Train Epoch: 2 [12800/24000 (53%)]\tLoss: 4.934211 \t Time:  97.473729\n",
            "Train Epoch: 2 [16000/24000 (67%)]\tLoss: 6.661184 \t Time:  121.585350\n",
            "Train Epoch: 2 [19200/24000 (80%)]\tLoss: 6.332237 \t Time:  145.712495\n",
            "Train Epoch: 2 [22400/24000 (93%)]\tLoss: 4.851974 \t Time:  169.854332\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      1.00      0.87      4607\n",
            "           1       0.00      0.00      0.00       224\n",
            "           2       0.00      0.00      0.00       871\n",
            "           3       0.00      0.00      0.00       243\n",
            "           4       0.00      0.00      0.00       223\n",
            "           5       0.00      0.00      0.00       271\n",
            "           6       0.00      0.00      0.00       211\n",
            "           7       0.00      0.00      0.00       457\n",
            "           8       0.00      0.00      0.00       231\n",
            "           9       0.00      0.00      0.00       289\n",
            "          10       0.00      0.00      0.00       112\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.00      0.00      0.00       107\n",
            "          13       0.00      0.00      0.00        50\n",
            "          14       0.00      0.00      0.00       376\n",
            "          15       0.00      0.00      0.00       208\n",
            "          16       0.00      0.00      0.00       255\n",
            "          17       0.00      0.00      0.00       270\n",
            "          18       0.00      0.00      0.00       216\n",
            "\n",
            "   micro avg       0.77      0.50      0.61      9221\n",
            "   macro avg       0.04      0.05      0.05      9221\n",
            "weighted avg       0.38      0.50      0.43      9221\n",
            " samples avg       0.77      0.60      0.65      9221\n",
            "\n",
            "\n",
            "Test set: Average loss: 5.2693, Accuracy: 2904.0/6000 (48.40%)\n",
            ", F1 score: 0.6485\n",
            "Counter 2 of 3\n",
            "Train Epoch: 3 [0/24000 (0%)]\tLoss: 5.674342 \t Time:  1.003639\n",
            "Train Epoch: 3 [3200/24000 (13%)]\tLoss: 5.180921 \t Time:  25.110867\n",
            "Train Epoch: 3 [6400/24000 (27%)]\tLoss: 4.194079 \t Time:  49.194527\n",
            "Train Epoch: 3 [9600/24000 (40%)]\tLoss: 5.098684 \t Time:  73.324678\n",
            "Train Epoch: 3 [12800/24000 (53%)]\tLoss: 5.592105 \t Time:  97.461924\n",
            "Train Epoch: 3 [16000/24000 (67%)]\tLoss: 5.509869 \t Time:  121.636508\n",
            "Train Epoch: 3 [19200/24000 (80%)]\tLoss: 6.907895 \t Time:  145.769430\n",
            "Train Epoch: 3 [22400/24000 (93%)]\tLoss: 6.496711 \t Time:  169.919138\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      1.00      0.87      4607\n",
            "           1       0.00      0.00      0.00       224\n",
            "           2       0.00      0.00      0.00       871\n",
            "           3       0.00      0.00      0.00       243\n",
            "           4       0.00      0.00      0.00       223\n",
            "           5       0.00      0.00      0.00       271\n",
            "           6       0.00      0.00      0.00       211\n",
            "           7       0.00      0.00      0.00       457\n",
            "           8       0.00      0.00      0.00       231\n",
            "           9       0.00      0.00      0.00       289\n",
            "          10       0.00      0.00      0.00       112\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.00      0.00      0.00       107\n",
            "          13       0.00      0.00      0.00        50\n",
            "          14       0.00      0.00      0.00       376\n",
            "          15       0.00      0.00      0.00       208\n",
            "          16       0.00      0.00      0.00       255\n",
            "          17       0.00      0.00      0.00       270\n",
            "          18       0.00      0.00      0.00       216\n",
            "\n",
            "   micro avg       0.77      0.50      0.61      9221\n",
            "   macro avg       0.04      0.05      0.05      9221\n",
            "weighted avg       0.38      0.50      0.43      9221\n",
            " samples avg       0.77      0.60      0.65      9221\n",
            "\n",
            "\n",
            "Test set: Average loss: 5.2693, Accuracy: 2904.0/6000 (48.40%)\n",
            ", F1 score: 0.6485\n",
            "Counter 3 of 3\n",
            "Early stopping with best loss:  5.468640408198039 and val_acc for this epoch:  0.6485154761904762\n"
          ]
        }
      ],
      "source": [
        "lr_3e_2 = lr_tuning(3e-2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "9oPAiHeN-JSz",
        "outputId": "8455c008-a3f9-4a26-95c8-1cf2453a448e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-431a1b0d-796e-407e-a70a-fbdc11943897\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>learning rate</th>\n",
              "      <th>f1 score</th>\n",
              "      <th>model size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0003</td>\n",
              "      <td>0.871</td>\n",
              "      <td>96.36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0030</td>\n",
              "      <td>0.801</td>\n",
              "      <td>96.36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0300</td>\n",
              "      <td>0.649</td>\n",
              "      <td>96.36</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-431a1b0d-796e-407e-a70a-fbdc11943897')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-431a1b0d-796e-407e-a70a-fbdc11943897 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-431a1b0d-796e-407e-a70a-fbdc11943897');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   learning rate  f1 score  model size\n",
              "0         0.0003     0.871       96.36\n",
              "1         0.0030     0.801       96.36\n",
              "2         0.0300     0.649       96.36"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lr_list = [3e-4, 3e-3, 3e-2]\n",
        "lr_dict = {}\n",
        "lr_dict['learning rate'] = lr_list\n",
        "lr_dict['f1 score'] = [default_f1_score, lr_3e_3, lr_3e_2]\n",
        "lr_dict['model size'] = [default_model_size, 96.36, 96.36]\n",
        "\n",
        "import pandas as pd\n",
        "lr_df = pd.DataFrame.from_dict(lr_dict)\n",
        "lr_df['f1 score'] = round(lr_df['f1 score'],3)\n",
        "lr_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "jMGErD-y-Oju",
        "outputId": "74b0c5ab-7042-4006-fc7a-7fe0a2182dd4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'f1 score')"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(lr_df['learning rate'], lr_df['f1 score'])\n",
        "plt.title(\"f1 score of different learning rates\")\n",
        "plt.xlabel(\"learning rate\")\n",
        "plt.ylabel(\"f1 score\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2uHsv82otf0"
      },
      "source": [
        "# hidden dimension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bxKE_EdHowhI"
      },
      "outputs": [],
      "source": [
        "def n_hidden_tuning (n_hidden = 128):\n",
        "\n",
        "  device = torch.device('cuda' if torch.cuda.is_available else 'cpu')\n",
        "  img_model = Resnext50(num_class).to(device)\n",
        "  # img_model = DenseNet121(num_class).to(device)\n",
        "  gpu_usage() \n",
        "  # text_model = Bi_LSTM_Attention(emb_table, 256, n_emb = 2048).to(device)\n",
        "  n_hidden = n_hidden\n",
        "  text_model = Bi_GRU_Attention(emb_table, n_hidden, n_emb = 256).to(device)\n",
        "  gpu_usage() \n",
        "  n_emb = 256\n",
        "  model = Concatenate_Embed_Model(img_model, text_model, n_emb, num_class).to(device)\n",
        "  gpu_usage() \n",
        "  print('Model initialized.')\n",
        "\n",
        "  # from torch.optim.lr_scheduler import StepLR\n",
        "  n_epochs = 15\n",
        "  log_interval = 50\n",
        "  lr = 3e-4\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr= lr)\n",
        "\n",
        "  criterion = nn.BCELoss()\n",
        "  train_loss = []\n",
        "  best_f1_score = -float(\"inf\") # record the best loss to get the best model\n",
        "\n",
        "  for epoch in range(n_epochs):\n",
        "      loss = train_epoch(log_interval, model, train_loader, optimizer, epoch, criterion)\n",
        "      train_loss.append(loss)\n",
        "      f1score = validation(model, device, val_loader, criterion, 0.5)\n",
        "\n",
        "      # https://www.kaggle.com/general/178486\n",
        "      if f1score > best_f1_score:\n",
        "          best_f1_score = f1score\n",
        "          es = 0\n",
        "          torch.save(model, str(n_hidden)+\"model.pt\")\n",
        "      else:\n",
        "          es += 1\n",
        "          print(\"Counter {} of 3\".format(es))\n",
        "\n",
        "          if es >= 3:\n",
        "              print(\"Early stopping with best loss: \", loss, \"and val_acc for this epoch: \", f1score)\n",
        "              break\n",
        "  return best_f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzYeq-jBpfJ-",
        "outputId": "d5f49494-4d9f-4cdf-f771-f68866d9eaa5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| ID | GPU | MEM |\n",
            "------------------\n",
            "|  0 |  0% | 59% |\n",
            "| ID | GPU | MEM |\n",
            "------------------\n",
            "|  0 |  5% | 59% |\n",
            "| ID | GPU | MEM |\n",
            "------------------\n",
            "|  0 |  5% | 59% |\n",
            "Model initialized.\n",
            "Train Epoch: 0 [0/24000 (0%)]\tLoss: 0.683889 \t Time:  1.106834\n",
            "Train Epoch: 0 [3200/24000 (13%)]\tLoss: 0.594692 \t Time:  25.169781\n",
            "Train Epoch: 0 [6400/24000 (27%)]\tLoss: 0.587987 \t Time:  49.424859\n",
            "Train Epoch: 0 [9600/24000 (40%)]\tLoss: 0.573744 \t Time:  73.521507\n",
            "Train Epoch: 0 [12800/24000 (53%)]\tLoss: 0.575863 \t Time:  97.593418\n",
            "Train Epoch: 0 [16000/24000 (67%)]\tLoss: 0.577518 \t Time:  121.688796\n",
            "Train Epoch: 0 [19200/24000 (80%)]\tLoss: 0.574601 \t Time:  146.181824\n",
            "Train Epoch: 0 [22400/24000 (93%)]\tLoss: 0.573209 \t Time:  170.317933\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.83      0.84      4607\n",
            "           1       0.03      0.02      0.02       224\n",
            "           2       0.41      0.39      0.40       871\n",
            "           3       0.00      0.00      0.00       243\n",
            "           4       0.23      0.71      0.34       223\n",
            "           5       0.66      0.20      0.31       271\n",
            "           6       0.00      0.00      0.00       211\n",
            "           7       0.38      0.07      0.12       457\n",
            "           8       1.00      0.01      0.02       231\n",
            "           9       0.12      0.00      0.01       289\n",
            "          10       0.00      0.00      0.00       112\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.00      0.00      0.00       107\n",
            "          13       0.00      0.00      0.00        50\n",
            "          14       0.00      0.00      0.00       376\n",
            "          15       0.06      0.00      0.01       208\n",
            "          16       1.00      0.00      0.01       255\n",
            "          17       0.00      0.00      0.00       270\n",
            "          18       0.00      0.00      0.00       216\n",
            "\n",
            "   micro avg       0.68      0.48      0.56      9221\n",
            "   macro avg       0.25      0.12      0.11      9221\n",
            "weighted avg       0.56      0.48      0.48      9221\n",
            " samples avg       0.63      0.56      0.57      9221\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5735, Accuracy: 2358.0/6000 (39.30%)\n",
            ", F1 score: 0.5700\n",
            "Train Epoch: 1 [0/24000 (0%)]\tLoss: 0.573398 \t Time:  1.057379\n",
            "Train Epoch: 1 [3200/24000 (13%)]\tLoss: 0.574608 \t Time:  25.165330\n",
            "Train Epoch: 1 [6400/24000 (27%)]\tLoss: 0.570998 \t Time:  49.221699\n",
            "Train Epoch: 1 [9600/24000 (40%)]\tLoss: 0.573176 \t Time:  73.278935\n",
            "Train Epoch: 1 [12800/24000 (53%)]\tLoss: 0.572392 \t Time:  97.327309\n",
            "Train Epoch: 1 [16000/24000 (67%)]\tLoss: 0.570880 \t Time:  121.385100\n",
            "Train Epoch: 1 [19200/24000 (80%)]\tLoss: 0.567709 \t Time:  145.465127\n",
            "Train Epoch: 1 [22400/24000 (93%)]\tLoss: 0.568814 \t Time:  169.560800\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.90      0.87      4607\n",
            "           1       0.02      0.00      0.01       224\n",
            "           2       0.38      0.55      0.45       871\n",
            "           3       1.00      0.01      0.02       243\n",
            "           4       0.23      0.69      0.34       223\n",
            "           5       0.62      0.04      0.07       271\n",
            "           6       1.00      0.07      0.12       211\n",
            "           7       0.27      0.35      0.31       457\n",
            "           8       0.05      0.00      0.01       231\n",
            "           9       0.36      0.03      0.05       289\n",
            "          10       0.00      0.00      0.00       112\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.88      0.21      0.35       107\n",
            "          13       0.00      0.00      0.00        50\n",
            "          14       0.00      0.00      0.00       376\n",
            "          15       0.12      0.00      0.01       208\n",
            "          16       0.83      0.10      0.18       255\n",
            "          17       0.00      0.00      0.00       270\n",
            "          18       0.00      0.00      0.00       216\n",
            "\n",
            "   micro avg       0.66      0.54      0.59      9221\n",
            "   macro avg       0.35      0.16      0.15      9221\n",
            "weighted avg       0.59      0.54      0.52      9221\n",
            " samples avg       0.67      0.62      0.62      9221\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5727, Accuracy: 2460.0/6000 (41.00%)\n",
            ", F1 score: 0.6152\n",
            "Train Epoch: 2 [0/24000 (0%)]\tLoss: 0.569003 \t Time:  1.036035\n",
            "Train Epoch: 2 [3200/24000 (13%)]\tLoss: 0.569902 \t Time:  25.108818\n",
            "Train Epoch: 2 [6400/24000 (27%)]\tLoss: 0.569321 \t Time:  49.167676\n",
            "Train Epoch: 2 [9600/24000 (40%)]\tLoss: 0.567231 \t Time:  73.222537\n",
            "Train Epoch: 2 [12800/24000 (53%)]\tLoss: 0.568246 \t Time:  97.229546\n",
            "Train Epoch: 2 [16000/24000 (67%)]\tLoss: 0.571724 \t Time:  121.302678\n",
            "Train Epoch: 2 [19200/24000 (80%)]\tLoss: 0.568921 \t Time:  145.388945\n",
            "Train Epoch: 2 [22400/24000 (93%)]\tLoss: 0.567775 \t Time:  169.491311\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.87      0.85      4607\n",
            "           1       0.02      0.01      0.02       224\n",
            "           2       0.28      0.46      0.35       871\n",
            "           3       0.00      0.00      0.00       243\n",
            "           4       0.20      0.76      0.31       223\n",
            "           5       1.00      0.00      0.01       271\n",
            "           6       0.97      0.15      0.26       211\n",
            "           7       0.19      0.40      0.26       457\n",
            "           8       0.09      0.12      0.11       231\n",
            "           9       0.37      0.05      0.09       289\n",
            "          10       0.00      0.00      0.00       112\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.91      0.27      0.42       107\n",
            "          13       0.00      0.00      0.00        50\n",
            "          14       0.00      0.00      0.00       376\n",
            "          15       0.00      0.00      0.00       208\n",
            "          16       1.00      0.21      0.34       255\n",
            "          17       0.00      0.00      0.00       270\n",
            "          18       0.00      0.00      0.00       216\n",
            "\n",
            "   micro avg       0.57      0.53      0.55      9221\n",
            "   macro avg       0.31      0.17      0.16      9221\n",
            "weighted avg       0.56      0.53      0.51      9221\n",
            " samples avg       0.60      0.61      0.58      9221\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5668, Accuracy: 2135.0/6000 (35.58%)\n",
            ", F1 score: 0.5795\n",
            "Counter 1 of 3\n",
            "Train Epoch: 3 [0/24000 (0%)]\tLoss: 0.565570 \t Time:  1.063179\n",
            "Train Epoch: 3 [3200/24000 (13%)]\tLoss: 0.563702 \t Time:  25.138926\n",
            "Train Epoch: 3 [6400/24000 (27%)]\tLoss: 0.564338 \t Time:  49.218960\n",
            "Train Epoch: 3 [9600/24000 (40%)]\tLoss: 0.566903 \t Time:  73.257456\n",
            "Train Epoch: 3 [12800/24000 (53%)]\tLoss: 0.559540 \t Time:  97.348206\n",
            "Train Epoch: 3 [16000/24000 (67%)]\tLoss: 0.561629 \t Time:  121.431858\n",
            "Train Epoch: 3 [19200/24000 (80%)]\tLoss: 0.560894 \t Time:  145.531944\n",
            "Train Epoch: 3 [22400/24000 (93%)]\tLoss: 0.564228 \t Time:  169.641100\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.86      0.87      4607\n",
            "           1       0.03      0.02      0.02       224\n",
            "           2       0.32      0.51      0.39       871\n",
            "           3       1.00      0.00      0.01       243\n",
            "           4       0.22      0.89      0.35       223\n",
            "           5       0.78      0.03      0.05       271\n",
            "           6       0.97      0.16      0.28       211\n",
            "           7       0.23      0.44      0.30       457\n",
            "           8       0.17      0.02      0.04       231\n",
            "           9       0.26      0.04      0.07       289\n",
            "          10       0.00      0.00      0.00       112\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       1.00      0.10      0.19       107\n",
            "          13       0.00      0.00      0.00        50\n",
            "          14       0.00      0.00      0.00       376\n",
            "          15       0.96      0.11      0.19       208\n",
            "          16       0.99      0.60      0.75       255\n",
            "          17       0.00      0.00      0.00       270\n",
            "          18       0.00      0.00      0.00       216\n",
            "\n",
            "   micro avg       0.62      0.55      0.58      9221\n",
            "   macro avg       0.41      0.20      0.18      9221\n",
            "weighted avg       0.63      0.55      0.53      9221\n",
            " samples avg       0.66      0.63      0.62      9221\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5625, Accuracy: 2528.0/6000 (42.13%)\n",
            ", F1 score: 0.6190\n",
            "Train Epoch: 4 [0/24000 (0%)]\tLoss: 0.560948 \t Time:  1.027218\n",
            "Train Epoch: 4 [3200/24000 (13%)]\tLoss: 0.563416 \t Time:  25.134763\n",
            "Train Epoch: 4 [6400/24000 (27%)]\tLoss: 0.565252 \t Time:  49.189978\n",
            "Train Epoch: 4 [9600/24000 (40%)]\tLoss: 0.557478 \t Time:  73.275309\n",
            "Train Epoch: 4 [12800/24000 (53%)]\tLoss: 0.559569 \t Time:  97.404381\n",
            "Train Epoch: 4 [16000/24000 (67%)]\tLoss: 0.562205 \t Time:  121.579150\n",
            "Train Epoch: 4 [19200/24000 (80%)]\tLoss: 0.557047 \t Time:  145.739671\n",
            "Train Epoch: 4 [22400/24000 (93%)]\tLoss: 0.563541 \t Time:  169.835210\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.87      0.87      4607\n",
            "           1       0.03      0.02      0.02       224\n",
            "           2       0.34      0.53      0.41       871\n",
            "           3       1.00      0.14      0.24       243\n",
            "           4       0.26      0.91      0.41       223\n",
            "           5       0.95      0.07      0.12       271\n",
            "           6       1.00      0.18      0.31       211\n",
            "           7       0.29      0.42      0.34       457\n",
            "           8       0.33      0.00      0.01       231\n",
            "           9       0.21      0.01      0.02       289\n",
            "          10       0.00      0.00      0.00       112\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.95      0.34      0.50       107\n",
            "          13       0.00      0.00      0.00        50\n",
            "          14       0.00      0.00      0.00       376\n",
            "          15       0.95      0.25      0.40       208\n",
            "          16       0.99      0.62      0.76       255\n",
            "          17       0.00      0.00      0.00       270\n",
            "          18       0.00      0.00      0.00       216\n",
            "\n",
            "   micro avg       0.66      0.56      0.61      9221\n",
            "   macro avg       0.43      0.23      0.23      9221\n",
            "weighted avg       0.64      0.56      0.56      9221\n",
            " samples avg       0.68      0.65      0.64      9221\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5610, Accuracy: 2617.0/6000 (43.62%)\n",
            ", F1 score: 0.6391\n",
            "Train Epoch: 5 [0/24000 (0%)]\tLoss: 0.561515 \t Time:  1.042396\n",
            "Train Epoch: 5 [3200/24000 (13%)]\tLoss: 0.562850 \t Time:  25.181460\n",
            "Train Epoch: 5 [6400/24000 (27%)]\tLoss: 0.557455 \t Time:  49.278750\n",
            "Train Epoch: 5 [9600/24000 (40%)]\tLoss: 0.561902 \t Time:  73.358603\n",
            "Train Epoch: 5 [12800/24000 (53%)]\tLoss: 0.561125 \t Time:  97.365825\n",
            "Train Epoch: 5 [16000/24000 (67%)]\tLoss: 0.560563 \t Time:  121.446833\n",
            "Train Epoch: 5 [19200/24000 (80%)]\tLoss: 0.557945 \t Time:  145.529360\n",
            "Train Epoch: 5 [22400/24000 (93%)]\tLoss: 0.561104 \t Time:  169.630593\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.85      0.86      4607\n",
            "           1       0.03      0.01      0.01       224\n",
            "           2       0.30      0.58      0.40       871\n",
            "           3       0.99      0.39      0.56       243\n",
            "           4       0.33      0.87      0.48       223\n",
            "           5       0.71      0.15      0.25       271\n",
            "           6       0.94      0.27      0.42       211\n",
            "           7       0.28      0.45      0.35       457\n",
            "           8       0.04      0.01      0.01       231\n",
            "           9       0.33      0.03      0.06       289\n",
            "          10       1.00      0.02      0.04       112\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.71      0.50      0.58       107\n",
            "          13       0.00      0.00      0.00        50\n",
            "          14       0.00      0.00      0.00       376\n",
            "          15       0.98      0.27      0.43       208\n",
            "          16       0.99      0.45      0.62       255\n",
            "          17       0.00      0.00      0.00       270\n",
            "          18       0.00      0.00      0.00       216\n",
            "\n",
            "   micro avg       0.65      0.57      0.61      9221\n",
            "   macro avg       0.45      0.26      0.27      9221\n",
            "weighted avg       0.64      0.57      0.57      9221\n",
            " samples avg       0.65      0.65      0.62      9221\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5600, Accuracy: 2359.0/6000 (39.32%)\n",
            ", F1 score: 0.6222\n",
            "Counter 1 of 3\n",
            "Train Epoch: 6 [0/24000 (0%)]\tLoss: 0.556587 \t Time:  1.050076\n",
            "Train Epoch: 6 [3200/24000 (13%)]\tLoss: 0.557834 \t Time:  25.160915\n",
            "Train Epoch: 6 [6400/24000 (27%)]\tLoss: 0.561983 \t Time:  49.258415\n",
            "Train Epoch: 6 [9600/24000 (40%)]\tLoss: 0.558661 \t Time:  73.324486\n",
            "Train Epoch: 6 [12800/24000 (53%)]\tLoss: 0.560011 \t Time:  97.443121\n",
            "Train Epoch: 6 [16000/24000 (67%)]\tLoss: 0.561045 \t Time:  121.591648\n",
            "Train Epoch: 6 [19200/24000 (80%)]\tLoss: 0.561429 \t Time:  145.716701\n",
            "Train Epoch: 6 [22400/24000 (93%)]\tLoss: 0.559229 \t Time:  169.824931\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.88      0.87      4607\n",
            "           1       0.03      0.02      0.03       224\n",
            "           2       0.33      0.54      0.41       871\n",
            "           3       1.00      0.37      0.54       243\n",
            "           4       0.31      0.89      0.46       223\n",
            "           5       0.82      0.18      0.30       271\n",
            "           6       0.98      0.20      0.34       211\n",
            "           7       0.33      0.37      0.35       457\n",
            "           8       0.35      0.03      0.06       231\n",
            "           9       0.56      0.02      0.03       289\n",
            "          10       0.00      0.00      0.00       112\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.81      0.44      0.57       107\n",
            "          13       0.00      0.00      0.00        50\n",
            "          14       0.00      0.00      0.00       376\n",
            "          15       1.00      0.30      0.46       208\n",
            "          16       0.99      0.66      0.79       255\n",
            "          17       0.00      0.00      0.00       270\n",
            "          18       0.00      0.00      0.00       216\n",
            "\n",
            "   micro avg       0.68      0.58      0.63      9221\n",
            "   macro avg       0.44      0.26      0.27      9221\n",
            "weighted avg       0.65      0.58      0.58      9221\n",
            " samples avg       0.70      0.66      0.66      9221\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5594, Accuracy: 2645.0/6000 (44.08%)\n",
            ", F1 score: 0.6552\n",
            "Train Epoch: 7 [0/24000 (0%)]\tLoss: 0.561175 \t Time:  1.043802\n",
            "Train Epoch: 7 [3200/24000 (13%)]\tLoss: 0.558831 \t Time:  25.157719\n",
            "Train Epoch: 7 [6400/24000 (27%)]\tLoss: 0.558984 \t Time:  49.275195\n",
            "Train Epoch: 7 [9600/24000 (40%)]\tLoss: 0.557475 \t Time:  73.369153\n",
            "Train Epoch: 7 [12800/24000 (53%)]\tLoss: 0.558044 \t Time:  97.442404\n",
            "Train Epoch: 7 [16000/24000 (67%)]\tLoss: 0.561318 \t Time:  121.553597\n",
            "Train Epoch: 7 [19200/24000 (80%)]\tLoss: 0.559749 \t Time:  145.652919\n",
            "Train Epoch: 7 [22400/24000 (93%)]\tLoss: 0.558114 \t Time:  169.699083\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.86      0.87      4607\n",
            "           1       0.12      0.07      0.09       224\n",
            "           2       0.30      0.51      0.38       871\n",
            "           3       1.00      0.20      0.34       243\n",
            "           4       0.29      0.94      0.44       223\n",
            "           5       0.90      0.20      0.33       271\n",
            "           6       0.78      0.47      0.59       211\n",
            "           7       0.30      0.45      0.36       457\n",
            "           8       0.26      0.03      0.05       231\n",
            "           9       0.53      0.03      0.05       289\n",
            "          10       0.00      0.00      0.00       112\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.56      0.51      0.54       107\n",
            "          13       0.00      0.00      0.00        50\n",
            "          14       0.00      0.00      0.00       376\n",
            "          15       0.98      0.38      0.55       208\n",
            "          16       0.99      0.70      0.82       255\n",
            "          17       0.00      0.00      0.00       270\n",
            "          18       0.00      0.00      0.00       216\n",
            "\n",
            "   micro avg       0.66      0.58      0.62      9221\n",
            "   macro avg       0.42      0.28      0.28      9221\n",
            "weighted avg       0.64      0.58      0.58      9221\n",
            " samples avg       0.69      0.67      0.65      9221\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5609, Accuracy: 2575.0/6000 (42.92%)\n",
            ", F1 score: 0.6542\n",
            "Counter 1 of 3\n",
            "Train Epoch: 8 [0/24000 (0%)]\tLoss: 0.562363 \t Time:  1.062863\n",
            "Train Epoch: 8 [3200/24000 (13%)]\tLoss: 0.564895 \t Time:  25.203561\n",
            "Train Epoch: 8 [6400/24000 (27%)]\tLoss: 0.560701 \t Time:  49.295345\n",
            "Train Epoch: 8 [9600/24000 (40%)]\tLoss: 0.561785 \t Time:  73.344254\n",
            "Train Epoch: 8 [12800/24000 (53%)]\tLoss: 0.557509 \t Time:  97.369338\n",
            "Train Epoch: 8 [16000/24000 (67%)]\tLoss: 0.558566 \t Time:  121.406440\n",
            "Train Epoch: 8 [19200/24000 (80%)]\tLoss: 0.560371 \t Time:  145.478491\n",
            "Train Epoch: 8 [22400/24000 (93%)]\tLoss: 0.556075 \t Time:  169.573246\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.86      0.87      4607\n",
            "           1       0.06      0.05      0.05       224\n",
            "           2       0.31      0.62      0.41       871\n",
            "           3       0.97      0.27      0.42       243\n",
            "           4       0.36      0.89      0.51       223\n",
            "           5       0.82      0.13      0.23       271\n",
            "           6       0.88      0.44      0.58       211\n",
            "           7       0.24      0.55      0.33       457\n",
            "           8       0.04      0.00      0.01       231\n",
            "           9       0.38      0.04      0.08       289\n",
            "          10       0.00      0.00      0.00       112\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.47      0.54      0.50       107\n",
            "          13       0.00      0.00      0.00        50\n",
            "          14       0.00      0.00      0.00       376\n",
            "          15       0.95      0.34      0.50       208\n",
            "          16       0.99      0.68      0.81       255\n",
            "          17       0.00      0.00      0.00       270\n",
            "          18       0.00      0.00      0.00       216\n",
            "\n",
            "   micro avg       0.62      0.59      0.61      9221\n",
            "   macro avg       0.39      0.29      0.28      9221\n",
            "weighted avg       0.62      0.59      0.57      9221\n",
            " samples avg       0.67      0.67      0.64      9221\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5601, Accuracy: 2524.0/6000 (42.07%)\n",
            ", F1 score: 0.6429\n",
            "Counter 2 of 3\n",
            "Train Epoch: 9 [0/24000 (0%)]\tLoss: 0.560113 \t Time:  1.045552\n",
            "Train Epoch: 9 [3200/24000 (13%)]\tLoss: 0.553938 \t Time:  25.171085\n",
            "Train Epoch: 9 [6400/24000 (27%)]\tLoss: 0.557805 \t Time:  49.271205\n",
            "Train Epoch: 9 [9600/24000 (40%)]\tLoss: 0.554638 \t Time:  73.368708\n",
            "Train Epoch: 9 [12800/24000 (53%)]\tLoss: 0.563229 \t Time:  97.411866\n",
            "Train Epoch: 9 [16000/24000 (67%)]\tLoss: 0.554059 \t Time:  121.497447\n",
            "Train Epoch: 9 [19200/24000 (80%)]\tLoss: 0.562372 \t Time:  145.554484\n",
            "Train Epoch: 9 [22400/24000 (93%)]\tLoss: 0.556190 \t Time:  169.622450\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.86      0.87      4607\n",
            "           1       0.14      0.08      0.11       224\n",
            "           2       0.28      0.64      0.39       871\n",
            "           3       0.72      0.35      0.47       243\n",
            "           4       0.31      0.86      0.46       223\n",
            "           5       0.88      0.25      0.39       271\n",
            "           6       0.82      0.45      0.58       211\n",
            "           7       0.23      0.54      0.32       457\n",
            "           8       0.11      0.02      0.03       231\n",
            "           9       0.53      0.11      0.18       289\n",
            "          10       1.00      0.03      0.05       112\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.93      0.36      0.52       107\n",
            "          13       0.00      0.00      0.00        50\n",
            "          14       0.00      0.00      0.00       376\n",
            "          15       0.99      0.36      0.53       208\n",
            "          16       0.94      0.57      0.71       255\n",
            "          17       0.00      0.00      0.00       270\n",
            "          18       0.00      0.00      0.00       216\n",
            "\n",
            "   micro avg       0.62      0.60      0.61      9221\n",
            "   macro avg       0.46      0.29      0.30      9221\n",
            "weighted avg       0.65      0.60      0.58      9221\n",
            " samples avg       0.65      0.66      0.63      9221\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5599, Accuracy: 2335.0/6000 (38.92%)\n",
            ", F1 score: 0.6261\n",
            "Counter 3 of 3\n",
            "Early stopping with best loss:  0.5584481536547343 and val_acc for this epoch:  0.626052946127946\n"
          ]
        }
      ],
      "source": [
        "n_hidden_list = [32, 64, 128]\n",
        "\n",
        "n_hidden_32 = n_hidden_tuning(32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_n_MflbYbYj"
      },
      "outputs": [],
      "source": [
        "n_hidden_32 = 0.5776"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_34Wk5aRqGPb",
        "outputId": "0210547f-dbab-4d34-d772-818111d0ee31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| ID | GPU | MEM |\n",
            "------------------\n",
            "|  0 |  0% | 59% |\n",
            "| ID | GPU | MEM |\n",
            "------------------\n",
            "|  0 |  5% | 59% |\n",
            "| ID | GPU | MEM |\n",
            "------------------\n",
            "|  0 |  5% | 59% |\n",
            "Model initialized.\n",
            "Train Epoch: 0 [0/24000 (0%)]\tLoss: 0.690795 \t Time:  1.219042\n",
            "Train Epoch: 0 [3200/24000 (13%)]\tLoss: 0.608334 \t Time:  25.928183\n",
            "Train Epoch: 0 [6400/24000 (27%)]\tLoss: 0.604082 \t Time:  50.244909\n",
            "Train Epoch: 0 [9600/24000 (40%)]\tLoss: 0.594228 \t Time:  74.287362\n",
            "Train Epoch: 0 [12800/24000 (53%)]\tLoss: 0.593457 \t Time:  98.517852\n",
            "Train Epoch: 0 [16000/24000 (67%)]\tLoss: 0.588798 \t Time:  122.865381\n",
            "Train Epoch: 0 [19200/24000 (80%)]\tLoss: 0.590519 \t Time:  146.960907\n",
            "Train Epoch: 0 [22400/24000 (93%)]\tLoss: 0.587410 \t Time:  171.363304\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.96      0.88      4607\n",
            "           1       0.00      0.00      0.00       224\n",
            "           2       0.47      0.31      0.38       871\n",
            "           3       0.22      0.05      0.09       243\n",
            "           4       0.50      0.31      0.38       223\n",
            "           5       1.00      0.00      0.01       271\n",
            "           6       0.38      0.20      0.26       211\n",
            "           7       0.13      0.64      0.21       457\n",
            "           8       0.00      0.00      0.00       231\n",
            "           9       0.10      0.00      0.01       289\n",
            "          10       0.00      0.00      0.00       112\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.01      0.04      0.02       107\n",
            "          13       0.02      0.40      0.03        50\n",
            "          14       0.00      0.00      0.00       376\n",
            "          15       0.50      0.02      0.04       208\n",
            "          16       0.50      0.00      0.01       255\n",
            "          17       0.00      0.00      0.00       270\n",
            "          18       0.00      0.00      0.00       216\n",
            "\n",
            "   micro avg       0.51      0.56      0.53      9221\n",
            "   macro avg       0.24      0.16      0.12      9221\n",
            "weighted avg       0.54      0.56      0.50      9221\n",
            " samples avg       0.59      0.63      0.58      9221\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5924, Accuracy: 1905.0/6000 (31.75%)\n",
            ", F1 score: 0.5773\n",
            "Train Epoch: 1 [0/24000 (0%)]\tLoss: 0.586239 \t Time:  1.098965\n",
            "Train Epoch: 1 [3200/24000 (13%)]\tLoss: 0.587936 \t Time:  25.281577\n",
            "Train Epoch: 1 [6400/24000 (27%)]\tLoss: 0.587905 \t Time:  49.399269\n",
            "Train Epoch: 1 [9600/24000 (40%)]\tLoss: 0.583784 \t Time:  73.724751\n",
            "Train Epoch: 1 [12800/24000 (53%)]\tLoss: 0.583773 \t Time:  97.795653\n",
            "Train Epoch: 1 [16000/24000 (67%)]\tLoss: 0.586744 \t Time:  121.874189\n",
            "Train Epoch: 1 [19200/24000 (80%)]\tLoss: 0.583261 \t Time:  145.937683\n",
            "Train Epoch: 1 [22400/24000 (93%)]\tLoss: 0.579095 \t Time:  170.018516\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.94      0.88      4607\n",
            "           1       0.00      0.00      0.00       224\n",
            "           2       0.44      0.32      0.37       871\n",
            "           3       0.22      0.19      0.20       243\n",
            "           4       0.67      0.44      0.53       223\n",
            "           5       0.00      0.00      0.00       271\n",
            "           6       0.24      0.53      0.33       211\n",
            "           7       0.15      0.68      0.25       457\n",
            "           8       0.00      0.00      0.00       231\n",
            "           9       0.08      0.11      0.09       289\n",
            "          10       0.00      0.00      0.00       112\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.03      0.02      0.02       107\n",
            "          13       0.01      0.18      0.01        50\n",
            "          14       1.00      0.01      0.01       376\n",
            "          15       0.00      0.00      0.00       208\n",
            "          16       0.91      0.13      0.22       255\n",
            "          17       0.82      0.07      0.12       270\n",
            "          18       0.33      0.00      0.01       216\n",
            "\n",
            "   micro avg       0.49      0.57      0.53      9221\n",
            "   macro avg       0.30      0.19      0.16      9221\n",
            "weighted avg       0.59      0.57      0.53      9221\n",
            " samples avg       0.52      0.65      0.55      9221\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5851, Accuracy: 1184.0/6000 (19.73%)\n",
            ", F1 score: 0.5459\n",
            "Counter 1 of 3\n",
            "Train Epoch: 2 [0/24000 (0%)]\tLoss: 0.582838 \t Time:  1.053630\n",
            "Train Epoch: 2 [3200/24000 (13%)]\tLoss: 0.584742 \t Time:  25.156943\n",
            "Train Epoch: 2 [6400/24000 (27%)]\tLoss: 0.585931 \t Time:  49.273523\n",
            "Train Epoch: 2 [9600/24000 (40%)]\tLoss: 0.583103 \t Time:  73.446887\n",
            "Train Epoch: 2 [12800/24000 (53%)]\tLoss: 0.581490 \t Time:  97.682934\n",
            "Train Epoch: 2 [16000/24000 (67%)]\tLoss: 0.581854 \t Time:  121.860883\n",
            "Train Epoch: 2 [19200/24000 (80%)]\tLoss: 0.583558 \t Time:  146.035000\n",
            "Train Epoch: 2 [22400/24000 (93%)]\tLoss: 0.584831 \t Time:  170.256482\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.94      0.88      4607\n",
            "           1       0.00      0.00      0.00       224\n",
            "           2       0.42      0.23      0.29       871\n",
            "           3       0.45      0.24      0.31       243\n",
            "           4       0.34      0.73      0.47       223\n",
            "           5       1.00      0.00      0.01       271\n",
            "           6       0.26      0.34      0.29       211\n",
            "           7       0.14      0.53      0.22       457\n",
            "           8       0.50      0.03      0.05       231\n",
            "           9       0.29      0.31      0.30       289\n",
            "          10       0.00      0.00      0.00       112\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.00      0.00      0.00       107\n",
            "          13       0.01      0.16      0.02        50\n",
            "          14       0.00      0.00      0.00       376\n",
            "          15       1.00      0.01      0.03       208\n",
            "          16       0.90      0.47      0.62       255\n",
            "          17       0.98      0.23      0.37       270\n",
            "          18       0.48      0.06      0.10       216\n",
            "\n",
            "   micro avg       0.57      0.58      0.57      9221\n",
            "   macro avg       0.40      0.22      0.21      9221\n",
            "weighted avg       0.63      0.58      0.55      9221\n",
            " samples avg       0.63      0.67      0.61      9221\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5833, Accuracy: 2042.0/6000 (34.03%)\n",
            ", F1 score: 0.6126\n",
            "Train Epoch: 3 [0/24000 (0%)]\tLoss: 0.580915 \t Time:  1.113147\n",
            "Train Epoch: 3 [3200/24000 (13%)]\tLoss: 0.576094 \t Time:  25.295838\n",
            "Train Epoch: 3 [6400/24000 (27%)]\tLoss: 0.580392 \t Time:  49.417007\n",
            "Train Epoch: 3 [9600/24000 (40%)]\tLoss: 0.580632 \t Time:  73.524644\n",
            "Train Epoch: 3 [12800/24000 (53%)]\tLoss: 0.579884 \t Time:  97.604837\n",
            "Train Epoch: 3 [16000/24000 (67%)]\tLoss: 0.580994 \t Time:  121.721459\n",
            "Train Epoch: 3 [19200/24000 (80%)]\tLoss: 0.576616 \t Time:  145.803311\n",
            "Train Epoch: 3 [22400/24000 (93%)]\tLoss: 0.580022 \t Time:  169.923687\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.96      0.90      4607\n",
            "           1       0.00      0.00      0.00       224\n",
            "           2       0.52      0.18      0.27       871\n",
            "           3       0.80      0.02      0.03       243\n",
            "           4       0.37      0.62      0.47       223\n",
            "           5       1.00      0.02      0.04       271\n",
            "           6       0.22      0.63      0.32       211\n",
            "           7       0.14      0.56      0.22       457\n",
            "           8       0.56      0.02      0.04       231\n",
            "           9       0.22      0.11      0.15       289\n",
            "          10       0.00      0.00      0.00       112\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.67      0.02      0.04       107\n",
            "          13       0.01      0.10      0.02        50\n",
            "          14       0.56      0.01      0.03       376\n",
            "          15       1.00      0.00      0.01       208\n",
            "          16       0.96      0.59      0.73       255\n",
            "          17       0.96      0.29      0.44       270\n",
            "          18       0.81      0.06      0.11       216\n",
            "\n",
            "   micro avg       0.59      0.59      0.59      9221\n",
            "   macro avg       0.51      0.22      0.20      9221\n",
            "weighted avg       0.69      0.59      0.55      9221\n",
            " samples avg       0.66      0.68      0.64      9221\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5798, Accuracy: 2183.0/6000 (36.38%)\n",
            ", F1 score: 0.6368\n",
            "Train Epoch: 4 [0/24000 (0%)]\tLoss: 0.577587 \t Time:  1.046233\n",
            "Train Epoch: 4 [3200/24000 (13%)]\tLoss: 0.579217 \t Time:  25.165018\n",
            "Train Epoch: 4 [6400/24000 (27%)]\tLoss: 0.577990 \t Time:  49.233373\n",
            "Train Epoch: 4 [9600/24000 (40%)]\tLoss: 0.580477 \t Time:  73.294459\n",
            "Train Epoch: 4 [12800/24000 (53%)]\tLoss: 0.578984 \t Time:  97.347505\n",
            "Train Epoch: 4 [16000/24000 (67%)]\tLoss: 0.577681 \t Time:  121.374093\n",
            "Train Epoch: 4 [19200/24000 (80%)]\tLoss: 0.580438 \t Time:  145.475538\n",
            "Train Epoch: 4 [22400/24000 (93%)]\tLoss: 0.580278 \t Time:  169.593978\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.97      0.89      4607\n",
            "           1       0.00      0.00      0.00       224\n",
            "           2       0.41      0.04      0.08       871\n",
            "           3       0.86      0.13      0.22       243\n",
            "           4       0.53      0.77      0.63       223\n",
            "           5       0.88      0.24      0.38       271\n",
            "           6       0.15      0.36      0.21       211\n",
            "           7       0.13      0.50      0.21       457\n",
            "           8       0.67      0.03      0.07       231\n",
            "           9       0.19      0.19      0.19       289\n",
            "          10       1.00      0.01      0.02       112\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.17      0.03      0.05       107\n",
            "          13       0.02      0.18      0.03        50\n",
            "          14       0.57      0.05      0.10       376\n",
            "          15       1.00      0.01      0.02       208\n",
            "          16       0.93      0.77      0.84       255\n",
            "          17       0.96      0.29      0.44       270\n",
            "          18       0.85      0.13      0.22       216\n",
            "\n",
            "   micro avg       0.59      0.59      0.59      9221\n",
            "   macro avg       0.53      0.25      0.24      9221\n",
            "weighted avg       0.68      0.59      0.56      9221\n",
            " samples avg       0.66      0.70      0.64      9221\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5805, Accuracy: 2107.0/6000 (35.12%)\n",
            ", F1 score: 0.6420\n",
            "Train Epoch: 5 [0/24000 (0%)]\tLoss: 0.577705 \t Time:  1.056337\n",
            "Train Epoch: 5 [3200/24000 (13%)]\tLoss: 0.576708 \t Time:  25.180019\n",
            "Train Epoch: 5 [6400/24000 (27%)]\tLoss: 0.582650 \t Time:  49.242128\n",
            "Train Epoch: 5 [9600/24000 (40%)]\tLoss: 0.579984 \t Time:  73.343774\n",
            "Train Epoch: 5 [12800/24000 (53%)]\tLoss: 0.574817 \t Time:  97.405083\n",
            "Train Epoch: 5 [16000/24000 (67%)]\tLoss: 0.579111 \t Time:  121.497300\n",
            "Train Epoch: 5 [19200/24000 (80%)]\tLoss: 0.579090 \t Time:  145.611872\n",
            "Train Epoch: 5 [22400/24000 (93%)]\tLoss: 0.579103 \t Time:  169.701565\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.99      0.89      4607\n",
            "           1       0.00      0.00      0.00       224\n",
            "           2       0.50      0.17      0.25       871\n",
            "           3       0.59      0.11      0.18       243\n",
            "           4       0.55      0.70      0.61       223\n",
            "           5       0.97      0.11      0.20       271\n",
            "           6       0.20      0.30      0.24       211\n",
            "           7       0.13      0.51      0.21       457\n",
            "           8       0.89      0.03      0.07       231\n",
            "           9       0.24      0.15      0.18       289\n",
            "          10       0.00      0.00      0.00       112\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.80      0.04      0.07       107\n",
            "          13       0.01      0.12      0.02        50\n",
            "          14       0.92      0.06      0.11       376\n",
            "          15       1.00      0.00      0.01       208\n",
            "          16       0.88      0.75      0.81       255\n",
            "          17       0.97      0.28      0.43       270\n",
            "          18       0.70      0.07      0.13       216\n",
            "\n",
            "   micro avg       0.59      0.60      0.59      9221\n",
            "   macro avg       0.53      0.23      0.23      9221\n",
            "weighted avg       0.69      0.60      0.56      9221\n",
            " samples avg       0.67      0.70      0.65      9221\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5779, Accuracy: 2101.0/6000 (35.02%)\n",
            ", F1 score: 0.6463\n",
            "Train Epoch: 6 [0/24000 (0%)]\tLoss: 0.578319 \t Time:  1.043787\n",
            "Train Epoch: 6 [3200/24000 (13%)]\tLoss: 0.582228 \t Time:  25.147657\n",
            "Train Epoch: 6 [6400/24000 (27%)]\tLoss: 0.581125 \t Time:  49.232468\n",
            "Train Epoch: 6 [9600/24000 (40%)]\tLoss: 0.578624 \t Time:  73.328556\n",
            "Train Epoch: 6 [12800/24000 (53%)]\tLoss: 0.577006 \t Time:  97.392847\n",
            "Train Epoch: 6 [16000/24000 (67%)]\tLoss: 0.577566 \t Time:  121.470268\n",
            "Train Epoch: 6 [19200/24000 (80%)]\tLoss: 0.577105 \t Time:  145.552855\n",
            "Train Epoch: 6 [22400/24000 (93%)]\tLoss: 0.578882 \t Time:  169.664585\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.98      0.89      4607\n",
            "           1       0.00      0.00      0.00       224\n",
            "           2       0.48      0.03      0.06       871\n",
            "           3       0.00      0.00      0.00       243\n",
            "           4       0.64      0.44      0.52       223\n",
            "           5       0.96      0.32      0.48       271\n",
            "           6       0.09      0.22      0.13       211\n",
            "           7       0.13      0.50      0.21       457\n",
            "           8       0.97      0.17      0.29       231\n",
            "           9       0.20      0.21      0.21       289\n",
            "          10       1.00      0.01      0.02       112\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.33      0.04      0.07       107\n",
            "          13       0.02      0.18      0.04        50\n",
            "          14       0.67      0.07      0.13       376\n",
            "          15       1.00      0.12      0.21       208\n",
            "          16       0.94      0.75      0.83       255\n",
            "          17       0.99      0.26      0.41       270\n",
            "          18       0.70      0.13      0.22       216\n",
            "\n",
            "   micro avg       0.59      0.59      0.59      9221\n",
            "   macro avg       0.52      0.23      0.25      9221\n",
            "weighted avg       0.67      0.59      0.56      9221\n",
            " samples avg       0.67      0.69      0.64      9221\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5816, Accuracy: 2050.0/6000 (34.17%)\n",
            ", F1 score: 0.6372\n",
            "Counter 1 of 3\n",
            "Train Epoch: 7 [0/24000 (0%)]\tLoss: 0.575361 \t Time:  1.034300\n",
            "Train Epoch: 7 [3200/24000 (13%)]\tLoss: 0.581669 \t Time:  25.132093\n",
            "Train Epoch: 7 [6400/24000 (27%)]\tLoss: 0.580119 \t Time:  49.199964\n",
            "Train Epoch: 7 [9600/24000 (40%)]\tLoss: 0.578627 \t Time:  73.255868\n",
            "Train Epoch: 7 [12800/24000 (53%)]\tLoss: 0.580262 \t Time:  97.331331\n",
            "Train Epoch: 7 [16000/24000 (67%)]\tLoss: 0.577600 \t Time:  121.350496\n",
            "Train Epoch: 7 [19200/24000 (80%)]\tLoss: 0.576320 \t Time:  145.393922\n",
            "Train Epoch: 7 [22400/24000 (93%)]\tLoss: 0.574934 \t Time:  169.458159\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.98      0.89      4607\n",
            "           1       0.00      0.00      0.00       224\n",
            "           2       0.56      0.09      0.15       871\n",
            "           3       0.29      0.01      0.02       243\n",
            "           4       0.88      0.49      0.63       223\n",
            "           5       1.00      0.18      0.30       271\n",
            "           6       0.04      0.16      0.07       211\n",
            "           7       0.13      0.58      0.21       457\n",
            "           8       0.92      0.10      0.17       231\n",
            "           9       0.33      0.26      0.29       289\n",
            "          10       1.00      0.02      0.04       112\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.80      0.07      0.14       107\n",
            "          13       0.01      0.20      0.02        50\n",
            "          14       0.88      0.10      0.18       376\n",
            "          15       1.00      0.03      0.06       208\n",
            "          16       0.97      0.65      0.78       255\n",
            "          17       0.99      0.33      0.49       270\n",
            "          18       0.69      0.18      0.28       216\n",
            "\n",
            "   micro avg       0.54      0.60      0.57      9221\n",
            "   macro avg       0.60      0.23      0.25      9221\n",
            "weighted avg       0.71      0.60      0.56      9221\n",
            " samples avg       0.62      0.69      0.61      9221\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5783, Accuracy: 1785.0/6000 (29.75%)\n",
            ", F1 score: 0.6110\n",
            "Counter 2 of 3\n",
            "Train Epoch: 8 [0/24000 (0%)]\tLoss: 0.577007 \t Time:  1.044824\n",
            "Train Epoch: 8 [3200/24000 (13%)]\tLoss: 0.577564 \t Time:  25.168421\n",
            "Train Epoch: 8 [6400/24000 (27%)]\tLoss: 0.580229 \t Time:  49.259993\n",
            "Train Epoch: 8 [9600/24000 (40%)]\tLoss: 0.577994 \t Time:  73.325220\n",
            "Train Epoch: 8 [12800/24000 (53%)]\tLoss: 0.577391 \t Time:  97.380653\n",
            "Train Epoch: 8 [16000/24000 (67%)]\tLoss: 0.583483 \t Time:  121.449212\n",
            "Train Epoch: 8 [19200/24000 (80%)]\tLoss: 0.578796 \t Time:  145.545647\n",
            "Train Epoch: 8 [22400/24000 (93%)]\tLoss: 0.585474 \t Time:  169.666501\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.98      0.89      4607\n",
            "           1       0.00      0.00      0.00       224\n",
            "           2       0.67      0.03      0.06       871\n",
            "           3       1.00      0.01      0.02       243\n",
            "           4       0.38      0.59      0.46       223\n",
            "           5       0.98      0.18      0.30       271\n",
            "           6       0.09      0.22      0.13       211\n",
            "           7       0.15      0.58      0.23       457\n",
            "           8       1.00      0.14      0.24       231\n",
            "           9       0.32      0.30      0.31       289\n",
            "          10       1.00      0.01      0.02       112\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.73      0.10      0.18       107\n",
            "          13       0.01      0.22      0.03        50\n",
            "          14       0.94      0.16      0.28       376\n",
            "          15       1.00      0.06      0.11       208\n",
            "          16       0.90      0.78      0.84       255\n",
            "          17       0.97      0.29      0.45       270\n",
            "          18       0.51      0.17      0.26       216\n",
            "\n",
            "   micro avg       0.57      0.60      0.58      9221\n",
            "   macro avg       0.60      0.25      0.25      9221\n",
            "weighted avg       0.72      0.60      0.56      9221\n",
            " samples avg       0.64      0.71      0.63      9221\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5779, Accuracy: 1921.0/6000 (32.02%)\n",
            ", F1 score: 0.6340\n",
            "Counter 3 of 3\n",
            "Early stopping with best loss:  0.5784084580739339 and val_acc for this epoch:  0.6339533068783069\n"
          ]
        }
      ],
      "source": [
        "n_hidden_64 = n_hidden_tuning(64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "VAag5eR15xyO",
        "outputId": "104872bd-befa-45f2-e657-2685c197b0ea"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4bfdd8f1-4dfd-4a66-9202-102ee5c7a544\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hidden dimension</th>\n",
              "      <th>f1 score</th>\n",
              "      <th>model size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>32</td>\n",
              "      <td>0.655</td>\n",
              "      <td>95.49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>64</td>\n",
              "      <td>0.646</td>\n",
              "      <td>95.73</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>128</td>\n",
              "      <td>0.871</td>\n",
              "      <td>96.36</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4bfdd8f1-4dfd-4a66-9202-102ee5c7a544')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4bfdd8f1-4dfd-4a66-9202-102ee5c7a544 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4bfdd8f1-4dfd-4a66-9202-102ee5c7a544');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   hidden dimension  f1 score  model size\n",
              "0                32     0.655       95.49\n",
              "1                64     0.646       95.73\n",
              "2               128     0.871       96.36"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_hidden_dict_df = {}\n",
        "n_hidden_dict_df['hidden dimension'] = n_hidden_list\n",
        "n_hidden_dict_df['f1 score'] = [n_hidden_32, n_hidden_64, default_f1_score]\n",
        "n_hidden_dict_df['model size'] = [95.49, 95.73, 96.36]\n",
        "\n",
        "n_hidden_df = pd.DataFrame.from_dict(n_hidden_dict_df)\n",
        "n_hidden_df['f1 score'] = round(n_hidden_df['f1 score'],3)\n",
        "n_hidden_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "7M06-esR6s8H",
        "outputId": "97ac3fb5-2f62-4e0e-ae75-cbca11e1f539"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'f1 score')"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(n_hidden_df['hidden dimension'], n_hidden_df['f1 score'])\n",
        "plt.title(\"f1 score of different hidden dimensions\")\n",
        "plt.xlabel(\"number of hidden dimension\")\n",
        "plt.ylabel(\"f1 score\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYnHc0E6642Z"
      },
      "source": [
        "# word embedding dimension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yNZ2Mudp7Qpv"
      },
      "outputs": [],
      "source": [
        "def word_emb_dim_tuning(emb_dim = 150):\n",
        "\n",
        "  from gensim.models import Word2Vec, FastText\n",
        "  class Text_Embedding(nn.Module):\n",
        "      def __init__(self, word_list, training_data):\n",
        "          super(Text_Embedding, self).__init__()\n",
        "          # self.tokenizer = tokenizer\n",
        "          self.emb_table = None\n",
        "          self.training_data = training_data\n",
        "          # self.model = api.load(\"glove-twitter-25\")\n",
        "          self.model = FastText(sentences=self.training_data, size=emb_dim, window=5, min_count=1, workers=4, sg=1)\n",
        "          self.keys = list(self.model.wv.vocab.keys())\n",
        "          # self.keys = self.model # for glove model\n",
        "          self.emb_dim = self.model.vector_size\n",
        "\n",
        "      def get_embedding(self):\n",
        "          # training model\n",
        "          model = self.model\n",
        "          assert(model is not None)\n",
        "          emb_table = []\n",
        "          for i, word in enumerate(word_list):\n",
        "              if word in self.keys:\n",
        "                  word_emb = model.wv[word] # for word2vec\n",
        "                  # word_emb = model[word]\n",
        "                  emb_table.append(word_emb)\n",
        "              else:\n",
        "                  word_emb = [0]* self.emb_dim\n",
        "                  emb_table.append(word_emb)\n",
        "          emb_table = np.array(emb_table)\n",
        "          self.emb_table = emb_table\n",
        "          return emb_table\n",
        "      \n",
        "  training_data = x_train[\"Caption\"].to_list()\n",
        "  embedding =  Text_Embedding(word_list, training_data)\n",
        "  emb_table = embedding.get_embedding()\n",
        "\n",
        "  device = torch.device('cuda' if torch.cuda.is_available else 'cpu')\n",
        "  img_model = Resnext50(num_class).to(device)\n",
        "  # img_model = DenseNet121(num_class).to(device)\n",
        "  gpu_usage() \n",
        "  # text_model = Bi_LSTM_Attention(emb_table, 256, n_emb = 2048).to(device)\n",
        "  n_hidden = 128\n",
        "  text_model = Bi_GRU_Attention(emb_table, n_hidden, n_emb = 256).to(device)\n",
        "  gpu_usage() \n",
        "  n_emb = 256\n",
        "  model = Concatenate_Embed_Model(img_model, text_model, n_emb, num_class).to(device)\n",
        "  gpu_usage() \n",
        "  print('Model initialized.')\n",
        "\n",
        "  # from torch.optim.lr_scheduler import StepLR\n",
        "  n_epochs = 15\n",
        "  log_interval = 50\n",
        "  lr = 3e-4\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr= lr)\n",
        "\n",
        "  criterion = nn.BCELoss()\n",
        "  train_loss = []\n",
        "  best_f1_score = -float(\"inf\") # record the best loss to get the best model\n",
        "\n",
        "  for epoch in range(n_epochs):\n",
        "      loss = train_epoch(log_interval, model, train_loader, optimizer, epoch, criterion)\n",
        "      train_loss.append(loss)\n",
        "      f1score = validation(model, device, val_loader, criterion, 0.5)\n",
        "\n",
        "      # https://www.kaggle.com/general/178486\n",
        "      if f1score > best_f1_score:\n",
        "          best_f1_score = f1score\n",
        "          es = 0\n",
        "          torch.save(model, 'word_emb'+str(emb_dim)+\"model.pt\")\n",
        "      else:\n",
        "          es += 1\n",
        "          print(\"Counter {} of 3\".format(es))\n",
        "\n",
        "          if es >= 3:\n",
        "              print(\"Early stopping with best loss: \", loss, \"and val_acc for this epoch: \", f1score)\n",
        "              break\n",
        "\n",
        "  return best_f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMYC3aLn6_Rm",
        "outputId": "e935ff90-4028-4465-8a03-5f59c37586af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| ID | GPU | MEM |\n",
            "------------------\n",
            "|  0 |  5% | 59% |\n",
            "| ID | GPU | MEM |\n",
            "------------------\n",
            "|  0 |  0% | 59% |\n",
            "| ID | GPU | MEM |\n",
            "------------------\n",
            "|  0 |  0% | 59% |\n",
            "Model initialized.\n",
            "Train Epoch: 0 [0/24000 (0%)]\tLoss: 0.693250 \t Time:  1.701497\n",
            "Train Epoch: 0 [3200/24000 (13%)]\tLoss: 0.605086 \t Time:  26.745268\n",
            "Train Epoch: 0 [6400/24000 (27%)]\tLoss: 0.596005 \t Time:  50.761876\n",
            "Train Epoch: 0 [9600/24000 (40%)]\tLoss: 0.595074 \t Time:  75.125317\n",
            "Train Epoch: 0 [12800/24000 (53%)]\tLoss: 0.589391 \t Time:  99.156192\n",
            "Train Epoch: 0 [16000/24000 (67%)]\tLoss: 0.592983 \t Time:  123.245176\n",
            "Train Epoch: 0 [19200/24000 (80%)]\tLoss: 0.587870 \t Time:  147.295753\n",
            "Train Epoch: 0 [22400/24000 (93%)]\tLoss: 0.588488 \t Time:  171.419008\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.97      0.88      4607\n",
            "           1       0.00      0.00      0.00       224\n",
            "           2       0.30      0.58      0.40       871\n",
            "           3       0.02      0.03      0.02       243\n",
            "           4       0.00      0.00      0.00       223\n",
            "           5       0.13      0.88      0.22       271\n",
            "           6       0.00      0.00      0.00       211\n",
            "           7       0.00      0.00      0.00       457\n",
            "           8       0.05      0.40      0.10       231\n",
            "           9       0.00      0.00      0.00       289\n",
            "          10       0.06      0.12      0.08       112\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.00      0.00      0.00       107\n",
            "          13       0.00      0.00      0.00        50\n",
            "          14       0.00      0.00      0.00       376\n",
            "          15       0.00      0.00      0.00       208\n",
            "          16       1.00      0.00      0.01       255\n",
            "          17       0.17      0.17      0.17       270\n",
            "          18       0.00      0.00      0.00       216\n",
            "\n",
            "   micro avg       0.46      0.58      0.51      9221\n",
            "   macro avg       0.13      0.17      0.10      9221\n",
            "weighted avg       0.47      0.58      0.49      9221\n",
            " samples avg       0.54      0.65      0.55      9221\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5928, Accuracy: 1504.0/6000 (25.07%)\n",
            ", F1 score: 0.5510\n",
            "Train Epoch: 1 [0/24000 (0%)]\tLoss: 0.583248 \t Time:  1.159662\n",
            "Train Epoch: 1 [3200/24000 (13%)]\tLoss: 0.584254 \t Time:  25.358657\n",
            "Train Epoch: 1 [6400/24000 (27%)]\tLoss: 0.582554 \t Time:  49.418784\n",
            "Train Epoch: 1 [9600/24000 (40%)]\tLoss: 0.582152 \t Time:  73.503514\n",
            "Train Epoch: 1 [12800/24000 (53%)]\tLoss: 0.576341 \t Time:  97.541384\n",
            "Train Epoch: 1 [16000/24000 (67%)]\tLoss: 0.582871 \t Time:  121.641653\n",
            "Train Epoch: 1 [19200/24000 (80%)]\tLoss: 0.585395 \t Time:  145.708063\n",
            "Train Epoch: 1 [22400/24000 (93%)]\tLoss: 0.582478 \t Time:  169.796958\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.98      0.89      4607\n",
            "           1       0.00      0.00      0.00       224\n",
            "           2       0.24      0.25      0.24       871\n",
            "           3       0.12      0.35      0.18       243\n",
            "           4       1.00      0.06      0.12       223\n",
            "           5       0.14      0.46      0.21       271\n",
            "           6       1.00      0.00      0.01       211\n",
            "           7       0.00      0.00      0.00       457\n",
            "           8       0.04      0.08      0.05       231\n",
            "           9       0.00      0.00      0.00       289\n",
            "          10       0.06      0.17      0.08       112\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.00      0.00      0.00       107\n",
            "          13       0.00      0.00      0.00        50\n",
            "          14       0.00      0.00      0.00       376\n",
            "          15       0.00      0.00      0.00       208\n",
            "          16       1.00      0.00      0.01       255\n",
            "          17       0.52      0.04      0.08       270\n",
            "          18       0.00      0.00      0.00       216\n",
            "\n",
            "   micro avg       0.56      0.54      0.55      9221\n",
            "   macro avg       0.26      0.13      0.10      9221\n",
            "weighted avg       0.53      0.54      0.49      9221\n",
            " samples avg       0.60      0.63      0.58      9221\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5814, Accuracy: 1790.0/6000 (29.83%)\n",
            ", F1 score: 0.5760\n",
            "Train Epoch: 2 [0/24000 (0%)]\tLoss: 0.581115 \t Time:  1.120437\n",
            "Train Epoch: 2 [3200/24000 (13%)]\tLoss: 0.584009 \t Time:  25.342712\n",
            "Train Epoch: 2 [6400/24000 (27%)]\tLoss: 0.579973 \t Time:  49.387521\n",
            "Train Epoch: 2 [9600/24000 (40%)]\tLoss: 0.578902 \t Time:  73.469744\n",
            "Train Epoch: 2 [12800/24000 (53%)]\tLoss: 0.581695 \t Time:  97.545726\n",
            "Train Epoch: 2 [16000/24000 (67%)]\tLoss: 0.578464 \t Time:  121.628737\n",
            "Train Epoch: 2 [19200/24000 (80%)]\tLoss: 0.580610 \t Time:  145.657799\n",
            "Train Epoch: 2 [22400/24000 (93%)]\tLoss: 0.578023 \t Time:  169.711527\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.96      0.90      4607\n",
            "           1       0.00      0.00      0.00       224\n",
            "           2       0.22      0.08      0.12       871\n",
            "           3       0.36      0.25      0.29       243\n",
            "           4       1.00      0.04      0.07       223\n",
            "           5       0.22      0.50      0.31       271\n",
            "           6       1.00      0.03      0.06       211\n",
            "           7       0.33      0.00      0.00       457\n",
            "           8       0.15      0.21      0.17       231\n",
            "           9       0.00      0.00      0.00       289\n",
            "          10       0.07      0.12      0.08       112\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.00      0.00      0.00       107\n",
            "          13       0.00      0.00      0.00        50\n",
            "          14       0.00      0.00      0.00       376\n",
            "          15       0.00      0.00      0.00       208\n",
            "          16       0.00      0.00      0.00       255\n",
            "          17       0.86      0.02      0.04       270\n",
            "          18       0.00      0.00      0.00       216\n",
            "\n",
            "   micro avg       0.69      0.52      0.59      9221\n",
            "   macro avg       0.27      0.12      0.11      9221\n",
            "weighted avg       0.55      0.52      0.49      9221\n",
            " samples avg       0.68      0.61      0.61      9221\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5785, Accuracy: 2483.0/6000 (41.38%)\n",
            ", F1 score: 0.6148\n",
            "Train Epoch: 3 [0/24000 (0%)]\tLoss: 0.580020 \t Time:  1.087474\n",
            "Train Epoch: 3 [3200/24000 (13%)]\tLoss: 0.582555 \t Time:  25.295143\n",
            "Train Epoch: 3 [6400/24000 (27%)]\tLoss: 0.582273 \t Time:  49.335934\n",
            "Train Epoch: 3 [9600/24000 (40%)]\tLoss: 0.577318 \t Time:  73.417397\n",
            "Train Epoch: 3 [12800/24000 (53%)]\tLoss: 0.580113 \t Time:  97.516320\n",
            "Train Epoch: 3 [16000/24000 (67%)]\tLoss: 0.577534 \t Time:  121.595714\n",
            "Train Epoch: 3 [19200/24000 (80%)]\tLoss: 0.581023 \t Time:  145.656130\n",
            "Train Epoch: 3 [22400/24000 (93%)]\tLoss: 0.573489 \t Time:  169.759667\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.95      0.90      4607\n",
            "           1       0.00      0.00      0.00       224\n",
            "           2       0.23      0.11      0.15       871\n",
            "           3       0.56      0.23      0.33       243\n",
            "           4       1.00      0.18      0.30       223\n",
            "           5       0.38      0.36      0.37       271\n",
            "           6       0.00      0.00      0.00       211\n",
            "           7       1.00      0.00      0.00       457\n",
            "           8       0.12      0.17      0.14       231\n",
            "           9       0.00      0.00      0.00       289\n",
            "          10       0.05      0.07      0.06       112\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.00      0.00      0.00       107\n",
            "          13       0.00      0.00      0.00        50\n",
            "          14       1.00      0.00      0.01       376\n",
            "          15       0.00      0.00      0.00       208\n",
            "          16       1.00      0.00      0.01       255\n",
            "          17       1.00      0.04      0.08       270\n",
            "          18       0.00      0.00      0.00       216\n",
            "\n",
            "   micro avg       0.73      0.52      0.60      9221\n",
            "   macro avg       0.38      0.11      0.12      9221\n",
            "weighted avg       0.65      0.52      0.50      9221\n",
            " samples avg       0.70      0.61      0.62      9221\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5786, Accuracy: 2572.0/6000 (42.87%)\n",
            ", F1 score: 0.6217\n",
            "Train Epoch: 4 [0/24000 (0%)]\tLoss: 0.581570 \t Time:  1.156687\n",
            "Train Epoch: 4 [3200/24000 (13%)]\tLoss: 0.581057 \t Time:  25.281392\n",
            "Train Epoch: 4 [6400/24000 (27%)]\tLoss: 0.578588 \t Time:  49.344264\n",
            "Train Epoch: 4 [9600/24000 (40%)]\tLoss: 0.579091 \t Time:  73.374341\n",
            "Train Epoch: 4 [12800/24000 (53%)]\tLoss: 0.575205 \t Time:  97.432768\n",
            "Train Epoch: 4 [16000/24000 (67%)]\tLoss: 0.575113 \t Time:  121.502986\n",
            "Train Epoch: 4 [19200/24000 (80%)]\tLoss: 0.578134 \t Time:  145.588999\n",
            "Train Epoch: 4 [22400/24000 (93%)]\tLoss: 0.580448 \t Time:  169.675574\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.96      0.90      4607\n",
            "           1       0.00      0.00      0.00       224\n",
            "           2       0.27      0.11      0.16       871\n",
            "           3       0.62      0.29      0.40       243\n",
            "           4       1.00      0.57      0.72       223\n",
            "           5       0.25      0.51      0.34       271\n",
            "           6       1.00      0.08      0.14       211\n",
            "           7       0.67      0.00      0.01       457\n",
            "           8       0.08      0.39      0.14       231\n",
            "           9       0.00      0.00      0.00       289\n",
            "          10       0.22      0.21      0.22       112\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.00      0.00      0.00       107\n",
            "          13       0.00      0.00      0.00        50\n",
            "          14       0.00      0.00      0.00       376\n",
            "          15       0.00      0.00      0.00       208\n",
            "          16       1.00      0.03      0.05       255\n",
            "          17       0.73      0.07      0.13       270\n",
            "          18       1.00      0.00      0.01       216\n",
            "\n",
            "   micro avg       0.66      0.54      0.60      9221\n",
            "   macro avg       0.41      0.17      0.17      9221\n",
            "weighted avg       0.63      0.54      0.52      9221\n",
            " samples avg       0.67      0.64      0.62      9221\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5795, Accuracy: 2268.0/6000 (37.80%)\n",
            ", F1 score: 0.6193\n",
            "Counter 1 of 3\n",
            "Train Epoch: 5 [0/24000 (0%)]\tLoss: 0.581781 \t Time:  1.125988\n",
            "Train Epoch: 5 [3200/24000 (13%)]\tLoss: 0.577144 \t Time:  25.342112\n",
            "Train Epoch: 5 [6400/24000 (27%)]\tLoss: 0.584321 \t Time:  49.374245\n",
            "Train Epoch: 5 [9600/24000 (40%)]\tLoss: 0.587597 \t Time:  73.404598\n",
            "Train Epoch: 5 [12800/24000 (53%)]\tLoss: 0.578656 \t Time:  97.455895\n",
            "Train Epoch: 5 [16000/24000 (67%)]\tLoss: 0.577209 \t Time:  121.474387\n",
            "Train Epoch: 5 [19200/24000 (80%)]\tLoss: 0.581548 \t Time:  145.522650\n",
            "Train Epoch: 5 [22400/24000 (93%)]\tLoss: 0.573936 \t Time:  169.629602\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.98      0.89      4607\n",
            "           1       0.00      0.00      0.00       224\n",
            "           2       0.31      0.10      0.15       871\n",
            "           3       0.51      0.55      0.53       243\n",
            "           4       1.00      0.23      0.37       223\n",
            "           5       0.48      0.40      0.43       271\n",
            "           6       0.00      0.00      0.00       211\n",
            "           7       1.00      0.01      0.01       457\n",
            "           8       0.17      0.28      0.21       231\n",
            "           9       0.00      0.00      0.00       289\n",
            "          10       0.09      0.20      0.13       112\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.00      0.00      0.00       107\n",
            "          13       0.00      0.00      0.00        50\n",
            "          14       0.00      0.00      0.00       376\n",
            "          15       0.00      0.00      0.00       208\n",
            "          16       1.00      0.03      0.05       255\n",
            "          17       0.68      0.10      0.17       270\n",
            "          18       1.00      0.00      0.01       216\n",
            "\n",
            "   micro avg       0.72      0.54      0.62      9221\n",
            "   macro avg       0.37      0.15      0.16      9221\n",
            "weighted avg       0.61      0.54      0.51      9221\n",
            " samples avg       0.73      0.64      0.65      9221\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5764, Accuracy: 2779.0/6000 (46.32%)\n",
            ", F1 score: 0.6518\n",
            "Train Epoch: 6 [0/24000 (0%)]\tLoss: 0.573214 \t Time:  1.106547\n",
            "Train Epoch: 6 [3200/24000 (13%)]\tLoss: 0.581100 \t Time:  25.328159\n",
            "Train Epoch: 6 [6400/24000 (27%)]\tLoss: 0.575875 \t Time:  49.369257\n",
            "Train Epoch: 6 [9600/24000 (40%)]\tLoss: 0.578592 \t Time:  73.433749\n",
            "Train Epoch: 6 [12800/24000 (53%)]\tLoss: 0.577664 \t Time:  97.520907\n",
            "Train Epoch: 6 [16000/24000 (67%)]\tLoss: 0.577008 \t Time:  121.605374\n",
            "Train Epoch: 6 [19200/24000 (80%)]\tLoss: 0.582543 \t Time:  145.674847\n",
            "Train Epoch: 6 [22400/24000 (93%)]\tLoss: 0.577598 \t Time:  169.745383\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.99      0.88      4607\n",
            "           1       0.00      0.00      0.00       224\n",
            "           2       0.26      0.15      0.19       871\n",
            "           3       0.45      0.17      0.25       243\n",
            "           4       1.00      0.46      0.63       223\n",
            "           5       0.43      0.51      0.47       271\n",
            "           6       0.00      0.00      0.00       211\n",
            "           7       0.00      0.00      0.00       457\n",
            "           8       0.15      0.43      0.22       231\n",
            "           9       0.00      0.00      0.00       289\n",
            "          10       0.15      0.24      0.19       112\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.00      0.00      0.00       107\n",
            "          13       0.00      0.00      0.00        50\n",
            "          14       0.00      0.00      0.00       376\n",
            "          15       0.00      0.00      0.00       208\n",
            "          16       1.00      0.02      0.05       255\n",
            "          17       0.52      0.10      0.17       270\n",
            "          18       1.00      0.04      0.08       216\n",
            "\n",
            "   micro avg       0.67      0.56      0.61      9221\n",
            "   macro avg       0.30      0.16      0.16      9221\n",
            "weighted avg       0.54      0.56      0.51      9221\n",
            " samples avg       0.71      0.65      0.65      9221\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5782, Accuracy: 2611.0/6000 (43.52%)\n",
            ", F1 score: 0.6493\n",
            "Counter 1 of 3\n",
            "Train Epoch: 7 [0/24000 (0%)]\tLoss: 0.575565 \t Time:  1.132204\n",
            "Train Epoch: 7 [3200/24000 (13%)]\tLoss: 0.572995 \t Time:  25.276389\n",
            "Train Epoch: 7 [6400/24000 (27%)]\tLoss: 0.577797 \t Time:  49.332132\n",
            "Train Epoch: 7 [9600/24000 (40%)]\tLoss: 0.576899 \t Time:  73.376096\n",
            "Train Epoch: 7 [12800/24000 (53%)]\tLoss: 0.575109 \t Time:  97.464191\n",
            "Train Epoch: 7 [16000/24000 (67%)]\tLoss: 0.580360 \t Time:  121.549078\n",
            "Train Epoch: 7 [19200/24000 (80%)]\tLoss: 0.579599 \t Time:  145.624919\n",
            "Train Epoch: 7 [22400/24000 (93%)]\tLoss: 0.578475 \t Time:  169.734328\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.99      0.88      4607\n",
            "           1       0.00      0.00      0.00       224\n",
            "           2       0.28      0.14      0.19       871\n",
            "           3       0.55      0.37      0.45       243\n",
            "           4       1.00      0.40      0.58       223\n",
            "           5       0.30      0.66      0.42       271\n",
            "           6       0.00      0.00      0.00       211\n",
            "           7       0.86      0.01      0.03       457\n",
            "           8       0.16      0.42      0.23       231\n",
            "           9       0.00      0.00      0.00       289\n",
            "          10       0.17      0.26      0.20       112\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.00      0.00      0.00       107\n",
            "          13       0.00      0.00      0.00        50\n",
            "          14       1.00      0.00      0.01       376\n",
            "          15       0.00      0.00      0.00       208\n",
            "          16       1.00      0.01      0.02       255\n",
            "          17       0.84      0.08      0.14       270\n",
            "          18       1.00      0.01      0.03       216\n",
            "\n",
            "   micro avg       0.67      0.56      0.61      9221\n",
            "   macro avg       0.42      0.18      0.17      9221\n",
            "weighted avg       0.64      0.56      0.51      9221\n",
            " samples avg       0.70      0.65      0.65      9221\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5766, Accuracy: 2541.0/6000 (42.35%)\n",
            ", F1 score: 0.6462\n",
            "Counter 2 of 3\n",
            "Train Epoch: 8 [0/24000 (0%)]\tLoss: 0.579057 \t Time:  1.149883\n",
            "Train Epoch: 8 [3200/24000 (13%)]\tLoss: 0.577797 \t Time:  25.343686\n",
            "Train Epoch: 8 [6400/24000 (27%)]\tLoss: 0.575809 \t Time:  49.423610\n",
            "Train Epoch: 8 [9600/24000 (40%)]\tLoss: 0.572489 \t Time:  73.512045\n",
            "Train Epoch: 8 [12800/24000 (53%)]\tLoss: 0.578500 \t Time:  97.553957\n",
            "Train Epoch: 8 [16000/24000 (67%)]\tLoss: 0.577862 \t Time:  121.582339\n",
            "Train Epoch: 8 [19200/24000 (80%)]\tLoss: 0.584048 \t Time:  145.666390\n",
            "Train Epoch: 8 [22400/24000 (93%)]\tLoss: 0.579549 \t Time:  169.755078\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.98      0.88      4607\n",
            "           1       0.00      0.00      0.00       224\n",
            "           2       0.21      0.07      0.11       871\n",
            "           3       0.41      0.20      0.27       243\n",
            "           4       1.00      0.55      0.71       223\n",
            "           5       0.46      0.56      0.51       271\n",
            "           6       0.00      0.00      0.00       211\n",
            "           7       1.00      0.00      0.00       457\n",
            "           8       0.19      0.48      0.28       231\n",
            "           9       0.00      0.00      0.00       289\n",
            "          10       0.35      0.16      0.22       112\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.00      0.00      0.00       107\n",
            "          13       0.00      0.00      0.00        50\n",
            "          14       0.00      0.00      0.00       376\n",
            "          15       1.00      0.00      0.01       208\n",
            "          16       1.00      0.01      0.02       255\n",
            "          17       0.84      0.06      0.11       270\n",
            "          18       0.93      0.06      0.12       216\n",
            "\n",
            "   micro avg       0.71      0.55      0.62      9221\n",
            "   macro avg       0.43      0.17      0.17      9221\n",
            "weighted avg       0.63      0.55      0.51      9221\n",
            " samples avg       0.71      0.64      0.65      9221\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5780, Accuracy: 2604.0/6000 (43.40%)\n",
            ", F1 score: 0.6460\n",
            "Counter 3 of 3\n",
            "Early stopping with best loss:  0.5775908451080323 and val_acc for this epoch:  0.6459747354497355\n"
          ]
        }
      ],
      "source": [
        "word_emb_dim = [50, 100, 150]\n",
        "\n",
        "word_emb_50 = word_emb_dim_tuning(50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvN20mn90CwD",
        "outputId": "e32e2f2b-13a0-4a3c-b203-c1f98204bb63"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.6518322751322752"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_emb_50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPX9zdop80d1",
        "outputId": "d04d6967-7341-419d-f304-9387b84a07fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| ID | GPU | MEM |\n",
            "------------------\n",
            "|  0 |  5% | 59% |\n",
            "| ID | GPU | MEM |\n",
            "------------------\n",
            "|  0 |  0% | 59% |\n",
            "| ID | GPU | MEM |\n",
            "------------------\n",
            "|  0 |  0% | 59% |\n",
            "Model initialized.\n",
            "Train Epoch: 0 [0/24000 (0%)]\tLoss: 0.695126 \t Time:  2.121323\n",
            "Train Epoch: 0 [3200/24000 (13%)]\tLoss: 0.606610 \t Time:  27.768179\n",
            "Train Epoch: 0 [6400/24000 (27%)]\tLoss: 0.600983 \t Time:  51.945139\n",
            "Train Epoch: 0 [9600/24000 (40%)]\tLoss: 0.600595 \t Time:  76.057237\n",
            "Train Epoch: 0 [12800/24000 (53%)]\tLoss: 0.595872 \t Time:  100.450124\n",
            "Train Epoch: 0 [16000/24000 (67%)]\tLoss: 0.591609 \t Time:  124.551430\n",
            "Train Epoch: 0 [19200/24000 (80%)]\tLoss: 0.596393 \t Time:  148.758499\n",
            "Train Epoch: 0 [22400/24000 (93%)]\tLoss: 0.597076 \t Time:  172.911099\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.89      0.85      4607\n",
            "           1       0.07      0.12      0.09       224\n",
            "           2       0.53      0.13      0.20       871\n",
            "           3       0.00      0.00      0.00       243\n",
            "           4       1.00      0.12      0.21       223\n",
            "           5       0.38      0.16      0.22       271\n",
            "           6       0.00      0.00      0.00       211\n",
            "           7       0.09      0.48      0.16       457\n",
            "           8       0.00      0.00      0.00       231\n",
            "           9       0.00      0.00      0.00       289\n",
            "          10       0.00      0.00      0.00       112\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.00      0.00      0.00       107\n",
            "          13       0.00      0.00      0.00        50\n",
            "          14       0.00      0.00      0.00       376\n",
            "          15       0.05      0.60      0.09       208\n",
            "          16       0.00      0.00      0.00       255\n",
            "          17       0.08      0.15      0.10       270\n",
            "          18       0.00      0.00      0.00       216\n",
            "\n",
            "   micro avg       0.42      0.51      0.46      9221\n",
            "   macro avg       0.16      0.14      0.10      9221\n",
            "weighted avg       0.50      0.51      0.47      9221\n",
            " samples avg       0.43      0.60      0.47      9221\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.6044, Accuracy: 686.0/6000 (11.43%)\n",
            ", F1 score: 0.4718\n",
            "Train Epoch: 1 [0/24000 (0%)]\tLoss: 0.594781 \t Time:  1.223126\n",
            "Train Epoch: 1 [3200/24000 (13%)]\tLoss: 0.592604 \t Time:  25.729825\n",
            "Train Epoch: 1 [6400/24000 (27%)]\tLoss: 0.595073 \t Time:  50.242885\n",
            "Train Epoch: 1 [9600/24000 (40%)]\tLoss: 0.598063 \t Time:  75.185883\n",
            "Train Epoch: 1 [12800/24000 (53%)]\tLoss: 0.593186 \t Time:  99.833365\n",
            "Train Epoch: 1 [16000/24000 (67%)]\tLoss: 0.589575 \t Time:  124.424800\n",
            "Train Epoch: 1 [19200/24000 (80%)]\tLoss: 0.589893 \t Time:  148.938952\n",
            "Train Epoch: 1 [22400/24000 (93%)]\tLoss: 0.590268 \t Time:  173.125486\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.91      0.87      4607\n",
            "           1       0.03      0.03      0.03       224\n",
            "           2       0.50      0.06      0.11       871\n",
            "           3       0.00      0.00      0.00       243\n",
            "           4       0.98      0.23      0.37       223\n",
            "           5       0.46      0.05      0.09       271\n",
            "           6       1.00      0.03      0.06       211\n",
            "           7       0.10      0.50      0.17       457\n",
            "           8       0.00      0.00      0.00       231\n",
            "           9       0.25      0.00      0.01       289\n",
            "          10       0.00      0.00      0.00       112\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.00      0.00      0.00       107\n",
            "          13       0.00      0.00      0.00        50\n",
            "          14       0.00      0.00      0.00       376\n",
            "          15       0.05      0.64      0.10       208\n",
            "          16       0.00      0.00      0.00       255\n",
            "          17       0.17      0.18      0.17       270\n",
            "          18       0.17      0.00      0.01       216\n",
            "\n",
            "   micro avg       0.45      0.51      0.48      9221\n",
            "   macro avg       0.24      0.14      0.10      9221\n",
            "weighted avg       0.55      0.51      0.47      9221\n",
            " samples avg       0.44      0.62      0.49      9221\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5970, Accuracy: 636.0/6000 (10.60%)\n",
            ", F1 score: 0.4868\n",
            "Train Epoch: 2 [0/24000 (0%)]\tLoss: 0.592594 \t Time:  1.172252\n",
            "Train Epoch: 2 [3200/24000 (13%)]\tLoss: 0.590544 \t Time:  25.518071\n",
            "Train Epoch: 2 [6400/24000 (27%)]\tLoss: 0.588308 \t Time:  49.680805\n",
            "Train Epoch: 2 [9600/24000 (40%)]\tLoss: 0.592295 \t Time:  73.859231\n",
            "Train Epoch: 2 [12800/24000 (53%)]\tLoss: 0.588572 \t Time:  97.955519\n",
            "Train Epoch: 2 [16000/24000 (67%)]\tLoss: 0.592308 \t Time:  122.136721\n",
            "Train Epoch: 2 [19200/24000 (80%)]\tLoss: 0.589962 \t Time:  146.316517\n",
            "Train Epoch: 2 [22400/24000 (93%)]\tLoss: 0.590620 \t Time:  170.581817\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.87      0.86      4607\n",
            "           1       0.00      0.00      0.00       224\n",
            "           2       0.51      0.21      0.30       871\n",
            "           3       0.00      0.00      0.00       243\n",
            "           4       0.97      0.13      0.22       223\n",
            "           5       0.39      0.48      0.43       271\n",
            "           6       1.00      0.21      0.35       211\n",
            "           7       0.05      0.32      0.09       457\n",
            "           8       0.00      0.00      0.00       231\n",
            "           9       0.36      0.09      0.14       289\n",
            "          10       0.00      0.00      0.00       112\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.00      0.00      0.00       107\n",
            "          13       0.00      0.00      0.00        50\n",
            "          14       0.00      0.00      0.00       376\n",
            "          15       0.06      0.52      0.10       208\n",
            "          16       0.00      0.00      0.00       255\n",
            "          17       0.11      0.13      0.12       270\n",
            "          18       0.43      0.15      0.22       216\n",
            "\n",
            "   micro avg       0.44      0.52      0.48      9221\n",
            "   macro avg       0.25      0.16      0.15      9221\n",
            "weighted avg       0.55      0.52      0.50      9221\n",
            " samples avg       0.43      0.61      0.47      9221\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5918, Accuracy: 424.0/6000 (7.07%)\n",
            ", F1 score: 0.4692\n",
            "Counter 1 of 3\n",
            "Train Epoch: 3 [0/24000 (0%)]\tLoss: 0.591189 \t Time:  1.168122\n",
            "Train Epoch: 3 [3200/24000 (13%)]\tLoss: 0.587060 \t Time:  26.100367\n",
            "Train Epoch: 3 [6400/24000 (27%)]\tLoss: 0.591794 \t Time:  50.527128\n",
            "Train Epoch: 3 [9600/24000 (40%)]\tLoss: 0.583010 \t Time:  74.914660\n",
            "Train Epoch: 3 [12800/24000 (53%)]\tLoss: 0.589872 \t Time:  99.424194\n",
            "Train Epoch: 3 [16000/24000 (67%)]\tLoss: 0.587132 \t Time:  123.853499\n",
            "Train Epoch: 3 [19200/24000 (80%)]\tLoss: 0.587340 \t Time:  148.480809\n",
            "Train Epoch: 3 [22400/24000 (93%)]\tLoss: 0.590465 \t Time:  173.047181\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.82      0.83      4607\n",
            "           1       0.03      0.00      0.01       224\n",
            "           2       0.52      0.28      0.36       871\n",
            "           3       0.00      0.00      0.00       243\n",
            "           4       0.82      0.62      0.71       223\n",
            "           5       0.68      0.57      0.62       271\n",
            "           6       0.94      0.38      0.54       211\n",
            "           7       0.07      0.55      0.13       457\n",
            "           8       0.00      0.00      0.00       231\n",
            "           9       0.20      0.37      0.26       289\n",
            "          10       0.00      0.00      0.00       112\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.00      0.00      0.00       107\n",
            "          13       0.00      0.00      0.00        50\n",
            "          14       0.06      0.01      0.01       376\n",
            "          15       0.06      0.46      0.11       208\n",
            "          16       0.00      0.00      0.00       255\n",
            "          17       0.15      0.14      0.14       270\n",
            "          18       0.34      0.21      0.26       216\n",
            "\n",
            "   micro avg       0.42      0.53      0.47      9221\n",
            "   macro avg       0.25      0.23      0.21      9221\n",
            "weighted avg       0.56      0.53      0.52      9221\n",
            " samples avg       0.43      0.62      0.47      9221\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5926, Accuracy: 431.0/6000 (7.18%)\n",
            ", F1 score: 0.4728\n",
            "Counter 2 of 3\n",
            "Train Epoch: 4 [0/24000 (0%)]\tLoss: 0.590629 \t Time:  1.219860\n",
            "Train Epoch: 4 [3200/24000 (13%)]\tLoss: 0.588552 \t Time:  26.020970\n",
            "Train Epoch: 4 [6400/24000 (27%)]\tLoss: 0.586839 \t Time:  50.399444\n",
            "Train Epoch: 4 [9600/24000 (40%)]\tLoss: 0.586504 \t Time:  74.636808\n",
            "Train Epoch: 4 [12800/24000 (53%)]\tLoss: 0.588541 \t Time:  99.215857\n",
            "Train Epoch: 4 [16000/24000 (67%)]\tLoss: 0.584899 \t Time:  123.765501\n",
            "Train Epoch: 4 [19200/24000 (80%)]\tLoss: 0.587941 \t Time:  148.248770\n",
            "Train Epoch: 4 [22400/24000 (93%)]\tLoss: 0.588507 \t Time:  172.732347\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.92      0.86      4607\n",
            "           1       0.03      0.03      0.03       224\n",
            "           2       0.54      0.07      0.13       871\n",
            "           3       0.00      0.00      0.00       243\n",
            "           4       1.00      0.49      0.66       223\n",
            "           5       1.00      0.08      0.15       271\n",
            "           6       1.00      0.04      0.08       211\n",
            "           7       0.09      0.57      0.15       457\n",
            "           8       0.00      0.00      0.00       231\n",
            "           9       0.67      0.01      0.01       289\n",
            "          10       0.00      0.00      0.00       112\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.25      0.02      0.03       107\n",
            "          13       0.00      0.00      0.00        50\n",
            "          14       0.00      0.00      0.00       376\n",
            "          15       0.05      0.57      0.09       208\n",
            "          16       1.00      0.01      0.02       255\n",
            "          17       0.27      0.21      0.23       270\n",
            "          18       1.00      0.02      0.05       216\n",
            "\n",
            "   micro avg       0.44      0.53      0.48      9221\n",
            "   macro avg       0.41      0.16      0.13      9221\n",
            "weighted avg       0.62      0.53      0.49      9221\n",
            " samples avg       0.45      0.63      0.49      9221\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5918, Accuracy: 508.0/6000 (8.47%)\n",
            ", F1 score: 0.4935\n",
            "Train Epoch: 5 [0/24000 (0%)]\tLoss: 0.589513 \t Time:  1.200538\n",
            "Train Epoch: 5 [3200/24000 (13%)]\tLoss: 0.587725 \t Time:  25.913064\n",
            "Train Epoch: 5 [6400/24000 (27%)]\tLoss: 0.591596 \t Time:  50.690049\n",
            "Train Epoch: 5 [9600/24000 (40%)]\tLoss: 0.586497 \t Time:  75.366349\n",
            "Train Epoch: 5 [12800/24000 (53%)]\tLoss: 0.590503 \t Time:  100.068384\n",
            "Train Epoch: 5 [16000/24000 (67%)]\tLoss: 0.586780 \t Time:  124.774609\n",
            "Train Epoch: 5 [19200/24000 (80%)]\tLoss: 0.590282 \t Time:  149.589692\n",
            "Train Epoch: 5 [22400/24000 (93%)]\tLoss: 0.588091 \t Time:  174.104576\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.92      0.87      4607\n",
            "           1       0.04      0.01      0.01       224\n",
            "           2       0.60      0.05      0.09       871\n",
            "           3       0.00      0.00      0.00       243\n",
            "           4       0.88      0.54      0.67       223\n",
            "           5       0.83      0.04      0.07       271\n",
            "           6       1.00      0.07      0.12       211\n",
            "           7       0.12      0.59      0.19       457\n",
            "           8       0.00      0.00      0.00       231\n",
            "           9       0.20      0.01      0.01       289\n",
            "          10       0.00      0.00      0.00       112\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.00      0.00      0.00       107\n",
            "          13       0.00      0.00      0.00        50\n",
            "          14       0.50      0.01      0.02       376\n",
            "          15       0.03      0.47      0.06       208\n",
            "          16       1.00      0.00      0.01       255\n",
            "          17       0.12      0.17      0.14       270\n",
            "          18       0.66      0.12      0.21       216\n",
            "\n",
            "   micro avg       0.44      0.53      0.48      9221\n",
            "   macro avg       0.36      0.16      0.13      9221\n",
            "weighted avg       0.62      0.53      0.49      9221\n",
            " samples avg       0.45      0.63      0.49      9221\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5887, Accuracy: 671.0/6000 (11.18%)\n",
            ", F1 score: 0.4898\n",
            "Counter 1 of 3\n",
            "Train Epoch: 6 [0/24000 (0%)]\tLoss: 0.590583 \t Time:  1.178201\n",
            "Train Epoch: 6 [3200/24000 (13%)]\tLoss: 0.588474 \t Time:  25.669415\n",
            "Train Epoch: 6 [6400/24000 (27%)]\tLoss: 0.588431 \t Time:  50.185053\n",
            "Train Epoch: 6 [9600/24000 (40%)]\tLoss: 0.586546 \t Time:  74.594666\n",
            "Train Epoch: 6 [12800/24000 (53%)]\tLoss: 0.586948 \t Time:  98.858743\n",
            "Train Epoch: 6 [16000/24000 (67%)]\tLoss: 0.590638 \t Time:  123.257816\n",
            "Train Epoch: 6 [19200/24000 (80%)]\tLoss: 0.588086 \t Time:  147.937310\n",
            "Train Epoch: 6 [22400/24000 (93%)]\tLoss: 0.587392 \t Time:  172.242822\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.96      0.88      4607\n",
            "           1       0.05      0.02      0.03       224\n",
            "           2       0.63      0.07      0.13       871\n",
            "           3       0.00      0.00      0.00       243\n",
            "           4       0.90      0.48      0.62       223\n",
            "           5       0.93      0.05      0.10       271\n",
            "           6       1.00      0.08      0.14       211\n",
            "           7       0.09      0.51      0.15       457\n",
            "           8       1.00      0.01      0.02       231\n",
            "           9       0.67      0.01      0.01       289\n",
            "          10       0.00      0.00      0.00       112\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.00      0.00      0.00       107\n",
            "          13       0.00      0.00      0.00        50\n",
            "          14       0.25      0.00      0.01       376\n",
            "          15       0.05      0.59      0.10       208\n",
            "          16       1.00      0.01      0.02       255\n",
            "          17       0.41      0.23      0.30       270\n",
            "          18       0.82      0.17      0.28       216\n",
            "\n",
            "   micro avg       0.46      0.55      0.50      9221\n",
            "   macro avg       0.45      0.17      0.15      9221\n",
            "weighted avg       0.66      0.55      0.50      9221\n",
            " samples avg       0.50      0.65      0.53      9221\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5874, Accuracy: 779.0/6000 (12.98%)\n",
            ", F1 score: 0.5276\n",
            "Train Epoch: 7 [0/24000 (0%)]\tLoss: 0.587542 \t Time:  1.174256\n",
            "Train Epoch: 7 [3200/24000 (13%)]\tLoss: 0.586537 \t Time:  25.511959\n",
            "Train Epoch: 7 [6400/24000 (27%)]\tLoss: 0.588185 \t Time:  49.743051\n",
            "Train Epoch: 7 [9600/24000 (40%)]\tLoss: 0.586972 \t Time:  74.037377\n",
            "Train Epoch: 7 [12800/24000 (53%)]\tLoss: 0.588216 \t Time:  98.214678\n",
            "Train Epoch: 7 [16000/24000 (67%)]\tLoss: 0.588950 \t Time:  122.681031\n",
            "Train Epoch: 7 [19200/24000 (80%)]\tLoss: 0.587011 \t Time:  146.933467\n",
            "Train Epoch: 7 [22400/24000 (93%)]\tLoss: 0.593583 \t Time:  171.288776\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.95      0.88      4607\n",
            "           1       0.05      0.07      0.06       224\n",
            "           2       0.59      0.02      0.04       871\n",
            "           3       0.00      0.00      0.00       243\n",
            "           4       0.97      0.14      0.25       223\n",
            "           5       1.00      0.02      0.04       271\n",
            "           6       1.00      0.18      0.31       211\n",
            "           7       0.11      0.65      0.19       457\n",
            "           8       1.00      0.03      0.06       231\n",
            "           9       0.00      0.00      0.00       289\n",
            "          10       0.00      0.00      0.00       112\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.00      0.00      0.00       107\n",
            "          13       0.00      0.00      0.00        50\n",
            "          14       0.00      0.00      0.00       376\n",
            "          15       0.05      0.68      0.09       208\n",
            "          16       0.00      0.00      0.00       255\n",
            "          17       0.27      0.31      0.29       270\n",
            "          18       0.95      0.19      0.32       216\n",
            "\n",
            "   micro avg       0.42      0.55      0.48      9221\n",
            "   macro avg       0.36      0.17      0.13      9221\n",
            "weighted avg       0.61      0.55      0.49      9221\n",
            " samples avg       0.45      0.65      0.50      9221\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5911, Accuracy: 509.0/6000 (8.48%)\n",
            ", F1 score: 0.4956\n",
            "Counter 1 of 3\n",
            "Train Epoch: 8 [0/24000 (0%)]\tLoss: 0.591664 \t Time:  1.187835\n",
            "Train Epoch: 8 [3200/24000 (13%)]\tLoss: 0.589084 \t Time:  25.550670\n",
            "Train Epoch: 8 [6400/24000 (27%)]\tLoss: 0.585938 \t Time:  49.709988\n",
            "Train Epoch: 8 [9600/24000 (40%)]\tLoss: 0.584316 \t Time:  73.798633\n",
            "Train Epoch: 8 [12800/24000 (53%)]\tLoss: 0.584571 \t Time:  97.957089\n",
            "Train Epoch: 8 [16000/24000 (67%)]\tLoss: 0.587012 \t Time:  122.119588\n",
            "Train Epoch: 8 [19200/24000 (80%)]\tLoss: 0.585950 \t Time:  146.246000\n",
            "Train Epoch: 8 [22400/24000 (93%)]\tLoss: 0.586766 \t Time:  170.411858\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.95      0.89      4607\n",
            "           1       0.09      0.12      0.10       224\n",
            "           2       0.63      0.09      0.16       871\n",
            "           3       0.00      0.00      0.00       243\n",
            "           4       0.78      0.33      0.46       223\n",
            "           5       1.00      0.14      0.24       271\n",
            "           6       1.00      0.25      0.40       211\n",
            "           7       0.10      0.55      0.17       457\n",
            "           8       1.00      0.01      0.02       231\n",
            "           9       0.89      0.03      0.05       289\n",
            "          10       0.00      0.00      0.00       112\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.00      0.00      0.00       107\n",
            "          13       0.00      0.00      0.00        50\n",
            "          14       0.00      0.00      0.00       376\n",
            "          15       0.05      0.58      0.09       208\n",
            "          16       1.00      0.06      0.12       255\n",
            "          17       0.11      0.23      0.15       270\n",
            "          18       0.75      0.32      0.45       216\n",
            "\n",
            "   micro avg       0.45      0.56      0.50      9221\n",
            "   macro avg       0.43      0.19      0.17      9221\n",
            "weighted avg       0.66      0.56      0.52      9221\n",
            " samples avg       0.50      0.66      0.53      9221\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5904, Accuracy: 1042.0/6000 (17.37%)\n",
            ", F1 score: 0.5295\n",
            "Train Epoch: 9 [0/24000 (0%)]\tLoss: 0.586511 \t Time:  1.130038\n",
            "Train Epoch: 9 [3200/24000 (13%)]\tLoss: 0.589962 \t Time:  25.325368\n",
            "Train Epoch: 9 [6400/24000 (27%)]\tLoss: 0.582104 \t Time:  49.389387\n",
            "Train Epoch: 9 [9600/24000 (40%)]\tLoss: 0.584869 \t Time:  73.497154\n",
            "Train Epoch: 9 [12800/24000 (53%)]\tLoss: 0.588906 \t Time:  97.640132\n",
            "Train Epoch: 9 [16000/24000 (67%)]\tLoss: 0.587715 \t Time:  121.749180\n",
            "Train Epoch: 9 [19200/24000 (80%)]\tLoss: 0.584523 \t Time:  145.889506\n",
            "Train Epoch: 9 [22400/24000 (93%)]\tLoss: 0.581796 \t Time:  170.019473\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.96      0.88      4607\n",
            "           1       0.09      0.08      0.08       224\n",
            "           2       0.67      0.03      0.06       871\n",
            "           3       0.00      0.00      0.00       243\n",
            "           4       0.95      0.39      0.56       223\n",
            "           5       1.00      0.02      0.04       271\n",
            "           6       1.00      0.21      0.35       211\n",
            "           7       0.12      0.69      0.20       457\n",
            "           8       0.00      0.00      0.00       231\n",
            "           9       1.00      0.01      0.02       289\n",
            "          10       0.00      0.00      0.00       112\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.04      0.02      0.02       107\n",
            "          13       0.00      0.00      0.00        50\n",
            "          14       0.00      0.00      0.00       376\n",
            "          15       0.04      0.56      0.07       208\n",
            "          16       1.00      0.01      0.02       255\n",
            "          17       0.20      0.31      0.24       270\n",
            "          18       0.87      0.25      0.38       216\n",
            "\n",
            "   micro avg       0.43      0.56      0.49      9221\n",
            "   macro avg       0.41      0.19      0.15      9221\n",
            "weighted avg       0.64      0.56      0.50      9221\n",
            " samples avg       0.47      0.66      0.51      9221\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5864, Accuracy: 777.0/6000 (12.95%)\n",
            ", F1 score: 0.5130\n",
            "Counter 1 of 3\n",
            "Train Epoch: 10 [0/24000 (0%)]\tLoss: 0.585843 \t Time:  1.147549\n",
            "Train Epoch: 10 [3200/24000 (13%)]\tLoss: 0.587097 \t Time:  25.381625\n",
            "Train Epoch: 10 [6400/24000 (27%)]\tLoss: 0.586658 \t Time:  49.463392\n",
            "Train Epoch: 10 [9600/24000 (40%)]\tLoss: 0.586947 \t Time:  73.560650\n",
            "Train Epoch: 10 [12800/24000 (53%)]\tLoss: 0.585624 \t Time:  97.648297\n",
            "Train Epoch: 10 [16000/24000 (67%)]\tLoss: 0.588693 \t Time:  121.780497\n",
            "Train Epoch: 10 [19200/24000 (80%)]\tLoss: 0.584631 \t Time:  145.875783\n",
            "Train Epoch: 10 [22400/24000 (93%)]\tLoss: 0.587682 \t Time:  169.994460\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.96      0.88      4607\n",
            "           1       0.12      0.09      0.10       224\n",
            "           2       0.74      0.03      0.06       871\n",
            "           3       0.00      0.00      0.00       243\n",
            "           4       0.97      0.26      0.40       223\n",
            "           5       1.00      0.04      0.07       271\n",
            "           6       1.00      0.18      0.30       211\n",
            "           7       0.11      0.60      0.18       457\n",
            "           8       0.00      0.00      0.00       231\n",
            "           9       0.50      0.01      0.01       289\n",
            "          10       0.00      0.00      0.00       112\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.16      0.03      0.05       107\n",
            "          13       0.00      0.00      0.00        50\n",
            "          14       0.00      0.00      0.00       376\n",
            "          15       0.05      0.65      0.09       208\n",
            "          16       0.00      0.00      0.00       255\n",
            "          17       0.28      0.31      0.29       270\n",
            "          18       0.89      0.19      0.31       216\n",
            "\n",
            "   micro avg       0.45      0.55      0.50      9221\n",
            "   macro avg       0.35      0.18      0.15      9221\n",
            "weighted avg       0.61      0.55      0.50      9221\n",
            " samples avg       0.48      0.66      0.52      9221\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5860, Accuracy: 800.0/6000 (13.33%)\n",
            ", F1 score: 0.5211\n",
            "Counter 2 of 3\n",
            "Train Epoch: 11 [0/24000 (0%)]\tLoss: 0.584958 \t Time:  1.149354\n",
            "Train Epoch: 11 [3200/24000 (13%)]\tLoss: 0.587098 \t Time:  25.362800\n",
            "Train Epoch: 11 [6400/24000 (27%)]\tLoss: 0.583743 \t Time:  49.500515\n",
            "Train Epoch: 11 [9600/24000 (40%)]\tLoss: 0.584669 \t Time:  73.606829\n",
            "Train Epoch: 11 [12800/24000 (53%)]\tLoss: 0.587381 \t Time:  97.687219\n",
            "Train Epoch: 11 [16000/24000 (67%)]\tLoss: 0.590136 \t Time:  121.746036\n",
            "Train Epoch: 11 [19200/24000 (80%)]\tLoss: 0.586704 \t Time:  145.794776\n",
            "Train Epoch: 11 [22400/24000 (93%)]\tLoss: 0.587566 \t Time:  169.818980\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.97      0.88      4607\n",
            "           1       0.12      0.01      0.02       224\n",
            "           2       0.51      0.08      0.15       871\n",
            "           3       0.00      0.00      0.00       243\n",
            "           4       0.69      0.08      0.14       223\n",
            "           5       0.93      0.05      0.09       271\n",
            "           6       0.98      0.28      0.44       211\n",
            "           7       0.11      0.65      0.19       457\n",
            "           8       0.00      0.00      0.00       231\n",
            "           9       0.64      0.06      0.11       289\n",
            "          10       0.00      0.00      0.00       112\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.03      0.02      0.02       107\n",
            "          13       0.00      0.00      0.00        50\n",
            "          14       0.50      0.00      0.01       376\n",
            "          15       0.05      0.64      0.10       208\n",
            "          16       0.97      0.14      0.24       255\n",
            "          17       0.18      0.26      0.21       270\n",
            "          18       0.86      0.31      0.46       216\n",
            "\n",
            "   micro avg       0.45      0.57      0.50      9221\n",
            "   macro avg       0.39      0.19      0.16      9221\n",
            "weighted avg       0.62      0.57      0.51      9221\n",
            " samples avg       0.49      0.66      0.53      9221\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5887, Accuracy: 893.0/6000 (14.88%)\n",
            ", F1 score: 0.5295\n",
            "Counter 3 of 3\n",
            "Early stopping with best loss:  0.5865559690793355 and val_acc for this epoch:  0.5294633597883598\n"
          ]
        }
      ],
      "source": [
        "word_emb_100 = word_emb_dim_tuning(100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "L0-ZblJg9DCb",
        "outputId": "e608f0f9-1d14-477b-be15-6e1d14976e97"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4eedc983-ff0a-466a-89f8-606b86d5f185\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word embedding dimension</th>\n",
              "      <th>f1 score</th>\n",
              "      <th>model size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>50</td>\n",
              "      <td>0.652</td>\n",
              "      <td>93.77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100</td>\n",
              "      <td>0.530</td>\n",
              "      <td>95.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>150</td>\n",
              "      <td>0.871</td>\n",
              "      <td>96.36</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4eedc983-ff0a-466a-89f8-606b86d5f185')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4eedc983-ff0a-466a-89f8-606b86d5f185 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4eedc983-ff0a-466a-89f8-606b86d5f185');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   word embedding dimension  f1 score  model size\n",
              "0                        50     0.652       93.77\n",
              "1                       100     0.530       95.06\n",
              "2                       150     0.871       96.36"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_emb_dim_dict = {}\n",
        "word_emb_dim_dict['word embedding dimension'] = word_emb_dim\n",
        "word_emb_dim_dict['f1 score'] = [word_emb_50, word_emb_100, default_f1_score]\n",
        "word_emb_dim_dict['model size'] = [93.77, 95.06, 96.36]\n",
        "\n",
        "word_emb_dim_df = pd.DataFrame.from_dict(word_emb_dim_dict)\n",
        "word_emb_dim_df['f1 score'] = round(word_emb_dim_df['f1 score'],3)\n",
        "word_emb_dim_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "45LSAIUG9bFt",
        "outputId": "8549cf6d-f9f7-4f10-a74a-6ae6e249fddb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'f1 score')"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(word_emb_dim_df['word embedding dimension'], word_emb_dim_df['f1 score'])\n",
        "plt.title(\"f1 score of different word embedding dimension\")\n",
        "plt.xlabel(\"number of word embedding dimension\")\n",
        "plt.ylabel(\"f1 score\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KS8oIEIiNfCe"
      },
      "source": [
        "# batch size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mB8cM3ZsNnke"
      },
      "outputs": [],
      "source": [
        "def batch_size_tuning(batch_size = 64):\n",
        "  BATCH_SIZE = batch_size\n",
        "  train_loader, val_loader = train_val_loader(transformed_train_dataset, val_ratio=VAL_RATIO, batch_size=BATCH_SIZE)\n",
        "  testloader = test_loader(transformed_test_dataset, BATCH_SIZE)\n",
        "\n",
        "  n_epochs = 15\n",
        "  log_interval = 50\n",
        "  lr = 3e-4\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr= lr)\n",
        "\n",
        "  criterion = nn.BCELoss()\n",
        "  train_loss = []\n",
        "  best_f1_score = -float(\"inf\") # record the best loss to get the best model\n",
        "\n",
        "  for epoch in range(n_epochs):\n",
        "      loss = train_epoch(log_interval, model, train_loader, optimizer, epoch, criterion)\n",
        "      train_loss.append(loss)\n",
        "      f1score = validation(model, device, val_loader, criterion, 0.5)\n",
        "\n",
        "      # https://www.kaggle.com/general/178486\n",
        "      if f1score > best_f1_score:\n",
        "          best_f1_score = f1score\n",
        "          es = 0\n",
        "          torch.save(model, 'batch_size'+str(batch_size)+\"model.pt\")\n",
        "      else:\n",
        "          es += 1\n",
        "          print(\"Counter {} of 3\".format(es))\n",
        "\n",
        "          if es >= 3:\n",
        "              print(\"Early stopping with best loss: \", loss, \"and val_acc for this epoch: \", f1score)\n",
        "              break\n",
        "\n",
        "  return best_f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjcP02GBS70d",
        "outputId": "4c176d11-85d7-4e93-c156-5aa21f6111f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [0/24000 (0%)]\tLoss: 0.693025 \t Time:  1.847053\n",
            "Train Epoch: 0 [1600/24000 (7%)]\tLoss: 0.619556 \t Time:  17.515766\n",
            "Train Epoch: 0 [3200/24000 (13%)]\tLoss: 0.602605 \t Time:  30.942487\n",
            "Train Epoch: 0 [4800/24000 (20%)]\tLoss: 0.599909 \t Time:  44.341965\n",
            "Train Epoch: 0 [6400/24000 (27%)]\tLoss: 0.596458 \t Time:  57.711319\n",
            "Train Epoch: 0 [8000/24000 (33%)]\tLoss: 0.594303 \t Time:  71.223948\n",
            "Train Epoch: 0 [9600/24000 (40%)]\tLoss: 0.599688 \t Time:  84.703373\n",
            "Train Epoch: 0 [11200/24000 (47%)]\tLoss: 0.598291 \t Time:  98.770356\n",
            "Train Epoch: 0 [12800/24000 (53%)]\tLoss: 0.594169 \t Time:  112.277912\n",
            "Train Epoch: 0 [14400/24000 (60%)]\tLoss: 0.595299 \t Time:  127.197708\n",
            "Train Epoch: 0 [16000/24000 (67%)]\tLoss: 0.595387 \t Time:  140.675279\n",
            "Train Epoch: 0 [17600/24000 (73%)]\tLoss: 0.589602 \t Time:  154.177680\n",
            "Train Epoch: 0 [19200/24000 (80%)]\tLoss: 0.593144 \t Time:  167.702727\n",
            "Train Epoch: 0 [20800/24000 (87%)]\tLoss: 0.593338 \t Time:  181.174728\n",
            "Train Epoch: 0 [22400/24000 (93%)]\tLoss: 0.595385 \t Time:  194.636101\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      1.00      0.86      4537\n",
            "           1       0.05      0.10      0.06       240\n",
            "           2       0.80      0.00      0.01       903\n",
            "           3       0.08      0.33      0.13       254\n",
            "           4       0.00      0.00      0.00       246\n",
            "           5       0.00      0.00      0.00       306\n",
            "           6       0.00      0.00      0.00       242\n",
            "           7       1.00      0.00      0.01       487\n",
            "           8       0.00      0.00      0.00       225\n",
            "           9       0.00      0.00      0.00       286\n",
            "          10       0.00      0.00      0.00       129\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.00      0.00      0.00       124\n",
            "          13       0.00      0.00      0.00        42\n",
            "          14       0.09      0.13      0.11       388\n",
            "          15       0.00      0.00      0.00       225\n",
            "          16       0.09      0.82      0.17       289\n",
            "          17       0.00      0.00      0.00       307\n",
            "          18       0.00      0.00      0.00       213\n",
            "\n",
            "   micro avg       0.46      0.52      0.49      9443\n",
            "   macro avg       0.15      0.13      0.07      9443\n",
            "weighted avg       0.50      0.52      0.43      9443\n",
            " samples avg       0.54      0.63      0.54      9443\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5960, Accuracy: 1222.0/6000 (20.37%)\n",
            ", F1 score: 0.5398\n",
            "Train Epoch: 1 [0/24000 (0%)]\tLoss: 0.591858 \t Time:  0.755457\n",
            "Train Epoch: 1 [1600/24000 (7%)]\tLoss: 0.592845 \t Time:  14.222312\n",
            "Train Epoch: 1 [3200/24000 (13%)]\tLoss: 0.594923 \t Time:  27.650431\n",
            "Train Epoch: 1 [4800/24000 (20%)]\tLoss: 0.590395 \t Time:  41.132602\n",
            "Train Epoch: 1 [6400/24000 (27%)]\tLoss: 0.590961 \t Time:  54.577776\n",
            "Train Epoch: 1 [8000/24000 (33%)]\tLoss: 0.591179 \t Time:  68.086125\n",
            "Train Epoch: 1 [9600/24000 (40%)]\tLoss: 0.587913 \t Time:  81.648227\n",
            "Train Epoch: 1 [11200/24000 (47%)]\tLoss: 0.591776 \t Time:  95.142601\n",
            "Train Epoch: 1 [12800/24000 (53%)]\tLoss: 0.586334 \t Time:  108.671557\n",
            "Train Epoch: 1 [14400/24000 (60%)]\tLoss: 0.586828 \t Time:  122.122906\n",
            "Train Epoch: 1 [16000/24000 (67%)]\tLoss: 0.589267 \t Time:  135.577970\n",
            "Train Epoch: 1 [17600/24000 (73%)]\tLoss: 0.593477 \t Time:  149.086503\n",
            "Train Epoch: 1 [19200/24000 (80%)]\tLoss: 0.587289 \t Time:  162.551199\n",
            "Train Epoch: 1 [20800/24000 (87%)]\tLoss: 0.589378 \t Time:  176.026829\n",
            "Train Epoch: 1 [22400/24000 (93%)]\tLoss: 0.584801 \t Time:  189.548313\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      1.00      0.86      4537\n",
            "           1       0.12      0.05      0.07       240\n",
            "           2       0.58      0.08      0.14       903\n",
            "           3       0.09      0.59      0.16       254\n",
            "           4       1.00      0.00      0.01       246\n",
            "           5       1.00      0.00      0.01       306\n",
            "           6       1.00      0.01      0.02       242\n",
            "           7       1.00      0.01      0.03       487\n",
            "           8       0.36      0.07      0.12       225\n",
            "           9       1.00      0.00      0.01       286\n",
            "          10       0.92      0.27      0.42       129\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.00      0.00      0.00       124\n",
            "          13       0.00      0.00      0.00        42\n",
            "          14       0.25      0.21      0.23       388\n",
            "          15       0.00      0.00      0.00       225\n",
            "          16       0.12      0.87      0.22       289\n",
            "          17       0.91      0.30      0.45       307\n",
            "          18       0.57      0.06      0.10       213\n",
            "\n",
            "   micro avg       0.50      0.56      0.53      9443\n",
            "   macro avg       0.51      0.19      0.15      9443\n",
            "weighted avg       0.67      0.56      0.48      9443\n",
            " samples avg       0.56      0.66      0.57      9443\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5944, Accuracy: 1218.0/6000 (20.30%)\n",
            ", F1 score: 0.5674\n",
            "Train Epoch: 2 [0/24000 (0%)]\tLoss: 0.592122 \t Time:  0.676033\n",
            "Train Epoch: 2 [1600/24000 (7%)]\tLoss: 0.596150 \t Time:  14.191014\n",
            "Train Epoch: 2 [3200/24000 (13%)]\tLoss: 0.591482 \t Time:  27.685612\n",
            "Train Epoch: 2 [4800/24000 (20%)]\tLoss: 0.591784 \t Time:  41.130881\n",
            "Train Epoch: 2 [6400/24000 (27%)]\tLoss: 0.587180 \t Time:  54.613108\n",
            "Train Epoch: 2 [8000/24000 (33%)]\tLoss: 0.584109 \t Time:  68.100198\n",
            "Train Epoch: 2 [9600/24000 (40%)]\tLoss: 0.591222 \t Time:  81.578006\n",
            "Train Epoch: 2 [11200/24000 (47%)]\tLoss: 0.588513 \t Time:  95.122590\n",
            "Train Epoch: 2 [12800/24000 (53%)]\tLoss: 0.587991 \t Time:  109.005083\n",
            "Train Epoch: 2 [14400/24000 (60%)]\tLoss: 0.589837 \t Time:  125.659744\n",
            "Train Epoch: 2 [16000/24000 (67%)]\tLoss: 0.592293 \t Time:  143.043859\n",
            "Train Epoch: 2 [17600/24000 (73%)]\tLoss: 0.589954 \t Time:  157.064894\n",
            "Train Epoch: 2 [19200/24000 (80%)]\tLoss: 0.588099 \t Time:  170.587939\n",
            "Train Epoch: 2 [20800/24000 (87%)]\tLoss: 0.586425 \t Time:  184.097772\n",
            "Train Epoch: 2 [22400/24000 (93%)]\tLoss: 0.590398 \t Time:  197.580746\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      1.00      0.86      4537\n",
            "           1       0.06      0.09      0.07       240\n",
            "           2       0.59      0.05      0.10       903\n",
            "           3       0.17      0.49      0.25       254\n",
            "           4       1.00      0.02      0.05       246\n",
            "           5       0.00      0.00      0.00       306\n",
            "           6       1.00      0.00      0.01       242\n",
            "           7       1.00      0.05      0.10       487\n",
            "           8       0.81      0.11      0.20       225\n",
            "           9       1.00      0.01      0.01       286\n",
            "          10       0.97      0.29      0.45       129\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.00      0.00      0.00       124\n",
            "          13       0.00      0.00      0.00        42\n",
            "          14       0.18      0.19      0.18       388\n",
            "          15       1.00      0.03      0.06       225\n",
            "          16       0.19      0.89      0.32       289\n",
            "          17       0.93      0.26      0.40       307\n",
            "          18       0.89      0.08      0.15       213\n",
            "\n",
            "   micro avg       0.57      0.56      0.57      9443\n",
            "   macro avg       0.55      0.19      0.17      9443\n",
            "weighted avg       0.68      0.56      0.48      9443\n",
            " samples avg       0.66      0.66      0.62      9443\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5918, Accuracy: 2016.0/6000 (33.60%)\n",
            ", F1 score: 0.6184\n",
            "Train Epoch: 3 [0/24000 (0%)]\tLoss: 0.586992 \t Time:  0.700430\n",
            "Train Epoch: 3 [1600/24000 (7%)]\tLoss: 0.587265 \t Time:  14.240534\n",
            "Train Epoch: 3 [3200/24000 (13%)]\tLoss: 0.588132 \t Time:  27.706439\n",
            "Train Epoch: 3 [4800/24000 (20%)]\tLoss: 0.591391 \t Time:  41.171637\n",
            "Train Epoch: 3 [6400/24000 (27%)]\tLoss: 0.583045 \t Time:  54.663377\n",
            "Train Epoch: 3 [8000/24000 (33%)]\tLoss: 0.586967 \t Time:  68.187358\n",
            "Train Epoch: 3 [9600/24000 (40%)]\tLoss: 0.586801 \t Time:  81.690608\n",
            "Train Epoch: 3 [11200/24000 (47%)]\tLoss: 0.590157 \t Time:  96.024815\n",
            "Train Epoch: 3 [12800/24000 (53%)]\tLoss: 0.589687 \t Time:  109.555445\n",
            "Train Epoch: 3 [14400/24000 (60%)]\tLoss: 0.586166 \t Time:  123.084940\n",
            "Train Epoch: 3 [16000/24000 (67%)]\tLoss: 0.594330 \t Time:  136.590687\n",
            "Train Epoch: 3 [17600/24000 (73%)]\tLoss: 0.590528 \t Time:  150.093157\n",
            "Train Epoch: 3 [19200/24000 (80%)]\tLoss: 0.587065 \t Time:  163.616867\n",
            "Train Epoch: 3 [20800/24000 (87%)]\tLoss: 0.589120 \t Time:  177.141513\n",
            "Train Epoch: 3 [22400/24000 (93%)]\tLoss: 0.591777 \t Time:  190.660663\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      1.00      0.86      4537\n",
            "           1       0.09      0.10      0.10       240\n",
            "           2       0.67      0.01      0.02       903\n",
            "           3       0.16      0.46      0.24       254\n",
            "           4       1.00      0.01      0.02       246\n",
            "           5       1.00      0.00      0.01       306\n",
            "           6       1.00      0.01      0.02       242\n",
            "           7       1.00      0.02      0.04       487\n",
            "           8       0.50      0.18      0.26       225\n",
            "           9       0.00      0.00      0.00       286\n",
            "          10       1.00      0.39      0.56       129\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       1.00      0.01      0.02       124\n",
            "          13       0.60      0.07      0.13        42\n",
            "          14       0.38      0.18      0.24       388\n",
            "          15       1.00      0.03      0.05       225\n",
            "          16       0.16      0.86      0.26       289\n",
            "          17       0.93      0.22      0.36       307\n",
            "          18       0.83      0.14      0.23       213\n",
            "\n",
            "   micro avg       0.58      0.55      0.57      9443\n",
            "   macro avg       0.64      0.19      0.18      9443\n",
            "weighted avg       0.70      0.55      0.48      9443\n",
            " samples avg       0.65      0.66      0.61      9443\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5892, Accuracy: 1882.0/6000 (31.37%)\n",
            ", F1 score: 0.6114\n",
            "Counter 1 of 3\n",
            "Train Epoch: 4 [0/24000 (0%)]\tLoss: 0.591809 \t Time:  0.701572\n",
            "Train Epoch: 4 [1600/24000 (7%)]\tLoss: 0.585665 \t Time:  14.214705\n",
            "Train Epoch: 4 [3200/24000 (13%)]\tLoss: 0.585147 \t Time:  27.650835\n",
            "Train Epoch: 4 [4800/24000 (20%)]\tLoss: 0.584640 \t Time:  41.022845\n",
            "Train Epoch: 4 [6400/24000 (27%)]\tLoss: 0.585495 \t Time:  54.437421\n",
            "Train Epoch: 4 [8000/24000 (33%)]\tLoss: 0.584109 \t Time:  67.932722\n",
            "Train Epoch: 4 [9600/24000 (40%)]\tLoss: 0.585066 \t Time:  81.417234\n",
            "Train Epoch: 4 [11200/24000 (47%)]\tLoss: 0.581948 \t Time:  94.896118\n",
            "Train Epoch: 4 [12800/24000 (53%)]\tLoss: 0.589753 \t Time:  109.554752\n",
            "Train Epoch: 4 [14400/24000 (60%)]\tLoss: 0.585199 \t Time:  123.310402\n",
            "Train Epoch: 4 [16000/24000 (67%)]\tLoss: 0.584162 \t Time:  136.810407\n",
            "Train Epoch: 4 [17600/24000 (73%)]\tLoss: 0.590406 \t Time:  150.237432\n",
            "Train Epoch: 4 [19200/24000 (80%)]\tLoss: 0.582613 \t Time:  163.703027\n",
            "Train Epoch: 4 [20800/24000 (87%)]\tLoss: 0.585470 \t Time:  177.184575\n",
            "Train Epoch: 4 [22400/24000 (93%)]\tLoss: 0.587462 \t Time:  190.665095\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      1.00      0.86      4537\n",
            "           1       0.09      0.11      0.10       240\n",
            "           2       0.79      0.02      0.03       903\n",
            "           3       0.14      0.48      0.22       254\n",
            "           4       1.00      0.17      0.29       246\n",
            "           5       0.00      0.00      0.00       306\n",
            "           6       1.00      0.00      0.01       242\n",
            "           7       0.91      0.06      0.12       487\n",
            "           8       0.85      0.24      0.37       225\n",
            "           9       0.00      0.00      0.00       286\n",
            "          10       1.00      0.33      0.50       129\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.00      0.00      0.00       124\n",
            "          13       0.00      0.00      0.00        42\n",
            "          14       0.33      0.23      0.27       388\n",
            "          15       1.00      0.01      0.02       225\n",
            "          16       0.15      0.79      0.25       289\n",
            "          17       1.00      0.09      0.17       307\n",
            "          18       1.00      0.08      0.14       213\n",
            "\n",
            "   micro avg       0.57      0.55      0.56      9443\n",
            "   macro avg       0.53      0.19      0.18      9443\n",
            "weighted avg       0.67      0.55      0.48      9443\n",
            " samples avg       0.64      0.66      0.61      9443\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5886, Accuracy: 1832.0/6000 (30.53%)\n",
            ", F1 score: 0.6073\n",
            "Counter 2 of 3\n",
            "Train Epoch: 5 [0/24000 (0%)]\tLoss: 0.590894 \t Time:  0.705369\n",
            "Train Epoch: 5 [1600/24000 (7%)]\tLoss: 0.584899 \t Time:  14.145257\n",
            "Train Epoch: 5 [3200/24000 (13%)]\tLoss: 0.587187 \t Time:  27.598802\n",
            "Train Epoch: 5 [4800/24000 (20%)]\tLoss: 0.590743 \t Time:  41.060794\n",
            "Train Epoch: 5 [6400/24000 (27%)]\tLoss: 0.583905 \t Time:  54.516922\n",
            "Train Epoch: 5 [8000/24000 (33%)]\tLoss: 0.592973 \t Time:  68.020598\n",
            "Train Epoch: 5 [9600/24000 (40%)]\tLoss: 0.586181 \t Time:  81.497491\n",
            "Train Epoch: 5 [11200/24000 (47%)]\tLoss: 0.584228 \t Time:  94.991089\n",
            "Train Epoch: 5 [12800/24000 (53%)]\tLoss: 0.586747 \t Time:  108.432279\n",
            "Train Epoch: 5 [14400/24000 (60%)]\tLoss: 0.585964 \t Time:  121.826074\n",
            "Train Epoch: 5 [16000/24000 (67%)]\tLoss: 0.586766 \t Time:  135.306093\n",
            "Train Epoch: 5 [17600/24000 (73%)]\tLoss: 0.586201 \t Time:  148.780442\n",
            "Train Epoch: 5 [19200/24000 (80%)]\tLoss: 0.587640 \t Time:  162.263350\n",
            "Train Epoch: 5 [20800/24000 (87%)]\tLoss: 0.583680 \t Time:  175.736040\n",
            "Train Epoch: 5 [22400/24000 (93%)]\tLoss: 0.584451 \t Time:  189.267554\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      1.00      0.86      4537\n",
            "           1       0.05      0.10      0.06       240\n",
            "           2       0.59      0.04      0.08       903\n",
            "           3       0.28      0.48      0.36       254\n",
            "           4       1.00      0.01      0.02       246\n",
            "           5       1.00      0.00      0.01       306\n",
            "           6       1.00      0.01      0.02       242\n",
            "           7       0.97      0.07      0.13       487\n",
            "           8       0.89      0.17      0.29       225\n",
            "           9       0.00      0.00      0.00       286\n",
            "          10       1.00      0.39      0.56       129\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.00      0.00      0.00       124\n",
            "          13       1.00      0.05      0.09        42\n",
            "          14       0.48      0.19      0.28       388\n",
            "          15       1.00      0.01      0.03       225\n",
            "          16       0.16      0.87      0.26       289\n",
            "          17       0.93      0.22      0.36       307\n",
            "          18       0.97      0.15      0.25       213\n",
            "\n",
            "   micro avg       0.59      0.56      0.57      9443\n",
            "   macro avg       0.64      0.20      0.19      9443\n",
            "weighted avg       0.70      0.56      0.49      9443\n",
            " samples avg       0.67      0.67      0.62      9443\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5863, Accuracy: 2052.0/6000 (34.20%)\n",
            ", F1 score: 0.6222\n",
            "Train Epoch: 6 [0/24000 (0%)]\tLoss: 0.589685 \t Time:  0.673118\n",
            "Train Epoch: 6 [1600/24000 (7%)]\tLoss: 0.587975 \t Time:  14.130602\n",
            "Train Epoch: 6 [3200/24000 (13%)]\tLoss: 0.586699 \t Time:  27.567208\n",
            "Train Epoch: 6 [4800/24000 (20%)]\tLoss: 0.582902 \t Time:  40.966534\n",
            "Train Epoch: 6 [6400/24000 (27%)]\tLoss: 0.588125 \t Time:  54.402599\n",
            "Train Epoch: 6 [8000/24000 (33%)]\tLoss: 0.585738 \t Time:  67.839951\n",
            "Train Epoch: 6 [9600/24000 (40%)]\tLoss: 0.580431 \t Time:  81.272371\n",
            "Train Epoch: 6 [11200/24000 (47%)]\tLoss: 0.582134 \t Time:  94.698390\n",
            "Train Epoch: 6 [12800/24000 (53%)]\tLoss: 0.584424 \t Time:  108.166950\n",
            "Train Epoch: 6 [14400/24000 (60%)]\tLoss: 0.583311 \t Time:  121.642193\n",
            "Train Epoch: 6 [16000/24000 (67%)]\tLoss: 0.575168 \t Time:  135.078138\n",
            "Train Epoch: 6 [17600/24000 (73%)]\tLoss: 0.584108 \t Time:  148.569249\n",
            "Train Epoch: 6 [19200/24000 (80%)]\tLoss: 0.583642 \t Time:  162.022039\n",
            "Train Epoch: 6 [20800/24000 (87%)]\tLoss: 0.585708 \t Time:  175.498861\n",
            "Train Epoch: 6 [22400/24000 (93%)]\tLoss: 0.582626 \t Time:  188.953378\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      1.00      0.86      4537\n",
            "           1       0.12      0.13      0.13       240\n",
            "           2       0.71      0.06      0.12       903\n",
            "           3       0.21      0.46      0.29       254\n",
            "           4       1.00      0.00      0.01       246\n",
            "           5       1.00      0.00      0.01       306\n",
            "           6       1.00      0.02      0.03       242\n",
            "           7       0.96      0.05      0.09       487\n",
            "           8       0.87      0.15      0.26       225\n",
            "           9       1.00      0.00      0.01       286\n",
            "          10       1.00      0.47      0.63       129\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.00      0.00      0.00       124\n",
            "          13       1.00      0.02      0.05        42\n",
            "          14       0.53      0.20      0.29       388\n",
            "          15       1.00      0.01      0.02       225\n",
            "          16       0.15      0.88      0.26       289\n",
            "          17       0.97      0.21      0.34       307\n",
            "          18       1.00      0.19      0.32       213\n",
            "\n",
            "   micro avg       0.59      0.56      0.58      9443\n",
            "   macro avg       0.70      0.20      0.19      9443\n",
            "weighted avg       0.75      0.56      0.50      9443\n",
            " samples avg       0.66      0.67      0.62      9443\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5862, Accuracy: 1891.0/6000 (31.52%)\n",
            ", F1 score: 0.6196\n",
            "Counter 1 of 3\n",
            "Train Epoch: 7 [0/24000 (0%)]\tLoss: 0.586051 \t Time:  0.669994\n",
            "Train Epoch: 7 [1600/24000 (7%)]\tLoss: 0.582344 \t Time:  14.157513\n",
            "Train Epoch: 7 [3200/24000 (13%)]\tLoss: 0.586315 \t Time:  27.601582\n",
            "Train Epoch: 7 [4800/24000 (20%)]\tLoss: 0.580968 \t Time:  41.049439\n",
            "Train Epoch: 7 [6400/24000 (27%)]\tLoss: 0.588553 \t Time:  54.517894\n",
            "Train Epoch: 7 [8000/24000 (33%)]\tLoss: 0.585802 \t Time:  67.986019\n",
            "Train Epoch: 7 [9600/24000 (40%)]\tLoss: 0.587572 \t Time:  81.510606\n",
            "Train Epoch: 7 [11200/24000 (47%)]\tLoss: 0.588314 \t Time:  94.984990\n",
            "Train Epoch: 7 [12800/24000 (53%)]\tLoss: 0.581767 \t Time:  108.438102\n",
            "Train Epoch: 7 [14400/24000 (60%)]\tLoss: 0.585472 \t Time:  121.879729\n",
            "Train Epoch: 7 [16000/24000 (67%)]\tLoss: 0.588966 \t Time:  135.377939\n",
            "Train Epoch: 7 [17600/24000 (73%)]\tLoss: 0.589041 \t Time:  148.842880\n",
            "Train Epoch: 7 [19200/24000 (80%)]\tLoss: 0.582188 \t Time:  162.376281\n",
            "Train Epoch: 7 [20800/24000 (87%)]\tLoss: 0.582973 \t Time:  175.798742\n",
            "Train Epoch: 7 [22400/24000 (93%)]\tLoss: 0.588268 \t Time:  189.263184\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      1.00      0.86      4537\n",
            "           1       0.13      0.11      0.12       240\n",
            "           2       0.64      0.08      0.14       903\n",
            "           3       0.20      0.43      0.28       254\n",
            "           4       1.00      0.07      0.13       246\n",
            "           5       0.00      0.00      0.00       306\n",
            "           6       1.00      0.00      0.01       242\n",
            "           7       0.94      0.10      0.18       487\n",
            "           8       0.86      0.16      0.27       225\n",
            "           9       1.00      0.01      0.01       286\n",
            "          10       1.00      0.50      0.66       129\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.00      0.00      0.00       124\n",
            "          13       1.00      0.29      0.44        42\n",
            "          14       0.38      0.23      0.29       388\n",
            "          15       1.00      0.02      0.03       225\n",
            "          16       0.18      0.83      0.29       289\n",
            "          17       0.96      0.23      0.37       307\n",
            "          18       0.97      0.16      0.28       213\n",
            "\n",
            "   micro avg       0.61      0.57      0.59      9443\n",
            "   macro avg       0.63      0.22      0.23      9443\n",
            "weighted avg       0.70      0.57      0.51      9443\n",
            " samples avg       0.68      0.67      0.64      9443\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5861, Accuracy: 2132.0/6000 (35.53%)\n",
            ", F1 score: 0.6359\n",
            "Train Epoch: 8 [0/24000 (0%)]\tLoss: 0.577930 \t Time:  0.644418\n",
            "Train Epoch: 8 [1600/24000 (7%)]\tLoss: 0.584888 \t Time:  14.125780\n",
            "Train Epoch: 8 [3200/24000 (13%)]\tLoss: 0.585234 \t Time:  27.533843\n",
            "Train Epoch: 8 [4800/24000 (20%)]\tLoss: 0.583419 \t Time:  40.960623\n",
            "Train Epoch: 8 [6400/24000 (27%)]\tLoss: 0.582766 \t Time:  54.371771\n",
            "Train Epoch: 8 [8000/24000 (33%)]\tLoss: 0.590635 \t Time:  67.869231\n",
            "Train Epoch: 8 [9600/24000 (40%)]\tLoss: 0.585481 \t Time:  81.288724\n",
            "Train Epoch: 8 [11200/24000 (47%)]\tLoss: 0.579818 \t Time:  94.718607\n",
            "Train Epoch: 8 [12800/24000 (53%)]\tLoss: 0.581778 \t Time:  108.169955\n",
            "Train Epoch: 8 [14400/24000 (60%)]\tLoss: 0.583782 \t Time:  121.611688\n",
            "Train Epoch: 8 [16000/24000 (67%)]\tLoss: 0.583124 \t Time:  135.039658\n",
            "Train Epoch: 8 [17600/24000 (73%)]\tLoss: 0.578695 \t Time:  148.513553\n",
            "Train Epoch: 8 [19200/24000 (80%)]\tLoss: 0.582409 \t Time:  161.960186\n",
            "Train Epoch: 8 [20800/24000 (87%)]\tLoss: 0.580805 \t Time:  175.407148\n",
            "Train Epoch: 8 [22400/24000 (93%)]\tLoss: 0.585149 \t Time:  188.811628\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      1.00      0.86      4537\n",
            "           1       0.14      0.22      0.17       240\n",
            "           2       0.74      0.07      0.13       903\n",
            "           3       0.19      0.47      0.28       254\n",
            "           4       1.00      0.00      0.01       246\n",
            "           5       0.00      0.00      0.00       306\n",
            "           6       0.00      0.00      0.00       242\n",
            "           7       0.96      0.09      0.17       487\n",
            "           8       0.89      0.18      0.30       225\n",
            "           9       1.00      0.00      0.01       286\n",
            "          10       1.00      0.40      0.57       129\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.00      0.00      0.00       124\n",
            "          13       1.00      0.19      0.32        42\n",
            "          14       0.41      0.23      0.29       388\n",
            "          15       1.00      0.05      0.10       225\n",
            "          16       0.20      0.83      0.33       289\n",
            "          17       1.00      0.20      0.34       307\n",
            "          18       0.98      0.22      0.36       213\n",
            "\n",
            "   micro avg       0.61      0.57      0.59      9443\n",
            "   macro avg       0.59      0.22      0.22      9443\n",
            "weighted avg       0.69      0.57      0.51      9443\n",
            " samples avg       0.69      0.67      0.64      9443\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5855, Accuracy: 2210.0/6000 (36.83%)\n",
            ", F1 score: 0.6389\n",
            "Train Epoch: 9 [0/24000 (0%)]\tLoss: 0.584487 \t Time:  0.697202\n",
            "Train Epoch: 9 [1600/24000 (7%)]\tLoss: 0.585153 \t Time:  14.201026\n",
            "Train Epoch: 9 [3200/24000 (13%)]\tLoss: 0.584693 \t Time:  27.626042\n",
            "Train Epoch: 9 [4800/24000 (20%)]\tLoss: 0.584554 \t Time:  41.076849\n",
            "Train Epoch: 9 [6400/24000 (27%)]\tLoss: 0.587153 \t Time:  54.508577\n",
            "Train Epoch: 9 [8000/24000 (33%)]\tLoss: 0.579773 \t Time:  67.964341\n",
            "Train Epoch: 9 [9600/24000 (40%)]\tLoss: 0.584794 \t Time:  81.388516\n",
            "Train Epoch: 9 [11200/24000 (47%)]\tLoss: 0.581798 \t Time:  94.828118\n",
            "Train Epoch: 9 [12800/24000 (53%)]\tLoss: 0.581596 \t Time:  108.293331\n",
            "Train Epoch: 9 [14400/24000 (60%)]\tLoss: 0.583851 \t Time:  121.763944\n",
            "Train Epoch: 9 [16000/24000 (67%)]\tLoss: 0.582721 \t Time:  135.136737\n",
            "Train Epoch: 9 [17600/24000 (73%)]\tLoss: 0.587610 \t Time:  148.568252\n",
            "Train Epoch: 9 [19200/24000 (80%)]\tLoss: 0.584381 \t Time:  162.042681\n",
            "Train Epoch: 9 [20800/24000 (87%)]\tLoss: 0.581537 \t Time:  175.509201\n",
            "Train Epoch: 9 [22400/24000 (93%)]\tLoss: 0.586018 \t Time:  188.985675\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      1.00      0.86      4537\n",
            "           1       0.11      0.13      0.12       240\n",
            "           2       0.74      0.10      0.18       903\n",
            "           3       0.31      0.53      0.39       254\n",
            "           4       1.00      0.09      0.16       246\n",
            "           5       0.00      0.00      0.00       306\n",
            "           6       1.00      0.01      0.02       242\n",
            "           7       0.98      0.09      0.17       487\n",
            "           8       0.94      0.13      0.23       225\n",
            "           9       0.75      0.01      0.02       286\n",
            "          10       1.00      0.48      0.65       129\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.00      0.00      0.00       124\n",
            "          13       0.90      0.21      0.35        42\n",
            "          14       0.36      0.21      0.27       388\n",
            "          15       1.00      0.05      0.10       225\n",
            "          16       0.22      0.82      0.34       289\n",
            "          17       0.96      0.31      0.47       307\n",
            "          18       0.98      0.21      0.34       213\n",
            "\n",
            "   micro avg       0.64      0.58      0.61      9443\n",
            "   macro avg       0.63      0.23      0.25      9443\n",
            "weighted avg       0.71      0.58      0.52      9443\n",
            " samples avg       0.71      0.68      0.66      9443\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5850, Accuracy: 2336.0/6000 (38.93%)\n",
            ", F1 score: 0.6561\n",
            "Train Epoch: 10 [0/24000 (0%)]\tLoss: 0.581685 \t Time:  0.679208\n",
            "Train Epoch: 10 [1600/24000 (7%)]\tLoss: 0.583380 \t Time:  14.175405\n",
            "Train Epoch: 10 [3200/24000 (13%)]\tLoss: 0.583585 \t Time:  27.629969\n",
            "Train Epoch: 10 [4800/24000 (20%)]\tLoss: 0.586056 \t Time:  41.030935\n",
            "Train Epoch: 10 [6400/24000 (27%)]\tLoss: 0.581122 \t Time:  54.467492\n",
            "Train Epoch: 10 [8000/24000 (33%)]\tLoss: 0.586915 \t Time:  67.877560\n",
            "Train Epoch: 10 [9600/24000 (40%)]\tLoss: 0.581872 \t Time:  81.398811\n",
            "Train Epoch: 10 [11200/24000 (47%)]\tLoss: 0.581143 \t Time:  94.858680\n",
            "Train Epoch: 10 [12800/24000 (53%)]\tLoss: 0.589902 \t Time:  108.310164\n",
            "Train Epoch: 10 [14400/24000 (60%)]\tLoss: 0.587417 \t Time:  121.756448\n",
            "Train Epoch: 10 [16000/24000 (67%)]\tLoss: 0.581288 \t Time:  135.198042\n",
            "Train Epoch: 10 [17600/24000 (73%)]\tLoss: 0.585181 \t Time:  148.648701\n",
            "Train Epoch: 10 [19200/24000 (80%)]\tLoss: 0.589736 \t Time:  162.119282\n",
            "Train Epoch: 10 [20800/24000 (87%)]\tLoss: 0.582287 \t Time:  175.536065\n",
            "Train Epoch: 10 [22400/24000 (93%)]\tLoss: 0.585788 \t Time:  188.986053\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      1.00      0.86      4537\n",
            "           1       0.13      0.15      0.14       240\n",
            "           2       0.70      0.06      0.11       903\n",
            "           3       0.27      0.44      0.34       254\n",
            "           4       1.00      0.08      0.14       246\n",
            "           5       0.00      0.00      0.00       306\n",
            "           6       1.00      0.01      0.02       242\n",
            "           7       0.97      0.08      0.14       487\n",
            "           8       0.87      0.15      0.26       225\n",
            "           9       1.00      0.02      0.03       286\n",
            "          10       1.00      0.50      0.67       129\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.00      0.00      0.00       124\n",
            "          13       1.00      0.21      0.35        42\n",
            "          14       0.47      0.23      0.31       388\n",
            "          15       1.00      0.01      0.02       225\n",
            "          16       0.19      0.81      0.31       289\n",
            "          17       0.95      0.27      0.43       307\n",
            "          18       0.97      0.30      0.45       213\n",
            "\n",
            "   micro avg       0.63      0.57      0.60      9443\n",
            "   macro avg       0.65      0.23      0.24      9443\n",
            "weighted avg       0.71      0.57      0.51      9443\n",
            " samples avg       0.70      0.68      0.65      9443\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5851, Accuracy: 2227.0/6000 (37.12%)\n",
            ", F1 score: 0.6463\n",
            "Counter 1 of 3\n",
            "Train Epoch: 11 [0/24000 (0%)]\tLoss: 0.583738 \t Time:  0.692583\n",
            "Train Epoch: 11 [1600/24000 (7%)]\tLoss: 0.578455 \t Time:  14.146941\n",
            "Train Epoch: 11 [3200/24000 (13%)]\tLoss: 0.586546 \t Time:  27.574487\n",
            "Train Epoch: 11 [4800/24000 (20%)]\tLoss: 0.580544 \t Time:  41.019793\n",
            "Train Epoch: 11 [6400/24000 (27%)]\tLoss: 0.586069 \t Time:  54.429137\n",
            "Train Epoch: 11 [8000/24000 (33%)]\tLoss: 0.584401 \t Time:  67.882185\n",
            "Train Epoch: 11 [9600/24000 (40%)]\tLoss: 0.582812 \t Time:  81.358839\n",
            "Train Epoch: 11 [11200/24000 (47%)]\tLoss: 0.583863 \t Time:  94.773384\n",
            "Train Epoch: 11 [12800/24000 (53%)]\tLoss: 0.585257 \t Time:  108.205727\n",
            "Train Epoch: 11 [14400/24000 (60%)]\tLoss: 0.579667 \t Time:  121.678598\n",
            "Train Epoch: 11 [16000/24000 (67%)]\tLoss: 0.580182 \t Time:  135.130655\n",
            "Train Epoch: 11 [17600/24000 (73%)]\tLoss: 0.581166 \t Time:  148.598590\n",
            "Train Epoch: 11 [19200/24000 (80%)]\tLoss: 0.579957 \t Time:  162.028466\n",
            "Train Epoch: 11 [20800/24000 (87%)]\tLoss: 0.582689 \t Time:  175.456841\n",
            "Train Epoch: 11 [22400/24000 (93%)]\tLoss: 0.583570 \t Time:  188.862025\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      1.00      0.86      4537\n",
            "           1       0.09      0.11      0.10       240\n",
            "           2       0.68      0.12      0.20       903\n",
            "           3       0.28      0.56      0.37       254\n",
            "           4       1.00      0.15      0.26       246\n",
            "           5       1.00      0.00      0.01       306\n",
            "           6       1.00      0.03      0.06       242\n",
            "           7       0.93      0.09      0.16       487\n",
            "           8       0.93      0.23      0.36       225\n",
            "           9       1.00      0.01      0.02       286\n",
            "          10       1.00      0.52      0.68       129\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.00      0.00      0.00       124\n",
            "          13       0.92      0.26      0.41        42\n",
            "          14       0.39      0.23      0.29       388\n",
            "          15       1.00      0.02      0.04       225\n",
            "          16       0.21      0.83      0.34       289\n",
            "          17       0.96      0.22      0.36       307\n",
            "          18       1.00      0.30      0.46       213\n",
            "\n",
            "   micro avg       0.63      0.58      0.61      9443\n",
            "   macro avg       0.69      0.25      0.26      9443\n",
            "weighted avg       0.74      0.58      0.53      9443\n",
            " samples avg       0.70      0.69      0.65      9443\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5858, Accuracy: 2229.0/6000 (37.15%)\n",
            ", F1 score: 0.6515\n",
            "Counter 2 of 3\n",
            "Train Epoch: 12 [0/24000 (0%)]\tLoss: 0.588762 \t Time:  0.659767\n",
            "Train Epoch: 12 [1600/24000 (7%)]\tLoss: 0.582366 \t Time:  14.123123\n",
            "Train Epoch: 12 [3200/24000 (13%)]\tLoss: 0.583269 \t Time:  27.566894\n",
            "Train Epoch: 12 [4800/24000 (20%)]\tLoss: 0.585120 \t Time:  41.039180\n",
            "Train Epoch: 12 [6400/24000 (27%)]\tLoss: 0.580626 \t Time:  54.510997\n",
            "Train Epoch: 12 [8000/24000 (33%)]\tLoss: 0.578228 \t Time:  67.897499\n",
            "Train Epoch: 12 [9600/24000 (40%)]\tLoss: 0.589046 \t Time:  81.334232\n",
            "Train Epoch: 12 [11200/24000 (47%)]\tLoss: 0.582545 \t Time:  94.801271\n",
            "Train Epoch: 12 [12800/24000 (53%)]\tLoss: 0.579327 \t Time:  108.273393\n",
            "Train Epoch: 12 [14400/24000 (60%)]\tLoss: 0.585164 \t Time:  121.711455\n",
            "Train Epoch: 12 [16000/24000 (67%)]\tLoss: 0.580397 \t Time:  135.180795\n",
            "Train Epoch: 12 [17600/24000 (73%)]\tLoss: 0.585546 \t Time:  148.630695\n",
            "Train Epoch: 12 [19200/24000 (80%)]\tLoss: 0.583411 \t Time:  162.081237\n",
            "Train Epoch: 12 [20800/24000 (87%)]\tLoss: 0.583255 \t Time:  175.527493\n",
            "Train Epoch: 12 [22400/24000 (93%)]\tLoss: 0.584424 \t Time:  188.960543\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      1.00      0.86      4537\n",
            "           1       0.09      0.11      0.10       240\n",
            "           2       0.75      0.08      0.15       903\n",
            "           3       0.21      0.55      0.31       254\n",
            "           4       1.00      0.19      0.32       246\n",
            "           5       0.00      0.00      0.00       306\n",
            "           6       1.00      0.01      0.02       242\n",
            "           7       0.94      0.10      0.18       487\n",
            "           8       0.98      0.25      0.40       225\n",
            "           9       1.00      0.02      0.03       286\n",
            "          10       1.00      0.48      0.65       129\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.00      0.00      0.00       124\n",
            "          13       1.00      0.33      0.50        42\n",
            "          14       0.42      0.24      0.31       388\n",
            "          15       0.00      0.00      0.00       225\n",
            "          16       0.24      0.80      0.37       289\n",
            "          17       0.95      0.27      0.42       307\n",
            "          18       0.98      0.27      0.43       213\n",
            "\n",
            "   micro avg       0.63      0.58      0.61      9443\n",
            "   macro avg       0.60      0.25      0.27      9443\n",
            "weighted avg       0.69      0.58      0.53      9443\n",
            " samples avg       0.70      0.68      0.66      9443\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5849, Accuracy: 2323.0/6000 (38.72%)\n",
            ", F1 score: 0.6551\n",
            "Counter 3 of 3\n",
            "Early stopping with best loss:  0.5838710970083872 and val_acc for this epoch:  0.6550928571428571\n"
          ]
        }
      ],
      "source": [
        "batch_size_list = [32, 64, 128]\n",
        "\n",
        "batch_size_32 = batch_size_tuning(32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5el_rb2TLPa",
        "outputId": "95e78911-2e97-4bef-bd69-20a308f45605"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [0/24000 (0%)]\tLoss: 0.584645 \t Time:  2.578530\n",
            "Train Epoch: 0 [6400/24000 (27%)]\tLoss: 0.145243 \t Time:  49.782960\n",
            "Train Epoch: 0 [12800/24000 (53%)]\tLoss: 0.089360 \t Time:  96.661785\n",
            "Train Epoch: 0 [19200/24000 (80%)]\tLoss: 0.100776 \t Time:  143.655802\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.91      0.94      4550\n",
            "           1       1.00      0.02      0.03       245\n",
            "           2       0.61      0.43      0.51       857\n",
            "           3       0.93      0.65      0.77       266\n",
            "           4       0.97      0.95      0.96       199\n",
            "           5       0.94      0.64      0.76       291\n",
            "           6       0.95      0.89      0.92       227\n",
            "           7       0.85      0.34      0.48       467\n",
            "           8       0.94      0.57      0.71       218\n",
            "           9       0.84      0.24      0.38       302\n",
            "          10       1.00      0.59      0.74       123\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.97      0.47      0.63       125\n",
            "          13       0.00      0.00      0.00        44\n",
            "          14       0.96      0.32      0.48       372\n",
            "          15       0.92      0.56      0.70       215\n",
            "          16       0.97      0.85      0.91       307\n",
            "          17       0.98      0.75      0.85       311\n",
            "          18       0.99      0.85      0.91       222\n",
            "\n",
            "   micro avg       0.93      0.72      0.81      9341\n",
            "   macro avg       0.83      0.53      0.61      9341\n",
            "weighted avg       0.92      0.72      0.78      9341\n",
            " samples avg       0.92      0.81      0.84      9341\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0870, Accuracy: 3953.0/6000 (65.88%)\n",
            ", F1 score: 0.8422\n",
            "Train Epoch: 1 [0/24000 (0%)]\tLoss: 0.080450 \t Time:  2.149971\n",
            "Train Epoch: 1 [6400/24000 (27%)]\tLoss: 0.068736 \t Time:  49.166446\n",
            "Train Epoch: 1 [12800/24000 (53%)]\tLoss: 0.070304 \t Time:  96.017975\n",
            "Train Epoch: 1 [19200/24000 (80%)]\tLoss: 0.067026 \t Time:  142.905878\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.93      0.94      4550\n",
            "           1       0.89      0.31      0.46       245\n",
            "           2       0.64      0.43      0.51       857\n",
            "           3       1.00      0.64      0.78       266\n",
            "           4       0.97      0.95      0.96       199\n",
            "           5       0.94      0.64      0.76       291\n",
            "           6       0.94      0.89      0.92       227\n",
            "           7       0.84      0.37      0.51       467\n",
            "           8       0.90      0.58      0.70       218\n",
            "           9       0.74      0.38      0.50       302\n",
            "          10       1.00      0.59      0.74       123\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.86      0.58      0.70       125\n",
            "          13       1.00      0.52      0.69        44\n",
            "          14       0.95      0.33      0.49       372\n",
            "          15       0.91      0.60      0.73       215\n",
            "          16       0.97      0.89      0.93       307\n",
            "          17       0.98      0.75      0.85       311\n",
            "          18       0.99      0.86      0.92       222\n",
            "\n",
            "   micro avg       0.93      0.74      0.83      9341\n",
            "   macro avg       0.87      0.59      0.69      9341\n",
            "weighted avg       0.92      0.74      0.81      9341\n",
            " samples avg       0.93      0.84      0.86      9341\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0817, Accuracy: 4054.0/6000 (67.57%)\n",
            ", F1 score: 0.8606\n",
            "Train Epoch: 2 [0/24000 (0%)]\tLoss: 0.110620 \t Time:  2.055646\n",
            "Train Epoch: 2 [6400/24000 (27%)]\tLoss: 0.092577 \t Time:  48.872986\n",
            "Train Epoch: 2 [12800/24000 (53%)]\tLoss: 0.068728 \t Time:  95.316018\n",
            "Train Epoch: 2 [19200/24000 (80%)]\tLoss: 0.083673 \t Time:  141.851516\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.94      0.94      4550\n",
            "           1       0.90      0.32      0.47       245\n",
            "           2       0.58      0.53      0.56       857\n",
            "           3       0.94      0.68      0.79       266\n",
            "           4       0.96      0.95      0.96       199\n",
            "           5       0.94      0.65      0.77       291\n",
            "           6       0.94      0.90      0.92       227\n",
            "           7       0.95      0.31      0.47       467\n",
            "           8       0.88      0.62      0.73       218\n",
            "           9       0.89      0.29      0.44       302\n",
            "          10       1.00      0.59      0.74       123\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.87      0.58      0.70       125\n",
            "          13       1.00      0.45      0.62        44\n",
            "          14       0.96      0.33      0.49       372\n",
            "          15       0.91      0.60      0.72       215\n",
            "          16       0.99      0.88      0.93       307\n",
            "          17       0.98      0.76      0.86       311\n",
            "          18       0.98      0.86      0.92       222\n",
            "\n",
            "   micro avg       0.91      0.76      0.83      9341\n",
            "   macro avg       0.87      0.59      0.69      9341\n",
            "weighted avg       0.91      0.76      0.81      9341\n",
            " samples avg       0.92      0.84      0.86      9341\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0811, Accuracy: 4016.0/6000 (66.93%)\n",
            ", F1 score: 0.8608\n",
            "Train Epoch: 3 [0/24000 (0%)]\tLoss: 0.080806 \t Time:  2.083885\n",
            "Train Epoch: 3 [6400/24000 (27%)]\tLoss: 0.091506 \t Time:  48.922692\n",
            "Train Epoch: 3 [12800/24000 (53%)]\tLoss: 0.079780 \t Time:  95.472599\n",
            "Train Epoch: 3 [19200/24000 (80%)]\tLoss: 0.062730 \t Time:  142.023644\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.95      0.94      4550\n",
            "           1       0.91      0.35      0.51       245\n",
            "           2       0.65      0.45      0.53       857\n",
            "           3       0.95      0.70      0.81       266\n",
            "           4       0.97      0.95      0.96       199\n",
            "           5       0.94      0.65      0.77       291\n",
            "           6       0.95      0.88      0.91       227\n",
            "           7       0.86      0.36      0.50       467\n",
            "           8       0.87      0.65      0.74       218\n",
            "           9       0.69      0.40      0.51       302\n",
            "          10       1.00      0.59      0.74       123\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.98      0.51      0.67       125\n",
            "          13       1.00      0.57      0.72        44\n",
            "          14       0.96      0.33      0.50       372\n",
            "          15       0.93      0.58      0.71       215\n",
            "          16       0.97      0.89      0.93       307\n",
            "          17       0.98      0.77      0.86       311\n",
            "          18       0.97      0.88      0.92       222\n",
            "\n",
            "   micro avg       0.91      0.76      0.83      9341\n",
            "   macro avg       0.87      0.60      0.70      9341\n",
            "weighted avg       0.90      0.76      0.81      9341\n",
            " samples avg       0.93      0.85      0.87      9341\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0803, Accuracy: 4075.0/6000 (67.92%)\n",
            ", F1 score: 0.8653\n",
            "Train Epoch: 4 [0/24000 (0%)]\tLoss: 0.063532 \t Time:  2.049079\n",
            "Train Epoch: 4 [6400/24000 (27%)]\tLoss: 0.071557 \t Time:  48.786813\n",
            "Train Epoch: 4 [12800/24000 (53%)]\tLoss: 0.069263 \t Time:  95.319535\n",
            "Train Epoch: 4 [19200/24000 (80%)]\tLoss: 0.073491 \t Time:  141.879548\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.94      0.94      4550\n",
            "           1       0.91      0.37      0.52       245\n",
            "           2       0.66      0.46      0.54       857\n",
            "           3       0.95      0.72      0.82       266\n",
            "           4       0.98      0.95      0.97       199\n",
            "           5       0.92      0.66      0.77       291\n",
            "           6       0.94      0.90      0.92       227\n",
            "           7       0.80      0.40      0.53       467\n",
            "           8       0.94      0.55      0.70       218\n",
            "           9       0.75      0.38      0.51       302\n",
            "          10       1.00      0.59      0.74       123\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.98      0.51      0.67       125\n",
            "          13       1.00      0.52      0.69        44\n",
            "          14       0.92      0.35      0.51       372\n",
            "          15       0.88      0.61      0.72       215\n",
            "          16       0.97      0.90      0.93       307\n",
            "          17       0.97      0.77      0.85       311\n",
            "          18       0.98      0.88      0.93       222\n",
            "\n",
            "   micro avg       0.92      0.76      0.83      9341\n",
            "   macro avg       0.87      0.60      0.70      9341\n",
            "weighted avg       0.91      0.76      0.81      9341\n",
            " samples avg       0.93      0.85      0.86      9341\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0799, Accuracy: 4079.0/6000 (67.98%)\n",
            ", F1 score: 0.8649\n",
            "Counter 1 of 3\n",
            "Train Epoch: 5 [0/24000 (0%)]\tLoss: 0.059825 \t Time:  2.078865\n",
            "Train Epoch: 5 [6400/24000 (27%)]\tLoss: 0.058516 \t Time:  49.178225\n",
            "Train Epoch: 5 [12800/24000 (53%)]\tLoss: 0.077803 \t Time:  96.143164\n",
            "Train Epoch: 5 [19200/24000 (80%)]\tLoss: 0.068171 \t Time:  143.343488\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.93      0.94      4550\n",
            "           1       0.97      0.36      0.52       245\n",
            "           2       0.68      0.41      0.51       857\n",
            "           3       0.98      0.70      0.82       266\n",
            "           4       0.98      0.95      0.97       199\n",
            "           5       0.94      0.66      0.77       291\n",
            "           6       0.94      0.90      0.92       227\n",
            "           7       0.88      0.36      0.51       467\n",
            "           8       0.91      0.61      0.73       218\n",
            "           9       0.83      0.39      0.53       302\n",
            "          10       1.00      0.59      0.74       123\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.98      0.51      0.67       125\n",
            "          13       1.00      0.55      0.71        44\n",
            "          14       0.94      0.35      0.51       372\n",
            "          15       0.88      0.63      0.74       215\n",
            "          16       0.99      0.88      0.93       307\n",
            "          17       0.98      0.77      0.86       311\n",
            "          18       0.99      0.88      0.94       222\n",
            "\n",
            "   micro avg       0.93      0.75      0.83      9341\n",
            "   macro avg       0.88      0.60      0.70      9341\n",
            "weighted avg       0.92      0.75      0.81      9341\n",
            " samples avg       0.94      0.84      0.87      9341\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0798, Accuracy: 4115.0/6000 (68.58%)\n",
            ", F1 score: 0.8666\n",
            "Train Epoch: 6 [0/24000 (0%)]\tLoss: 0.060643 \t Time:  2.033293\n",
            "Train Epoch: 6 [6400/24000 (27%)]\tLoss: 0.072857 \t Time:  48.902184\n",
            "Train Epoch: 6 [12800/24000 (53%)]\tLoss: 0.057881 \t Time:  95.627337\n",
            "Train Epoch: 6 [19200/24000 (80%)]\tLoss: 0.061541 \t Time:  142.499105\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.94      0.95      4550\n",
            "           1       0.92      0.39      0.55       245\n",
            "           2       0.70      0.42      0.53       857\n",
            "           3       0.97      0.71      0.82       266\n",
            "           4       0.98      0.95      0.97       199\n",
            "           5       0.93      0.65      0.77       291\n",
            "           6       0.93      0.90      0.92       227\n",
            "           7       0.77      0.42      0.54       467\n",
            "           8       0.89      0.64      0.74       218\n",
            "           9       0.79      0.38      0.51       302\n",
            "          10       1.00      0.59      0.74       123\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.99      0.54      0.69       125\n",
            "          13       1.00      0.57      0.72        44\n",
            "          14       0.85      0.36      0.51       372\n",
            "          15       0.91      0.62      0.74       215\n",
            "          16       0.98      0.88      0.93       307\n",
            "          17       0.98      0.77      0.86       311\n",
            "          18       0.99      0.88      0.94       222\n",
            "\n",
            "   micro avg       0.93      0.76      0.83      9341\n",
            "   macro avg       0.87      0.61      0.71      9341\n",
            "weighted avg       0.91      0.76      0.82      9341\n",
            " samples avg       0.94      0.85      0.87      9341\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0801, Accuracy: 4118.0/6000 (68.63%)\n",
            ", F1 score: 0.8674\n",
            "Train Epoch: 7 [0/24000 (0%)]\tLoss: 0.059736 \t Time:  2.077710\n",
            "Train Epoch: 7 [6400/24000 (27%)]\tLoss: 0.068426 \t Time:  48.836041\n",
            "Train Epoch: 7 [12800/24000 (53%)]\tLoss: 0.060685 \t Time:  95.462925\n",
            "Train Epoch: 7 [19200/24000 (80%)]\tLoss: 0.075699 \t Time:  141.919255\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.94      0.94      4550\n",
            "           1       0.96      0.37      0.53       245\n",
            "           2       0.65      0.48      0.55       857\n",
            "           3       0.99      0.71      0.82       266\n",
            "           4       0.98      0.95      0.97       199\n",
            "           5       0.94      0.65      0.77       291\n",
            "           6       0.94      0.89      0.92       227\n",
            "           7       0.85      0.39      0.54       467\n",
            "           8       0.92      0.65      0.76       218\n",
            "           9       0.63      0.46      0.53       302\n",
            "          10       1.00      0.60      0.75       123\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.88      0.57      0.69       125\n",
            "          13       1.00      0.57      0.72        44\n",
            "          14       0.87      0.35      0.50       372\n",
            "          15       0.92      0.61      0.73       215\n",
            "          16       0.98      0.88      0.93       307\n",
            "          17       0.98      0.77      0.86       311\n",
            "          18       0.98      0.88      0.93       222\n",
            "\n",
            "   micro avg       0.91      0.77      0.83      9341\n",
            "   macro avg       0.86      0.62      0.71      9341\n",
            "weighted avg       0.90      0.77      0.82      9341\n",
            " samples avg       0.93      0.85      0.87      9341\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0809, Accuracy: 4086.0/6000 (68.10%)\n",
            ", F1 score: 0.8667\n",
            "Counter 1 of 3\n",
            "Train Epoch: 8 [0/24000 (0%)]\tLoss: 0.064446 \t Time:  2.046167\n",
            "Train Epoch: 8 [6400/24000 (27%)]\tLoss: 0.064933 \t Time:  48.927391\n",
            "Train Epoch: 8 [12800/24000 (53%)]\tLoss: 0.071411 \t Time:  95.611817\n",
            "Train Epoch: 8 [19200/24000 (80%)]\tLoss: 0.070001 \t Time:  142.385789\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.93      0.94      4550\n",
            "           1       0.92      0.40      0.56       245\n",
            "           2       0.65      0.47      0.55       857\n",
            "           3       0.97      0.73      0.83       266\n",
            "           4       0.98      0.96      0.97       199\n",
            "           5       0.93      0.66      0.78       291\n",
            "           6       0.95      0.90      0.93       227\n",
            "           7       0.77      0.43      0.55       467\n",
            "           8       0.93      0.64      0.76       218\n",
            "           9       0.65      0.45      0.53       302\n",
            "          10       0.99      0.60      0.75       123\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.99      0.54      0.69       125\n",
            "          13       1.00      0.55      0.71        44\n",
            "          14       0.83      0.37      0.51       372\n",
            "          15       0.84      0.64      0.73       215\n",
            "          16       0.97      0.89      0.93       307\n",
            "          17       0.95      0.78      0.86       311\n",
            "          18       0.99      0.87      0.93       222\n",
            "\n",
            "   micro avg       0.92      0.76      0.83      9341\n",
            "   macro avg       0.86      0.62      0.71      9341\n",
            "weighted avg       0.90      0.76      0.82      9341\n",
            " samples avg       0.93      0.85      0.87      9341\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0814, Accuracy: 4091.0/6000 (68.18%)\n",
            ", F1 score: 0.8661\n",
            "Counter 2 of 3\n",
            "Train Epoch: 9 [0/24000 (0%)]\tLoss: 0.045577 \t Time:  2.056132\n",
            "Train Epoch: 9 [6400/24000 (27%)]\tLoss: 0.056615 \t Time:  48.773148\n",
            "Train Epoch: 9 [12800/24000 (53%)]\tLoss: 0.061313 \t Time:  95.372506\n",
            "Train Epoch: 9 [19200/24000 (80%)]\tLoss: 0.064565 \t Time:  142.100996\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.93      0.94      4550\n",
            "           1       0.90      0.39      0.54       245\n",
            "           2       0.67      0.43      0.53       857\n",
            "           3       0.97      0.72      0.83       266\n",
            "           4       0.98      0.95      0.97       199\n",
            "           5       0.94      0.64      0.76       291\n",
            "           6       0.95      0.89      0.92       227\n",
            "           7       0.82      0.41      0.54       467\n",
            "           8       0.91      0.61      0.73       218\n",
            "           9       0.65      0.44      0.52       302\n",
            "          10       0.99      0.60      0.75       123\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.99      0.54      0.70       125\n",
            "          13       1.00      0.48      0.65        44\n",
            "          14       0.78      0.37      0.50       372\n",
            "          15       0.77      0.67      0.71       215\n",
            "          16       0.97      0.89      0.93       307\n",
            "          17       0.96      0.78      0.86       311\n",
            "          18       0.99      0.88      0.93       222\n",
            "\n",
            "   micro avg       0.92      0.76      0.83      9341\n",
            "   macro avg       0.85      0.61      0.70      9341\n",
            "weighted avg       0.90      0.76      0.81      9341\n",
            " samples avg       0.93      0.84      0.86      9341\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0841, Accuracy: 4078.0/6000 (67.97%)\n",
            ", F1 score: 0.8620\n",
            "Counter 3 of 3\n",
            "Early stopping with best loss:  0.06299259117309083 and val_acc for this epoch:  0.8620473424723424\n"
          ]
        }
      ],
      "source": [
        "batch_size_128 = batch_size_tuning(128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "RTNEeVEXTRXa",
        "outputId": "90f9535b-48b0-4cf4-e113-20ce2befc0a7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2bbbe747-8fc5-4c90-b03f-a307a4781831\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>batch size</th>\n",
              "      <th>f1 score</th>\n",
              "      <th>model size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>32</td>\n",
              "      <td>0.656</td>\n",
              "      <td>96.36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>64</td>\n",
              "      <td>0.871</td>\n",
              "      <td>96.36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>128</td>\n",
              "      <td>0.867</td>\n",
              "      <td>96.36</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2bbbe747-8fc5-4c90-b03f-a307a4781831')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2bbbe747-8fc5-4c90-b03f-a307a4781831 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2bbbe747-8fc5-4c90-b03f-a307a4781831');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   batch size  f1 score  model size\n",
              "0          32     0.656       96.36\n",
              "1          64     0.871       96.36\n",
              "2         128     0.867       96.36"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch_size__dict = {}\n",
        "batch_size__dict['batch size'] = batch_size_list\n",
        "batch_size__dict['f1 score'] = [batch_size_32, default_f1_score, batch_size_128]\n",
        "batch_size__dict['model size'] = [96.36, 96.36, 96.36]\n",
        "\n",
        "batch_size_df = pd.DataFrame.from_dict(batch_size__dict)\n",
        "batch_size_df['f1 score'] = round(batch_size_df['f1 score'],3)\n",
        "batch_size_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-jhPHLChTuDQ",
        "outputId": "b09c0715-1b78-4d2d-8e20-97913f121a04"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'f1 score')"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(batch_size_df['batch size'], batch_size_df['f1 score'])\n",
        "plt.title(\"f1 score of different batch size\")\n",
        "plt.xlabel(\"batch size\")\n",
        "plt.ylabel(\"f1 score\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETEMdaLNXJHa"
      },
      "source": [
        "# word embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8XIWS4utXMcx"
      },
      "outputs": [],
      "source": [
        "def word_emb_dim_tuning(cbow=False, skipgram=False):\n",
        "\n",
        "  from gensim.models import Word2Vec, FastText\n",
        "  class Text_Embedding(nn.Module):\n",
        "      def __init__(self, word_list, training_data):\n",
        "          super(Text_Embedding, self).__init__()\n",
        "          # self.tokenizer = tokenizer\n",
        "          self.emb_table = None\n",
        "          self.training_data = training_data\n",
        "          # self.model = api.load(\"glove-twitter-25\")\n",
        "          if cbow == True:\n",
        "            self.model = Word2Vec(sentences=self.training_data, size=150, window=5, min_count=1, workers=4, sg=0)\n",
        "          if skipgram == True:\n",
        "            self.model = Word2Vec(sentences=self.training_data, size=150, window=5, min_count=1, workers=4, sg=1)\n",
        "          self.keys = list(self.model.wv.vocab.keys())\n",
        "          # self.keys = self.model # for glove model\n",
        "          self.emb_dim = self.model.vector_size\n",
        "\n",
        "      def get_embedding(self):\n",
        "          # training model\n",
        "          model = self.model\n",
        "          assert(model is not None)\n",
        "          emb_table = []\n",
        "          for i, word in enumerate(word_list):\n",
        "              if word in self.keys:\n",
        "                  word_emb = model.wv[word] # for word2vec\n",
        "                  # word_emb = model[word]\n",
        "                  emb_table.append(word_emb)\n",
        "              else:\n",
        "                  word_emb = [0]* self.emb_dim\n",
        "                  emb_table.append(word_emb)\n",
        "          emb_table = np.array(emb_table)\n",
        "          self.emb_table = emb_table\n",
        "          return emb_table\n",
        "      \n",
        "  training_data = x_train[\"Caption\"].to_list()\n",
        "  embedding =  Text_Embedding(word_list, training_data)\n",
        "  emb_table = embedding.get_embedding()\n",
        "\n",
        "  device = torch.device('cuda' if torch.cuda.is_available else 'cpu')\n",
        "  img_model = Resnext50(num_class).to(device)\n",
        "  # img_model = DenseNet121(num_class).to(device)\n",
        "  gpu_usage() \n",
        "  # text_model = Bi_LSTM_Attention(emb_table, 256, n_emb = 2048).to(device)\n",
        "  n_hidden = 128\n",
        "  text_model = Bi_GRU_Attention(emb_table, n_hidden, n_emb = 256).to(device)\n",
        "  gpu_usage() \n",
        "  n_emb = 256\n",
        "  model = Concatenate_Embed_Model(img_model, text_model, n_emb, num_class).to(device)\n",
        "  gpu_usage() \n",
        "  print('Model initialized.')\n",
        "\n",
        "  # from torch.optim.lr_scheduler import StepLR\n",
        "  n_epochs = 15\n",
        "  log_interval = 50\n",
        "  lr = 3e-4\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr= lr)\n",
        "\n",
        "  criterion = nn.BCELoss()\n",
        "  train_loss = []\n",
        "  best_f1_score = -float(\"inf\") # record the best loss to get the best model\n",
        "\n",
        "  for epoch in range(n_epochs):\n",
        "      loss = train_epoch(log_interval, model, train_loader, optimizer, epoch, criterion)\n",
        "      train_loss.append(loss)\n",
        "      f1score = validation(model, device, val_loader, criterion, 0.5)\n",
        "\n",
        "      # https://www.kaggle.com/general/178486\n",
        "      if f1score > best_f1_score:\n",
        "          best_f1_score = f1score\n",
        "          es = 0\n",
        "          if cbow==True:\n",
        "            torch.save(model, \"cbow_model.pt\")\n",
        "          if skipgram==True:\n",
        "            torch.save(model, \"skipgram_model.pt\")\n",
        "      else:\n",
        "          es += 1\n",
        "          print(\"Counter {} of 3\".format(es))\n",
        "\n",
        "          if es >= 3:\n",
        "              print(\"Early stopping with best loss: \", loss, \"and val_acc for this epoch: \", f1score)\n",
        "              break\n",
        "\n",
        "  return best_f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJjhGPlqbG7x",
        "outputId": "35567e5a-8c6f-48bc-d191-a3a94087e337"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| ID | GPU | MEM |\n",
            "------------------\n",
            "|  0 |  1% | 59% |\n",
            "| ID | GPU | MEM |\n",
            "------------------\n",
            "|  0 |  1% | 59% |\n",
            "| ID | GPU | MEM |\n",
            "------------------\n",
            "|  0 |  5% | 59% |\n",
            "Model initialized.\n",
            "Train Epoch: 0 [0/24000 (0%)]\tLoss: 0.695941 \t Time:  1.128481\n",
            "Train Epoch: 0 [3200/24000 (13%)]\tLoss: 0.616993 \t Time:  25.228561\n",
            "Train Epoch: 0 [6400/24000 (27%)]\tLoss: 0.607876 \t Time:  49.230968\n",
            "Train Epoch: 0 [9600/24000 (40%)]\tLoss: 0.607904 \t Time:  73.241834\n",
            "Train Epoch: 0 [12800/24000 (53%)]\tLoss: 0.601604 \t Time:  97.305757\n",
            "Train Epoch: 0 [16000/24000 (67%)]\tLoss: 0.603696 \t Time:  121.328594\n",
            "Train Epoch: 0 [19200/24000 (80%)]\tLoss: 0.600378 \t Time:  145.361748\n",
            "Train Epoch: 0 [22400/24000 (93%)]\tLoss: 0.603328 \t Time:  169.402500\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.99      0.86      4526\n",
            "           1       0.00      0.00      0.00       222\n",
            "           2       0.50      0.27      0.35       890\n",
            "           3       0.00      0.00      0.00       254\n",
            "           4       0.20      0.02      0.03       231\n",
            "           5       0.00      0.00      0.00       253\n",
            "           6       1.00      0.03      0.05       254\n",
            "           7       0.05      0.00      0.00       460\n",
            "           8       0.00      0.00      0.00       233\n",
            "           9       0.00      0.00      0.00       307\n",
            "          10       0.45      0.14      0.22       140\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.00      0.00      0.00       123\n",
            "          13       0.00      0.09      0.01        47\n",
            "          14       0.05      0.08      0.06       399\n",
            "          15       0.00      0.00      0.00       205\n",
            "          16       0.00      0.00      0.00       282\n",
            "          17       0.33      0.00      0.01       329\n",
            "          18       0.05      0.01      0.01       181\n",
            "\n",
            "   micro avg       0.59      0.51      0.55      9336\n",
            "   macro avg       0.18      0.09      0.08      9336\n",
            "weighted avg       0.47      0.51      0.46      9336\n",
            " samples avg       0.64      0.60      0.58      9336\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.6007, Accuracy: 1834.0/6000 (30.57%)\n",
            ", F1 score: 0.5812\n",
            "Train Epoch: 1 [0/24000 (0%)]\tLoss: 0.595799 \t Time:  1.028936\n",
            "Train Epoch: 1 [3200/24000 (13%)]\tLoss: 0.597632 \t Time:  25.056669\n",
            "Train Epoch: 1 [6400/24000 (27%)]\tLoss: 0.597489 \t Time:  49.035773\n",
            "Train Epoch: 1 [9600/24000 (40%)]\tLoss: 0.601335 \t Time:  73.042240\n",
            "Train Epoch: 1 [12800/24000 (53%)]\tLoss: 0.597571 \t Time:  97.015239\n",
            "Train Epoch: 1 [16000/24000 (67%)]\tLoss: 0.596567 \t Time:  121.007489\n",
            "Train Epoch: 1 [19200/24000 (80%)]\tLoss: 0.597576 \t Time:  145.020655\n",
            "Train Epoch: 1 [22400/24000 (93%)]\tLoss: 0.596660 \t Time:  169.052929\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.98      0.88      4526\n",
            "           1       0.17      0.06      0.09       222\n",
            "           2       0.41      0.47      0.44       890\n",
            "           3       0.00      0.00      0.00       254\n",
            "           4       0.77      0.21      0.33       231\n",
            "           5       0.94      0.06      0.12       253\n",
            "           6       0.95      0.39      0.55       254\n",
            "           7       0.23      0.50      0.32       460\n",
            "           8       0.00      0.00      0.00       233\n",
            "           9       0.34      0.24      0.28       307\n",
            "          10       0.57      0.14      0.23       140\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.00      0.00      0.00       123\n",
            "          13       0.01      0.17      0.01        47\n",
            "          14       0.12      0.25      0.16       399\n",
            "          15       0.00      0.00      0.00       205\n",
            "          16       1.00      0.05      0.09       282\n",
            "          17       0.42      0.02      0.05       329\n",
            "          18       0.14      0.01      0.02       181\n",
            "\n",
            "   micro avg       0.55      0.59      0.57      9336\n",
            "   macro avg       0.36      0.19      0.19      9336\n",
            "weighted avg       0.58      0.59      0.54      9336\n",
            " samples avg       0.61      0.65      0.59      9336\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5951, Accuracy: 1898.0/6000 (31.63%)\n",
            ", F1 score: 0.5944\n",
            "Train Epoch: 2 [0/24000 (0%)]\tLoss: 0.596860 \t Time:  1.008086\n",
            "Train Epoch: 2 [3200/24000 (13%)]\tLoss: 0.594790 \t Time:  25.012149\n",
            "Train Epoch: 2 [6400/24000 (27%)]\tLoss: 0.594879 \t Time:  48.997054\n",
            "Train Epoch: 2 [9600/24000 (40%)]\tLoss: 0.593995 \t Time:  72.991545\n",
            "Train Epoch: 2 [12800/24000 (53%)]\tLoss: 0.593996 \t Time:  97.019491\n",
            "Train Epoch: 2 [16000/24000 (67%)]\tLoss: 0.593936 \t Time:  121.054281\n",
            "Train Epoch: 2 [19200/24000 (80%)]\tLoss: 0.595145 \t Time:  145.076401\n",
            "Train Epoch: 2 [22400/24000 (93%)]\tLoss: 0.590733 \t Time:  169.094333\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.99      0.87      4526\n",
            "           1       0.11      0.01      0.02       222\n",
            "           2       0.41      0.30      0.35       890\n",
            "           3       0.00      0.00      0.00       254\n",
            "           4       0.20      0.07      0.10       231\n",
            "           5       0.97      0.24      0.38       253\n",
            "           6       0.97      0.35      0.51       254\n",
            "           7       0.27      0.06      0.10       460\n",
            "           8       0.00      0.00      0.00       233\n",
            "           9       0.58      0.06      0.11       307\n",
            "          10       0.34      0.42      0.37       140\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.00      0.00      0.00       123\n",
            "          13       0.01      0.26      0.02        47\n",
            "          14       0.08      0.14      0.10       399\n",
            "          15       0.00      0.00      0.00       205\n",
            "          16       0.93      0.22      0.36       282\n",
            "          17       0.60      0.04      0.07       329\n",
            "          18       0.25      0.03      0.05       181\n",
            "\n",
            "   micro avg       0.57      0.56      0.56      9336\n",
            "   macro avg       0.34      0.17      0.18      9336\n",
            "weighted avg       0.57      0.56      0.51      9336\n",
            " samples avg       0.64      0.64      0.60      9336\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5983, Accuracy: 1892.0/6000 (31.53%)\n",
            ", F1 score: 0.6013\n",
            "Train Epoch: 3 [0/24000 (0%)]\tLoss: 0.593625 \t Time:  0.997961\n",
            "Train Epoch: 3 [3200/24000 (13%)]\tLoss: 0.592222 \t Time:  24.998261\n",
            "Train Epoch: 3 [6400/24000 (27%)]\tLoss: 0.593589 \t Time:  48.980669\n",
            "Train Epoch: 3 [9600/24000 (40%)]\tLoss: 0.594306 \t Time:  73.011195\n",
            "Train Epoch: 3 [12800/24000 (53%)]\tLoss: 0.591414 \t Time:  97.001242\n",
            "Train Epoch: 3 [16000/24000 (67%)]\tLoss: 0.593872 \t Time:  121.027468\n",
            "Train Epoch: 3 [19200/24000 (80%)]\tLoss: 0.590154 \t Time:  145.045241\n",
            "Train Epoch: 3 [22400/24000 (93%)]\tLoss: 0.593908 \t Time:  169.092378\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.98      0.87      4526\n",
            "           1       0.02      0.00      0.01       222\n",
            "           2       0.38      0.31      0.34       890\n",
            "           3       0.00      0.00      0.00       254\n",
            "           4       0.11      0.37      0.17       231\n",
            "           5       0.95      0.52      0.67       253\n",
            "           6       0.94      0.39      0.55       254\n",
            "           7       0.31      0.27      0.29       460\n",
            "           8       1.00      0.01      0.02       233\n",
            "           9       1.00      0.01      0.01       307\n",
            "          10       0.12      0.51      0.19       140\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.00      0.00      0.00       123\n",
            "          13       0.01      0.32      0.02        47\n",
            "          14       0.05      0.08      0.06       399\n",
            "          15       0.90      0.04      0.08       205\n",
            "          16       0.78      0.27      0.40       282\n",
            "          17       0.89      0.10      0.18       329\n",
            "          18       0.17      0.10      0.12       181\n",
            "\n",
            "   micro avg       0.50      0.58      0.54      9336\n",
            "   macro avg       0.44      0.22      0.21      9336\n",
            "weighted avg       0.62      0.58      0.54      9336\n",
            " samples avg       0.57      0.67      0.57      9336\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.6044, Accuracy: 1402.0/6000 (23.37%)\n",
            ", F1 score: 0.5710\n",
            "Counter 1 of 3\n",
            "Train Epoch: 4 [0/24000 (0%)]\tLoss: 0.591228 \t Time:  0.988981\n",
            "Train Epoch: 4 [3200/24000 (13%)]\tLoss: 0.593040 \t Time:  25.018890\n",
            "Train Epoch: 4 [6400/24000 (27%)]\tLoss: 0.588469 \t Time:  49.031189\n",
            "Train Epoch: 4 [9600/24000 (40%)]\tLoss: 0.593418 \t Time:  73.035419\n",
            "Train Epoch: 4 [12800/24000 (53%)]\tLoss: 0.594979 \t Time:  97.028514\n",
            "Train Epoch: 4 [16000/24000 (67%)]\tLoss: 0.588629 \t Time:  120.952544\n",
            "Train Epoch: 4 [19200/24000 (80%)]\tLoss: 0.589697 \t Time:  144.989763\n",
            "Train Epoch: 4 [22400/24000 (93%)]\tLoss: 0.595235 \t Time:  169.002172\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.99      0.87      4526\n",
            "           1       0.00      0.00      0.00       222\n",
            "           2       0.29      0.47      0.36       890\n",
            "           3       0.00      0.00      0.00       254\n",
            "           4       0.79      0.30      0.44       231\n",
            "           5       0.97      0.38      0.55       253\n",
            "           6       0.95      0.47      0.63       254\n",
            "           7       0.65      0.15      0.24       460\n",
            "           8       1.00      0.01      0.02       233\n",
            "           9       0.67      0.03      0.05       307\n",
            "          10       0.91      0.41      0.57       140\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.00      0.00      0.00       123\n",
            "          13       0.01      0.38      0.03        47\n",
            "          14       0.13      0.19      0.15       399\n",
            "          15       1.00      0.06      0.11       205\n",
            "          16       0.80      0.13      0.23       282\n",
            "          17       0.97      0.12      0.21       329\n",
            "          18       0.68      0.23      0.34       181\n",
            "\n",
            "   micro avg       0.57      0.59      0.58      9336\n",
            "   macro avg       0.56      0.23      0.25      9336\n",
            "weighted avg       0.67      0.59      0.55      9336\n",
            " samples avg       0.63      0.67      0.61      9336\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5922, Accuracy: 1845.0/6000 (30.75%)\n",
            ", F1 score: 0.6119\n",
            "Train Epoch: 5 [0/24000 (0%)]\tLoss: 0.597325 \t Time:  0.992140\n",
            "Train Epoch: 5 [3200/24000 (13%)]\tLoss: 0.590126 \t Time:  25.026048\n",
            "Train Epoch: 5 [6400/24000 (27%)]\tLoss: 0.591986 \t Time:  49.015250\n",
            "Train Epoch: 5 [9600/24000 (40%)]\tLoss: 0.591271 \t Time:  73.012799\n",
            "Train Epoch: 5 [12800/24000 (53%)]\tLoss: 0.586537 \t Time:  97.009150\n",
            "Train Epoch: 5 [16000/24000 (67%)]\tLoss: 0.590875 \t Time:  121.016814\n",
            "Train Epoch: 5 [19200/24000 (80%)]\tLoss: 0.594459 \t Time:  145.043843\n",
            "Train Epoch: 5 [22400/24000 (93%)]\tLoss: 0.584953 \t Time:  169.089456\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.97      0.88      4526\n",
            "           1       0.00      0.00      0.00       222\n",
            "           2       0.35      0.41      0.38       890\n",
            "           3       1.00      0.02      0.03       254\n",
            "           4       0.90      0.45      0.60       231\n",
            "           5       0.92      0.32      0.47       253\n",
            "           6       0.98      0.22      0.35       254\n",
            "           7       0.72      0.17      0.27       460\n",
            "           8       1.00      0.02      0.04       233\n",
            "           9       0.76      0.07      0.13       307\n",
            "          10       0.96      0.37      0.54       140\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.00      0.00      0.00       123\n",
            "          13       0.02      0.45      0.04        47\n",
            "          14       0.22      0.15      0.18       399\n",
            "          15       1.00      0.08      0.15       205\n",
            "          16       0.93      0.18      0.30       282\n",
            "          17       0.96      0.14      0.24       329\n",
            "          18       0.84      0.18      0.29       181\n",
            "\n",
            "   micro avg       0.63      0.58      0.60      9336\n",
            "   macro avg       0.65      0.22      0.26      9336\n",
            "weighted avg       0.73      0.58      0.56      9336\n",
            " samples avg       0.67      0.66      0.63      9336\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5904, Accuracy: 2202.0/6000 (36.70%)\n",
            ", F1 score: 0.6331\n",
            "Train Epoch: 6 [0/24000 (0%)]\tLoss: 0.587718 \t Time:  1.019504\n",
            "Train Epoch: 6 [3200/24000 (13%)]\tLoss: 0.589906 \t Time:  24.957543\n",
            "Train Epoch: 6 [6400/24000 (27%)]\tLoss: 0.591680 \t Time:  48.956913\n",
            "Train Epoch: 6 [9600/24000 (40%)]\tLoss: 0.590414 \t Time:  72.952631\n",
            "Train Epoch: 6 [12800/24000 (53%)]\tLoss: 0.592972 \t Time:  96.978576\n",
            "Train Epoch: 6 [16000/24000 (67%)]\tLoss: 0.592051 \t Time:  121.048576\n",
            "Train Epoch: 6 [19200/24000 (80%)]\tLoss: 0.592540 \t Time:  145.068481\n",
            "Train Epoch: 6 [22400/24000 (93%)]\tLoss: 0.589621 \t Time:  169.127590\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.99      0.87      4526\n",
            "           1       0.07      0.00      0.01       222\n",
            "           2       0.32      0.48      0.39       890\n",
            "           3       1.00      0.01      0.02       254\n",
            "           4       0.52      0.32      0.40       231\n",
            "           5       0.98      0.38      0.55       253\n",
            "           6       0.98      0.37      0.54       254\n",
            "           7       0.65      0.15      0.25       460\n",
            "           8       1.00      0.01      0.02       233\n",
            "           9       0.33      0.02      0.03       307\n",
            "          10       0.62      0.43      0.51       140\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.00      0.00      0.00       123\n",
            "          13       0.02      0.40      0.04        47\n",
            "          14       0.24      0.23      0.23       399\n",
            "          15       0.92      0.12      0.21       205\n",
            "          16       0.93      0.48      0.63       282\n",
            "          17       0.95      0.25      0.39       329\n",
            "          18       0.65      0.49      0.56       181\n",
            "\n",
            "   micro avg       0.62      0.62      0.62      9336\n",
            "   macro avg       0.58      0.27      0.30      9336\n",
            "weighted avg       0.68      0.62      0.58      9336\n",
            " samples avg       0.68      0.70      0.65      9336\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5909, Accuracy: 2230.0/6000 (37.17%)\n",
            ", F1 score: 0.6529\n",
            "Train Epoch: 7 [0/24000 (0%)]\tLoss: 0.591558 \t Time:  1.009685\n",
            "Train Epoch: 7 [3200/24000 (13%)]\tLoss: 0.587838 \t Time:  25.052804\n",
            "Train Epoch: 7 [6400/24000 (27%)]\tLoss: 0.586100 \t Time:  49.003113\n",
            "Train Epoch: 7 [9600/24000 (40%)]\tLoss: 0.588214 \t Time:  73.043336\n",
            "Train Epoch: 7 [12800/24000 (53%)]\tLoss: 0.587858 \t Time:  97.056700\n",
            "Train Epoch: 7 [16000/24000 (67%)]\tLoss: 0.586771 \t Time:  121.013614\n",
            "Train Epoch: 7 [19200/24000 (80%)]\tLoss: 0.587299 \t Time:  145.020793\n",
            "Train Epoch: 7 [22400/24000 (93%)]\tLoss: 0.590714 \t Time:  169.032048\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.98      0.87      4526\n",
            "           1       0.11      0.03      0.05       222\n",
            "           2       0.32      0.38      0.35       890\n",
            "           3       1.00      0.02      0.05       254\n",
            "           4       0.96      0.70      0.81       231\n",
            "           5       0.92      0.23      0.37       253\n",
            "           6       0.94      0.20      0.33       254\n",
            "           7       0.57      0.17      0.27       460\n",
            "           8       1.00      0.07      0.13       233\n",
            "           9       0.45      0.05      0.09       307\n",
            "          10       0.98      0.36      0.53       140\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.00      0.00      0.00       123\n",
            "          13       0.05      0.47      0.08        47\n",
            "          14       0.40      0.27      0.32       399\n",
            "          15       1.00      0.28      0.44       205\n",
            "          16       0.92      0.46      0.62       282\n",
            "          17       0.97      0.31      0.47       329\n",
            "          18       0.93      0.44      0.59       181\n",
            "\n",
            "   micro avg       0.68      0.61      0.64      9336\n",
            "   macro avg       0.65      0.29      0.33      9336\n",
            "weighted avg       0.72      0.61      0.59      9336\n",
            " samples avg       0.74      0.71      0.69      9336\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5885, Accuracy: 2634.0/6000 (43.90%)\n",
            ", F1 score: 0.6879\n",
            "Train Epoch: 8 [0/24000 (0%)]\tLoss: 0.584291 \t Time:  1.013350\n",
            "Train Epoch: 8 [3200/24000 (13%)]\tLoss: 0.588166 \t Time:  25.035080\n",
            "Train Epoch: 8 [6400/24000 (27%)]\tLoss: 0.593562 \t Time:  49.040237\n",
            "Train Epoch: 8 [9600/24000 (40%)]\tLoss: 0.592560 \t Time:  73.016866\n",
            "Train Epoch: 8 [12800/24000 (53%)]\tLoss: 0.589095 \t Time:  97.058467\n",
            "Train Epoch: 8 [16000/24000 (67%)]\tLoss: 0.587134 \t Time:  121.074581\n",
            "Train Epoch: 8 [19200/24000 (80%)]\tLoss: 0.589437 \t Time:  145.098634\n",
            "Train Epoch: 8 [22400/24000 (93%)]\tLoss: 0.590247 \t Time:  169.104044\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.98      0.87      4526\n",
            "           1       0.06      0.02      0.03       222\n",
            "           2       0.32      0.46      0.38       890\n",
            "           3       1.00      0.08      0.15       254\n",
            "           4       0.90      0.48      0.62       231\n",
            "           5       0.93      0.25      0.40       253\n",
            "           6       1.00      0.15      0.25       254\n",
            "           7       0.84      0.13      0.22       460\n",
            "           8       1.00      0.12      0.22       233\n",
            "           9       0.68      0.12      0.20       307\n",
            "          10       0.93      0.31      0.46       140\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.00      0.00      0.00       123\n",
            "          13       0.03      0.47      0.06        47\n",
            "          14       0.61      0.22      0.32       399\n",
            "          15       0.98      0.29      0.45       205\n",
            "          16       0.93      0.47      0.62       282\n",
            "          17       0.94      0.44      0.60       329\n",
            "          18       0.85      0.51      0.64       181\n",
            "\n",
            "   micro avg       0.66      0.62      0.64      9336\n",
            "   macro avg       0.67      0.29      0.34      9336\n",
            "weighted avg       0.74      0.62      0.60      9336\n",
            " samples avg       0.72      0.71      0.68      9336\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5896, Accuracy: 2470.0/6000 (41.17%)\n",
            ", F1 score: 0.6772\n",
            "Counter 1 of 3\n",
            "Train Epoch: 9 [0/24000 (0%)]\tLoss: 0.585375 \t Time:  0.996047\n",
            "Train Epoch: 9 [3200/24000 (13%)]\tLoss: 0.588732 \t Time:  24.988863\n",
            "Train Epoch: 9 [6400/24000 (27%)]\tLoss: 0.589734 \t Time:  48.973171\n",
            "Train Epoch: 9 [9600/24000 (40%)]\tLoss: 0.590314 \t Time:  73.019101\n",
            "Train Epoch: 9 [12800/24000 (53%)]\tLoss: 0.591585 \t Time:  97.014317\n",
            "Train Epoch: 9 [16000/24000 (67%)]\tLoss: 0.589152 \t Time:  121.046760\n",
            "Train Epoch: 9 [19200/24000 (80%)]\tLoss: 0.586208 \t Time:  145.096580\n",
            "Train Epoch: 9 [22400/24000 (93%)]\tLoss: 0.587605 \t Time:  169.113908\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.98      0.87      4526\n",
            "           1       0.11      0.04      0.05       222\n",
            "           2       0.33      0.48      0.39       890\n",
            "           3       1.00      0.08      0.15       254\n",
            "           4       0.96      0.44      0.61       231\n",
            "           5       0.94      0.29      0.45       253\n",
            "           6       0.96      0.11      0.19       254\n",
            "           7       0.85      0.22      0.35       460\n",
            "           8       0.96      0.31      0.47       233\n",
            "           9       0.73      0.12      0.20       307\n",
            "          10       0.98      0.30      0.46       140\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.00      0.00      0.00       123\n",
            "          13       0.03      0.57      0.05        47\n",
            "          14       0.53      0.25      0.34       399\n",
            "          15       1.00      0.33      0.50       205\n",
            "          16       0.98      0.52      0.68       282\n",
            "          17       0.95      0.40      0.56       329\n",
            "          18       0.81      0.49      0.61       181\n",
            "\n",
            "   micro avg       0.64      0.63      0.64      9336\n",
            "   macro avg       0.68      0.31      0.36      9336\n",
            "weighted avg       0.74      0.63      0.62      9336\n",
            " samples avg       0.71      0.72      0.68      9336\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5879, Accuracy: 2563.0/6000 (42.72%)\n",
            ", F1 score: 0.6824\n",
            "Counter 2 of 3\n",
            "Train Epoch: 10 [0/24000 (0%)]\tLoss: 0.585422 \t Time:  1.004686\n",
            "Train Epoch: 10 [3200/24000 (13%)]\tLoss: 0.592293 \t Time:  25.057827\n",
            "Train Epoch: 10 [6400/24000 (27%)]\tLoss: 0.589007 \t Time:  49.096908\n",
            "Train Epoch: 10 [9600/24000 (40%)]\tLoss: 0.587930 \t Time:  73.144081\n",
            "Train Epoch: 10 [12800/24000 (53%)]\tLoss: 0.593337 \t Time:  97.177404\n",
            "Train Epoch: 10 [16000/24000 (67%)]\tLoss: 0.593521 \t Time:  121.190513\n",
            "Train Epoch: 10 [19200/24000 (80%)]\tLoss: 0.589201 \t Time:  145.158551\n",
            "Train Epoch: 10 [22400/24000 (93%)]\tLoss: 0.591557 \t Time:  169.203565\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.97      0.86      4526\n",
            "           1       0.05      0.00      0.01       222\n",
            "           2       0.33      0.41      0.37       890\n",
            "           3       1.00      0.13      0.23       254\n",
            "           4       0.87      0.27      0.41       231\n",
            "           5       1.00      0.23      0.37       253\n",
            "           6       0.89      0.07      0.12       254\n",
            "           7       0.79      0.18      0.30       460\n",
            "           8       1.00      0.06      0.11       233\n",
            "           9       0.49      0.12      0.19       307\n",
            "          10       1.00      0.31      0.48       140\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.00      0.00      0.00       123\n",
            "          13       0.03      0.53      0.06        47\n",
            "          14       0.61      0.22      0.32       399\n",
            "          15       0.95      0.19      0.31       205\n",
            "          16       0.98      0.42      0.59       282\n",
            "          17       0.96      0.45      0.61       329\n",
            "          18       0.89      0.59      0.71       181\n",
            "\n",
            "   micro avg       0.65      0.60      0.63      9336\n",
            "   macro avg       0.66      0.27      0.32      9336\n",
            "weighted avg       0.73      0.60      0.59      9336\n",
            " samples avg       0.71      0.69      0.66      9336\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5885, Accuracy: 2482.0/6000 (41.37%)\n",
            ", F1 score: 0.6634\n",
            "Counter 3 of 3\n",
            "Early stopping with best loss:  0.5885193514823913 and val_acc for this epoch:  0.6633903439153438\n"
          ]
        }
      ],
      "source": [
        "cbow_model = word_emb_dim_tuning(cbow=True, skipgram=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4A3QIazbK4m",
        "outputId": "3540404c-2699-430f-f2f8-515f7037bf14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| ID | GPU | MEM |\n",
            "------------------\n",
            "|  0 |  0% | 60% |\n",
            "| ID | GPU | MEM |\n",
            "------------------\n",
            "|  0 |  5% | 60% |\n",
            "| ID | GPU | MEM |\n",
            "------------------\n",
            "|  0 |  5% | 60% |\n",
            "Model initialized.\n",
            "Train Epoch: 0 [0/24000 (0%)]\tLoss: 0.690644 \t Time:  1.006032\n",
            "Train Epoch: 0 [3200/24000 (13%)]\tLoss: 0.604151 \t Time:  25.023249\n",
            "Train Epoch: 0 [6400/24000 (27%)]\tLoss: 0.594438 \t Time:  49.056904\n",
            "Train Epoch: 0 [9600/24000 (40%)]\tLoss: 0.594814 \t Time:  73.066408\n",
            "Train Epoch: 0 [12800/24000 (53%)]\tLoss: 0.594251 \t Time:  97.084569\n",
            "Train Epoch: 0 [16000/24000 (67%)]\tLoss: 0.589498 \t Time:  121.120754\n",
            "Train Epoch: 0 [19200/24000 (80%)]\tLoss: 0.588189 \t Time:  145.162687\n",
            "Train Epoch: 0 [22400/24000 (93%)]\tLoss: 0.586243 \t Time:  169.168890\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.75      0.82      4526\n",
            "           1       0.07      0.36      0.12       222\n",
            "           2       0.59      0.23      0.34       890\n",
            "           3       0.00      0.00      0.00       254\n",
            "           4       0.98      0.19      0.32       231\n",
            "           5       0.75      0.23      0.36       253\n",
            "           6       0.97      0.55      0.70       254\n",
            "           7       0.06      0.01      0.02       460\n",
            "           8       0.10      0.05      0.07       233\n",
            "           9       0.09      0.23      0.13       307\n",
            "          10       0.00      0.00      0.00       140\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.41      0.32      0.36       123\n",
            "          13       0.00      0.00      0.00        47\n",
            "          14       0.09      0.21      0.13       399\n",
            "          15       0.00      0.00      0.00       205\n",
            "          16       0.62      0.28      0.39       282\n",
            "          17       0.00      0.00      0.00       329\n",
            "          18       0.00      0.00      0.00       181\n",
            "\n",
            "   micro avg       0.56      0.45      0.50      9336\n",
            "   macro avg       0.30      0.18      0.20      9336\n",
            "weighted avg       0.60      0.45      0.50      9336\n",
            " samples avg       0.52      0.54      0.50      9336\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5884, Accuracy: 1733.0/6000 (28.88%)\n",
            ", F1 score: 0.5034\n",
            "Train Epoch: 1 [0/24000 (0%)]\tLoss: 0.588322 \t Time:  1.067379\n",
            "Train Epoch: 1 [3200/24000 (13%)]\tLoss: 0.588025 \t Time:  25.090220\n",
            "Train Epoch: 1 [6400/24000 (27%)]\tLoss: 0.586162 \t Time:  49.072493\n",
            "Train Epoch: 1 [9600/24000 (40%)]\tLoss: 0.589511 \t Time:  73.047922\n",
            "Train Epoch: 1 [12800/24000 (53%)]\tLoss: 0.581966 \t Time:  97.050638\n",
            "Train Epoch: 1 [16000/24000 (67%)]\tLoss: 0.588228 \t Time:  121.065814\n",
            "Train Epoch: 1 [19200/24000 (80%)]\tLoss: 0.581428 \t Time:  145.025593\n",
            "Train Epoch: 1 [22400/24000 (93%)]\tLoss: 0.580998 \t Time:  169.070596\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.80      0.85      4526\n",
            "           1       0.10      0.29      0.15       222\n",
            "           2       0.61      0.22      0.33       890\n",
            "           3       0.75      0.01      0.02       254\n",
            "           4       0.88      0.42      0.57       231\n",
            "           5       1.00      0.18      0.30       253\n",
            "           6       0.89      0.58      0.70       254\n",
            "           7       0.30      0.06      0.10       460\n",
            "           8       0.03      0.04      0.04       233\n",
            "           9       0.09      0.23      0.13       307\n",
            "          10       0.00      0.00      0.00       140\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.43      0.28      0.34       123\n",
            "          13       1.00      0.02      0.04        47\n",
            "          14       0.10      0.27      0.14       399\n",
            "          15       0.00      0.00      0.00       205\n",
            "          16       0.37      0.60      0.45       282\n",
            "          17       0.00      0.00      0.00       329\n",
            "          18       0.00      0.00      0.00       181\n",
            "\n",
            "   micro avg       0.57      0.49      0.53      9336\n",
            "   macro avg       0.39      0.21      0.22      9336\n",
            "weighted avg       0.64      0.49      0.52      9336\n",
            " samples avg       0.57      0.58      0.54      9336\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5833, Accuracy: 1806.0/6000 (30.10%)\n",
            ", F1 score: 0.5447\n",
            "Train Epoch: 2 [0/24000 (0%)]\tLoss: 0.579769 \t Time:  1.001096\n",
            "Train Epoch: 2 [3200/24000 (13%)]\tLoss: 0.583287 \t Time:  25.071687\n",
            "Train Epoch: 2 [6400/24000 (27%)]\tLoss: 0.580111 \t Time:  49.064351\n",
            "Train Epoch: 2 [9600/24000 (40%)]\tLoss: 0.581881 \t Time:  73.041465\n",
            "Train Epoch: 2 [12800/24000 (53%)]\tLoss: 0.584165 \t Time:  96.995501\n",
            "Train Epoch: 2 [16000/24000 (67%)]\tLoss: 0.579088 \t Time:  121.012519\n",
            "Train Epoch: 2 [19200/24000 (80%)]\tLoss: 0.586026 \t Time:  145.039377\n",
            "Train Epoch: 2 [22400/24000 (93%)]\tLoss: 0.580933 \t Time:  169.070903\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.84      0.85      4526\n",
            "           1       0.10      0.15      0.12       222\n",
            "           2       0.60      0.14      0.22       890\n",
            "           3       0.38      0.01      0.02       254\n",
            "           4       0.87      0.45      0.59       231\n",
            "           5       0.97      0.15      0.25       253\n",
            "           6       0.80      0.61      0.70       254\n",
            "           7       0.39      0.05      0.09       460\n",
            "           8       0.07      0.09      0.07       233\n",
            "           9       0.10      0.26      0.14       307\n",
            "          10       0.00      0.00      0.00       140\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.43      0.18      0.25       123\n",
            "          13       0.00      0.00      0.00        47\n",
            "          14       0.10      0.14      0.12       399\n",
            "          15       0.00      0.00      0.00       205\n",
            "          16       0.84      0.16      0.27       282\n",
            "          17       0.00      0.00      0.00       329\n",
            "          18       0.00      0.00      0.00       181\n",
            "\n",
            "   micro avg       0.63      0.48      0.55      9336\n",
            "   macro avg       0.34      0.17      0.19      9336\n",
            "weighted avg       0.61      0.48      0.50      9336\n",
            " samples avg       0.64      0.58      0.58      9336\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5827, Accuracy: 2332.0/6000 (38.87%)\n",
            ", F1 score: 0.5804\n",
            "Train Epoch: 3 [0/24000 (0%)]\tLoss: 0.577666 \t Time:  1.009995\n",
            "Train Epoch: 3 [3200/24000 (13%)]\tLoss: 0.583012 \t Time:  25.044500\n",
            "Train Epoch: 3 [6400/24000 (27%)]\tLoss: 0.582617 \t Time:  49.076332\n",
            "Train Epoch: 3 [9600/24000 (40%)]\tLoss: 0.582261 \t Time:  73.104415\n",
            "Train Epoch: 3 [12800/24000 (53%)]\tLoss: 0.580757 \t Time:  97.134854\n",
            "Train Epoch: 3 [16000/24000 (67%)]\tLoss: 0.581599 \t Time:  121.158024\n",
            "Train Epoch: 3 [19200/24000 (80%)]\tLoss: 0.579552 \t Time:  145.184943\n",
            "Train Epoch: 3 [22400/24000 (93%)]\tLoss: 0.575932 \t Time:  169.242118\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.81      0.84      4526\n",
            "           1       0.09      0.22      0.13       222\n",
            "           2       0.58      0.27      0.37       890\n",
            "           3       0.66      0.09      0.16       254\n",
            "           4       0.88      0.49      0.63       231\n",
            "           5       0.97      0.33      0.49       253\n",
            "           6       0.99      0.52      0.68       254\n",
            "           7       0.41      0.17      0.24       460\n",
            "           8       0.06      0.06      0.06       233\n",
            "           9       0.08      0.11      0.09       307\n",
            "          10       0.00      0.00      0.00       140\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.72      0.31      0.43       123\n",
            "          13       0.00      0.00      0.00        47\n",
            "          14       0.08      0.20      0.12       399\n",
            "          15       0.00      0.00      0.00       205\n",
            "          16       0.49      0.42      0.45       282\n",
            "          17       0.00      0.00      0.00       329\n",
            "          18       0.00      0.00      0.00       181\n",
            "\n",
            "   micro avg       0.62      0.50      0.55      9336\n",
            "   macro avg       0.36      0.21      0.25      9336\n",
            "weighted avg       0.63      0.50      0.54      9336\n",
            " samples avg       0.59      0.59      0.56      9336\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5812, Accuracy: 2002.0/6000 (33.37%)\n",
            ", F1 score: 0.5611\n",
            "Counter 1 of 3\n",
            "Train Epoch: 4 [0/24000 (0%)]\tLoss: 0.581805 \t Time:  1.009450\n",
            "Train Epoch: 4 [3200/24000 (13%)]\tLoss: 0.578390 \t Time:  25.038270\n",
            "Train Epoch: 4 [6400/24000 (27%)]\tLoss: 0.581557 \t Time:  49.031600\n",
            "Train Epoch: 4 [9600/24000 (40%)]\tLoss: 0.580209 \t Time:  73.040529\n",
            "Train Epoch: 4 [12800/24000 (53%)]\tLoss: 0.577904 \t Time:  97.019566\n",
            "Train Epoch: 4 [16000/24000 (67%)]\tLoss: 0.579179 \t Time:  121.041483\n",
            "Train Epoch: 4 [19200/24000 (80%)]\tLoss: 0.580786 \t Time:  145.072977\n",
            "Train Epoch: 4 [22400/24000 (93%)]\tLoss: 0.579910 \t Time:  169.128799\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.79      0.85      4526\n",
            "           1       0.12      0.38      0.18       222\n",
            "           2       0.57      0.39      0.46       890\n",
            "           3       0.60      0.13      0.21       254\n",
            "           4       0.86      0.52      0.65       231\n",
            "           5       0.75      0.57      0.65       253\n",
            "           6       0.71      0.83      0.76       254\n",
            "           7       0.53      0.33      0.40       460\n",
            "           8       0.14      0.09      0.11       233\n",
            "           9       0.07      0.12      0.09       307\n",
            "          10       0.00      0.00      0.00       140\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.61      0.51      0.56       123\n",
            "          13       1.00      0.04      0.08        47\n",
            "          14       0.10      0.12      0.11       399\n",
            "          15       0.00      0.00      0.00       205\n",
            "          16       0.54      0.49      0.51       282\n",
            "          17       0.00      0.00      0.00       329\n",
            "          18       0.00      0.00      0.00       181\n",
            "\n",
            "   micro avg       0.65      0.53      0.58      9336\n",
            "   macro avg       0.40      0.28      0.30      9336\n",
            "weighted avg       0.65      0.53      0.57      9336\n",
            " samples avg       0.62      0.60      0.58      9336\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5794, Accuracy: 2219.0/6000 (36.98%)\n",
            ", F1 score: 0.5845\n",
            "Train Epoch: 5 [0/24000 (0%)]\tLoss: 0.576608 \t Time:  0.978924\n",
            "Train Epoch: 5 [3200/24000 (13%)]\tLoss: 0.582132 \t Time:  25.002795\n",
            "Train Epoch: 5 [6400/24000 (27%)]\tLoss: 0.578916 \t Time:  49.050742\n",
            "Train Epoch: 5 [9600/24000 (40%)]\tLoss: 0.576352 \t Time:  73.046954\n",
            "Train Epoch: 5 [12800/24000 (53%)]\tLoss: 0.582318 \t Time:  97.057174\n",
            "Train Epoch: 5 [16000/24000 (67%)]\tLoss: 0.577772 \t Time:  120.997496\n",
            "Train Epoch: 5 [19200/24000 (80%)]\tLoss: 0.576224 \t Time:  145.044517\n",
            "Train Epoch: 5 [22400/24000 (93%)]\tLoss: 0.575534 \t Time:  169.089090\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.80      0.85      4526\n",
            "           1       0.11      0.24      0.15       222\n",
            "           2       0.61      0.25      0.36       890\n",
            "           3       0.95      0.07      0.13       254\n",
            "           4       0.66      0.58      0.62       231\n",
            "           5       0.93      0.49      0.65       253\n",
            "           6       0.85      0.67      0.75       254\n",
            "           7       0.31      0.19      0.23       460\n",
            "           8       0.11      0.09      0.10       233\n",
            "           9       0.12      0.20      0.15       307\n",
            "          10       0.00      0.00      0.00       140\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.72      0.49      0.58       123\n",
            "          13       0.00      0.00      0.00        47\n",
            "          14       0.12      0.22      0.15       399\n",
            "          15       0.00      0.00      0.00       205\n",
            "          16       0.57      0.56      0.57       282\n",
            "          17       0.00      0.00      0.00       329\n",
            "          18       0.00      0.00      0.00       181\n",
            "\n",
            "   micro avg       0.64      0.52      0.57      9336\n",
            "   macro avg       0.37      0.26      0.28      9336\n",
            "weighted avg       0.64      0.52      0.55      9336\n",
            " samples avg       0.62      0.61      0.58      9336\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5799, Accuracy: 2089.0/6000 (34.82%)\n",
            ", F1 score: 0.5820\n",
            "Counter 1 of 3\n",
            "Train Epoch: 6 [0/24000 (0%)]\tLoss: 0.577293 \t Time:  0.985116\n",
            "Train Epoch: 6 [3200/24000 (13%)]\tLoss: 0.574757 \t Time:  25.064208\n",
            "Train Epoch: 6 [6400/24000 (27%)]\tLoss: 0.576728 \t Time:  49.081702\n",
            "Train Epoch: 6 [9600/24000 (40%)]\tLoss: 0.579399 \t Time:  73.100632\n",
            "Train Epoch: 6 [12800/24000 (53%)]\tLoss: 0.573376 \t Time:  97.117465\n",
            "Train Epoch: 6 [16000/24000 (67%)]\tLoss: 0.579427 \t Time:  121.130346\n",
            "Train Epoch: 6 [19200/24000 (80%)]\tLoss: 0.580410 \t Time:  145.145082\n",
            "Train Epoch: 6 [22400/24000 (93%)]\tLoss: 0.575475 \t Time:  169.157845\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.81      0.85      4526\n",
            "           1       0.11      0.38      0.17       222\n",
            "           2       0.59      0.37      0.45       890\n",
            "           3       0.88      0.20      0.33       254\n",
            "           4       0.70      0.58      0.63       231\n",
            "           5       0.59      0.62      0.61       253\n",
            "           6       0.75      0.81      0.78       254\n",
            "           7       0.46      0.25      0.33       460\n",
            "           8       0.11      0.10      0.11       233\n",
            "           9       0.09      0.17      0.12       307\n",
            "          10       0.00      0.00      0.00       140\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.53      0.54      0.53       123\n",
            "          13       0.00      0.00      0.00        47\n",
            "          14       0.11      0.08      0.09       399\n",
            "          15       0.00      0.00      0.00       205\n",
            "          16       0.55      0.49      0.52       282\n",
            "          17       0.00      0.00      0.00       329\n",
            "          18       0.00      0.00      0.00       181\n",
            "\n",
            "   micro avg       0.64      0.54      0.59      9336\n",
            "   macro avg       0.34      0.28      0.29      9336\n",
            "weighted avg       0.63      0.54      0.57      9336\n",
            " samples avg       0.64      0.62      0.60      9336\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5794, Accuracy: 2229.0/6000 (37.15%)\n",
            ", F1 score: 0.6037\n",
            "Train Epoch: 7 [0/24000 (0%)]\tLoss: 0.578232 \t Time:  1.021380\n",
            "Train Epoch: 7 [3200/24000 (13%)]\tLoss: 0.577914 \t Time:  25.071905\n",
            "Train Epoch: 7 [6400/24000 (27%)]\tLoss: 0.580537 \t Time:  49.106051\n",
            "Train Epoch: 7 [9600/24000 (40%)]\tLoss: 0.577976 \t Time:  73.155403\n",
            "Train Epoch: 7 [12800/24000 (53%)]\tLoss: 0.578010 \t Time:  97.194843\n",
            "Train Epoch: 7 [16000/24000 (67%)]\tLoss: 0.577858 \t Time:  121.256009\n",
            "Train Epoch: 7 [19200/24000 (80%)]\tLoss: 0.576648 \t Time:  145.297090\n",
            "Train Epoch: 7 [22400/24000 (93%)]\tLoss: 0.577882 \t Time:  169.361578\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.84      0.87      4526\n",
            "           1       0.10      0.23      0.14       222\n",
            "           2       0.61      0.26      0.37       890\n",
            "           3       1.00      0.06      0.11       254\n",
            "           4       0.84      0.54      0.66       231\n",
            "           5       0.85      0.52      0.65       253\n",
            "           6       0.95      0.58      0.72       254\n",
            "           7       0.35      0.21      0.26       460\n",
            "           8       0.15      0.10      0.12       233\n",
            "           9       0.13      0.17      0.15       307\n",
            "          10       1.00      0.01      0.01       140\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.68      0.49      0.57       123\n",
            "          13       0.83      0.11      0.19        47\n",
            "          14       0.10      0.08      0.09       399\n",
            "          15       0.00      0.00      0.00       205\n",
            "          16       0.85      0.53      0.65       282\n",
            "          17       0.00      0.00      0.00       329\n",
            "          18       0.00      0.00      0.00       181\n",
            "\n",
            "   micro avg       0.71      0.53      0.60      9336\n",
            "   macro avg       0.49      0.25      0.29      9336\n",
            "weighted avg       0.68      0.53      0.57      9336\n",
            " samples avg       0.67      0.62      0.62      9336\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5785, Accuracy: 2461.0/6000 (41.02%)\n",
            ", F1 score: 0.6179\n",
            "Train Epoch: 8 [0/24000 (0%)]\tLoss: 0.574754 \t Time:  1.015075\n",
            "Train Epoch: 8 [3200/24000 (13%)]\tLoss: 0.578183 \t Time:  25.043859\n",
            "Train Epoch: 8 [6400/24000 (27%)]\tLoss: 0.576873 \t Time:  49.059176\n",
            "Train Epoch: 8 [9600/24000 (40%)]\tLoss: 0.575091 \t Time:  73.070547\n",
            "Train Epoch: 8 [12800/24000 (53%)]\tLoss: 0.571214 \t Time:  97.070675\n",
            "Train Epoch: 8 [16000/24000 (67%)]\tLoss: 0.578519 \t Time:  121.001927\n",
            "Train Epoch: 8 [19200/24000 (80%)]\tLoss: 0.575674 \t Time:  145.043997\n",
            "Train Epoch: 8 [22400/24000 (93%)]\tLoss: 0.576583 \t Time:  169.075275\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.83      0.85      4526\n",
            "           1       0.10      0.31      0.16       222\n",
            "           2       0.54      0.35      0.43       890\n",
            "           3       0.81      0.27      0.40       254\n",
            "           4       0.65      0.57      0.61       231\n",
            "           5       0.81      0.59      0.68       253\n",
            "           6       0.75      0.75      0.75       254\n",
            "           7       0.61      0.30      0.40       460\n",
            "           8       0.14      0.23      0.17       233\n",
            "           9       0.08      0.15      0.11       307\n",
            "          10       0.00      0.00      0.00       140\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.65      0.45      0.53       123\n",
            "          13       0.45      0.11      0.17        47\n",
            "          14       0.19      0.12      0.15       399\n",
            "          15       0.00      0.00      0.00       205\n",
            "          16       0.73      0.47      0.57       282\n",
            "          17       0.00      0.00      0.00       329\n",
            "          18       0.00      0.00      0.00       181\n",
            "\n",
            "   micro avg       0.64      0.55      0.59      9336\n",
            "   macro avg       0.39      0.29      0.31      9336\n",
            "weighted avg       0.63      0.55      0.58      9336\n",
            " samples avg       0.66      0.64      0.62      9336\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5790, Accuracy: 2289.0/6000 (38.15%)\n",
            ", F1 score: 0.6171\n",
            "Counter 1 of 3\n",
            "Train Epoch: 9 [0/24000 (0%)]\tLoss: 0.580100 \t Time:  1.009528\n",
            "Train Epoch: 9 [3200/24000 (13%)]\tLoss: 0.576044 \t Time:  24.994532\n",
            "Train Epoch: 9 [6400/24000 (27%)]\tLoss: 0.578409 \t Time:  48.996513\n",
            "Train Epoch: 9 [9600/24000 (40%)]\tLoss: 0.578578 \t Time:  73.001522\n",
            "Train Epoch: 9 [12800/24000 (53%)]\tLoss: 0.576462 \t Time:  97.030146\n",
            "Train Epoch: 9 [16000/24000 (67%)]\tLoss: 0.579793 \t Time:  121.078424\n",
            "Train Epoch: 9 [19200/24000 (80%)]\tLoss: 0.574730 \t Time:  145.075848\n",
            "Train Epoch: 9 [22400/24000 (93%)]\tLoss: 0.574878 \t Time:  169.107396\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.82      0.86      4526\n",
            "           1       0.11      0.34      0.17       222\n",
            "           2       0.58      0.33      0.42       890\n",
            "           3       0.87      0.27      0.41       254\n",
            "           4       0.57      0.61      0.59       231\n",
            "           5       0.66      0.62      0.64       253\n",
            "           6       0.86      0.73      0.79       254\n",
            "           7       0.58      0.33      0.42       460\n",
            "           8       0.10      0.22      0.13       233\n",
            "           9       0.09      0.16      0.11       307\n",
            "          10       0.00      0.00      0.00       140\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.71      0.50      0.58       123\n",
            "          13       0.44      0.09      0.14        47\n",
            "          14       0.18      0.10      0.12       399\n",
            "          15       0.00      0.00      0.00       205\n",
            "          16       0.68      0.58      0.63       282\n",
            "          17       0.00      0.00      0.00       329\n",
            "          18       0.00      0.00      0.00       181\n",
            "\n",
            "   micro avg       0.64      0.55      0.59      9336\n",
            "   macro avg       0.39      0.30      0.32      9336\n",
            "weighted avg       0.64      0.55      0.58      9336\n",
            " samples avg       0.64      0.64      0.61      9336\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5783, Accuracy: 2224.0/6000 (37.07%)\n",
            ", F1 score: 0.6106\n",
            "Counter 2 of 3\n",
            "Train Epoch: 10 [0/24000 (0%)]\tLoss: 0.576315 \t Time:  1.026884\n",
            "Train Epoch: 10 [3200/24000 (13%)]\tLoss: 0.576851 \t Time:  25.022847\n",
            "Train Epoch: 10 [6400/24000 (27%)]\tLoss: 0.579623 \t Time:  49.033720\n",
            "Train Epoch: 10 [9600/24000 (40%)]\tLoss: 0.570817 \t Time:  73.022771\n",
            "Train Epoch: 10 [12800/24000 (53%)]\tLoss: 0.574713 \t Time:  97.042712\n",
            "Train Epoch: 10 [16000/24000 (67%)]\tLoss: 0.577033 \t Time:  121.093496\n",
            "Train Epoch: 10 [19200/24000 (80%)]\tLoss: 0.575289 \t Time:  145.102421\n",
            "Train Epoch: 10 [22400/24000 (93%)]\tLoss: 0.574747 \t Time:  169.126076\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.89      0.87      4526\n",
            "           1       0.14      0.38      0.20       222\n",
            "           2       0.60      0.29      0.39       890\n",
            "           3       0.60      0.31      0.41       254\n",
            "           4       0.64      0.55      0.59       231\n",
            "           5       0.80      0.55      0.65       253\n",
            "           6       0.89      0.66      0.76       254\n",
            "           7       0.49      0.30      0.38       460\n",
            "           8       0.15      0.19      0.17       233\n",
            "           9       0.15      0.13      0.14       307\n",
            "          10       0.00      0.00      0.00       140\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.61      0.41      0.50       123\n",
            "          13       1.00      0.13      0.23        47\n",
            "          14       0.14      0.20      0.17       399\n",
            "          15       0.00      0.00      0.00       205\n",
            "          16       0.80      0.61      0.69       282\n",
            "          17       0.00      0.00      0.00       329\n",
            "          18       0.00      0.00      0.00       181\n",
            "\n",
            "   micro avg       0.66      0.58      0.62      9336\n",
            "   macro avg       0.41      0.29      0.32      9336\n",
            "weighted avg       0.63      0.58      0.59      9336\n",
            " samples avg       0.69      0.67      0.65      9336\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5774, Accuracy: 2489.0/6000 (41.48%)\n",
            ", F1 score: 0.6479\n",
            "Train Epoch: 11 [0/24000 (0%)]\tLoss: 0.574897 \t Time:  1.061726\n",
            "Train Epoch: 11 [3200/24000 (13%)]\tLoss: 0.579117 \t Time:  25.114003\n",
            "Train Epoch: 11 [6400/24000 (27%)]\tLoss: 0.577021 \t Time:  49.117620\n",
            "Train Epoch: 11 [9600/24000 (40%)]\tLoss: 0.573627 \t Time:  73.147143\n",
            "Train Epoch: 11 [12800/24000 (53%)]\tLoss: 0.576889 \t Time:  97.183249\n",
            "Train Epoch: 11 [16000/24000 (67%)]\tLoss: 0.579472 \t Time:  121.141967\n",
            "Train Epoch: 11 [19200/24000 (80%)]\tLoss: 0.574561 \t Time:  145.166420\n",
            "Train Epoch: 11 [22400/24000 (93%)]\tLoss: 0.573056 \t Time:  169.190374\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.88      0.86      4526\n",
            "           1       0.13      0.30      0.18       222\n",
            "           2       0.56      0.30      0.39       890\n",
            "           3       0.68      0.39      0.50       254\n",
            "           4       0.82      0.47      0.60       231\n",
            "           5       0.75      0.53      0.62       253\n",
            "           6       0.76      0.63      0.69       254\n",
            "           7       0.56      0.34      0.43       460\n",
            "           8       0.19      0.29      0.23       233\n",
            "           9       0.06      0.09      0.07       307\n",
            "          10       0.00      0.00      0.00       140\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.52      0.55      0.53       123\n",
            "          13       1.00      0.06      0.12        47\n",
            "          14       0.17      0.15      0.16       399\n",
            "          15       0.00      0.00      0.00       205\n",
            "          16       0.60      0.54      0.57       282\n",
            "          17       0.00      0.00      0.00       329\n",
            "          18       0.00      0.00      0.00       181\n",
            "\n",
            "   micro avg       0.66      0.57      0.61      9336\n",
            "   macro avg       0.40      0.29      0.31      9336\n",
            "weighted avg       0.62      0.57      0.58      9336\n",
            " samples avg       0.68      0.66      0.64      9336\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5752, Accuracy: 2433.0/6000 (40.55%)\n",
            ", F1 score: 0.6377\n",
            "Counter 1 of 3\n",
            "Train Epoch: 12 [0/24000 (0%)]\tLoss: 0.572304 \t Time:  1.014374\n",
            "Train Epoch: 12 [3200/24000 (13%)]\tLoss: 0.573261 \t Time:  25.063246\n",
            "Train Epoch: 12 [6400/24000 (27%)]\tLoss: 0.572366 \t Time:  49.075306\n",
            "Train Epoch: 12 [9600/24000 (40%)]\tLoss: 0.573826 \t Time:  73.113271\n",
            "Train Epoch: 12 [12800/24000 (53%)]\tLoss: 0.573690 \t Time:  97.122114\n",
            "Train Epoch: 12 [16000/24000 (67%)]\tLoss: 0.576149 \t Time:  121.135553\n",
            "Train Epoch: 12 [19200/24000 (80%)]\tLoss: 0.577134 \t Time:  145.132289\n",
            "Train Epoch: 12 [22400/24000 (93%)]\tLoss: 0.579570 \t Time:  169.167818\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.91      0.87      4526\n",
            "           1       0.14      0.30      0.19       222\n",
            "           2       0.60      0.31      0.41       890\n",
            "           3       0.56      0.41      0.47       254\n",
            "           4       0.65      0.54      0.59       231\n",
            "           5       0.59      0.56      0.58       253\n",
            "           6       0.90      0.49      0.64       254\n",
            "           7       0.52      0.37      0.43       460\n",
            "           8       0.14      0.21      0.17       233\n",
            "           9       0.06      0.06      0.06       307\n",
            "          10       1.00      0.01      0.01       140\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.70      0.44      0.54       123\n",
            "          13       0.83      0.11      0.19        47\n",
            "          14       0.20      0.06      0.09       399\n",
            "          15       1.00      0.00      0.01       205\n",
            "          16       0.60      0.23      0.34       282\n",
            "          17       0.00      0.00      0.00       329\n",
            "          18       0.00      0.00      0.00       181\n",
            "\n",
            "   micro avg       0.67      0.57      0.62      9336\n",
            "   macro avg       0.49      0.26      0.29      9336\n",
            "weighted avg       0.64      0.57      0.57      9336\n",
            " samples avg       0.70      0.66      0.65      9336\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5751, Accuracy: 2533.0/6000 (42.22%)\n",
            ", F1 score: 0.6471\n",
            "Counter 2 of 3\n",
            "Train Epoch: 13 [0/24000 (0%)]\tLoss: 0.575128 \t Time:  1.005486\n",
            "Train Epoch: 13 [3200/24000 (13%)]\tLoss: 0.572062 \t Time:  24.972270\n",
            "Train Epoch: 13 [6400/24000 (27%)]\tLoss: 0.572522 \t Time:  48.976314\n",
            "Train Epoch: 13 [9600/24000 (40%)]\tLoss: 0.577824 \t Time:  73.005520\n",
            "Train Epoch: 13 [12800/24000 (53%)]\tLoss: 0.579219 \t Time:  97.047796\n",
            "Train Epoch: 13 [16000/24000 (67%)]\tLoss: 0.573966 \t Time:  121.088511\n",
            "Train Epoch: 13 [19200/24000 (80%)]\tLoss: 0.576174 \t Time:  145.181929\n",
            "Train Epoch: 13 [22400/24000 (93%)]\tLoss: 0.572537 \t Time:  169.185809\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.86      4526\n",
            "           1       0.11      0.31      0.16       222\n",
            "           2       0.59      0.35      0.44       890\n",
            "           3       0.74      0.47      0.57       254\n",
            "           4       0.72      0.58      0.64       231\n",
            "           5       0.64      0.60      0.62       253\n",
            "           6       0.84      0.78      0.81       254\n",
            "           7       0.63      0.34      0.45       460\n",
            "           8       0.19      0.24      0.21       233\n",
            "           9       0.11      0.20      0.14       307\n",
            "          10       0.00      0.00      0.00       140\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.67      0.50      0.57       123\n",
            "          13       1.00      0.15      0.26        47\n",
            "          14       0.28      0.07      0.11       399\n",
            "          15       1.00      0.02      0.05       205\n",
            "          16       0.73      0.44      0.55       282\n",
            "          17       0.00      0.00      0.00       329\n",
            "          18       0.00      0.00      0.00       181\n",
            "\n",
            "   micro avg       0.67      0.58      0.62      9336\n",
            "   macro avg       0.48      0.31      0.34      9336\n",
            "weighted avg       0.66      0.58      0.60      9336\n",
            " samples avg       0.69      0.66      0.65      9336\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.5747, Accuracy: 2427.0/6000 (40.45%)\n",
            ", F1 score: 0.6463\n",
            "Counter 3 of 3\n",
            "Early stopping with best loss:  0.574228483359019 and val_acc for this epoch:  0.6463167508417509\n"
          ]
        }
      ],
      "source": [
        "skipgram_model = word_emb_dim_tuning(cbow=False, skipgram=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLJPkVeRQSPv"
      },
      "outputs": [],
      "source": [
        "def fasttext_cbow_model():\n",
        "  # from torch.optim.lr_scheduler import StepLR\n",
        "  n_epochs = 15\n",
        "  log_interval = 50\n",
        "  lr = 3e-4\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr= lr)\n",
        "\n",
        "  criterion = nn.BCELoss()\n",
        "  train_loss = []\n",
        "  best_f1_score = -float(\"inf\") # record the best loss to get the best model\n",
        "\n",
        "  for epoch in range(n_epochs):\n",
        "      loss = train_epoch(log_interval, model, train_loader, optimizer, epoch, criterion)\n",
        "      train_loss.append(loss)\n",
        "      f1score = validation(model, device, val_loader, criterion, 0.5)\n",
        "\n",
        "      # https://www.kaggle.com/general/178486\n",
        "      if f1score > best_f1_score:\n",
        "          best_f1_score = f1score\n",
        "          es = 0\n",
        "          torch.save(model, \"default_model.pt\")\n",
        "      else:\n",
        "          es += 1\n",
        "          print(\"Counter {} of 3\".format(es))\n",
        "\n",
        "          if es >= 3:\n",
        "              print(\"Early stopping with best loss: \", loss, \"and val_acc for this epoch: \", f1score)\n",
        "              break\n",
        "\n",
        "  return best_f1_score"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "DRSIMxj-GUkh",
        "PFW4txWqUCGJ",
        "ETEMdaLNXJHa"
      ],
      "name": "Copy of ass2.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8ffe055efe14a307031c28e43e34bafe9cc519c0026ddc37ac9e817c8eac76d1"
    },
    "kernelspec": {
      "display_name": "Python 3.8.5 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "130c68e2fee049168983783b681b1ee9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "458208829c0f4b56b9ba526c09ffe66b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4d4bd7967ad3447fa4ea98aa6d73adc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_130c68e2fee049168983783b681b1ee9",
            "max": 100441675,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_458208829c0f4b56b9ba526c09ffe66b",
            "value": 100441675
          }
        },
        "56ca59c8bf62419e840417b4df31d123": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ebb6da5634a4b1fbc0377591ec1d550": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86b84161439848279403d6d1d470fa80": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ae34a953aed4c92ae5e8a07c77b2541": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8df3763ef0ae4c53be78c9be76bcfceb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86b84161439848279403d6d1d470fa80",
            "placeholder": "​",
            "style": "IPY_MODEL_af69a79a0e084d2db28e40858d7ef96e",
            "value": "100%"
          }
        },
        "af69a79a0e084d2db28e40858d7ef96e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e600667c592d4b8fa9346ed7bd2df604": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8df3763ef0ae4c53be78c9be76bcfceb",
              "IPY_MODEL_4d4bd7967ad3447fa4ea98aa6d73adc9",
              "IPY_MODEL_ff68dbfccef84777b9c3fa5da6809c2b"
            ],
            "layout": "IPY_MODEL_6ebb6da5634a4b1fbc0377591ec1d550"
          }
        },
        "ff68dbfccef84777b9c3fa5da6809c2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56ca59c8bf62419e840417b4df31d123",
            "placeholder": "​",
            "style": "IPY_MODEL_8ae34a953aed4c92ae5e8a07c77b2541",
            "value": " 95.8M/95.8M [00:02&lt;00:00, 62.5MB/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
